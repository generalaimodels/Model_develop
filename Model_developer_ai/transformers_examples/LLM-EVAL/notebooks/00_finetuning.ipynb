{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c0fcf471f6ad416b9a3d14411922c13a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7bbd6e1e99144121bfa18dd29c371664",
              "IPY_MODEL_5c43bb45b14b4dd79b408a1118d60346",
              "IPY_MODEL_394017b0673244b2b5dd80021c251304"
            ],
            "layout": "IPY_MODEL_7267d780b585467394a54d691cc92fc6"
          }
        },
        "7bbd6e1e99144121bfa18dd29c371664": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d209a99dfc24f8cafb095121ceb488d",
            "placeholder": "​",
            "style": "IPY_MODEL_716ad8fbdfcf481392cc010053ea77bc",
            "value": "100%"
          }
        },
        "5c43bb45b14b4dd79b408a1118d60346": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8aef4ca2dd7e4959a45573c3a5e7bbbe",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_65dab9bc647541a18c60442836414291",
            "value": 2
          }
        },
        "394017b0673244b2b5dd80021c251304": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_320eb480590a4b2fa849cad98872cb38",
            "placeholder": "​",
            "style": "IPY_MODEL_31f7f264b2b043aaa4461fddd8b4909b",
            "value": " 2/2 [00:00&lt;00:00, 75.09it/s]"
          }
        },
        "7267d780b585467394a54d691cc92fc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d209a99dfc24f8cafb095121ceb488d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "716ad8fbdfcf481392cc010053ea77bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8aef4ca2dd7e4959a45573c3a5e7bbbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65dab9bc647541a18c60442836414291": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "320eb480590a4b2fa849cad98872cb38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31f7f264b2b043aaa4461fddd8b4909b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aaf319eda7554fa28a6c681918036e11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dd13939824b647689cd8230e8fcdf295",
              "IPY_MODEL_1c50469af82347e6be56338be468e720",
              "IPY_MODEL_7f3bd28fdfa043e6849eae0f5bf14ac1"
            ],
            "layout": "IPY_MODEL_bc8d8f73bb3243eab28060a83f6e489e"
          }
        },
        "dd13939824b647689cd8230e8fcdf295": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2917b08495b4305ae9aac857ee9c6a5",
            "placeholder": "​",
            "style": "IPY_MODEL_9e230062d85848d9aa59da8fb4cca53f",
            "value": "100%"
          }
        },
        "1c50469af82347e6be56338be468e720": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03bdb2643746433d9ac09c285c9f6803",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f3100b8213ae46698697d30f25e93a38",
            "value": 2
          }
        },
        "7f3bd28fdfa043e6849eae0f5bf14ac1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdf476b5cda146bdb0b1f01f0091fc8e",
            "placeholder": "​",
            "style": "IPY_MODEL_7393ab4a0b9f4a7981e1e4a269458baa",
            "value": " 2/2 [00:00&lt;00:00, 28.78it/s]"
          }
        },
        "bc8d8f73bb3243eab28060a83f6e489e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2917b08495b4305ae9aac857ee9c6a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e230062d85848d9aa59da8fb4cca53f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03bdb2643746433d9ac09c285c9f6803": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3100b8213ae46698697d30f25e93a38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cdf476b5cda146bdb0b1f01f0091fc8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7393ab4a0b9f4a7981e1e4a269458baa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d7e2bb3e84741e0a3f5ef475e153280": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c4de14bae91d40ed83616f0cc78c00e6",
              "IPY_MODEL_55ae03d3ac3442a38bd3556ab4800fdd",
              "IPY_MODEL_3154873881134fcabe4867beccef0512"
            ],
            "layout": "IPY_MODEL_4210afdc9db94b3b94593cba903456e1"
          }
        },
        "c4de14bae91d40ed83616f0cc78c00e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d056429d1c049848f72b90cfcbc30b8",
            "placeholder": "​",
            "style": "IPY_MODEL_0dde15f47fba44c89b16f0516075bceb",
            "value": "100%"
          }
        },
        "55ae03d3ac3442a38bd3556ab4800fdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_950e2913ac5b4b4098331cb1560028c3",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cb6da5c01642448ebc6db9e32f77630e",
            "value": 2
          }
        },
        "3154873881134fcabe4867beccef0512": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_092f960247514d23a767e70685dfb70c",
            "placeholder": "​",
            "style": "IPY_MODEL_1233ba0f5ba5456fbd9d8d55037dec70",
            "value": " 2/2 [00:00&lt;00:00, 27.69it/s]"
          }
        },
        "4210afdc9db94b3b94593cba903456e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d056429d1c049848f72b90cfcbc30b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0dde15f47fba44c89b16f0516075bceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "950e2913ac5b4b4098331cb1560028c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb6da5c01642448ebc6db9e32f77630e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "092f960247514d23a767e70685dfb70c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1233ba0f5ba5456fbd9d8d55037dec70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75a67ae1f71c47a18d3fab6f29676854": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6f8eff6173224d57bd4cd4aed90ae8df",
              "IPY_MODEL_a6e6d5340ac34d04b6c8b21f19ecbdc6",
              "IPY_MODEL_7f45b8c42d3d47d6aa432f1763328d1e"
            ],
            "layout": "IPY_MODEL_7e56a3ca4daf47d68d10a43fd9e1bbb9"
          }
        },
        "6f8eff6173224d57bd4cd4aed90ae8df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4985876c2f4141d39cc458fa65a96423",
            "placeholder": "​",
            "style": "IPY_MODEL_d3b9aa602852442a8bee449e466b21eb",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "a6e6d5340ac34d04b6c8b21f19ecbdc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60e96417f95f44f798a2fb16722b427b",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_40b9e36614074cea9bc29529bf8d3e89",
            "value": 2
          }
        },
        "7f45b8c42d3d47d6aa432f1763328d1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95fbf359dcdf48baac7cc9d14ac8d40f",
            "placeholder": "​",
            "style": "IPY_MODEL_d9399e14419446ec88cce15ec5f07255",
            "value": " 2/2 [01:02&lt;00:00, 28.55s/it]"
          }
        },
        "7e56a3ca4daf47d68d10a43fd9e1bbb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4985876c2f4141d39cc458fa65a96423": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3b9aa602852442a8bee449e466b21eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60e96417f95f44f798a2fb16722b427b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40b9e36614074cea9bc29529bf8d3e89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "95fbf359dcdf48baac7cc9d14ac8d40f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9399e14419446ec88cce15ec5f07255": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LoRA Finetuning\n",
        "\n",
        "Low-Rank Adaptation (LoRA) is an innovative technique designed to fine-tune large language models (LLMs) efficiently. Let's dive into what makes LoRA a game-changer in the realm of machine learning and natural language processing:\n",
        "\n",
        "## What is LoRA?\n",
        "\n",
        "- **Concept**: LoRA introduces a low-rank decomposition to the weight matrices within transformer models.\n",
        "- **Efficiency**: By only training a small number of additional parameters, LoRA dramatically reduces the computational cost.\n",
        "\n",
        "## Benefits of LoRA\n",
        "\n",
        "- **Speed**: Fine-tuning with LoRA is significantly faster due to fewer parameters being updated.\n",
        "- **Customization**: It allows data scientists to tailor large models to their specific tasks without extensive retraining.\n",
        "\n",
        "## Some Use Cases\n",
        "\n",
        "- **Personalized AI**: Customize AI models to understand specific jargons or concepts in niche fields.\n",
        "- **Optimized Performance**: Improve performance on tasks like sentiment analysis or document summarization with domain-specific fine-tuning.\n",
        "- **Efficient Deployment**: Able to deploy one large base LLM and several small LoRA adapters, instead of having to deploy several large models.\n",
        "\n",
        "In the following sections, we will explore how to implement LoRA in practice and see its benefits firsthand.\n"
      ],
      "metadata": {
        "id": "hVFG07SMfUN8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation\n",
        "\n",
        "\n",
        "*   Make sure we're on a GPU instance\n",
        "*   Install required packages for finetuning; see [LLM Finetuning Hub](https://github.com/georgian-io/LLM-Finetuning-Hub)\n",
        "*   Install PEFT from source for new features\n",
        "*   Restart instance as required\n",
        "\n"
      ],
      "metadata": {
        "id": "_DVRLWa_H15m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install requirements.py\n",
        "!git clone https://github.com/georgian-io/LLM-Finetuning-Hub.git\n",
        "!pip install -r ./LLM-Finetuning-Hub/requirements.txt"
      ],
      "metadata": {
        "id": "YVIFXEYwH2nN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flash-attn --no-build-isolation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5_xmoQ81bhM",
        "outputId": "e053579a-c841-4a19-a55f-8958fdd8f0f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flash-attn\n",
            "  Downloading flash_attn-2.3.3.tar.gz (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from flash-attn) (2.1.0+cu118)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from flash-attn) (0.6.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from flash-attn) (23.1)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from flash-attn) (1.11.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->flash-attn) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->flash-attn) (1.3.0)\n",
            "Building wheels for collected packages: flash-attn\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash-attn: filename=flash_attn-2.3.3-cp310-cp310-linux_x86_64.whl size=57075008 sha256=bcb63b64213ab61590b340b77de84e448a442e19c100480895194df39ad7673d\n",
            "  Stored in directory: /root/.cache/pip/wheels/e5/e6/fa/941802ec61d1afd320d27160ab1db98e6dba65381f84b76d4a\n",
            "Successfully built flash-attn\n",
            "Installing collected packages: flash-attn\n",
            "Successfully installed flash-attn-2.3.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp ./LLM-Finetuning-Hub/llama2/llama_patch.py ./llama_patch.py"
      ],
      "metadata": {
        "id": "sRrn3Wjp1RdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install peft from source\n",
        "!git clone https://github.com/huggingface/peft\n",
        "!pip install peft"
      ],
      "metadata": {
        "id": "KxmWOxiLJF0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Restart Runtime!**"
      ],
      "metadata": {
        "id": "712mrc5004ch"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "yTdYfgohI3Hi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# peft module helps us generate & inject LoRA modules into base model\n",
        "from peft import (\n",
        "    LoraConfig,\n",
        "    prepare_model_for_kbit_training,\n",
        "    get_peft_model,\n",
        ")\n",
        "\n",
        "# transformers module helps us load a base model\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    BitsAndBytesConfig, # helper to quantize the model so we can run on a single GPU\n",
        "    TrainingArguments,\n",
        ")\n",
        "\n",
        "# trl modules help us train LoRA weights\n",
        "from trl import SFTTrainer\n",
        "\n",
        "\n",
        "# huggingface datasets module\n",
        "import datasets\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "jnOdG7EsI_ol",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3c9d798-533c-4d6e-cf70-d64c096ec088"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please run\n",
            "\n",
            "python -m bitsandbytes\n",
            "\n",
            " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "================================================================================\n",
            "bin /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda118.so\n",
            "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
            "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
            "CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n",
            "CUDA SETUP: Detected CUDA version 118\n",
            "CUDA SETUP: Loading binary /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /usr/lib64-nvidia did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/sys/fs/cgroup/memory.events /var/colab/cgroup/jupyter-children/memory.events')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//172.28.0.1'), PosixPath('http'), PosixPath('8013')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('--logtostderr --listen_host=172.28.0.12 --target_host=172.28.0.12 --tunnel_background_save_url=https'), PosixPath('//colab.research.google.com/tun/m/cc48301118ce562b961b3c22d803539adc1e0c19/gpu-t4-s-1luhgnzgvsnbu --tunnel_background_save_delay=10s --tunnel_periodic_background_save_frequency=30m0s --enable_output_coalescing=true --output_coalescing_required=true')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/datalab/web/pyright/typeshed-fallback/stdlib,/usr/local/lib/python3.10/dist-packages')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/env/python')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//ipykernel.pylab.backend_inline'), PosixPath('module')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so'), PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
            "Either way, this might cause trouble in the future:\n",
            "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
            "  warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's also filter out warnings so outputs are little bit easier to read\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "0-8yMBmok0fY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting NewsGroup Classification Dataset\n",
        "The 20 Newsgroups dataset is a classic text classification dataset used in Natural Language Processing. It contains around 20,000 newsgroup posts on 20 topics, serving as an excellent basis for classification tasks. The following functions are designed to streamline the process of loading and preparing this dataset for fine-tuning with LoRA:\n",
        "\n",
        "- `get_newsgroup_instruction_data`: Constructs formatted prompts for training or inference from texts and labels, useful for guiding the model during fine-tuning.\n",
        "- `clean_newsgroup_data`: Cleans the dataset by ensuring that both texts and labels are strings, thus preparing the data for further processing.\n",
        "- `get_newsgroup_data_for_ft`: Loads the dataset, splits it into training and testing sets, and prepares it for fine-tuning by applying the aforementioned functions.\n",
        "- `get_newsgroup_classes`: Retrieves and lists all unique classes from the dataset, which can be helpful for understanding the classification landscape.\n",
        "\n",
        "By utilizing these functions, we can effectively prepare the Newsgroups dataset for various classification models, ensuring our fine-tuning process is robust and well-guided.\n"
      ],
      "metadata": {
        "id": "GWKHui7GTHT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAINING_CLASSIFIER_PROMPT_v2 = \"\"\"### Sentence:{sentence} ### Class:{label}\"\"\"\n",
        "INFERENCE_CLASSIFIER_PROMPT_v2 = \"\"\"### Sentence:{sentence} ### Class:\"\"\"\n",
        "\n",
        "def get_newsgroup_instruction_data(mode, texts, labels):\n",
        "    # this function injects the prompt above to the dataset\n",
        "    if mode == \"train\":\n",
        "        prompt = TRAINING_CLASSIFIER_PROMPT_v2\n",
        "    elif mode == \"inference\":\n",
        "        prompt = INFERENCE_CLASSIFIER_PROMPT_v2\n",
        "\n",
        "    instructions = []\n",
        "\n",
        "    for text, label in zip(texts, labels):\n",
        "        if mode == \"train\":\n",
        "            example = prompt.format(\n",
        "                sentence=text,\n",
        "                label=label,\n",
        "            )\n",
        "        elif mode == \"inference\":\n",
        "            example = prompt.format(\n",
        "                sentence=text,\n",
        "            )\n",
        "        instructions.append(example)\n",
        "\n",
        "    return instructions\n",
        "\n",
        "\n",
        "def clean_newsgroup_data(texts, labels):\n",
        "    label2data = {}\n",
        "    clean_data, clean_labels = [], []\n",
        "    for data, label in zip(texts, labels):\n",
        "        if isinstance(data, str) and isinstance(label, str):\n",
        "            clean_data.append(data)\n",
        "            clean_labels.append(label)\n",
        "\n",
        "            if label not in label2data:\n",
        "                label2data[label] = data\n",
        "\n",
        "    return label2data, clean_data, clean_labels\n",
        "\n",
        "\n",
        "def get_newsgroup_data_for_ft(mode=\"train\", train_sample_fraction=0.99):\n",
        "    newsgroup_dataset = load_dataset(\"rungalileo/20_Newsgroups_Fixed\")\n",
        "    train_data = newsgroup_dataset[\"train\"][\"text\"]\n",
        "    train_labels = newsgroup_dataset[\"train\"][\"label\"]\n",
        "    label2data, train_data, train_labels = clean_newsgroup_data(\n",
        "        train_data, train_labels\n",
        "    )\n",
        "\n",
        "    test_data = newsgroup_dataset[\"test\"][\"text\"]\n",
        "    test_labels = newsgroup_dataset[\"test\"][\"label\"]\n",
        "    _, test_data, test_labels = clean_newsgroup_data(test_data, test_labels)\n",
        "\n",
        "    # sample n points from training data\n",
        "    train_df = pd.DataFrame(data={\"text\": train_data, \"label\": train_labels})\n",
        "    train_df, _ = train_test_split(\n",
        "        train_df,\n",
        "        train_size=train_sample_fraction,\n",
        "        stratify=train_df[\"label\"],\n",
        "        random_state=42,\n",
        "    )\n",
        "    train_data = train_df[\"text\"]\n",
        "    train_labels = train_df[\"label\"]\n",
        "\n",
        "    train_instructions = get_newsgroup_instruction_data(mode, train_data, train_labels)\n",
        "    test_instructions = get_newsgroup_instruction_data(mode, test_data, test_labels)\n",
        "\n",
        "    train_dataset = datasets.Dataset.from_pandas(\n",
        "        pd.DataFrame(\n",
        "            data={\n",
        "                \"instructions\": train_instructions,\n",
        "                \"labels\": train_labels,\n",
        "            }\n",
        "        )\n",
        "    )\n",
        "    test_dataset = datasets.Dataset.from_pandas(\n",
        "        pd.DataFrame(\n",
        "            data={\n",
        "                \"instructions\": test_instructions,\n",
        "                \"labels\": test_labels,\n",
        "            }\n",
        "        )\n",
        "    )\n",
        "\n",
        "    return train_dataset, test_dataset\n",
        "\n",
        "\n",
        "def get_newsgroup_classes():\n",
        "    newsgroup_dataset = load_dataset(\"rungalileo/20_Newsgroups_Fixed\")\n",
        "    train_data = newsgroup_dataset[\"train\"][\"text\"]\n",
        "    train_labels = newsgroup_dataset[\"train\"][\"label\"]\n",
        "\n",
        "    label2data, clean_data, clean_labels = clean_newsgroup_data(\n",
        "        train_data, train_labels\n",
        "    )\n",
        "    df = pd.DataFrame(data={\"text\": clean_data, \"label\": clean_labels})\n",
        "\n",
        "    newsgroup_classes = df[\"label\"].unique()\n",
        "    newsgroup_classes = \", \".join(newsgroup_classes)\n",
        "\n",
        "    return newsgroup_classes"
      ],
      "metadata": {
        "id": "DMupr4_WJA0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's load in the dataset!"
      ],
      "metadata": {
        "id": "cuKzfOMkiMp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_fraction = 0.025 # editable\n",
        "\n",
        "train_dataset, _ = get_newsgroup_data_for_ft(mode=\"train\", train_sample_fraction=sample_fraction)\n",
        "_, test_dataset = get_newsgroup_data_for_ft(mode=\"inference\")\n",
        "newsgroup_classes = get_newsgroup_classes()\n",
        "\n",
        "print(f\"Sample fraction:{sample_fraction}\")\n",
        "print(f\"Training samples:{train_dataset.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222,
          "referenced_widgets": [
            "c0fcf471f6ad416b9a3d14411922c13a",
            "7bbd6e1e99144121bfa18dd29c371664",
            "5c43bb45b14b4dd79b408a1118d60346",
            "394017b0673244b2b5dd80021c251304",
            "7267d780b585467394a54d691cc92fc6",
            "7d209a99dfc24f8cafb095121ceb488d",
            "716ad8fbdfcf481392cc010053ea77bc",
            "8aef4ca2dd7e4959a45573c3a5e7bbbe",
            "65dab9bc647541a18c60442836414291",
            "320eb480590a4b2fa849cad98872cb38",
            "31f7f264b2b043aaa4461fddd8b4909b",
            "aaf319eda7554fa28a6c681918036e11",
            "dd13939824b647689cd8230e8fcdf295",
            "1c50469af82347e6be56338be468e720",
            "7f3bd28fdfa043e6849eae0f5bf14ac1",
            "bc8d8f73bb3243eab28060a83f6e489e",
            "e2917b08495b4305ae9aac857ee9c6a5",
            "9e230062d85848d9aa59da8fb4cca53f",
            "03bdb2643746433d9ac09c285c9f6803",
            "f3100b8213ae46698697d30f25e93a38",
            "cdf476b5cda146bdb0b1f01f0091fc8e",
            "7393ab4a0b9f4a7981e1e4a269458baa",
            "7d7e2bb3e84741e0a3f5ef475e153280",
            "c4de14bae91d40ed83616f0cc78c00e6",
            "55ae03d3ac3442a38bd3556ab4800fdd",
            "3154873881134fcabe4867beccef0512",
            "4210afdc9db94b3b94593cba903456e1",
            "1d056429d1c049848f72b90cfcbc30b8",
            "0dde15f47fba44c89b16f0516075bceb",
            "950e2913ac5b4b4098331cb1560028c3",
            "cb6da5c01642448ebc6db9e32f77630e",
            "092f960247514d23a767e70685dfb70c",
            "1233ba0f5ba5456fbd9d8d55037dec70"
          ]
        },
        "id": "5yf5KU3cUwNE",
        "outputId": "de085ee8-8d97-4bc4-e1b0-201fdafa111c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset csv (/root/.cache/huggingface/datasets/rungalileo___csv/rungalileo--20_Newsgroups_Fixed-edf414ecc72dd622/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c0fcf471f6ad416b9a3d14411922c13a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset csv (/root/.cache/huggingface/datasets/rungalileo___csv/rungalileo--20_Newsgroups_Fixed-edf414ecc72dd622/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aaf319eda7554fa28a6c681918036e11"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset csv (/root/.cache/huggingface/datasets/rungalileo___csv/rungalileo--20_Newsgroups_Fixed-edf414ecc72dd622/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7d7e2bb3e84741e0a3f5ef475e153280"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample fraction:0.025\n",
            "Training samples:(266, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's take a look at a training example\n",
        "train_dataset['instructions'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "QHtC1qCKVfQd",
        "outputId": "8c132a64-1993-4df2-b99c-9adccc88c62e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"### Sentence:\\n\\nThere's a package called Workspace on cica that has 5 desktops; I\\nhaven't done much with it yet, but it seems to be able to do what you\\nwant it to.\\n\\nDon't have the exact archive name handy, but it's something like\\nwspace<blah>.zip.\\n\\nTom\\n\\n-- \\n finn@convex.com           \\t\\t\\t      I speak only for myself. ### Class:comp.os.ms-windows.misc\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# how about a test example?\n",
        "test_dataset['instructions'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "bVztIeyLUiwd",
        "outputId": "c016d847-0c7b-44b7-fb2a-fdcc6fc4e501"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'### Sentence:I am a little confused on all of the models of the 88-89 bonnevilles.\\nI have heard of the LE SE LSE SSE SSEI. Could someone tell me the\\ndifferences are far as features or performance. I am also curious to\\nknow what the book value is for prefereably the 89 model. And how much\\nless than book value can you usually get them for. In other words how\\nmuch are they in demand this time of year. I have heard that the mid-spring\\nearly summer is the best time to buy. ### Class:'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Model"
      ],
      "metadata": {
        "id": "nWAaaytUWPpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quantization Config\n",
        "\n",
        "-  We are using 4-bit quantization for LoRA training (QLoRA [link text](https://arxiv.org/abs/2305.14314))\n",
        "-  From huggingface [blog](https://huggingface.co/blog/4bit-transformers-bitsandbytes): **QLoRA reduces the memory usage of LLM finetuning without performance tradeoffs compared to standard 16-bit model finetuning. This method enables 33B model finetuning on a single 24GB GPU and 65B model finetuning on a single 46GB GPU.**\n"
      ],
      "metadata": {
        "id": "YJn8yB7cWRVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BitsAndBytesConfig int-4 config\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        ")"
      ],
      "metadata": {
        "id": "26QhLq0vWQsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Model and Tokenizer\n",
        "\n",
        "To begin fine-tuning the model with LoRA, we first need to load a pre-trained model and its corresponding tokenizer. This code snippet accomplishes the following:\n",
        "\n",
        "- **Model Loading**: We use `AutoModelForCausalLM` to load a pre-trained causal language model from Hugging Face's model hub, which is suitable for tasks such as text generation. Here, we're using \"NousResearch/Llama-2-7b-hf\", a model checkpoint that's been pre-trained with specific capabilities.\n",
        "  \n",
        "- **Quantization**: We apply a `bnb_config ` to `quantization_config` parameter in order to optimize model's size and performance. This is particularly useful when working with large models or when there's a need to deploy models to environments with limited resources.\n",
        "  \n",
        "- **Tokenizer**: We use `AutoTokenizer` to load the tokenizer that corresponds to our pre-trained model.\n",
        "\n",
        "This setup is critical to ensure that the model and tokenizer are correctly configured before starting the fine-tuning process with LoRA.\n"
      ],
      "metadata": {
        "id": "dfFiISd6ih3w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model and tokenizer\n",
        "pretrained_ckpt = \"NousResearch/Llama-2-7b-hf\"\n",
        "\n",
        "# You can try any of the following 7B models (or any parameter count, if you have access to better GPUs):\n",
        "# [mistral, flan, falcon, rp, zephyr]\n",
        "\n",
        "# [\"tiiuae/falcon-7b\", \"\"]\n",
        "\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    pretrained_ckpt,\n",
        "    quantization_config=bnb_config,\n",
        "    use_cache=False,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "model.config.pretraining_tp = 1 #value different than 1 will activate the more accurate but slower computation of the linear layers\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(pretrained_ckpt)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168,
          "referenced_widgets": [
            "75a67ae1f71c47a18d3fab6f29676854",
            "6f8eff6173224d57bd4cd4aed90ae8df",
            "a6e6d5340ac34d04b6c8b21f19ecbdc6",
            "7f45b8c42d3d47d6aa432f1763328d1e",
            "7e56a3ca4daf47d68d10a43fd9e1bbb9",
            "4985876c2f4141d39cc458fa65a96423",
            "d3b9aa602852442a8bee449e466b21eb",
            "60e96417f95f44f798a2fb16722b427b",
            "40b9e36614074cea9bc29529bf8d3e89",
            "95fbf359dcdf48baac7cc9d14ac8d40f",
            "d9399e14419446ec88cce15ec5f07255"
          ]
        },
        "id": "yxrPK0_EWWbf",
        "outputId": "51ce0047-9897-4302-ec73-e200c4d38efb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "75a67ae1f71c47a18d3fab6f29676854"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:367: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference Helper\n",
        "\n",
        "The function `infer_one_example` is designed to perform inference on a single example using the provided model and tokenizer.\n",
        "\n",
        "The function takes a text instruction, tokenizes it, and feeds it to the model to generate a prediction. It processes the output to extract the generated text, handling any potential errors (e.g., input too long) by returning an empty string.\n"
      ],
      "metadata": {
        "id": "9ZxUT0WvbRZd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def infer_one_example(model, tokenizer, instruction):\n",
        "  input_ids = tokenizer(instruction, return_tensors=\"pt\", truncation=True).input_ids.cuda()\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    try:\n",
        "        outputs = model.generate(\n",
        "            input_ids=input_ids,\n",
        "            max_new_tokens=20,\n",
        "            do_sample=True,\n",
        "            top_p=0.95,\n",
        "            temperature=1e-3,\n",
        "        )\n",
        "        result = tokenizer.batch_decode(\n",
        "            outputs.detach().cpu().numpy(), skip_special_tokens=True\n",
        "        )[0]\n",
        "        result = result[len(instruction) :]\n",
        "\n",
        "    except:\n",
        "        # oops, it's too long!\n",
        "        result = \"\"\n",
        "\n",
        "  return result"
      ],
      "metadata": {
        "id": "bzRJH2YMbTIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Zero-Shot Example on Base Model\n",
        "\n",
        "After setting up our model and tokenizer, we should evaluate the base model's performance before any fine-tuning (maybe it's already good enough!). We'll conduct a zero-shot test, which allows us to assess the model's ability to make predictions on tasks it hasn't been explicitly trained on.\n",
        "\n",
        "In zero-shot learning, the model uses its pre-trained knowledge to infer the correct output for a given input. Here's how we'll proceed:\n",
        "\n",
        "1. **Select an Example**: We'll choose a text example that the model hasn't seen during training.\n",
        "2. **Run Inference**: Using the `infer_one_example` function, we will pass our selected text to the model and generate a prediction.\n",
        "3. **Evaluate**: We'll examine the model's output to determine if it aligns with expected outcomes, considering that the model has no prior fine-tuning on this specific task.\n"
      ],
      "metadata": {
        "id": "X_V7w77qaJgW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's get the first instance in our dataset\n",
        "instruction, label = test_dataset[\"instructions\"][0], test_dataset[\"labels\"][0]\n",
        "instruction, label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRhiG2hnYmRv",
        "outputId": "74698cbf-97b9-404c-9823-2602370d56da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('### Sentence:I am a little confused on all of the models of the 88-89 bonnevilles.\\nI have heard of the LE SE LSE SSE SSEI. Could someone tell me the\\ndifferences are far as features or performance. I am also curious to\\nknow what the book value is for prefereably the 89 model. And how much\\nless than book value can you usually get them for. In other words how\\nmuch are they in demand this time of year. I have heard that the mid-spring\\nearly summer is the best time to buy. ### Class:',\n",
              " 'rec.autos')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt format\n",
        "ZERO_SHOT_CLASSIFIER_PROMPT = \"\"\"Classify the sentence into one of 20 classes. The list of classes is provided below, where the classes are separated by commas:\n",
        "\n",
        "{newsgroup_classes}\n",
        "\n",
        "From the above list of classes, select only one class that the provided sentence can be classified into. The sentence will be delimited with triple backticks. Once again, only predict the class from the given list of classes. Do not predict anything else.\n",
        "\n",
        "### Sentence: ```{sentence}```\n",
        "### Class:\n",
        "\"\"\"\n",
        "\n",
        "# inject data into the prompt\n",
        "prompt_zeroshot = ZERO_SHOT_CLASSIFIER_PROMPT.format(\n",
        "    newsgroup_classes = newsgroup_classes,\n",
        "    sentence = instruction\n",
        ")"
      ],
      "metadata": {
        "id": "6yCVxxNeaQY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "infer_one_example(model, tokenizer, prompt_zeroshot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "8MneFu3oawMD",
        "outputId": "a974d647-51b1-4fcd-9871-be5c91d101d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1421: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n### Sentence: ```### Sentence:I am a little confused on all of'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Obviously not what we wanted!\n",
        "- Let's try to coerce the model in to the correct output by finetuning it!"
      ],
      "metadata": {
        "id": "GMXi9g_Za9O8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine Tuning!"
      ],
      "metadata": {
        "id": "oOngw6CZb-Pl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's the fun part!\n",
        "\n",
        "Now that we have assessed the base model's performance, the next stage is to fine-tune it using Low-Rank Adaptation (LoRA). Fine-tuning is a critical step to tailor a pre-trained model to our specific task, in this case, text classification within the 20 Newsgroups dataset. We will implement LoRA as it enables us to update the model's parameters efficiently, providing a significant computational advantage.\n"
      ],
      "metadata": {
        "id": "bdf_JnJecD66"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic Configs\n",
        "\n",
        "- **Dropout**: A dropout rate of 0.1 to prevent overfitting during training.\n",
        "- **Epochs**: How many epochs to train\n",
        "\n",
        "- **Rank**: A rank of 8, which determines the size of the low-rank matrices in LoRA, note that we need to balance between model flexibility and parameter efficiency.\n",
        "- **Alpha**: How strongly should LoRA weight differentials affect base weights"
      ],
      "metadata": {
        "id": "CIsdDf9EmLnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic training config\n",
        "dropout = 0.1\n",
        "epochs = 3    # 3 epochs takes ~20 min on a T4\n",
        "\n",
        "# LoRA Configs\n",
        "rank = 8      # try larger value for more complex task\n",
        "alpha = 16    # try larger value if task is substantially different from language understanding/processing"
      ],
      "metadata": {
        "id": "c4sIpA37l1pQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuring LoRA Parameters\n",
        "\n",
        "Using `peft` library, we create a `LoraConfig` object with our defined parameters, preparing our model for fine-tuning with these settings.\n",
        "\n",
        "\n",
        "We then invoke `prepare_model_for_kbit_training` to get model with quantized weights\n",
        "\n",
        "And invoke `get_peft_model` to apply the LoRA configuration to our model (creates LoRA weights that we can train on).\n"
      ],
      "metadata": {
        "id": "lyqOFCPXl0AA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LoRA config based on QLoRA paper\n",
        "peft_config = LoraConfig(\n",
        "    lora_alpha=alpha,\n",
        "    lora_dropout=dropout,\n",
        "    r=rank,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "# prepare model for training\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "model = get_peft_model(model, peft_config)"
      ],
      "metadata": {
        "id": "bmERa50SayQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# directory to save model artifact\n",
        "results_dir = \"./finetuned_model\""
      ],
      "metadata": {
        "id": "wVQcVzaGcGQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Loop\n",
        "\n",
        "With all configurations in place, we initiate a training loop using the `SFTTrainer` class, which has been set up to accommodate our LoRA-enhanced model. We pass our training dataset along with other parameters like maximum sequence length, tokenizer, and the training arguments.\n",
        "\n",
        "After training, we output the training loss to monitor our model's performance and save the fine-tuned model along with the tokenizer to our specified directory. Additionally, we serialize the training results using `pickle` for later analysis.\n",
        "\n",
        "By the end of this stage, our model will be fine-tuned with LoRA, making it more adept at handling the classification tasks specific to our dataset.\n"
      ],
      "metadata": {
        "id": "n809hel3mo7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "        output_dir=results_dir,\n",
        "        logging_dir=f\"{results_dir}/logs\",\n",
        "        num_train_epochs=epochs,\n",
        "        per_device_train_batch_size=6,\n",
        "        gradient_accumulation_steps=2,\n",
        "        gradient_checkpointing=True,\n",
        "        optim=\"paged_adamw_32bit\",\n",
        "        logging_steps=100,\n",
        "        learning_rate=2e-4,\n",
        "        bf16=False, # Set to true if you're using A10/A100\n",
        "        tf32=False, # Set to true if you're using A10/A100\n",
        "        fp16=True,\n",
        "        max_grad_norm=0.3,\n",
        "        warmup_ratio=0.03,\n",
        "        lr_scheduler_type=\"constant\",\n",
        "        report_to=\"none\",\n",
        "    )\n",
        "\n",
        "max_seq_length = 512  # max sequence length for model and packing of the dataset\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=train_dataset,\n",
        "    peft_config=peft_config,\n",
        "    max_seq_length=max_seq_length,\n",
        "    tokenizer=tokenizer,\n",
        "    packing=True,\n",
        "    args=training_args,\n",
        "    dataset_text_field=\"instructions\",\n",
        ")\n",
        "\n",
        "trainer_stats = trainer.train()\n",
        "train_loss = trainer_stats.training_loss\n",
        "print(f\"Training loss:{train_loss}\")\n",
        "\n",
        "peft_model_id = f\"{results_dir}/assets\"\n",
        "trainer.model.save_pretrained(peft_model_id)\n",
        "tokenizer.save_pretrained(peft_model_id)\n",
        "\n",
        "with open(f\"{results_dir}/results.pkl\", \"wb\") as handle:\n",
        "    run_result = [\n",
        "        epochs,\n",
        "        rank,\n",
        "        dropout,\n",
        "        train_loss,\n",
        "    ]\n",
        "    pickle.dump(run_result, handle)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "QjqG3yMQchf0",
        "outputId": "7b242f52-357c-4055-d3a4-a6cc95a67bc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using 8-bit optimizers with a version of `bitsandbytes` < 0.41.1. It is recommended to update your version as a major bug has been fixed in 8-bit optimizers.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='100' max='110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [100/110 32:34 < 03:19, 0.05 it/s, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.735000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss:1.7350161743164063\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing Out Fine-Tuned Model\n",
        "\n",
        "After completing the fine-tuning process, let's evaluate the performance of the updated model. Testing allows us to verify that the model has indeed learned from the training data and can now perform better on the task at hand."
      ],
      "metadata": {
        "id": "HOelLZU-_vb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 0\n",
        "instruction, label = test_dataset[\"instructions\"][idx], test_dataset[\"labels\"][idx]"
      ],
      "metadata": {
        "id": "GxRfyWiUtExy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Our test text\n",
        "instruction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "1puxBwOBA54F",
        "outputId": "a14f541b-643d-444b-8bba-41185f4b741e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'rec.motorcycles'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the fine-tuned model on it\n",
        "infer_one_example(model, tokenizer, instruction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BDhhlnAecte_",
        "outputId": "e2094e44-bbad-496d-814f-00fdf548ac1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'rec.motorcycles'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GT\n",
        "label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "j5cuwQl0ARHm",
        "outputId": "ecbcf3cf-e0ed-45ac-f3bb-2efa3e823bda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'rec.autos'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# More Models & Benchmarks!\n",
        "\n",
        "You can check out complete benchmark results for each models at [our repo](https://github.com/georgian-io/LLM-Finetuning-Hub).\n",
        "\n",
        "The repo hosts reusable code snippets to use for your experimentss!"
      ],
      "metadata": {
        "id": "BJ_lfhcpw6eY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now onto Mariia to tell us how we can serve a trained model**"
      ],
      "metadata": {
        "id": "nkY84jSslmlG"
      }
    }
  ]
}