







#======================================================================================
                                        Model
#======================================================================================



+--------------------------------------------------------------------------------------+
|                                    Model Summary                                     |
+--------------------------------------------------------------------------------------+
| Total Parameters: 124,439,808                                                        |
| Trainable Parameters: 124,439,808                                                    |
| Non-Trainable Parameters: 0                                                          |
+-------------------------------------+-------------------+-------------+-------+------+
| Layer Name                          | Type              | Parameters  | Train |Device|
+-------------------------------------+-------------------+-------------+-------+------+
|                                     | GPT2LMHeadModel   | 124,439,808 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer                         | GPT2Model         | 124,439,808 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.wte                     | Embedding         |  38,597,376 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.wpe                     | Embedding         |     786,432 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.drop                    | Dropout           |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h                       | ModuleList        |  85,054,464 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.0                     | GPT2Block         |   7,087,872 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.0.ln_1                | LayerNorm         |       1,536 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.0.attn                | GPT2Attention     |   2,362,368 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.0.attn.c_attn         | Conv1D            |   1,771,776 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.0.attn.c_proj         | Conv1D            |     590,592 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.0.attn.attn_dropout   | Dropout           |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.0.attn.resid_dropout  | Dropout           |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.0.ln_2                | LayerNorm         |       1,536 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.0.mlp                 | GPT2MLP           |   4,722,432 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.0.mlp.c_fc            | Conv1D            |   2,362,368 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.0.mlp.c_proj          | Conv1D            |   2,360,064 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.0.mlp.act             | NewGELUActivation |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.0.mlp.dropout         | Dropout           |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.1                     | GPT2Block         |   7,087,872 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.1.ln_1                | LayerNorm         |       1,536 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.1.attn                | GPT2Attention     |   2,362,368 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.1.attn.c_attn         | Conv1D            |   1,771,776 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.1.attn.c_proj         | Conv1D            |     590,592 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.1.attn.attn_dropout   | Dropout           |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.1.attn.resid_dropout  | Dropout           |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.1.ln_2                | LayerNorm         |       1,536 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.1.mlp                 | GPT2MLP           |   4,722,432 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.1.mlp.c_fc            | Conv1D            |   2,362,368 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.1.mlp.c_proj          | Conv1D            |   2,360,064 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.1.mlp.act             | NewGELUActivation |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.1.mlp.dropout         | Dropout           |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.2                     | GPT2Block         |   7,087,872 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.2.ln_1                | LayerNorm         |       1,536 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.2.attn                | GPT2Attention     |   2,362,368 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.2.attn.c_attn         | Conv1D            |   1,771,776 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.2.attn.c_proj         | Conv1D            |     590,592 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.2.attn.attn_dropout   | Dropout           |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.2.attn.resid_dropout  | Dropout           |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.2.ln_2                | LayerNorm         |       1,536 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.2.mlp                 | GPT2MLP           |   4,722,432 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.2.mlp.c_fc            | Conv1D            |   2,362,368 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.2.mlp.c_proj          | Conv1D            |   2,360,064 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.2.mlp.act             | NewGELUActivation |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.2.mlp.dropout         | Dropout           |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.3                     | GPT2Block         |   7,087,872 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.3.ln_1                | LayerNorm         |       1,536 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.3.attn                | GPT2Attention     |   2,362,368 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.3.attn.c_attn         | Conv1D            |   1,771,776 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.3.attn.c_proj         | Conv1D            |     590,592 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.3.attn.attn_dropout   | Dropout           |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.3.attn.resid_dropout  | Dropout           |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.3.ln_2                | LayerNorm         |       1,536 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.3.mlp                 | GPT2MLP           |   4,722,432 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.3.mlp.c_fc            | Conv1D            |   2,362,368 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.3.mlp.c_proj          | Conv1D            |   2,360,064 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.3.mlp.act             | NewGELUActivation |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.3.mlp.dropout         | Dropout           |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.4                     | GPT2Block         |   7,087,872 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.4.ln_1                | LayerNorm         |       1,536 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.4.attn                | GPT2Attention     |   2,362,368 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.4.attn.c_attn         | Conv1D            |   1,771,776 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.4.attn.c_proj         | Conv1D            |     590,592 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.4.attn.attn_dropout   | Dropout           |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.4.attn.resid_dropout  | Dropout           |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.4.ln_2                | LayerNorm         |       1,536 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.4.mlp                 | GPT2MLP           |   4,722,432 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.4.mlp.c_fc            | Conv1D            |   2,362,368 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.4.mlp.c_proj          | Conv1D            |   2,360,064 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.4.mlp.act             | NewGELUActivation |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.4.mlp.dropout         | Dropout           |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.5                     | GPT2Block         |   7,087,872 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.5.ln_1                | LayerNorm         |       1,536 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.5.attn                | GPT2Attention     |   2,362,368 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.5.attn.c_attn         | Conv1D            |   1,771,776 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.5.attn.c_proj         | Conv1D            |     590,592 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.5.attn.attn_dropout   | Dropout           |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.5.attn.resid_dropout  | Dropout           |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.5.ln_2                | LayerNorm         |       1,536 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.5.mlp                 | GPT2MLP           |   4,722,432 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.5.mlp.c_fc            | Conv1D            |   2,362,368 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.5.mlp.c_proj          | Conv1D            |   2,360,064 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.5.mlp.act             | NewGELUActivation |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.5.mlp.dropout         | Dropout           |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.6                     | GPT2Block         |   7,087,872 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.6.ln_1                | LayerNorm         |       1,536 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.6.attn                | GPT2Attention     |   2,362,368 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.6.attn.c_attn         | Conv1D            |   1,771,776 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.6.attn.c_proj         | Conv1D            |     590,592 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.6.attn.attn_dropout   | Dropout           |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.6.attn.resid_dropout  | Dropout           |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.6.ln_2                | LayerNorm         |       1,536 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.6.mlp                 | GPT2MLP           |   4,722,432 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.6.mlp.c_fc            | Conv1D            |   2,362,368 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.6.mlp.c_proj          | Conv1D            |   2,360,064 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.6.mlp.act             | NewGELUActivation |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.6.mlp.dropout         | Dropout           |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.7                     | GPT2Block         |   7,087,872 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.7.ln_1                | LayerNorm         |       1,536 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.7.attn                | GPT2Attention     |   2,362,368 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.7.attn.c_attn         | Conv1D            |   1,771,776 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.7.attn.c_proj         | Conv1D            |     590,592 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.7.attn.attn_dropout   | Dropout           |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.7.attn.resid_dropout  | Dropout           |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.7.ln_2                | LayerNorm         |       1,536 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.7.mlp                 | GPT2MLP           |   4,722,432 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.7.mlp.c_fc            | Conv1D            |   2,362,368 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.7.mlp.c_proj          | Conv1D            |   2,360,064 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.7.mlp.act             | NewGELUActivation |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.7.mlp.dropout         | Dropout           |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.8                     | GPT2Block         |   7,087,872 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.8.ln_1                | LayerNorm         |       1,536 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.8.attn                | GPT2Attention     |   2,362,368 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.8.attn.c_attn         | Conv1D            |   1,771,776 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.8.attn.c_proj         | Conv1D            |     590,592 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.8.attn.attn_dropout   | Dropout           |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.8.attn.resid_dropout  | Dropout           |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.8.ln_2                | LayerNorm         |       1,536 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.8.mlp                 | GPT2MLP           |   4,722,432 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.8.mlp.c_fc            | Conv1D            |   2,362,368 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.8.mlp.c_proj          | Conv1D            |   2,360,064 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.8.mlp.act             | NewGELUActivation |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.8.mlp.dropout         | Dropout           |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.9                     | GPT2Block         |   7,087,872 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.9.ln_1                | LayerNorm         |       1,536 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.9.attn                | GPT2Attention     |   2,362,368 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.9.attn.c_attn         | Conv1D            |   1,771,776 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.9.attn.c_proj         | Conv1D            |     590,592 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.9.attn.attn_dropout   | Dropout           |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.9.attn.resid_dropout  | Dropout           |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.9.ln_2                | LayerNorm         |       1,536 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.9.mlp                 | GPT2MLP           |   4,722,432 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.9.mlp.c_fc            | Conv1D            |   2,362,368 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.9.mlp.c_proj          | Conv1D            |   2,360,064 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.9.mlp.act             | NewGELUActivation |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.9.mlp.dropout         | Dropout           |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.10                    | GPT2Block         |   7,087,872 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.10.ln_1               | LayerNorm         |       1,536 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.10.attn               | GPT2Attention     |   2,362,368 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.10.attn.c_attn        | Conv1D            |   1,771,776 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.10.attn.c_proj        | Conv1D            |     590,592 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.10.attn.attn_dropout  | Dropout           |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.10.attn.resid_dropout | Dropout           |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.10.ln_2               | LayerNorm         |       1,536 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.10.mlp                | GPT2MLP           |   4,722,432 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.10.mlp.c_fc           | Conv1D            |   2,362,368 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.10.mlp.c_proj         | Conv1D            |   2,360,064 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.10.mlp.act            | NewGELUActivation |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.10.mlp.dropout        | Dropout           |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.11                    | GPT2Block         |   7,087,872 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.11.ln_1               | LayerNorm         |       1,536 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.11.attn               | GPT2Attention     |   2,362,368 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.11.attn.c_attn        | Conv1D            |   1,771,776 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.11.attn.c_proj        | Conv1D            |     590,592 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.11.attn.attn_dropout  | Dropout           |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.11.attn.resid_dropout | Dropout           |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.11.ln_2               | LayerNorm         |       1,536 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.11.mlp                | GPT2MLP           |   4,722,432 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.11.mlp.c_fc           | Conv1D            |   2,362,368 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.11.mlp.c_proj         | Conv1D            |   2,360,064 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.11.mlp.act            | NewGELUActivation |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.h.11.mlp.dropout        | Dropout           |           0 | False | None |
+-------------------------------------+-------------------+-------------+-------+------+
| transformer.ln_f                    | LayerNorm         |       1,536 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
| lm_head                             | Linear            |  38,597,376 |  True |  cpu |
+-------------------------------------+-------------------+-------------+-------+------+
