{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39192,"status":"ok","timestamp":1706862688972,"user":{"displayName":"hemanth varma","userId":"05483789954770220327"},"user_tz":-330},"id":"6BEwn-PpYqj8","outputId":"27d9ce33-a0ca-42ac-f522-77097be3713b"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.4/183.4 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.9/270.9 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install -q -U datasets peft accelerate peft transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":121,"referenced_widgets":["84567b25bd254c239ee17edf2701239d","6b01fc56e1fb4e68815b78bdadcaa5fc","4402a33edfd14d7e8c184bcff292031f","62ef01a30e0548b082c8a27b833bff6d","3777e42e035847889cae3c41ce64ecc2","0a16aa32bdee4bb881cabf1620f7652c","ef969a4e2250414ea5243c4e2be6a6b6","214492bb3f2a49dfbee6446fe02eb1f4","e16e5978921f415da428cf728e27c158","55d00dc969c64ae4be2c602afd2348f9","d8e02a18c43b49e5afdee6303b50b6e5"]},"id":"Ca3FtY6S8JXN","outputId":"da7c2685-683d-48e3-97d4-f55503dfde9f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Splits:  dict_keys(['train', 'test', 'eval'])\n","Columns:  {'train': ['url', 'text', 'date', 'meta'], 'test': ['url', 'text', 'date', 'meta'], 'eval': ['url', 'text', 'date', 'meta']}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"84567b25bd254c239ee17edf2701239d","version_major":2,"version_minor":0},"text/plain":["Running tokenizer on dataset:   0%|          | 0/2155654 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (5969 > 2048). Running this sequence through the model will result in indexing errors\n"]}],"source":["import gc\n","import os\n","import sys\n","import threading\n","import warnings\n","import numpy as np\n","import psutil\n","import torch\n","from accelerate import Accelerator\n","from datasets import load_dataset\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","from transformers import (\n","    AutoModelForCausalLM,\n","    AutoTokenizer,\n","    default_data_collator,\n","    get_linear_schedule_with_warmup,\n","    set_seed,\n",")\n","\n","from peft import LoraConfig, TaskType, get_peft_model\n","from typing import Union,List, Dict, Optional\n","from datasets import load_dataset, DatasetDict\n","from transformers import AutoTokenizer\n","import multiprocessing\n","def advanced_data_loader(input: Union[str, Dict[str, str]], format: Optional[str] = None, split_ratios: Optional[Dict[str, float]] = None) -> Optional[DatasetDict]:\n","    \"\"\"\n","    Loads a dataset from a given input path or dictionary specifying file paths and splits it.\n","\n","    :param input: A string representing the dataset name or directory, or a dictionary containing file paths.\n","    :param format: The format of the dataset if loading from a file (e.g., 'csv' or 'json').\n","    :param split_ratios: A dictionary with keys 'train', 'test', and 'eval' containing split ratios.\n","    :return: A loaded and split dataset or None in case of failure.\n","    \"\"\"\n","    if split_ratios is None:\n","        split_ratios = {'train': 0.8, 'test': 0.1, 'eval': 0.1}\n","\n","    try:\n","        # Load the dataset\n","        if isinstance(input, dict) and format in ['csv', 'json']:\n","            dataset = load_dataset(format, data_files=input)\n","        elif isinstance(input, str) and format == 'text':\n","            dataset = load_dataset(format, data_dir=input)\n","        elif isinstance(input, str) and format is None:\n","            dataset = load_dataset(input)\n","        else:\n","            warnings.warn(\"Invalid input or format. Please provide a valid dataset name, directory, or file paths.\")\n","            return None\n","    except FileNotFoundError as e:\n","        warnings.warn(str(e))\n","        return None\n","\n","    # Split the dataset\n","    if dataset:\n","        split_dataset = dataset['train'].train_test_split(test_size=split_ratios['test'] + split_ratios['eval'])\n","        test_eval_dataset = split_dataset['test'].train_test_split(test_size=split_ratios['eval'] / (split_ratios['test'] + split_ratios['eval']))\n","        dataset = DatasetDict({\n","            'train': split_dataset['train'],\n","            'test': test_eval_dataset['train'],\n","            'eval': test_eval_dataset['test']\n","        })\n","\n","    print(\"Splits: \", dataset.keys())\n","    print(\"Columns: \", {split: dataset[split].column_names for split in dataset.keys()})\n","    return dataset\n","\n","def levenshtein_distance(str1, str2):\n","    # TC: O(N^2)\n","    # SC: O(N^2)\n","    if str1 == str2:\n","        return 0\n","    num_rows = len(str1) + 1\n","    num_cols = len(str2) + 1\n","    dp_matrix = np.empty((num_rows, num_cols))\n","    dp_matrix[0, :] = range(num_cols)\n","    dp_matrix[:, 0] = range(num_rows)\n","\n","    for i in range(1, num_rows):\n","        for j in range(1, num_cols):\n","            if str1[i - 1] == str2[j - 1]:\n","                dp_matrix[i, j] = dp_matrix[i - 1, j - 1]\n","            else:\n","                dp_matrix[i, j] = min(dp_matrix[i - 1, j - 1], dp_matrix[i - 1, j], dp_matrix[i, j - 1]) + 1\n","\n","    return dp_matrix[num_rows - 1, num_cols - 1]\n","\n","\n","def get_closest_label(eval_pred, classes):\n","    min_id = sys.maxsize\n","    min_edit_distance = sys.maxsize\n","    for i, class_label in enumerate(classes):\n","        edit_distance = levenshtein_distance(eval_pred.strip(), class_label)\n","        if edit_distance < min_edit_distance:\n","            min_id = i\n","            min_edit_distance = edit_distance\n","    return classes[min_id]\n","\n","\n","# Converting Bytes to Megabytes\n","def b2mb(x):\n","    return int(x / 2**20)\n","\n","\n","# This context manager is used to track the peak memory usage of the process\n","class TorchTracemalloc:\n","    def __enter__(self):\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        torch.cuda.reset_max_memory_allocated()  # reset the peak gauge to zero\n","        self.begin = torch.cuda.memory_allocated()\n","        self.process = psutil.Process()\n","\n","        self.cpu_begin = self.cpu_mem_used()\n","        self.peak_monitoring = True\n","        peak_monitor_thread = threading.Thread(target=self.peak_monitor_func)\n","        peak_monitor_thread.daemon = True\n","        peak_monitor_thread.start()\n","        return self\n","\n","    def cpu_mem_used(self):\n","        \"\"\"get resident set size memory for the current process\"\"\"\n","        return self.process.memory_info().rss\n","\n","    def peak_monitor_func(self):\n","        self.cpu_peak = -1\n","\n","        while True:\n","            self.cpu_peak = max(self.cpu_mem_used(), self.cpu_peak)\n","\n","            # can't sleep or will not catch the peak right (this comment is here on purpose)\n","            # time.sleep(0.001) # 1msec\n","\n","            if not self.peak_monitoring:\n","                break\n","\n","    def __exit__(self, *exc):\n","        self.peak_monitoring = False\n","\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        self.end = torch.cuda.memory_allocated()\n","        self.peak = torch.cuda.max_memory_allocated()\n","        self.used = b2mb(self.end - self.begin)\n","        self.peaked = b2mb(self.peak - self.begin)\n","\n","        self.cpu_end = self.cpu_mem_used()\n","        self.cpu_used = b2mb(self.cpu_end - self.cpu_begin)\n","        self.cpu_peaked = b2mb(self.cpu_peak - self.cpu_begin)\n","        # print(f\"delta used/peak {self.used:4d}/{self.peaked:4d}\")\n","\n","\n","def main():\n","    accelerator = Accelerator()\n","    model_name_or_path = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n","    dataset_name = \"math-ai/AutoMathText\"\n","    peft_config = LoraConfig(task_type=TaskType.CAUSAL_LM, inference_mode=False, r=8, lora_alpha=32, lora_dropout=0.1)\n","    text_column = \"text\"\n","    label_column = \"meta\"\n","    lr = 3e-3\n","    num_epochs = 2\n","    batch_size = 4\n","    seed = 42\n","    max_length = 512\n","    do_test = False\n","    set_seed(seed)\n","    dataset=advanced_data_loader(dataset_name)\n","    dataset=dataset['train']\n","\n","    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n","\n","    def preprocess_function(examples):\n","        batch_size = len(examples[text_column])\n","        inputs = [f\"{text_column} : {x} Label : \" for x in examples[text_column]]\n","        targets = [str(x) for x in examples[label_column]]\n","        model_inputs = tokenizer(inputs)\n","        labels = tokenizer(targets, add_special_tokens=False)  # don't add bos token because we concatenate with inputs\n","        for i in range(batch_size):\n","            sample_input_ids = model_inputs[\"input_ids\"][i]\n","            label_input_ids = labels[\"input_ids\"][i] + [tokenizer.eos_token_id]\n","            model_inputs[\"input_ids\"][i] = sample_input_ids + label_input_ids\n","            labels[\"input_ids\"][i] = [-100] * len(sample_input_ids) + label_input_ids\n","            model_inputs[\"attention_mask\"][i] = [1] * len(model_inputs[\"input_ids\"][i])\n","        for i in range(batch_size):\n","            sample_input_ids = model_inputs[\"input_ids\"][i]\n","            label_input_ids = labels[\"input_ids\"][i]\n","            model_inputs[\"input_ids\"][i] = [tokenizer.pad_token_id] * (\n","                max_length - len(sample_input_ids)\n","            ) + sample_input_ids\n","            model_inputs[\"attention_mask\"][i] = [0] * (max_length - len(sample_input_ids)) + model_inputs[\n","                \"attention_mask\"\n","            ][i]\n","            labels[\"input_ids\"][i] = [-100] * (max_length - len(sample_input_ids)) + label_input_ids\n","            model_inputs[\"input_ids\"][i] = torch.tensor(model_inputs[\"input_ids\"][i][:max_length])\n","            model_inputs[\"attention_mask\"][i] = torch.tensor(model_inputs[\"attention_mask\"][i][:max_length])\n","            labels[\"input_ids\"][i] = torch.tensor(labels[\"input_ids\"][i][:max_length])\n","        model_inputs[\"labels\"] = labels[\"input_ids\"]\n","        return model_inputs\n","\n","    def test_preprocess_function(examples):\n","        batch_size = len(examples[text_column])\n","        inputs = [f\"{text_column} : {x} Label : \" for x in examples[text_column]]\n","        model_inputs = tokenizer(inputs)\n","        # print(model_inputs)\n","        for i in range(batch_size):\n","            sample_input_ids = model_inputs[\"input_ids\"][i]\n","            model_inputs[\"input_ids\"][i] = [tokenizer.pad_token_id] * (\n","                max_length - len(sample_input_ids)\n","            ) + sample_input_ids\n","            model_inputs[\"attention_mask\"][i] = [0] * (max_length - len(sample_input_ids)) + model_inputs[\n","                \"attention_mask\"\n","            ][i]\n","            model_inputs[\"input_ids\"][i] = torch.tensor(model_inputs[\"input_ids\"][i][:max_length])\n","            model_inputs[\"attention_mask\"][i] = torch.tensor(model_inputs[\"attention_mask\"][i][:max_length])\n","        return model_inputs\n","\n","    with accelerator.main_process_first():\n","        processed_datasets = dataset.map(\n","            preprocess_function,\n","            batched=True,\n","            num_proc=1,\n","            # remove_columns=dataset[\"train\"].column_names,\n","            load_from_cache_file=True,\n","            desc=\"Running tokenizer on dataset\",\n","        )\n","    accelerator.wait_for_everyone()\n","\n","    train_dataset = processed_datasets[\"train\"]\n","\n","    with accelerator.main_process_first():\n","        processed_datasets = dataset.map(\n","            test_preprocess_function,\n","            batched=True,\n","            num_proc=1,\n","            remove_columns=dataset[\"train\"].column_names,\n","            load_from_cache_file=False,\n","            desc=\"Running tokenizer on dataset\",\n","        )\n","    eval_dataset = processed_datasets[\"train\"]\n","    test_dataset = processed_datasets[\"test\"]\n","\n","    train_dataloader = DataLoader(\n","        train_dataset, shuffle=True, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True\n","    )\n","    eval_dataloader = DataLoader(\n","        eval_dataset, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True\n","    )\n","    test_dataloader = DataLoader(\n","        test_dataset, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True\n","    )\n","\n","\n","\n","    # creating model\n","    model = AutoModelForCausalLM.from_pretrained(model_name_or_path)\n","    model = get_peft_model(model, peft_config)\n","    model.print_trainable_parameters()\n","\n","    # optimizer\n","    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n","\n","    # lr scheduler\n","    lr_scheduler = get_linear_schedule_with_warmup(\n","        optimizer=optimizer,\n","        num_warmup_steps=0,\n","        num_training_steps=(len(train_dataloader) * num_epochs),\n","    )\n","\n","    model, train_dataloader, eval_dataloader, test_dataloader, optimizer, lr_scheduler = accelerator.prepare(\n","        model, train_dataloader, eval_dataloader, test_dataloader, optimizer, lr_scheduler\n","    )\n","    accelerator.print(model)\n","\n","    is_ds_zero_3 = False\n","    if getattr(accelerator.state, \"deepspeed_plugin\", None):\n","        is_ds_zero_3 = accelerator.state.deepspeed_plugin.zero_stage == 3\n","\n","    for epoch in range(num_epochs):\n","        with TorchTracemalloc() as tracemalloc:\n","            model.train()\n","            total_loss = 0\n","            for step, batch in enumerate(tqdm(train_dataloader)):\n","                outputs = model(**batch)\n","                loss = outputs.loss\n","                total_loss += loss.detach().float()\n","                accelerator.backward(loss)\n","                optimizer.step()\n","                lr_scheduler.step()\n","                optimizer.zero_grad()\n","        # Printing the GPU memory usage details such as allocated memory, peak memory, and total memory usage\n","        accelerator.print(\"GPU Memory before entering the train : {}\".format(b2mb(tracemalloc.begin)))\n","        accelerator.print(\"GPU Memory consumed at the end of the train (end-begin): {}\".format(tracemalloc.used))\n","        accelerator.print(\"GPU Peak Memory consumed during the train (max-begin): {}\".format(tracemalloc.peaked))\n","        accelerator.print(\n","            \"GPU Total Peak Memory consumed during the train (max): {}\".format(\n","                tracemalloc.peaked + b2mb(tracemalloc.begin)\n","            )\n","        )\n","\n","        accelerator.print(\"CPU Memory before entering the train : {}\".format(b2mb(tracemalloc.cpu_begin)))\n","        accelerator.print(\"CPU Memory consumed at the end of the train (end-begin): {}\".format(tracemalloc.cpu_used))\n","        accelerator.print(\"CPU Peak Memory consumed during the train (max-begin): {}\".format(tracemalloc.cpu_peaked))\n","        accelerator.print(\n","            \"CPU Total Peak Memory consumed during the train (max): {}\".format(\n","                tracemalloc.cpu_peaked + b2mb(tracemalloc.cpu_begin)\n","            )\n","        )\n","        train_epoch_loss = total_loss / len(train_dataloader)\n","        train_ppl = torch.exp(train_epoch_loss)\n","        accelerator.print(f\"{epoch=}: {train_ppl=} {train_epoch_loss=}\")\n","\n","        model.eval()\n","        eval_preds = []\n","        with TorchTracemalloc() as tracemalloc:\n","            for _, batch in enumerate(tqdm(eval_dataloader)):\n","                batch = {k: v for k, v in batch.items() if k != \"labels\"}\n","                with torch.no_grad():\n","                    outputs = accelerator.unwrap_model(model).generate(\n","                        **batch, synced_gpus=is_ds_zero_3, max_new_tokens=10\n","                    )  # synced_gpus=True for DS-stage 3\n","                outputs = accelerator.pad_across_processes(outputs, dim=1, pad_index=tokenizer.pad_token_id)\n","                preds = accelerator.gather_for_metrics(outputs)\n","                preds = preds[:, max_length:].detach().cpu().numpy()\n","                eval_preds.extend(tokenizer.batch_decode(preds, skip_special_tokens=True))\n","\n","        # Printing the GPU memory usage details such as allocated memory, peak memory, and total memory usage\n","        accelerator.print(\"GPU Memory before entering the eval : {}\".format(b2mb(tracemalloc.begin)))\n","        accelerator.print(\"GPU Memory consumed at the end of the eval (end-begin): {}\".format(tracemalloc.used))\n","        accelerator.print(\"GPU Peak Memory consumed during the eval (max-begin): {}\".format(tracemalloc.peaked))\n","        accelerator.print(\n","            \"GPU Total Peak Memory consumed during the eval (max): {}\".format(\n","                tracemalloc.peaked + b2mb(tracemalloc.begin)\n","            )\n","        )\n","\n","        accelerator.print(\"CPU Memory before entering the eval : {}\".format(b2mb(tracemalloc.cpu_begin)))\n","        accelerator.print(\"CPU Memory consumed at the end of the eval (end-begin): {}\".format(tracemalloc.cpu_used))\n","        accelerator.print(\"CPU Peak Memory consumed during the eval (max-begin): {}\".format(tracemalloc.cpu_peaked))\n","        accelerator.print(\n","            \"CPU Total Peak Memory consumed during the eval (max): {}\".format(\n","                tracemalloc.cpu_peaked + b2mb(tracemalloc.cpu_begin)\n","            )\n","        )\n","\n","        correct = 0\n","        total = 0\n","        assert len(eval_preds) == len(\n","            dataset[\"train\"][label_column]\n","        ), f\"{len(eval_preds)} != {len(dataset['train'][label_column])}\"\n","        for pred, true in zip(eval_preds, dataset[\"train\"][label_column]):\n","            if pred.strip() == true.strip():\n","                correct += 1\n","            total += 1\n","        accuracy = correct / total * 100\n","        accelerator.print(f\"{accuracy=}\")\n","        accelerator.print(f\"{eval_preds[:10]=}\")\n","        accelerator.print(f\"{dataset['train'][label_column][:10]=}\")\n","\n","    if do_test:\n","        model.eval()\n","        test_preds = []\n","        for _, batch in enumerate(tqdm(test_dataloader)):\n","            batch = {k: v for k, v in batch.items() if k != \"labels\"}\n","            with torch.no_grad():\n","                outputs = accelerator.unwrap_model(model).generate(\n","                    **batch, synced_gpus=is_ds_zero_3, max_new_tokens=10\n","                )  # synced_gpus=True for DS-stage 3\n","            outputs = accelerator.pad_across_processes(outputs, dim=1, pad_index=tokenizer.pad_token_id)\n","            preds = accelerator.gather(outputs)\n","            preds = preds[:, max_length:].detach().cpu().numpy()\n","            test_preds.extend(tokenizer.batch_decode(preds, skip_special_tokens=True))\n","\n","        test_preds_cleaned = []\n","        # for _, pred in enumerate(test_preds):\n","        #     test_preds_cleaned.append(get_closest_label(pred, classes))\n","\n","        test_df = dataset[\"test\"].to_pandas()\n","        assert len(test_preds_cleaned) == len(test_df), f\"{len(test_preds_cleaned)} != {len(test_df)}\"\n","        test_df[label_column] = test_preds_cleaned\n","        test_df[\"text_labels_orig\"] = test_preds\n","        accelerator.print(test_df[[text_column, label_column]].sample(20))\n","\n","        pred_df = test_df[[\"ID\", label_column]]\n","        pred_df.columns = [\"ID\", \"Label\"]\n","\n","        os.makedirs(f\"data/{dataset_name}\", exist_ok=True)\n","        pred_df.to_csv(f\"data/{dataset_name}/predictions.csv\", index=False)\n","\n","    accelerator.wait_for_everyone()\n","    peft_model_id = f\"{dataset_name}_{model_name_or_path}_{peft_config.peft_type}_{peft_config.task_type}\".replace(\n","        \"/\", \"_\"\n","    )\n","    model.save_pretrained(peft_model_id)\n","    # Option1: Pushing the model to Hugging Face Hub\n","    model.push_to_hub(\n","        f\"{dataset_name}_{model_name_or_path}_{peft_config.peft_type}_{peft_config.task_type}\".replace(\"/\", \"_\"),\n","        token = \"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\"\n","    )\n","    # token (`bool` or `str`, *optional*):\n","    #     `token` is to be used for HTTP Bearer authorization when accessing remote files. If `True`, will use the token generated\n","    #     when running `huggingface-cli login` (stored in `~/.huggingface`). Will default to `True` if `repo_url`\n","    #     is not specified.\n","    #     Or you can get your token from https://huggingface.co/settings/token\n","    # Option2: Saving the model locally\n","\n","    accelerator.wait_for_everyone()\n","\n","\n","if __name__ == \"__main__\":\n","    main()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zbogRspt_W1t"},"outputs":[],"source":["# prompt: datasets names , i am volunteering not set any columns names , so all that columns are to be trained write code for it using datasets modules\n","\n","dataset = load_dataset(\"my_dataset\", split=\"train\")\n","columns = list(dataset[0].keys())\n","train_dataset = dataset.map(lambda x: {k: x[k] for k in columns}, batched=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zkT70O5bFxIG"},"outputs":[],"source":["from typing import Union,List, Dict, Optional\n","from datasets import load_dataset, DatasetDict\n","from transformers import AutoTokenizer\n","import multiprocessing\n","def advanced_data_loader(input: Union[str, Dict[str, str]], format: Optional[str] = None, split_ratios: Optional[Dict[str, float]] = None) -> Optional[DatasetDict]:\n","    \"\"\"\n","    Loads a dataset from a given input path or dictionary specifying file paths and splits it.\n","\n","    :param input: A string representing the dataset name or directory, or a dictionary containing file paths.\n","    :param format: The format of the dataset if loading from a file (e.g., 'csv' or 'json').\n","    :param split_ratios: A dictionary with keys 'train', 'test', and 'eval' containing split ratios.\n","    :return: A loaded and split dataset or None in case of failure.\n","    \"\"\"\n","    if split_ratios is None:\n","        split_ratios = {'train': 0.8, 'test': 0.1, 'eval': 0.1}\n","\n","    try:\n","        # Load the dataset\n","        if isinstance(input, dict) and format in ['csv', 'json']:\n","            dataset = load_dataset(format, data_files=input)\n","        elif isinstance(input, str) and format == 'text':\n","            dataset = load_dataset(format, data_dir=input)\n","        elif isinstance(input, str) and format is None:\n","            dataset = load_dataset(input)\n","        else:\n","            warnings.warn(\"Invalid input or format. Please provide a valid dataset name, directory, or file paths.\")\n","            return None\n","    except FileNotFoundError as e:\n","        warnings.warn(str(e))\n","        return None\n","\n","    # Split the dataset\n","    if dataset:\n","        split_dataset = dataset['train'].train_test_split(test_size=split_ratios['test'] + split_ratios['eval'])\n","        test_eval_dataset = split_dataset['test'].train_test_split(test_size=split_ratios['eval'] / (split_ratios['test'] + split_ratios['eval']))\n","        dataset = DatasetDict({\n","            'train': split_dataset['train'],\n","            'test': test_eval_dataset['train'],\n","            'eval': test_eval_dataset['test']\n","        })\n","\n","    print(\"Splits: \", dataset.keys())\n","    print(\"Columns: \", {split: dataset[split].column_names for split in dataset.keys()})\n","    return dataset\n","\n","\n","def create_tokenizer(model_name_or_path: str = 'gpt2') -> AutoTokenizer:\n","    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n","    if tokenizer.pad_token_id is None:\n","        tokenizer.pad_token_id = tokenizer.eos_token_id\n","    if tokenizer.bos_token_id is None:\n","        tokenizer.bos_token_id = tokenizer.pad_token_id\n","    if tokenizer.eos_token_id is None:\n","        tokenizer.eos_token_id = tokenizer.pad_token_id\n","    if tokenizer.unk_token_id is None:\n","        tokenizer.unk_token_id = tokenizer.pad_token_id\n","    if tokenizer.sep_token_id is None:\n","        tokenizer.sep_token_id = tokenizer.pad_token_id\n","    if tokenizer.cls_token_id is None:\n","        tokenizer.cls_token_id = tokenizer.pad_token_id\n","    if tokenizer.mask_token_id is None:\n","        tokenizer.mask_token_id = tokenizer.pad_token_id\n","    return tokenizer\n","def preprocess_function(examples, tokenizer, max_length, columns):\n","    \"\"\"\n","    Preprocesses text examples for a tokenizer.\n","\n","    Args:\n","        examples: A list or a dictionary of text examples.\n","        tokenizer: A tokenizer object that can encode text.\n","        max_length: An integer that specifies the maximum length of the encoded tokens.\n","        columns: A list of strings that indicates which columns of the examples to use.\n","\n","    Returns:\n","        A dictionary of model inputs, which contains input_ids and attention_mask as tensors.\n","    \"\"\"\n","    # Initialize empty lists for input_ids and attention_mask\n","    input_ids = []\n","    attention_mask = []\n","\n","    # Loop through each column of the examples\n","    for column in columns:\n","        # Convert the examples in the column to a list of strings\n","        text = list(str(examples[column]))\n","        # Tokenize the text using the tokenizer\n","        tokenized_outputs = tokenizer(text, padding='max_length', truncation=True, max_length=max_length)\n","\n","        # Loop through each tokenized output\n","        for i in range(len(tokenized_outputs['input_ids'])):\n","            # Get the input_ids for the i-th output\n","            row_tokens = tokenized_outputs['input_ids'][i]\n","            # Truncate or pad the input_ids to the max_length\n","            row_tokens = row_tokens[:max_length]\n","            row_tokens += [tokenizer.pad_token_id] * (max_length - len(row_tokens))\n","            # Append the input_ids to the input_ids list\n","            input_ids.append(row_tokens)\n","\n","            # Create an attention_mask for the input_ids\n","            row_attention_mask = [int(token != tokenizer.pad_token_id) for token in row_tokens]\n","            # Append the attention_mask to the attention_mask list\n","            attention_mask.append(row_attention_mask)\n","\n","    # Create a dictionary of model inputs from the input_ids and attention_mask lists\n","    model_inputs = {'input_ids': torch.tensor(input_ids), 'attention_mask': torch.tensor(attention_mask)}\n","    # Return the model inputs\n","    return model_inputs\n","dataset=advanced_data_loader({'train': '/content/drive/MyDrive/MetaMathQA-395K.csv', 'test': '/content/drive/MyDrive/MetaMathQA-395K.csv'}, 'csv')\n","# print(dataset)\n","processed_datasets = dataset['train'].map(\n","    lambda examples: preprocess_function(examples=dataset['train'],tokenizer=tokenizer,max_length=128,columns=dataset['train'].column_names),\n","    batched=True,\n","    num_proc=multiprocessing.cpu_count(),\n","    remove_columns=columns,\n","    load_from_cache_file=False,\n","    desc=\"Running tokenizer on dataset\",\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["bdabf5c302d34f0f955914d325171dc0","a4b9895360c04a46be8d42bc31ade06a","6d01384d51174db5b5501c17886f3893","61a9176d07944de29b8430805aa3e58d","ec76ae25e8dd40509f440b5266e44b4f","bd72ac832df141c591eb4a31709e2bd9","15acb6c55eaf403c979a89eb3af49e86","c89e055049da4ef69e22a1068ab20495","092ea2e322e94d158043b02a4906fd90","156da1e906204601b0c17cef703e5f96","79d095c491fb4a4985c6d9269dd3bc93"]},"executionInfo":{"elapsed":237956,"status":"ok","timestamp":1706527290701,"user":{"displayName":"hemanth varma","userId":"05483789954770220327"},"user_tz":-330},"id":"5yXI1ovZwa_4","outputId":"21e17496-061f-4dee-ba1c-cb9392ba52db"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bdabf5c302d34f0f955914d325171dc0","version_major":2,"version_minor":0},"text/plain":["Running tokenizer on dataset:   0%|          | 0/316000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from typing import Union, Dict, Optional\n","from datasets import load_dataset, DatasetDict\n","from transformers import AutoTokenizer\n","import multiprocessing\n","import warnings\n","import torch\n","\n","# Function to load and optionally split a dataset\n","def advanced_data_loader(input: Union[str, Dict[str, str]], format: Optional[str] = None, split_ratios: Optional[Dict[str, float]] = None) -> Optional[DatasetDict]:\n","    if split_ratios is None:\n","        split_ratios = {'train': 0.8, 'test': 0.1, 'eval': 0.1}\n","\n","    try:\n","        if isinstance(input, dict) and format in ['csv', 'json']:\n","            dataset = load_dataset(format, data_files=input)\n","        elif isinstance(input, str) and format == 'text':\n","            dataset = load_dataset(format, data_dir=input)\n","        elif isinstance(input, str) and format is None:\n","            dataset = load_dataset(input)\n","        else:\n","            warnings.warn(\"Invalid input or format. Please provide a valid dataset name, directory, or file paths.\")\n","            return None\n","    except FileNotFoundError as e:\n","        warnings.warn(str(e))\n","        return None\n","\n","    if dataset:\n","        split_dataset = dataset['train'].train_test_split(test_size=split_ratios['test'] + split_ratios['eval'])\n","        test_eval_dataset = split_dataset['test'].train_test_split(test_size=split_ratios['eval'] / (split_ratios['test'] + split_ratios['eval']))\n","        dataset = DatasetDict({\n","            'train': split_dataset['train'],\n","            'test': test_eval_dataset['train'],\n","            'eval': test_eval_dataset['test']\n","        })\n","    return dataset\n","# def preprocess_function(batch: Dict[str, Any]) -> Dict[str, Any]:\n","#     \"\"\"\n","#     Tokenizes the input and instruction pairs in a batch using the T5 tokenizer\n","#     from the Google/flan-t5-base model, and returns a dictionary containing the\n","#     encoded inputs and labels.\n","\n","#     Args:\n","#         batch: A dictionary containing at least two keys, \"instruction\" and\n","#         \"input\", whose values are lists of strings.\n","\n","#     Returns:\n","#         A dictionary containing the encoded inputs and labels, as returned by\n","#         the T5 tokenizer.\n","#     \"\"\"\n","#     model_name = \"google/flan-t5-base\"\n","#     tokenizer = T5Tokenizer.from_pretrained(model_name)\n","\n","#     encoded_inputs = tokenizer(\n","#         list(batch[\"instruction\"]),\n","#         list(batch[\"input\"]),\n","#         padding=\"max_length\",\n","#         truncation=True,\n","#         return_tensors=\"np\",\n","#     )\n","\n","#     encoded_inputs[\"labels\"] = encoded_inputs[\"input_ids\"].copy()\n","\n","#     return dict(encoded_inputs)\n","# Function to create a tokenizer with proper token configurations\n","def create_tokenizer(model_name_or_path: str = 'gpt2') -> AutoTokenizer:\n","    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n","    # Set special tokens if they are not already set\n","    special_tokens = ['pad_token_id', 'bos_token_id', 'eos_token_id', 'unk_token_id', 'sep_token_id', 'cls_token_id', 'mask_token_id']\n","    for token in special_tokens:\n","        if getattr(tokenizer, token) is None:\n","            setattr(tokenizer, token, tokenizer.eos_token_id)\n","    return tokenizer\n","\n","def preprocess_function(examples, tokenizer, max_length, columns):\n","    # Check for missing columns\n","    missing_columns = [col for col in columns if col not in examples]\n","    if missing_columns:\n","        raise ValueError(f\"Missing columns: {missing_columns} in the examples\")\n","\n","    concatenated_texts = []\n","    # Iterate over multiple lists using zip()\n","    for texts in zip(*[examples[col] for col in columns]):\n","        # Concatenate all the column texts for each example\n","        text = ' '.join(str(t) for t in texts)\n","        concatenated_texts.append(text)\n","\n","\n","    # Tokenize the concatenated texts\n","    tokenized_outputs = tokenizer(concatenated_texts, padding='max_length', truncation=True, max_length=max_length)\n","    tokenized_outputs [\"labels\"] = tokenized_outputs [\"input_ids\"].copy()\n","    return dict(tokenized_outputs)\n","\n","# Example of loading a dataset and preprocessing it\n","dataset = advanced_data_loader({'train': '/content/drive/MyDrive/MetaMathQA-395K.csv', 'test': '/content/drive/MyDrive/MetaMathQA-395K.csv'}, 'csv')\n","# dataset=advanced_data_loader(\"fka/awesome-chatgpt-prompts\")\n","if dataset:\n","    tokenizer = create_tokenizer()\n","    columns = dataset['train'].column_names\n","    processed_datasets = dataset['train'].map(\n","        lambda examples: preprocess_function(examples=examples, tokenizer=tokenizer, max_length=128, columns=columns),\n","        batched=True,\n","        num_proc=1,\n","        remove_columns=columns,\n","        load_from_cache_file=False,\n","        desc=\"Running tokenizer on dataset\",\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31367,"status":"ok","timestamp":1706528628793,"user":{"displayName":"hemanth varma","userId":"05483789954770220327"},"user_tz":-330},"id":"pmSvmFPr63iQ","outputId":"08022b33-77a9-4ef7-da68-c1aa3ec97a37"},"outputs":[{"name":"stdout","output_type":"stream","text":["[1532, 262, 3650, 13339, 257, 10147, 329, 720, 1238, 290, 6673, 257, 1542, 4, 7630, 10330, 11, 475, 262, 10147, 318, 3058, 319, 5466, 329, 2026, 4, 572, 262, 6301, 2756, 11, 644, 318, 262, 1459, 2756, 286, 262, 10147, 30, 402, 12310, 62, 6207, 11840, 839, 383, 3650, 8155, 262, 10147, 329, 720, 1238, 290, 2087, 257, 1542, 4, 7630, 10330, 11, 523, 262, 6301, 2756, 878, 262, 9780, 318, 720, 1238, 1343, 7198, 1238, 1635, 657, 13, 1270, 8, 796, 720, 1238, 1343, 720, 21, 796, 720, 2075, 13, 198, 464, 10147, 318, 3058, 319, 5466, 329, 2026, 4, 572, 11, 523, 262, 9780, 2033, 318, 720, 2075, 1635, 657, 13, 1120, 796, 720, 1485, 13, 198, 464, 1459, 2756, 286, 262, 10147, 318, 262, 6301]\n"]}],"source":["print(processed_datasets['labels'][0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"amooKMjLzYDn"},"outputs":[],"source":["\n","from typing import Union, Dict, Optional\n","from datasets import load_dataset, DatasetDict\n","from transformers import (\n","    AutoModelForCausalLM,\n","    AutoTokenizer,\n","    default_data_collator,\n","    get_linear_schedule_with_warmup,\n","    set_seed,\n",")\n","import multiprocessing\n","import warnings\n","import torch\n","from torch.utils.data import DataLoader\n","batch_size=16\n","train_dataloader = DataLoader(\n","         processed_datasets, shuffle=True, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":479,"status":"ok","timestamp":1706529140192,"user":{"displayName":"hemanth varma","userId":"05483789954770220327"},"user_tz":-330},"id":"-HGFKA3DD6kP","outputId":"12c4bcc0-3590-417f-dff8-c96ad4205a09"},"outputs":[{"data":{"text/plain":["{'input_ids': tensor([[ 1532, 23386,  7317,  ..., 50256, 50256, 50256],\n","         [35475,  2227,   284,  ...,  1321,  1813,    25],\n","         [  464,  2811,   286,  ...,  2160,  2229,   477],\n","         ...,\n","         [ 1532, 18496,   460,  ...,   198,  4242,  2310],\n","         [ 9771,  3129,   378,  ..., 50256, 50256, 50256],\n","         [ 2514,  4911,  1160,  ...,  7029,    12, 11645]]),\n"," 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n","         [1, 1, 1,  ..., 1, 1, 1],\n","         [1, 1, 1,  ..., 1, 1, 1],\n","         ...,\n","         [1, 1, 1,  ..., 1, 1, 1],\n","         [1, 1, 1,  ..., 0, 0, 0],\n","         [1, 1, 1,  ..., 1, 1, 1]]),\n"," 'labels': tensor([[ 1532, 23386,  7317,  ..., 50256, 50256, 50256],\n","         [35475,  2227,   284,  ...,  1321,  1813,    25],\n","         [  464,  2811,   286,  ...,  2160,  2229,   477],\n","         ...,\n","         [ 1532, 18496,   460,  ...,   198,  4242,  2310],\n","         [ 9771,  3129,   378,  ..., 50256, 50256, 50256],\n","         [ 2514,  4911,  1160,  ...,  7029,    12, 11645]])}"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["import os\n","from transformers import AdamW\n","from tqdm.auto import tqdm\n","\n","# Set the seed for reproducibility\n","set_seed(42)\n","\n","# Check if a GPU is available and use CPU otherwise\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Load the model\n","model_name_or_path = \"gpt2\"\n","model = AutoModelForCausalLM.from_pretrained(model_name_or_path).to(device)\n","\n","# Prepare optimizer and schedule (linear warm-up and decay)\n","no_decay = [\"bias\", \"LayerNorm.weight\"]\n","optimizer_grouped_parameters = [\n","    {\n","        \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n","        \"weight_decay\": 0.0,\n","    },\n","    {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n","]\n","\n","optimizer = AdamW(optimizer_grouped_parameters, lr=5e-5)\n","\n","num_epochs = 3\n","num_training_steps = num_epochs * len(train_dataloader)\n","lr_scheduler = get_linear_schedule_with_warmup(\n","    optimizer,\n","    num_warmup_steps=0,\n","    num_training_steps=num_training_steps\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["bf78a7b1e66f4f6aa6f26450bb6314b3","42f184d93e1740b3aae296e6ca42ebc7","24d248d3e4fb4fb6b5e11a12b30662c8","6b5bc9c04c194838aac22e8f041461d6","ab7260fe494f469da37f654555282a60","ea1c803f9065486b8eb399e311d47d09","7f2255f5df1245b1b391332d9834e07d","79ea88bea71f45f0960f678f107d9d07","8eea0de02cf349fa897ec1cda8a4667e","7b1e9398d40344f592779b101d09c874","b92e16f9491045ba98eded6d34318024","7786378dd3f443c1bce8ce094e9e7b65","4656f14044264b379508976777caf7b1","64a05846a0c34a66a69d5376fafe6335","b49e04d6811040a4a0c74803918ea881","d4bc306133fd4f44b4c6a76815bfeeaa","f6da555cd0bb44ec8bd629c2868814ad","a2989aee0d4943848233bed9f0928be8","d2947540aeac4fd3af421283a17818c1","c25c354130e64329bc9f4e79cc2470a1","778e273172054af182d83b29902bd40f","223f81638c804cb19bcfe35b4f2671c3"]},"executionInfo":{"elapsed":60620,"status":"ok","timestamp":1706529402568,"user":{"displayName":"hemanth varma","userId":"05483789954770220327"},"user_tz":-330},"id":"vUUghjLVEzK4","outputId":"e95466fb-6e6e-41ee-bef4-207b311c4c4a"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bf78a7b1e66f4f6aa6f26450bb6314b3","version_major":2,"version_minor":0},"text/plain":["Running tokenizer on dataset:   0%|          | 0/39500 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7786378dd3f443c1bce8ce094e9e7b65","version_major":2,"version_minor":0},"text/plain":["Running tokenizer on dataset:   0%|          | 0/39500 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["processed_datasets_eval = dataset['eval'].map(\n","    lambda examples: preprocess_function(examples=examples, tokenizer=tokenizer, max_length=128, columns=columns),\n","    batched=True,\n","    num_proc=1,\n","    remove_columns=columns,\n","    load_from_cache_file=False,\n","    desc=\"Running tokenizer on dataset\",\n",")\n","eval_dataloader = DataLoader(\n","       processed_datasets_eval, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True\n","    )\n","\n","processed_datasets_test = dataset['test'].map(\n","    lambda examples: preprocess_function(examples=examples, tokenizer=tokenizer, max_length=128, columns=columns),\n","    batched=True,\n","    num_proc=1,\n","    remove_columns=columns,\n","    load_from_cache_file=False,\n","    desc=\"Running tokenizer on dataset\",\n",")\n","test_dataloader = DataLoader(\n","        processed_datasets_test, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True\n","    )\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5145,"status":"ok","timestamp":1706521413429,"user":{"displayName":"hemanth varma","userId":"05483789954770220327"},"user_tz":-330},"id":"3NchVshcIhUo","outputId":"d53aa79f-4013-4ada-bbd2-4d0b4dffa305"},"outputs":[{"name":"stdout","output_type":"stream","text":["Splits:  dict_keys(['train', 'test', 'eval'])\n","Columns:  {'train': ['query', 'type', 'response'], 'test': ['query', 'type', 'response'], 'eval': ['query', 'type', 'response']}\n","DatasetDict({\n","    train: Dataset({\n","        features: ['query', 'type', 'response'],\n","        num_rows: 316000\n","    })\n","    test: Dataset({\n","        features: ['query', 'type', 'response'],\n","        num_rows: 39500\n","    })\n","    eval: Dataset({\n","        features: ['query', 'type', 'response'],\n","        num_rows: 39500\n","    })\n","})\n"]}],"source":["# For a dataset from Hugging Face\n","# advanced_data_loader('name_of_dataset')\n","\n","# For a local CSV file\n","dataset=advanced_data_loader({'train': '/content/drive/MyDrive/MetaMathQA-395K.csv', 'test': '/content/drive/MyDrive/MetaMathQA-395K.csv'}, 'csv')\n","print(dataset)\n","# For a local JSON file\n","# advanced_data_loader({'train': 'path_to_train.json', 'test': 'path_to_test.json'}, 'json')\n","\n","# For a local folder\n","# advanced_data_loader('path_to_your_folder', 'text')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":158},"executionInfo":{"elapsed":872,"status":"error","timestamp":1706521717085,"user":{"displayName":"hemanth varma","userId":"05483789954770220327"},"user_tz":-330},"id":"igzJHmRNcrUd","outputId":"b5bd50e6-8662-41a4-df54-af6ba96bf9c4"},"outputs":[{"ename":"SyntaxError","evalue":"expression cannot contain assignment, perhaps you meant \"==\"? (<ipython-input-3-6d86c5cb460e>, line 6)","output_type":"error","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-6d86c5cb460e>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    lambda examples: examples=dataset['train'],tokenizer=tokenizer,max_length=128,columns=dataset['train'].column_names,\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expression cannot contain assignment, perhaps you meant \"==\"?\n"]}],"source":["dataset=advanced_data_loader({'train': '/content/drive/MyDrive/MetaMathQA-395K.csv', 'test': '/content/drive/MyDrive/MetaMathQA-395K.csv'}, 'csv')\n","# print(dataset)\n","\n","import multiprocessing\n","processed_datasets = dataset['train'].map(\n","    lambda examples: examples=dataset['train'],tokenizer=tokenizer,max_length=128,columns=dataset['train'].column_names,\n","    batched=True,\n","    num_proc=multiprocessing.cpu_count(),\n","    remove_columns=columns,\n","    load_from_cache_file=False,\n","    desc=\"Running tokenizer on dataset\",\n",")\n","# Create the tokenizer\n","tokenizer = create_tokenizer('gpt2')\n","print(dataset['train'].column_names)\n","# # Preprocess the dataset\n","preprocessed_dataset = preprocess_function(examples=dataset['train'],tokenizer=tokenizer,max_length=512,columns=dataset['train'].column_names)\n","\n","# # Create the data loaders\n","# data_loaders = create_data_loaders(preprocessed_dataset, batch_size=32)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cSEyaka-hZi0"},"outputs":[],"source":["import multiprocessing\n","processed_datasets = dataset['train'].map(\n","    lambda examples: examples=dataset['train'],tokenizer=tokenizer,max_length=512,columns=dataset['train'].column_names,\n","    batched=True,\n","    num_proc=multiprocessing.cpu_count(),\n","    remove_columns=columns,\n","    load_from_cache_file=False,\n","    desc=\"Running tokenizer on dataset\",\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CE5zVgUMivfZ"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yOYbs1-FkLbf"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":84,"referenced_widgets":["d21c425ecd7a414d86c3940c8791ed8e","012d41c2709e4d649236795fd8e7ff0e","764373327b3241658360fbea9aa808f0","f63c0ef9395a46479f0f963a1b9a5f0a","928ab9c982fc4c5891850aeefa902695","91440c88c0cf46939ed7a7a358199efb","f7f92e16ed1a47feb4a9107251bd621b","95c9bbbf4f904e40afbb24b684ec9f79","29c2dfea3c4046e3a35b03759699802d","ecfc300a59d14654aa4eb783cb48b176","0b990681454b44a0b244905ddae4b076"]},"executionInfo":{"elapsed":1164,"status":"ok","timestamp":1706519189136,"user":{"displayName":"hemanth varma","userId":"05483789954770220327"},"user_tz":-330},"id":"bWzyYCevd2v2","outputId":"7644e1bd-21db-4f2b-f5e1-9799120499b0"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d21c425ecd7a414d86c3940c8791ed8e","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/316000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Error preprocessing dataset: 'text'\n","Error creating data loaders: name 'preprocessed_dataset' is not defined\n"]}],"source":["import warnings\n","from typing import Union, Dict, Optional\n","from datasets import load_dataset, DatasetDict\n","from transformers import AutoTokenizer, PreTrainedTokenizerBase\n","from torch.utils.data import DataLoader\n","\n","def advanced_data_loader(input: Union[str, Dict[str, str]], format: Optional[str] = None, split_ratios: Optional[Dict[str, float]] = None) -> Optional[DatasetDict]:\n","    if split_ratios is None:\n","        split_ratios = {'train': 0.8, 'test': 0.1, 'eval': 0.1}\n","\n","    try:\n","        if isinstance(input, dict) and format in ['csv', 'json']:\n","            dataset = load_dataset(format, data_files=input)\n","        elif isinstance(input, str) and format == 'text':\n","            dataset = load_dataset(format, data_dir=input)\n","        elif isinstance(input, str) and format is None:\n","            dataset = load_dataset(input)\n","        else:\n","            warnings.warn(\"Invalid input or format. Please provide a valid dataset name, directory, or file paths.\")\n","            return None\n","    except FileNotFoundError as e:\n","        warnings.warn(str(e))\n","        return None\n","\n","    if dataset:\n","        split_dataset = dataset['train'].train_test_split(test_size=split_ratios['test'] + split_ratios['eval'])\n","        test_eval_dataset = split_dataset['test'].train_test_split(test_size=split_ratios['eval'] / (split_ratios['test'] + split_ratios['eval']))\n","        dataset = DatasetDict({\n","            'train': split_dataset['train'],\n","            'test': test_eval_dataset['train'],\n","            'eval': test_eval_dataset['test']\n","        })\n","\n","    return dataset\n","\n","def create_tokenizer(model_name_or_path: str = 'gpt2') -> AutoTokenizer:\n","    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n","    if tokenizer.pad_token_id is None:\n","        tokenizer.pad_token_id = tokenizer.eos_token_id\n","    return tokenizer\n","\n","def preprocess_datasets(datasets: DatasetDict, tokenizer: PreTrainedTokenizerBase, text_column: str, label_column: str, max_length: int, padding: str = 'max_length', truncation: bool = True) -> DatasetDict:\n","    def tokenize_function(examples):\n","        text = examples[text_column]\n","        labels = examples[label_column]\n","        tokenized_inputs = tokenizer(text, padding=padding, truncation=truncation, max_length=max_length)\n","        tokenized_labels = tokenizer(labels, padding=padding, truncation=truncation, max_length=max_length)\n","        tokenized_inputs['input_ids'] += tokenized_labels['input_ids']\n","        tokenized_inputs['attention_mask'] += tokenized_labels['attention_mask']\n","        return tokenized_inputs\n","\n","    return datasets.map(tokenize_function, batched=True)\n","\n","def create_data_loaders(datasets: DatasetDict, batch_size: int) -> Dict[str, DataLoader]:\n","    return {split: DataLoader(datasets[split], batch_size=batch_size) for split in datasets.keys()}\n","\n","# Load the dataset\n","try:\n","    dataset = advanced_data_loader({'train': '/content/drive/MyDrive/MetaMathQA-395K.csv', 'test': '/content/drive/MyDrive/MetaMathQA-395K.csv'}, 'csv')\n","except Exception as e:\n","    print(f\"Error loading dataset: {e}\")\n","    exit(1)\n","\n","# Create the tokenizer\n","try:\n","    tokenizer = create_tokenizer('gpt2')\n","except Exception as e:\n","    print(f\"Error creating tokenizer: {e}\")\n","    exit(1)\n","\n","# Preprocess the dataset\n","try:\n","    preprocessed_dataset = preprocess_datasets(dataset, tokenizer, text_column='text', label_column='response', max_length=128)\n","except Exception as e:\n","    print(f\"Error preprocessing dataset: {e}\")\n","    exit(1)\n","\n","# Create the data loaders\n","try:\n","    data_loaders = create_data_loaders(preprocessed_dataset, batch_size=32)\n","except Exception as e:\n","    print(f\"Error creating data loaders: {e}\")\n","    exit(1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yAbCtdtlG-aZ"},"outputs":[],"source":["\n","# Create the tokenizer\n","tokenizer = create_tokenizer(model_name_or_path='gpt2')\n","\n","# Preprocess the data\n","preprocessed_dataset = preprocess_data(dataset, tokenizer, max_length=512)\n","\n","# Print the preprocessed data\n","print(preprocessed_dataset)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BwJtbt4-G-Ww"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dSfPJcLOG-UK"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rMK8aHVvG-Ri"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x5EwUrspG-PN"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xr2hEV8LG-MY"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"72MBzpMjG-Jq"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v6xnVwOTG-G8"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qvQlaytiG-EW"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CazemspUG-B0"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Up0f5V6XG98d"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_WUXj2GlG9xi"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N8STrI-iG9u8"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tyRgg0MyG9sX"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WZO165omG9p_"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nwC5c9JyG9nW"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uHmcYIWHG9kk"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q5NqtUQyG9h6"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KaGqlxcZG9fZ"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p7vDxP_HG9c5"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ixElIevtG9aa"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gur9VxZZG9YA"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YMPQ1nwUfMGW"},"outputs":[],"source":["from transformers import AutoTokenizer\n","\n","# Define the tokenizer\n","tokenizer = AutoTokenizer.from_pretrained('gpt2')\n","\n","# Check if the tokenizer has a padding token, and if not, set it to the EOS token\n","if tokenizer.pad_token_id is None:\n","    tokenizer.pad_token_id = tokenizer.eos_token_id\n","\n","# Check if the tokenizer has a bos (beginning of sentence) token, and if not, set it\n","if tokenizer.bos_token_id is None:\n","    tokenizer.bos_token_id = tokenizer.pad_token_id\n","\n","# Check if the tokenizer has an eos (end of sentence) token, and if not, set it\n","if tokenizer.eos_token_id is None:\n","    tokenizer.eos_token_id = tokenizer.pad_token_id\n","\n","# Check if the tokenizer has a unk (unknown) token, and if not, set it\n","if tokenizer.unk_token_id is None:\n","    tokenizer.unk_token_id = tokenizer.pad_token_id\n","\n","# Check if the tokenizer has a sep (separator) token, and if not, set it\n","if tokenizer.sep_token_id is None:\n","    tokenizer.sep_token_id = tokenizer.pad_token_id\n","\n","# Check if the tokenizer has a cls (classification) token, and if not, set it\n","if tokenizer.cls_token_id is None:\n","    tokenizer.cls_token_id = tokenizer.pad_token_id\n","\n","# Check if the tokenizer has a mask (masking) token, and if not, set it\n","if tokenizer.mask_token_id is None:\n","    tokenizer.mask_token_id = tokenizer.pad_token_id\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":252,"referenced_widgets":["584fbf5d820a4e1baa3626764f21c362","8ad84df3b2ca4bf4813eb1d776ccc5ec","0c023c51cc674c6eaba1b4fd40ac3bfc","c467941570764d00a3625d73e897b504","f99c38bcadc34204b04506b6a9334fb8","221f0f1d33884504b12fb2bc34030214","be974a557b354fe3888e06a2140888bf","cd16f5616b7848a8a884149aff371d30","0b9a692a4f6e4ed0a13a95cfa5c1b49a","971f6639a3904092ace257c035e1fe73","b7d594c37b724e1d95a94ad92b5df379","9638a1305f7e4ba89d26f3d24274e0a1","1ddc282a1a6345688ee16dde947210b0","bb5775e233614278bb9b97c43466bfc9","143d05a70ce440d5a02731662a226235","dfdf4fff0c76485ab9a62afbf0d49eae","74f856199806447b870eb0c79961b0e5","7c28c799250a40169341d4e0adef2312","4fa48ac8650b4922b64630d79a41065b","8a78fe1ec72f4cb680f03b6e2a9b21c6","741ec9096bc0446493840207f5533fed","f7eb655f775e49eebc21e4492a381e74","d85f0be2132d435db97847e39ce04644","1e1894243d0f4eaa878d224dfe71fa2a","88455d140d0f4e4a8305b41aca772087","f1171cfc90d241f5b0d7449517ce82b5","16d18eee5ee147fb83f6678860e3f25c","130a2e2d27654cbc8acd52975432a87a","6c236ab9a98c44399d6808296d2aff7f","aca5cea704a94c5c88850badc0938b18","b592134efbdd43ec8d852ec9155c0396","466cbe7eabf54a5ca15a14c266441ec4","bf711dbbb5994d42bbf2c8ec797e914d"]},"executionInfo":{"elapsed":6945,"status":"ok","timestamp":1705938683145,"user":{"displayName":"hemanth varma","userId":"05483789954770220327"},"user_tz":-330},"id":"SJ8Rbt9-3aqQ","outputId":"e888a401-a605-49e0-80b2-5ad66a399057"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"584fbf5d820a4e1baa3626764f21c362","version_major":2,"version_minor":0},"text/plain":["Downloading readme:   0%|          | 0.00/274 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9638a1305f7e4ba89d26f3d24274e0a1","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/74.6k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d85f0be2132d435db97847e39ce04644","version_major":2,"version_minor":0},"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Splits: ['train']\n","Columns for train: ['act', 'prompt']\n"]}],"source":["from datasets import load_dataset\n","\n","# Load the dataset\n","dataset = load_dataset(\"fka/awesome-chatgpt-prompts\")\n","\n","# Get the splits\n","splits = list(dataset.keys())\n","print(f\"Splits: {splits}\")\n","\n","# Get the columns for each split\n","for split in splits:\n","    columns = dataset[split].column_names\n","    print(f\"Columns for {split}: {columns}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nOp8CkmgpGdX"},"outputs":[],"source":["import os\n","import warnings\n","import multiprocessing\n","import torch\n","import torch.nn as nn\n","\n","from typing import Union, List, Dict\n","from datasets import load_dataset\n","from torch.utils.data import DataLoader\n","from transformers import default_data_collator, get_linear_schedule_with_warmup\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","\n","def create_tokenizer(model_name_or_path: str = 'gpt2') -> AutoTokenizer:\n","    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n","    if tokenizer.pad_token_id is None:\n","        tokenizer.pad_token_id = tokenizer.eos_token_id\n","    return tokenizer\n","\n","def advanced_data_loader(input: Union[str, dict], format: str = None):\n","    if isinstance(input, dict):\n","        if format in ['csv', 'json']:\n","            try:\n","                dataset = load_dataset(format, data_files=input)\n","            except FileNotFoundError:\n","                warnings.warn(\"File not found. Please check your file path.\")\n","                return None\n","        else:\n","            warnings.warn(\"Invalid format. Please choose 'csv' or 'json'.\")\n","            return None\n","    elif isinstance(input, str):\n","        if format == 'text':\n","            if os.path.isdir(input):\n","                try:\n","                    dataset = load_dataset(format, data_dir=input)\n","                except FileNotFoundError:\n","                    warnings.warn(\"Directory not found. Please check your folder path.\")\n","                    return None\n","            else:\n","                warnings.warn(\"Invalid directory. Please check your folder path.\")\n","                return None\n","        elif format is None:\n","            try:\n","                dataset = load_dataset(input)\n","            except FileNotFoundError:\n","                warnings.warn(\"Dataset not found. Please check your dataset name.\")\n","                return None\n","        else:\n","            warnings.warn(\"Invalid input. Please enter a valid dataset name or folder path.\")\n","            return None\n","    else:\n","        warnings.warn(\"Invalid input type. Please enter a string (for dataset name or folder) or a dictionary (for CSV or JSON files).\")\n","        return None\n","    print(\"Splits: \", dataset.keys())\n","    print(\"Columns: \", dataset.column_names)\n","    return dataset\n","\n","def preprocess_function(examples, tokenizer, max_length, columns):\n","    input_ids = []\n","    attention_mask = []\n","\n","    for column in columns:\n","        text = list(str(examples[column]))\n","        tokenized_outputs = tokenizer(text, padding='max_length', truncation=True, max_length=max_length)\n","\n","        for i in range(len(tokenized_outputs['input_ids'])):\n","            row_tokens = tokenized_outputs['input_ids'][i]\n","            row_tokens = row_tokens[:max_length]\n","            row_tokens += [tokenizer.pad_token_id] * (max_length - len(row_tokens))\n","            input_ids.append(row_tokens)\n","\n","            row_attention_mask = [int(token != tokenizer.pad_token_id) for token in row_tokens]\n","            attention_mask.append(row_attention_mask)\n","\n","    model_inputs = {'input_ids': torch.tensor(input_ids), 'attention_mask': torch.tensor(attention_mask)}\n","    return model_inputs\n","\n","max_length = 512\n","model_name_or_path = 'gpt2'\n","batch_size = 16\n","\n","tokenizer = create_tokenizer(model_name_or_path)\n","dataset=advanced_data_loader('fka/awesome-chatgpt-prompts')\n","\n","# dataset = advanced_data_loader({'train': '/home/khemanth/LLMs_Models/Adversarial_data/data/dataset1.csv', 'test': '/home/khemanth/LLMs_Models/Adversarial_data/data/dataset1.csv'}, 'csv')\n","\n","split = list(dataset.keys())\n","columns = dataset[str(split[0])].column_names\n","processed_datasets = dataset.map(\n","    lambda examples: preprocess_function(examples, tokenizer, max_length, columns),\n","    batched=True,\n","    num_proc=multiprocessing.cpu_count(),\n","    remove_columns=columns,\n","    load_from_cache_file=False,\n","    desc=\"Running tokenizer on dataset\",\n",")\n","\n","train_dataset = processed_datasets[str(split[0])]\n","train_dataloader = DataLoader(\n","    train_dataset, shuffle=True, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True\n",")\n","\n","test_dataset = processed_datasets[str(split[0])]\n","test_dataloader = DataLoader(\n","    test_dataset, shuffle=True, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True\n",")\n","\n","model = AutoModelForCausalLM.from_pretrained('gpt2')\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)\n","\n","lr = 0.001\n","optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n","loss_fn = nn.CrossEntropyLoss()\n","\n","num_epochs = 2\n","for epoch in range(num_epochs):\n","    for batch in train_dataloader:\n","        batch = {k: v.to(device) for k, v in batch.items()}\n","        outputs = model(**batch)\n","        loss = loss_fn(outputs.logits.view(-1, outputs.logits.size(-1)), batch['input_ids'].view(-1))\n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":61789,"status":"ok","timestamp":1705589319284,"user":{"displayName":"hemanth varma","userId":"05483789954770220327"},"user_tz":-330},"id":"I10ldDRAYQhQ","outputId":"1a0d8bb5-96ce-4e1d-e773-e83c9f53d935"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.9/270.9 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.3/168.3 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install -q -U transformers accelerate evaluate deepspeed tqdm datasets peft"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":153,"referenced_widgets":["ca52c8bc8c6142fb8c9b1287c7c76f02","1cce0281c9b343ee94d805785c9b9eb7","5314a561638444c2acf6973c126184c6","38dc93cd639942a382310ba224290401","87c092f83b744cc68c8be592c76c0efc","783ea92abd1b445199b7bd39c7baf1d5","f0e1ef7242de4d81918640f934ef6dac","364914b801e44003bea00b92557094ec","b601e866490946dabf4295f290f02ffc","084dad79e6a74c39a6acfa878a01df92","e9bf16ab17154b1b9e26adda7cbc6d24"]},"executionInfo":{"elapsed":4526,"status":"ok","timestamp":1705596231446,"user":{"displayName":"hemanth varma","userId":"05483789954770220327"},"user_tz":-330},"id":"eAIimlJOIayR","outputId":"968e4858-134e-4c33-9f99-42279583998b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Splits:  dict_keys(['train'])\n","Columns:  {'train': ['act', 'prompt']}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ca52c8bc8c6142fb8c9b1287c7c76f02","version_major":2,"version_minor":0},"text/plain":["Running tokenizer on dataset (num_proc=2):   0%|          | 0/153 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["act\n","act\n","prompt\n","prompt\n"]}],"source":["import os\n","import warnings\n","import multiprocessing\n","import torch\n","from typing import Union\n","from datasets import load_dataset\n","from transformers import AutoTokenizer\n","# For a dataset from Hugging Face\n","# advanced_data_loader('name_of_dataset')\n","max_length=512\n","# Define the tokenizer\n","tokenizer = AutoTokenizer.from_pretrained('gpt2')\n","# For a local folder\n","# advanced_data_loader('path_to_your_folder', 'text')\n","def advanced_data_loader(input: Union[str, dict], format: str = None):\n","    # Check if input is a dictionary (for CSV and JSON files)\n","    if isinstance(input, dict or str):\n","        if format in ['csv', 'json']:\n","            try:\n","                dataset = load_dataset(format, data_files=input)\n","            except FileNotFoundError:\n","                warnings.warn(\"File not found. Please check your file path.\")\n","                return None\n","        else:\n","            warnings.warn(\"Invalid format. Please choose 'csv' or 'json'.\")\n","            return None\n","    # Check if input is a string (for dataset name or folder)\n","    elif isinstance(input, str):\n","        if format == 'text':\n","            if os.path.isdir(input):\n","                try:\n","                    dataset = load_dataset(format, data_dir=input)\n","                except FileNotFoundError:\n","                    warnings.warn(\"Directory not found. Please check your folder path.\")\n","                    return None\n","            else:\n","                warnings.warn(\"Invalid directory. Please check your folder path.\")\n","                return None\n","        elif format is None:\n","            try:\n","                dataset = load_dataset(input)\n","            except FileNotFoundError:\n","                warnings.warn(\"Dataset not found. Please check your dataset name.\")\n","                return None\n","        else:\n","            warnings.warn(\"Invalid input. Please enter a valid dataset name or folder path.\")\n","            return None\n","    else:\n","        warnings.warn(\"Invalid input type. Please enter a string (for dataset name or folder) or a dictionary (for CSV or JSON files).\")\n","        return None\n","\n","    print(\"Splits: \", dataset.keys())\n","    print(\"Columns: \", dataset.column_names)\n","    return dataset\n","if tokenizer.pad_token_id is None:\n","    tokenizer.pad_token_id = tokenizer.eos_token_id\n","# For a local CSV file\n","# dataset=advanced_data_loader({'train': '/content/drive/MyDrive/MetaMathQA-395K.json', 'test': '/content/drive/MyDrive/MetaMathQA-395K.json'}, 'json')\n","dataset=advanced_data_loader('fka/awesome-chatgpt-prompts')\n","# For a local JSON file\n","# advanced_data_loader({'train': 'path_to_train.json', 'test': 'path_to_test.json'}, 'json')\n","\n","\n","columns = dataset[str(list(dataset.keys())[0])].column_names\n","def preprocess_function(examples):\n","    # Initialize lists for input_ids and attention_mask\n","    input_ids = []\n","    attention_mask = []\n","\n","    # Iterate over each column\n","    for column in columns:\n","        print(column)\n","        # Tokenize the column\n","        tokenized_outputs = tokenizer(examples[column], padding='max_length', truncation=True, max_length=max_length)\n","\n","        for i in range(len(tokenized_outputs['input_ids'])):  # Number of examples\n","            row_tokens = tokenized_outputs['input_ids'][i]\n","            row_tokens = row_tokens[:max_length]  # Truncate to max_length if necessary\n","            row_tokens += [tokenizer.pad_token_id] * (max_length - len(row_tokens))  # Pad if necessary\n","            input_ids.append(row_tokens)\n","\n","            # Create a tensor for attention_mask based on input_ids\n","            row_attention_mask = [int(token != tokenizer.pad_token_id) for token in row_tokens]\n","            attention_mask.append(row_attention_mask)\n","\n","    # Convert input_ids and attention_mask to tensors\n","    model_inputs = {'input_ids': torch.tensor(input_ids), 'attention_mask': torch.tensor(attention_mask)}\n","    return model_inputs\n","\n","\n","# Map the preprocessing function across the entire dataset\n","processed_datasets = dataset.map(\n","    preprocess_function,\n","    batched=True,\n","    num_proc=multiprocessing.cpu_count(),\n","    remove_columns=columns,\n","    load_from_cache_file=False,\n","    desc=\"Running tokenizer on dataset\",\n",")\n","\n","from torch.utils.data import DataLoader\n","from transformers import default_data_collator, get_linear_schedule_with_warmup\n","\n","\n","train_dataset = processed_datasets[str(list(dataset.keys())[0])]\n","\n","batch_size=16\n","train_dataloader = DataLoader(\n","    train_dataset, shuffle=True, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":624,"status":"ok","timestamp":1705592254816,"user":{"displayName":"hemanth varma","userId":"05483789954770220327"},"user_tz":-330},"id":"C0OB6enUNCzf","outputId":"e81c6045-6d31-4e64-c901-a52d5ffa2f8e"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-17-31696bb12fd6>:34: UserWarning: Dataset not found. Please check your dataset name.\n","  warnings.warn(\"Dataset not found. Please check your dataset name.\")\n"]}],"source":["dataset=advanced_data_loader('/content/drive/MyDrive/MetaMathQA-395K.csv)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":355},"executionInfo":{"elapsed":388,"status":"error","timestamp":1705588651036,"user":{"displayName":"hemanth varma","userId":"05483789954770220327"},"user_tz":-330},"id":"IskL5nLWAAO3","outputId":"35378b97-c665-4df3-8462-88c4a8aecf4c"},"outputs":[{"ename":"NotADirectoryError","evalue":"[Errno 20] Not a directory: '/content/drive/MyDrive/training.csv'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-5369e4b43415>\u001b[0m in \u001b[0;36m<cell line: 73>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-3-5369e4b43415>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mlocal_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/training.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-5369e4b43415>\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(local_path)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: '/content/drive/MyDrive/training.csv'"]}],"source":["import os\n","import pandas as pd\n","import json\n","import torch\n","from transformers import AutoTokenizer\n","from typing import Dict, List, Union\n","import warnings\n","\n","def load_dataset(local_path: str) -> Dict[str, pd.DataFrame]:\n","    dataset = {}\n","    for file in os.listdir(local_path):\n","        file_path = os.path.join(local_path, file)\n","        try:\n","            if file.endswith('.csv'):\n","                dataset[file] = pd.read_csv(file_path, error_bad_lines=False, warn_bad_lines=True)\n","            elif file.endswith('.json'):\n","                with open(file_path, 'r') as f:\n","                    dataset[file] = pd.read_json(f)\n","            else:\n","                warnings.warn(f\"Unsupported file type: {file}\")\n","        except Exception as e:\n","            warnings.warn(f\"Error loading {file}: {str(e)}\")\n","    return dataset\n","\n","def preprocess_function(examples: Dict[str, pd.DataFrame], columns: List[str], tokenizer, max_length: int) -> Dict[str, torch.Tensor]:\n","    tokenized_outputs = {column: [] for column in columns}\n","    for column in columns:\n","        for example in examples.values():\n","            try:\n","                if column in example.columns:\n","                    column_tokens = tokenizer(example[column].tolist(), padding='max_length', truncation=True, max_length=max_length)\n","                    tokenized_outputs[column].extend(column_tokens['input_ids'])\n","                else:\n","                    warnings.warn(f\"Column {column} not found in dataset.\")\n","            except Exception as e:\n","                warnings.warn(f\"Error in tokenizing column {column}: {str(e)}\")\n","                continue\n","\n","    input_ids, attention_mask = [], []\n","    for i in range(len(tokenized_outputs[columns[0]])):  # Number of examples\n","        row_tokens = []\n","        for column in columns:\n","            row_tokens.extend(tokenized_outputs[column][i])\n","        row_tokens = row_tokens[:max_length]  # Truncate to max_length if necessary\n","        row_tokens += [tokenizer.pad_token_id] * (max_length - len(row_tokens))  # Pad if necessary\n","        input_ids.append(row_tokens)\n","\n","        row_attention_mask = [int(token != tokenizer.pad_token_id) for token in row_tokens]\n","        attention_mask.append(row_attention_mask)\n","\n","    model_inputs = {'input_ids': torch.tensor(input_ids), 'attention_mask': torch.tensor(attention_mask)}\n","    return model_inputs\n","\n","def main():\n","    local_path = '/content/drive/MyDrive/training.csv'\n","    dataset = load_dataset(local_path)\n","\n","    if not dataset:\n","        raise ValueError(\"No valid dataset found at the specified path.\")\n","\n","    columns = list(next(iter(dataset.values())).columns)\n","    max_length = 512\n","    model_name_or_path = \"gpt2\"\n","\n","    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n","    if tokenizer.pad_token_id is None:\n","        tokenizer.pad_token_id = tokenizer.eos_token_id\n","    tokenizer.padding_side = 'left'\n","\n","    # Assuming the dataset is a dictionary with keys as filenames and values as DataFrames\n","    model_inputs = preprocess_function(dataset, columns, tokenizer, max_length)\n","\n","if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":205,"referenced_widgets":["4e1414362ff54c3d8cc17c3ac4f3c2db","d3bf4280ce55434d8036816a199d6a51","bc55217731fb4984a588701eb009c3ca","548adba0a93842d4bb2ea761c85277d7","698e14ac93d442b8b8e415f43dee1ef0","e4a4bda583844cce9fc573eecab76e3b","df01a76a67674b5b865a33ac201cad8d","ad7a96ee3b7f4a57b8025662503b2d16","c2766a2d12114eb8b6f236a44cef33b2","b3fa3682c6ce402b8f61f19d51365a47","2370c63c477c41528d0c83bc141956b5","46c7bdbf5f744a7fb047299f2b97d976","51b41b79397944a2a9a63014a39238d8","71cadb0c5e6747ed95d3a0bede4f1077","4caad0d18906452da293c6f2c5b126fe","e09691124fcd4d5b9cd74f58782ad013","50951fe4d6f74d4db8eaf18516fd6abe","6a648ce76212466a93175e458a01aa83","3f9bc6d49ce54bf8b63eba51d9a20a49","8b167546c2cf49b6b9540a9350659ca5","1ea36f68f950405fb68d18323d8e610f","421ff935419c4c8bb0598512c56fbd42","b5e04037262749a992fe7b29be0c18e4","99eff6d3f17d4239a9225e5205e8a9aa","7341cdc51aa040b0b98ab5f1998253e3","364dd8c71e764141a3f54f8145c35f89","1c8a4b8813bd4530910fec96d2256801","691a02606aa74583ab01e16dfd1a8736","4ed79eeda328469fa05c12132653103c","00b6ccaf47b64f1eb6931e98709f5580","867d0b40895c4398a604638df2d42d98","93f65b48f30246918fdbba2f22f2404f","8e8694e9504b457f91add205c9483071","43705c4b0f7c47c183a336353299bcf3","b9c6aacfd11a42ec95b84a1e19c3b414","60602cb7db304c238392c750ed6eeba1","3b5bf3aa4a6e4ef68fd70c8b45ae177f","3e5ad6544d734d6d9d18b06bd2c62cb5","52f02ff4c7b5465986e8ec74b54fcbbe","c28be050deaa445987f3977e8128caf3","9ac770dfe1e4441eb6dd289ef9476673","1b963e8e113f42808a2c2eb2b9323516","359fc8b8ae9f4ffc9e5ece9118a842a9","753fc20470274ec781a83c0ceb9a9979","90e1d7b0a8ad410d815cf221c09c9f7a","7b25f5caaa56436c9640e8a027f323c5","120b58c9d7374ec1a179b7e61f975700","1035eb0d269c450a8c78f56a86451b86","9687edde9f19404f9fbd2236ec6bdbf5","58049287401e4c78977b7691eb91a9fe","a3d8998ece0d4124ac2b20140c4eb4c0","355f77e65f1a45c9a626e24169593ff7","eaaf536961034721bf2fc069b78e73bc","221481c5297042e89936ee8d923475f7","add9a3b0c00f4a7a8abc40d5d3d7240f"]},"id":"1Gxlax2aAN_O","outputId":"6c4bd42a-8acf-4fd9-8ac7-6b6fc9f6020f"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4e1414362ff54c3d8cc17c3ac4f3c2db","version_major":2,"version_minor":0},"text/plain":["Downloading readme:   0%|          | 0.00/12.0k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"46c7bdbf5f744a7fb047299f2b97d976","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/1.01G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b5e04037262749a992fe7b29be0c18e4","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"43705c4b0f7c47c183a336353299bcf3","version_major":2,"version_minor":0},"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"90e1d7b0a8ad410d815cf221c09c9f7a","version_major":2,"version_minor":0},"text/plain":["Running tokenizer on dataset (num_proc=2):   0%|          | 0/4233923 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["import gc\n","import os\n","import sys\n","import threading\n","import multiprocessing\n","import numpy as np\n","import psutil\n","import torch\n","from accelerate import Accelerator\n","from datasets import load_dataset\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","from transformers import (\n","    AutoModelForCausalLM,\n","    AutoTokenizer,\n","    default_data_collator,\n","    get_linear_schedule_with_warmup,\n","    set_seed,\n",")\n","\n","from peft import LoraConfig, TaskType, get_peft_model\n","\n","\n","def levenshtein_distance(str1, str2):\n","    # TC: O(N^2)\n","    # SC: O(N^2)\n","    if str1 == str2:\n","        return 0\n","    num_rows = len(str1) + 1\n","    num_cols = len(str2) + 1\n","    dp_matrix = np.empty((num_rows, num_cols))\n","    dp_matrix[0, :] = range(num_cols)\n","    dp_matrix[:, 0] = range(num_rows)\n","\n","    for i in range(1, num_rows):\n","        for j in range(1, num_cols):\n","            if str1[i - 1] == str2[j - 1]:\n","                dp_matrix[i, j] = dp_matrix[i - 1, j - 1]\n","            else:\n","                dp_matrix[i, j] = min(dp_matrix[i - 1, j - 1], dp_matrix[i - 1, j], dp_matrix[i, j - 1]) + 1\n","\n","    return dp_matrix[num_rows - 1, num_cols - 1]\n","\n","\n","def get_closest_label(eval_pred, classes):\n","    min_id = sys.maxsize\n","    min_edit_distance = sys.maxsize\n","    for i, class_label in enumerate(classes):\n","        edit_distance = levenshtein_distance(eval_pred.strip(), class_label)\n","        if edit_distance < min_edit_distance:\n","            min_id = i\n","            min_edit_distance = edit_distance\n","    return classes[min_id]\n","\n","\n","# Converting Bytes to Megabytes\n","def b2mb(x):\n","    return int(x / 2**20)\n","\n","\n","# This context manager is used to track the peak memory usage of the process\n","class TorchTracemalloc:\n","    def __enter__(self):\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        torch.cuda.reset_max_memory_allocated()  # reset the peak gauge to zero\n","        self.begin = torch.cuda.memory_allocated()\n","        self.process = psutil.Process()\n","\n","        self.cpu_begin = self.cpu_mem_used()\n","        self.peak_monitoring = True\n","        peak_monitor_thread = threading.Thread(target=self.peak_monitor_func)\n","        peak_monitor_thread.daemon = True\n","        peak_monitor_thread.start()\n","        return self\n","\n","    def cpu_mem_used(self):\n","        \"\"\"get resident set size memory for the current process\"\"\"\n","        return self.process.memory_info().rss\n","\n","    def peak_monitor_func(self):\n","        self.cpu_peak = -1\n","\n","        while True:\n","            self.cpu_peak = max(self.cpu_mem_used(), self.cpu_peak)\n","\n","            # can't sleep or will not catch the peak right (this comment is here on purpose)\n","            # time.sleep(0.001) # 1msec\n","\n","            if not self.peak_monitoring:\n","                break\n","\n","    def __exit__(self, *exc):\n","        self.peak_monitoring = False\n","\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        self.end = torch.cuda.memory_allocated()\n","        self.peak = torch.cuda.max_memory_allocated()\n","        self.used = b2mb(self.end - self.begin)\n","        self.peaked = b2mb(self.peak - self.begin)\n","\n","        self.cpu_end = self.cpu_mem_used()\n","        self.cpu_used = b2mb(self.cpu_end - self.cpu_begin)\n","        self.cpu_peaked = b2mb(self.cpu_peak - self.cpu_begin)\n","        # print(f\"delta used/peak {self.used:4d}/{self.peaked:4d}\")\n","\n","\n","\n","\n","def main():\n","    accelerator = Accelerator()\n","    dataset_name='Open-Orca/OpenOrca'\n","    dataset = load_dataset(dataset_name)\n","    columns = dataset[str(list(dataset.keys())[0])].column_names\n","    max_length = 512\n","    model_name_or_path = \"gpt2\"\n","    peft_config = LoraConfig(task_type=TaskType.CAUSAL_LM, inference_mode=False, r=8, lora_alpha=32, lora_dropout=0.1)\n","    lr = 3e-3\n","    num_epochs = 20\n","    batch_size = 8\n","    seed = 42\n","    max_length = 64\n","    do_test = False\n","    set_seed(seed)\n","    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n","    if tokenizer.pad_token_id is None:\n","\n","      tokenizer.pad_token_id = tokenizer.eos_token_id\n","    # Set the padding_side to 'left'\n","    tokenizer.padding_side = 'left'\n","\n","\n","    def preprocess_function(examples):\n","        # Tokenize each column separately and concatenate their token IDs.\n","        tokenized_outputs = {}\n","        for column in columns:\n","            column_tokens = tokenizer(examples[column], padding='max_length', truncation=True, max_length=max_length)\n","            tokenized_outputs[column] = column_tokens['input_ids']\n","        # Create a tensor for input_ids by concatenating the tokens from each column\n","        input_ids = []\n","        for i in range(len(tokenized_outputs[columns[0]])):  # Number of examples\n","            row_tokens = []\n","            for column in columns:\n","                row_tokens.extend(tokenized_outputs[column][i])\n","            row_tokens = row_tokens[:max_length]  # Truncate to max_length if necessary\n","            row_tokens += [tokenizer.pad_token_id] * (max_length - len(row_tokens))  # Pad if necessary\n","            input_ids.append(row_tokens)\n","        # Create a tensor for attention_mask based on input_ids\n","        attention_mask = []\n","        for i in range(len(input_ids)):\n","            row_attention_mask = []\n","            for token in input_ids[i]:\n","                row_attention_mask.append(int(token != tokenizer.pad_token_id))\n","            attention_mask.append(row_attention_mask)\n","        # Convert input_ids and attention_mask to tensors\n","        model_inputs = {'input_ids': torch.tensor(input_ids), 'attention_mask': torch.tensor(attention_mask)}\n","        return model_inputs\n","\n","    with accelerator.main_process_first():\n","        processed_datasets = dataset.map(\n","            preprocess_function,\n","            batched=True,\n","            num_proc=multiprocessing.cpu_count(),\n","            remove_columns=columns,\n","            load_from_cache_file=False,\n","            desc=\"Running tokenizer on dataset\",\n","          )\n","\n","    accelerator.wait_for_everyone()\n","\n","    train_dataset = processed_datasets[str(list(processed_datasets.keys())[0])]\n","    eval_dataset_name = str(list(processed_datasets.keys())[0])\n","    eval_dataset = processed_datasets[eval_dataset_name]\n","    test_dataset_name = str(list(processed_datasets.keys())[0])\n","    test_dataset = processed_datasets[test_dataset_name]\n","\n","    train_dataloader = DataLoader(\n","        train_dataset, shuffle=True, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True\n","    )\n","    eval_dataloader = DataLoader(\n","        eval_dataset, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True\n","    )\n","    test_dataloader = DataLoader(\n","        test_dataset, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True\n","    )\n","\n","\n","    model = AutoModelForCausalLM.from_pretrained(model_name_or_path)\n","    model.config.eos_token_id = tokenizer.pad_token_id\n","    model = get_peft_model(model, peft_config)\n","    model.print_trainable_parameters()\n","\n","    # optimizer\n","    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n","\n","    # lr scheduler\n","    lr_scheduler = get_linear_schedule_with_warmup(\n","        optimizer=optimizer,\n","        num_warmup_steps=0,\n","        num_training_steps=(len(train_dataloader) * num_epochs),\n","    )\n","\n","    model, train_dataloader, eval_dataloader, test_dataloader, optimizer, lr_scheduler = accelerator.prepare(\n","        model, train_dataloader, eval_dataloader, test_dataloader, optimizer, lr_scheduler\n","    )\n","\n","    is_ds_zero_3 = False\n","    if getattr(accelerator.state, \"deepspeed_plugin\", None):\n","        is_ds_zero_3 = accelerator.state.deepspeed_plugin.zero_stage == 3\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        for batch in train_dataloader:\n","            # Shift input_ids to the right to create labels\n","            batch['labels'] = batch['input_ids'][:, 1:].clone().detach()\n","            batch['input_ids'] = batch['input_ids'][:, :-1].clone().detach()\n","\n","            # Apply the attention mask to the labels as well, setting labels for padded tokens to -100\n","            # so that they are not taken into account for loss computation\n","            batch['labels'] = torch.where(\n","                batch['attention_mask'][:, 1:] == 1,\n","                batch['labels'],\n","                torch.tensor(-100).type_as(batch['labels'])\n","            )\n","\n","            # Update the attention mask to reflect the shifted input_ids\n","            batch['attention_mask'] = batch['attention_mask'][:, :-1].clone().detach()\n","\n","            # Send the batch through the model\n","            outputs = model(**batch)\n","\n","            # outputs.loss should not be None as long as 'labels' are provided\n","            loss = outputs.loss\n","            if loss is None:\n","                raise ValueError(\"Loss is None - check if the model's forward pass outputs a loss\")\n","\n","            # Perform backward pass and optimization step\n","            accelerator.backward(loss)\n","            optimizer.step()\n","            lr_scheduler.step()\n","            optimizer.zero_grad()\n","\n","    model.eval()\n","\n","    # Evaluation\n","    eval_preds = []\n","    for batch in eval_dataloader:\n","        with torch.no_grad():\n","            # Generate predictions\n","            generated_tokens = accelerator.unwrap_model(model).generate(\n","                **batch,\n","                synced_gpus=is_ds_zero_3  # Set to True if using DeepSpeed Stage 3, otherwise remove\n","            )\n","            # Decode generated tokens to text\n","            generated_texts = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n","            eval_preds.extend(generated_texts)\n","\n","    # Do something with eval_preds, such as calculating metrics or comparing with the ground truth\n","\n","    # Testing\n","    test_preds = []\n","    for batch in test_dataloader:\n","        with torch.no_grad():\n","            # Generate predictions\n","            generated_tokens = accelerator.unwrap_model(model).generate(\n","                **batch,\n","                synced_gpus=is_ds_zero_3  # Set to True if using DeepSpeed Stage 3, otherwise remove\n","            )\n","            # Decode generated tokens to text\n","            generated_texts = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n","            test_preds.extend(generated_texts)\n","\n","    # Do something with test_preds, such as calculating metrics or comparing with the ground truth\n","\n","    # save the model\n","    model.save_pretrained(\"model\")\n","    # train_epoch_loss = total_loss / len(train_dataloader)\n","    # train_ppl = torch.exp(train_epoch_loss)\n","    # accelerator.print(f\"{epoch=}: {train_ppl=} {train_epoch_loss=}\")\n","\n","    model.eval()\n","    eval_preds = []\n","    with TorchTracemalloc() as tracemalloc:\n","        for _, batch in enumerate(tqdm(eval_dataloader)):\n","            batch = {k: v for k, v in batch.items() if k != \"labels\"}\n","            with torch.no_grad():\n","                outputs = accelerator.unwrap_model(model).generate(\n","                    **batch, synced_gpus=is_ds_zero_3, max_new_tokens=10\n","                )  # synced_gpus=True for DS-stage 3\n","            outputs = accelerator.pad_across_processes(outputs, dim=1, pad_index=tokenizer.pad_token_id)\n","            preds = accelerator.gather_for_metrics(outputs)\n","            preds = preds[:, max_length:].detach().cpu().numpy()\n","            eval_preds.extend(tokenizer.batch_decode(preds, skip_special_tokens=True))\n","\n","    # Printing the GPU memory usage details such as allocated memory, peak memory, and total memory usage\n","    accelerator.print(\"GPU Memory before entering the eval : {}\".format(b2mb(tracemalloc.begin)))\n","    accelerator.print(\"GPU Memory consumed at the end of the eval (end-begin): {}\".format(tracemalloc.used))\n","    accelerator.print(\"GPU Peak Memory consumed during the eval (max-begin): {}\".format(tracemalloc.peaked))\n","    accelerator.print(\n","        \"GPU Total Peak Memory consumed during the eval (max): {}\".format(\n","            tracemalloc.peaked + b2mb(tracemalloc.begin)\n","        )\n","    )\n","\n","    accelerator.print(\"CPU Memory before entering the eval : {}\".format(b2mb(tracemalloc.cpu_begin)))\n","    accelerator.print(\"CPU Memory consumed at the end of the eval (end-begin): {}\".format(tracemalloc.cpu_used))\n","    accelerator.print(\"CPU Peak Memory consumed during the eval (max-begin): {}\".format(tracemalloc.cpu_peaked))\n","    accelerator.print(\n","        \"CPU Total Peak Memory consumed during the eval (max): {}\".format(\n","            tracemalloc.cpu_peaked + b2mb(tracemalloc.cpu_begin)\n","        )\n","    )\n","\n","    correct = 0\n","    total = 0\n","    eval_dataset=dataset[str(list(dataset.keys())[0])]\n","    label_column=columns[1]\n","    assert len(eval_preds) == len(\n","        eval_dataset[label_column]\n","    ), f\"{len(eval_preds)} != {len(eval_dataset[label_column])}\"\n","    for pred, true in zip(eval_preds, eval_dataset[label_column]):\n","        if pred.strip() == true.strip():\n","            correct += 1\n","        total += 1\n","    accuracy = correct / total * 100\n","    accelerator.print(f\"{accuracy=}\")\n","    accelerator.print(f\"{eval_preds[:10]=}\")\n","    accelerator.print(f\"{eval_dataset[label_column][:10]=}\")\n","\n","    if do_test:\n","        model.eval()\n","        test_preds = []\n","        for _, batch in enumerate(tqdm(test_dataloader)):\n","            batch = {k: v for k, v in batch.items() if k != \"labels\"}\n","            with torch.no_grad():\n","                outputs = accelerator.unwrap_model(model).generate(\n","                    **batch, synced_gpus=is_ds_zero_3, max_new_tokens=10\n","                )  # synced_gpus=True for DS-stage 3\n","            outputs = accelerator.pad_across_processes(outputs, dim=1, pad_index=tokenizer.pad_token_id)\n","            preds = accelerator.gather(outputs)\n","            preds = preds[:, max_length:].detach().cpu().numpy()\n","            test_preds.extend(tokenizer.batch_decode(preds, skip_special_tokens=True))\n","\n","        test_preds_cleaned = []\n","        for _, pred in enumerate(test_preds):\n","            test_preds_cleaned.append(get_closest_label(pred, classes))\n","\n","        test_df = test_dataset.to_pandas()\n","        assert len(test_preds_cleaned) == len(test_df), f\"{len(test_preds_cleaned)} != {len(test_df)}\"\n","        test_df[label_column] = test_preds_cleaned\n","        test_df[\"text_labels_orig\"] = test_preds\n","        accelerator.print(test_df[[text_column, label_column]].sample(20))\n","\n","        pred_df = test_df[[\"ID\", label_column]]\n","        pred_df.columns = [\"ID\", \"Label\"]\n","\n","        os.makedirs(f\"data/{dataset_name}\", exist_ok=True)\n","        pred_df.to_csv(f\"data/{dataset_name}/predictions.csv\", index=False)\n","\n","    accelerator.wait_for_everyone()\n","    # Option1: Pushing the model to Hugging Face Hub\n","    # model.push_to_hub(\n","    #     f\"{dataset_name}_{model_name_or_path}_{peft_config.peft_type}_{peft_config.task_type}\".replace(\"/\", \"_\"),\n","    #     token = \"hf_...\"\n","    # )\n","    # token (`bool` or `str`,\n","    peft_model_id = 'hemanth_weights'\n","    model.save_pretrained(peft_model_id)\n","    accelerator.wait_for_everyone()\n","\n","\n","if __name__ == \"__main__\":\n","    main()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":449,"referenced_widgets":["32754634c56646cfae52252c598687a1","847d55aed2454404812c79e3d1aa090d","12394e9531c04efa8fea0d5c2ed08449","3846d820343949c181ae183c0a2a415e","7b751de5237e438185174a97472b60f1","c4c2a5dd751e4b7facbec083fc4a4fdf","62533339afa543b3a86b0d79fcc57acf","dddf8f4228a445fa82d09e94e995ac59","e5a63c50fea94391b5f554b009c478c5","bbd0a537fd4346678df33b09ac9a594c","436d080fe79d4532bffea1fff23681d5","5932d43e2fe14c4eb346bba665807bba","9a52e6a48ac24ba08501fa6e5ed59965","ec25150149164fe2bca402a556f68b0f","ef9e6d3bd4184082b0e14e44e50dbb44","46f840feaefe4f5fb151732c420a8028","90b5d78bd64f474faba7dd79cc9f93fe","26efadfdfdec43c7b11cb11695b0a26f","98054981de6048138748c4679bc5b285","b3fa37f9d7994dd2bc85d03bff4ae69d","b875be6a3807428094e3083b742f7ae4","d4252f685404401c9640402bf4a88c2f","23ce103e80b848d1a82b01ecff71ab7c","d7050bd4cb654b04a4f4d43911317ecd","4df0cfc1dafd44c0b5a004792267cc4a","45f65b7cdbbb4856aa987ec15088a255","86d01777c9f649deb0ec0762a75a57f5","a197fa6bcd9341699e993ffe82b35710","ea8d35627aed4490b83184462b0b67b4","7b3374b389044ad48831d2f145fac31c","888348ad9f9f46e193df8586c4c88c41","9eba39c2ffff4d429c8df3bc6f0fb5c9","36fa757150cb4fa991b055372dd1367e","9bb971a8a84d47fb881094b3ae778cfb","df7cbcab80f94db59751c9f3babe4452","8064722977a140e991bb706caa020476","67c3cacee61643dcb7bc98fcef2fd069","711544b45c87413ea1a984f5bc29a606","057b534405d943fba373a3940b7edc1c","ad43c979a8aa4cb79517dd89303b727e","733a0727490b4b80a1ebeb8d3d024b87","79383bfa72304d4cbf388b7c87a47795","a2591614c6994246a8e14a0065b043e4","62e2263a07c044759c8074ecc4ba40e0","202ebfc132b14ae8ba975aff31a63854","01a1dc5cebeb4092b8f23f3f67968c7e","46d405c025b94d339da14148a1bdd827","5c735a091c164278b60ee26632632c36","44dfc57026d94018895b63c30ca04062","510e731e7350404f8ef4d2b002b2c730","48e4eb70420040c4aa34d86dde94257b","712dca51b351454289f143b34f1a2f1f","d4a1c11259d444f695a952ffcc8a4722","086d80481cc54cc8b66cac4a0f482168","4bb28896417c4426a843b6d1fbe770b4","6daac74d5fa44c4680b4d07b6c2bba68","6f00ddcd825c4cba996d02f082000d48","0766cf953d234336997d771d45935019","7ddd1cd7d90a40ef82b35960270bbba0","7ba8a400c70b4ab9a6a77792d6f7f02a","65f8860ccec141e2b3473515e0b8bce4","6f14bf9f327744dda29773257866396b","8c271047f8aa49759758cac88f93dbe5","5678540f3bf24a429f59aaf30fe0e907","a429f410050a4ff2afdd25bb78ae6ea0","3c6e0bf5d87341f784274d5708d27e15","d273ced174c3460dbe93409ad894c20a","0db4ef5df46d4da5b09b4e995d04336b","9bdb85bfe2af4693ac46c17663c61b16","81a9953142c3457aa95965b9be72c45a","1149502f598b4071a0ef99300aa053f9","6a6783ce49cf4f95944fbd1417654e5b","dee880c6eae749e0bec80e759ecd5808","b1d9f7e9a13148f9a5bba5035c5d213f","b65ed51167124d7999bcc4dd395b101f","b128b5a5304a4f4d9f1556f38abe6c33","5210fb3dd464499c84ea081786312b6c","f4a12d327a1742a7b0070b3bd40876fb","5aec6445934245d6b31f02233a921cc0","43a1fc32cc004af690461a240cceee79","f10dbd52499c4136a69fa1b610ac9f74","58e8188eb5764df1ac4d7d38d4d48057","409cc1a4d33f4744915266ddbff093a1","a35284c22181400f9b2f73df968be9b8","1aa4df44e4584efea55ebb604ec8dba1","e991183bfd3348849b306b7b30ac01ea","a65709fd3aa2475f95143403caeb2591","a9f989db21bd4bb6a737ffebc6c50278"]},"executionInfo":{"elapsed":15402,"status":"ok","timestamp":1705568143606,"user":{"displayName":"hemanth varma","userId":"05483789954770220327"},"user_tz":-330},"id":"3y3JlUr_Zmf1","outputId":"c7f6f33c-6b16-476c-f1f7-184fcab752a0"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"32754634c56646cfae52252c598687a1","version_major":2,"version_minor":0},"text/plain":["Downloading readme:   0%|          | 0.00/274 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5932d43e2fe14c4eb346bba665807bba","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/74.6k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"23ce103e80b848d1a82b01ecff71ab7c","version_major":2,"version_minor":0},"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["dict_keys(['train'])\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9bb971a8a84d47fb881094b3ae778cfb","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"202ebfc132b14ae8ba975aff31a63854","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6daac74d5fa44c4680b4d07b6c2bba68","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d273ced174c3460dbe93409ad894c20a","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["train\n","['act', 'prompt']\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f4a12d327a1742a7b0070b3bd40876fb","version_major":2,"version_minor":0},"text/plain":["Running tokenizer on dataset (num_proc=2):   0%|          | 0/153 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from datasets import load_dataset\n","from transformers import AutoTokenizer\n","import multiprocessing\n","import torch\n","from torch.utils.data import DataLoader\n","from transformers import default_data_collator, get_linear_schedule_with_warmup\n","\n","dataset_name='fka/awesome-chatgpt-prompts'\n","# Load the dataset\n","dataset = load_dataset(dataset_name)\n","print(dataset.keys())\n","# Define the tokenizer\n","model_name_or_path='gpt2'\n","tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n","\n","if tokenizer.pad_token_id is None:\n","    tokenizer.pad_token_id = tokenizer.eos_token_id\n","split_name=str(list(dataset.keys())[0])\n","print(split_name)\n","# Get the list of columns for the first split\n","columns = dataset[str(list(dataset.keys())[0])].column_names\n","print(columns)\n","# Define the maximum sequence length\n","max_length = 512\n","\n","def preprocess_function(examples):\n","    # example=example[str(dataset[list(dataset.keys())[0]])]\n","    # Tokenize each column separately and concatenate their token IDs.\n","    tokenized_outputs = {}\n","    for column in columns:\n","        column_tokens = tokenizer(examples[column], padding='max_length', truncation=True, max_length=max_length)\n","        tokenized_outputs[column] = column_tokens['input_ids']\n","\n","    # Create a tensor for input_ids by concatenating the tokens from each column\n","    input_ids = []\n","    for i in range(len(tokenized_outputs[columns[0]])): # Number of examples\n","        row_tokens = []\n","        for column in columns:\n","            row_tokens.extend(tokenized_outputs[column][i])\n","        row_tokens = row_tokens[:max_length]  # Truncate to max_length if necessary\n","        row_tokens += [tokenizer.pad_token_id] * (max_length - len(row_tokens))  # Pad if necessary\n","        input_ids.append(row_tokens)\n","\n","    # Create a tensor for attention_mask based on input_ids\n","    attention_mask = [[int(token_id != tokenizer.pad_token_id) for token_id in input_row] for input_row in input_ids]\n","\n","    # Convert input_ids and attention_mask to tensors\n","    model_inputs = {'input_ids': torch.tensor(input_ids), 'attention_mask': torch.tensor(attention_mask)}\n","\n","    return model_inputs\n","\n","# Map the preprocessing function across the entire dataset\n","processed_datasets = dataset.map(\n","    preprocess_function,\n","    batched=True,\n","    num_proc=multiprocessing.cpu_count(),\n","    remove_columns=columns,\n","    load_from_cache_file=False,\n","    desc=\"Running tokenizer on dataset\",\n",")\n","\n","from torch.utils.data import DataLoader\n","from transformers import default_data_collator, get_linear_schedule_with_warmup\n","\n","\n","train_dataset = processed_datasets[str(list(dataset.keys())[0])]\n","\n","batch_size=16\n","train_dataloader = DataLoader(\n","    train_dataset, shuffle=True, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True\n",")\n","# print(\"length of processed_datasets['train'],\",processed_datasets['train'])\n","# print(\"len of all inputs ids\",len(processed_datasets['train']['input_ids']))\n","# print(\"first input_is, length_of_token\",processed_datasets['train']['input_ids'][0],len(processed_datasets['train']['input_ids'][0]))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"35HXCHEUb-Hd"},"outputs":[],"source":["next(train_dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vieW2wZnZBEq"},"outputs":[],"source":["from datasets import load_dataset\n","from transformers import AutoTokenizer\n","# Load the dataset\n","dataset = load_dataset(\"fka/awesome-chatgpt-prompts\")\n","\n","# Define the tokenizer\n","tokenizer = AutoTokenizer.from_pretrained('gpt2')\n","\n","if tokenizer.pad_token_id is None:\n","    tokenizer.pad_token_id = tokenizer.eos_token_id\n","\n","split_name=str(list(dataset.keys()))\n","\n","# Get the list of columns for the first split\n","columns = dataset[str(list(dataset.keys())[0])].column_names\n","\n","# Define the maximum sequence length\n","max_length = 512\n","\n","def preprocess_dataset(dataset_name):\n","    # Load a dataset\n","    dataset = load_dataset(dataset_name)\n","\n","    # Function to preprocess an example based on detected feature types\n","    def preprocess_function(example):\n","        new_example = {}\n","        # Loop over all features in the example\n","        for feature_name, feature_value in example.items():\n","            if isinstance(feature_value, str):  # For text features\n","                # Apply text preprocessing like tokenization, lowercasing, etc.\n","                new_example[feature_name] = feature_value.lower()  # Example operation\n","            elif isinstance(feature_value, list):  # For categorical features\n","                if isinstance(feature_value[0], int):  # Label encoded list\n","                    # Convert numeric labels to strings if names are provided in the feature\n","                    label_feature = dataset[split_name].features[feature_name]\n","                    if hasattr(label_feature, 'names'):\n","                        new_example[feature_name] = [label_feature.names[label] for label in feature_value]\n","                    else:\n","                        new_example[feature_name] = feature_value  # Unchanged\n","                else:\n","                    # Handle other list data types if necessary\n","                    pass\n","            else:  # For numerical or other types of features\n","                # Apply numerical preprocessing like normalization, scaling, etc.\n","                new_example[feature_name] = feature_value  # Example operation\n","\n","        return new_example\n","\n","    # Apply the preprocessing function to all splits in the dataset\n","    processed_dataset = dataset.map(preprocess_function, batched=True, num_proc=1)\n","\n","    return processed_dataset\n","\n","# Replace 'some_specific_name' with the actual name of the dataset you want to load\n","dataset_name = \"LDJnr/Capybara\"\n","processed_dataset = preprocess_dataset(dataset_name)\n","\n","# Display the processed dataset and the first example of the train split\n","print(processed_dataset)\n","print(\"length of dataset:\",len(processed_dataset[\"train\"]))\n","print(\"Sample_data:\",processed_dataset[\"train\"][0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5B_GNRwYjTYi"},"outputs":[],"source":["from torch.utils.data import DataLoader\n","from transformers import default_data_collator, get_linear_schedule_with_warmup\n","\n","\n","train_dataset = processed_datasets[\"train\"]\n","\n","batch_size=16\n","train_dataloader = DataLoader(\n","    train_dataset, shuffle=True, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":485,"status":"ok","timestamp":1705568396678,"user":{"displayName":"hemanth varma","userId":"05483789954770220327"},"user_tz":-330},"id":"oTEq1Ewmjj4g","outputId":"3dc2a10c-c54a-442a-8767-da3a16e0ef65"},"outputs":[{"data":{"text/plain":["{'input_ids': tensor([[ 3109,  5276, 21616,  ..., 50256, 50256, 50256],\n","         [31923,  7451, 50256,  ..., 50256, 50256, 50256],\n","         [13908, 34270, 50256,  ..., 50256, 50256, 50256],\n","         ...,\n","         [17931,    56, 25516,  ..., 50256, 50256, 50256],\n","         [25896,  5886, 11125,  ..., 50256, 50256, 50256],\n","         [   50, 43490, 11915,  ..., 50256, 50256, 50256]]),\n"," 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n","         [1, 1, 0,  ..., 0, 0, 0],\n","         [1, 1, 0,  ..., 0, 0, 0],\n","         ...,\n","         [1, 1, 1,  ..., 0, 0, 0],\n","         [1, 1, 1,  ..., 0, 0, 0],\n","         [1, 1, 1,  ..., 0, 0, 0]])}"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["next(iter(train_dataloader))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y89tdPPtkAfT"},"outputs":[],"source":["pip install accelerate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PX__NPALjz3O"},"outputs":[],"source":["# Load the base model for CausalLM from the specified pre-trained model, considering the provided device mapping and max_memory settings\n","from transformers import AutoModelForCausalLM\n","model = AutoModelForCausalLM.from_pretrained('gpt2')\n","print(model)"]},{"cell_type":"markdown","metadata":{"id":"Uzjp8bELlrGe"},"source":["\n","\n","| Module | Description | Parameters |\n","| --- | --- | --- |\n","| GPT2LMHeadModel | The GPT2 model transformer with a language modeling head on top (linear layer with weights tied to the input embeddings) | config |\n","| transformer | The main GPT2Model that contains the core transformer layers | wte, wpe, drop, h, ln_f |\n","| wte | The word token embedding matrix that maps the token ids to their corresponding vector representations | vocab_size, n_embd |\n","| wpe | The position embedding matrix that maps the position ids to their corresponding vector representations | n_positions, n_embd |\n","| drop | The dropout layer that is applied to the embeddings and the outputs of each block | p |\n","| h | The module list that contains the 12 GPT2Block modules | n_layer |\n","| GPT2Block | A single transformer block that consists of a layer normalization, a self-attention layer, another layer normalization, and a feed-forward layer | ln_1, attn, ln_2, mlp |\n","| ln_1 | The first layer normalization layer that is applied before the self-attention layer | normalized_shape, eps, elementwise_affine |\n","| attn | The self-attention layer that computes the attention scores and values for the input tokens | c_attn, c_proj, attn_dropout, resid_dropout |\n","| c_attn | The 1D convolution layer that projects the input tokens into query, key, and value vectors | in_channels, out_channels |\n","| c_proj | The 1D convolution layer that projects the attention output into a vector of the same size as the input | in_channels, out_channels |\n","| attn_dropout | The dropout layer that is applied to the attention scores | p |\n","| resid_dropout | The dropout layer that is applied to the residual connection | p |\n","| ln_2 | The second layer normalization layer that is applied before the feed-forward layer | normalized_shape, eps, elementwise_affine |\n","| mlp | The feed-forward layer that consists of two 1D convolution layers and a GELU activation function | c_fc, c_proj, act, dropout |\n","| c_fc | The first 1D convolution layer that projects the input into a hidden size | in_channels, out_channels |\n","| c_proj | The second 1D convolution layer that projects the hidden output back to the input size | in_channels, out_channels |\n","| act | The GELU activation function that is applied between the two convolution layers | - |\n","| dropout | The dropout layer that is applied to the feed-forward output | p |\n","| ln_f | The final layer normalization layer that is applied to the transformer output | normalized_shape, eps, elementwise_affine |\n","| lm_head | The linear layer that is tied to the word token embedding matrix and used for language modeling | in_features, out_features, bias |\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T5mxWErGl1Pq"},"outputs":[],"source":["import torch\n","\n","from transformers import default_data_collator, get_linear_schedule_with_warmup\n","lr=0.001\n","num_epochs=5\n","\n","optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n","lr_scheduler = get_linear_schedule_with_warmup(\n","    optimizer=optimizer,\n","    num_warmup_steps=0,\n","    num_training_steps=(len(train_dataloader) * num_epochs),\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3733,"status":"ok","timestamp":1705590379264,"user":{"displayName":"hemanth varma","userId":"05483789954770220327"},"user_tz":-330},"id":"cvTW5TL9Cn09","outputId":"a5b33fc2-7e0e-432e-f473-6ec307055952"},"outputs":[{"name":"stdout","output_type":"stream","text":["AI models can be susceptible to data poisoning attacks, and assessing their vulnerability is crucial. To determine susceptibility, a thorough analysis of the specific model and dataset is required. Utilizing techniques such as detecting potential vulnerabilities and calculating a susceptibility score can help evaluate the risk. In cases where vulnerabilities are identified, implementing appropriate mitigation strategies is recommended to enhance the model's robustness against data poisoning attacks.\n"]}],"source":["import os\n","import pandas as pd\n","import torch\n","from datasets import load_dataset as hf_load_dataset\n","from transformers import AutoTokenizer\n","from typing import Dict, List, Union\n","import warnings\n","\n","def load_local_dataset(local_path: str) -> Dict[str, pd.DataFrame]:\n","    dataset = {}\n","    if os.path.isfile(local_path):\n","        # Single file loading\n","        try:\n","            if local_path.endswith('.csv'):\n","                dataset[os.path.basename(local_path)] = pd.read_csv(local_path)\n","            elif local_path.endswith('.json'):\n","                dataset[os.path.basename(local_path)] = pd.read_json(local_path)\n","            else:\n","                warnings.warn(f\"Unsupported file type: {local_path}\")\n","        except Exception as e:\n","            warnings.warn(f\"Error loading {local_path}: {str(e)}\")\n","    elif os.path.isdir(local_path):\n","        # Directory of files loading\n","        for file in os.listdir(local_path):\n","            file_path = os.path.join(local_path, file)\n","            try:\n","                if file.endswith('.csv'):\n","                    dataset[file] = pd.read_csv(file_path)\n","                elif file.endswith('.json'):\n","                    dataset[file] = pd.read_json(file_path)\n","                else:\n","                    warnings.warn(f\"Unsupported file type: {file}\")\n","            except Exception as e:\n","                warnings.warn(f\"Error loading {file}: {str(e)}\")\n","    else:\n","        warnings.warn(f\"Path does not exist: {local_path}\")\n","    return dataset\n","\n","def preprocess_function(examples: Union[Dict[str, pd.DataFrame], pd.DataFrame], columns: List[str], tokenizer, max_length: int) -> Dict[str, torch.Tensor]:\n","    if isinstance(examples, pd.DataFrame):\n","        examples = {'data': examples}  # Wrap single DataFrame for consistency\n","\n","    tokenized_outputs = {column: [] for column in columns}\n","    for column in columns:\n","        print(column )\n","        for example in examples.values():\n","            if column in example.columns:\n","               texts = example[column].astype(str).tolist()\n","\n","               column_tokens = tokenizer(texts, padding='max_length', truncation=True, max_length=max_length)\n","               tokenized_outputs[column].extend(column_tokens['input_ids'])\n","\n","                # if pd.api.types.is_string_dtype(example[str(column)]):\n","                #     column_tokens = tokenizer(example[str(column)].tolist(), padding='max_length', truncation=True, max_length=max_length)\n","                #     tokenized_outputs[column].extend(column_tokens['input_ids'])\n","                # else:\n","                #     warnings.warn(f\"Column {column} is not a string data type.\")\n","            else:\n","                warnings.warn(f\"Column {column} not found in dataset.\")\n","\n","    # Assume all columns are present in all dataframes and have the same length\n","    input_ids, attention_mask = [], []\n","    for i in range(len(tokenized_outputs[columns[0]])):  # Number of examples\n","        row_tokens = []\n","        for column in columns:\n","            row_tokens.extend(tokenized_outputs[column][i])\n","        row_tokens = row_tokens[:max_length]  # Truncate to max_length if necessary\n","        row_tokens += [tokenizer.pad_token_id] * (max_length - len(row_tokens))  # Pad if necessary\n","        input_ids.append(row_tokens)\n","\n","        row_attention_mask = [int(token != tokenizer.pad_token_id) for token in row_tokens]\n","        attention_mask.append(row_attention_mask)\n","\n","    model_inputs = {'input_ids': torch.tensor(input_ids), 'attention_mask': torch.tensor(attention_mask)}\n","    return model_inputs\n","\n","def main():\n","    dataset_name_or_local_path = '/content/drive/MyDrive/new_output.csv' # Example Hugging Face dataset name or local path to your dataset\n","    max_length = 512\n","    model_name_or_path = \"gpt2\"\n","    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n","    if tokenizer.pad_token_id is None:\n","        tokenizer.pad_token_id = tokenizer.eos_token_id\n","    tokenizer.padding_side = 'left'\n","\n","    try:\n","        # Try to load from Hugging Face datasets\n","        dataset = hf_load_dataset(dataset_name_or_local_path)\n","    except FileNotFoundError:\n","        # If not found, try to load from local path\n","        dataset = load_local_dataset(dataset_name_or_local_path)\n","\n","    if not dataset:\n","        raise ValueError(\"No valid dataset found at the specified path or with the specified name.\")\n","\n","    # Assuming the first dataset loaded will be used for processing\n","    first_dataset_key = next(iter(dataset.keys()))\n","    examples = dataset[first_dataset_key]\n","    columns = examples.columns.tolist() if isinstance(examples, pd.DataFrame) else []\n","\n","    # Preprocess the dataset\n","    model_inputs = preprocess_function(examples, columns, tokenizer, max_length)\n","\n","if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b7WYBP5KmSk-"},"outputs":[],"source":["# training and evaluation\n","from tqdm import tqdm\n","device='cpu'\n","model = model.to(device)\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    total_loss = 0\n","    for step, batch in enumerate(tqdm(train_dataloader)):\n","        batch = {k: v.to(device) for k, v in batch.items()}\n","        #         print(batch)\n","        #         print(batch[\"input_ids\"].shape)\n","        outputs = model(**batch)\n","        loss = outputs.loss\n","        total_loss += loss.detach().float()\n","        loss.backward()\n","        optimizer.step()\n","        lr_scheduler.step()\n","        optimizer.zero_grad()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tG5cbx7IZo8h"},"outputs":[],"source":["!pip install -q -U  transformers accelerate evaluate deepspeed tqdm datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CQTxwZS6cJfV"},"outputs":[],"source":["!pip install -q -U peft"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YupbMNHmb2NS"},"outputs":[],"source":["from transformers import AutoModelForCausalLM,AutoTokenizer\n","from peft import PeftModel, PeftConfig\n","import torch\n","from datasets import load_dataset\n","import os\n","from transformers import AutoTokenizer\n","from torch.utils.data import DataLoader\n","from transformers import default_data_collator, get_linear_schedule_with_warmup\n","from tqdm import tqdm\n","from datasets import load_dataset\n","\n","device = \"cuda\"\n","model_name_or_path = \"bigscience/bloomz-7b1\"\n","tokenizer_name_or_path = \"bigscience/bloomz-7b1\"\n","dataset_name = \"twitter_complaints\"\n","text_column = \"Tweet text\"\n","label_column = \"text_label\"\n","max_length = 64\n","lr = 1e-3\n","num_epochs = 50\n","batch_size = 8"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u2Rz-dQfp9G5"},"outputs":[],"source":["import logging\n","import os\n","import sys\n","import traceback\n","from datasets import load_dataset\n","from transformers import AutoTokenizer, default_data_collator, get_linear_schedule_with_warmup\n","import torch\n","from torch.utils.data import DataLoader\n","import multiprocessing\n","\n","class DatasetProcessor:\n","    def __init__(self, dataset_name, model_name_or_path, max_length):\n","        self.dataset_name = dataset_name\n","        self.model_name_or_path = model_name_or_path\n","        self.max_length = max_length\n","        self.columns = None\n","\n","    def load_dataset(self):\n","        try:\n","            logging.info(f\"Loading dataset: {self.dataset_name}\")\n","            self.dataset = load_dataset(self.dataset_name)\n","            logging.info(\"Dataset loaded successfully.\")\n","            return True\n","        except Exception as e:\n","            logging.error(f\"Error loading dataset: {e}\")\n","            traceback.print_exc(file=sys.stderr)\n","            return False\n","\n","    def initialize_tokenizer(self):\n","        try:\n","            logging.info(f\"Initializing tokenizer: {self.model_name_or_path}\")\n","            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name_or_path)\n","            self.tokenizer.pad_token_id = self.tokenizer.eos_token_id if self.tokenizer.pad_token_id is None else self.tokenizer.pad_token_id\n","            logging.info(\"Tokenizer initialized successfully.\")\n","            return True\n","        except Exception as e:\n","            logging.error(f\"Error initializing tokenizer: {e}\")\n","            traceback.print_exc(file=sys.stderr)\n","            return False\n","\n","    def preprocess_example(self, examples):\n","        try:\n","            tokenized_outputs = {}\n","            for column in self.columns:\n","                column_tokens = self.tokenizer(examples[column], padding='max_length', truncation=True, max_length=self.max_length)\n","                tokenized_outputs[column] = column_tokens['input_ids']\n","\n","            input_ids = []\n","            for i in range(len(tokenized_outputs[self.columns[0]])):\n","                row_tokens = []\n","                for column in self.columns:\n","                    row_tokens.extend(tokenized_outputs[column][i])\n","                row_tokens = row_tokens[:self.max_length]\n","                row_tokens += [self.tokenizer.pad_token_id] * (self.max_length - len(row_tokens))\n","                input_ids.append(row_tokens)\n","\n","            attention_mask = [[int(token_id != self.tokenizer.pad_token_id) for token_id in input_row] for input_row in input_ids]\n","\n","            model_inputs = {'input_ids': torch.tensor(input_ids), 'attention_mask': torch.tensor(attention_mask)}\n","\n","            return model_inputs\n","        except Exception as e:\n","            logging.error(f\"Error preprocessing example: {e}\")\n","            traceback.print_exc(file=sys.stderr)\n","            return None\n","\n","    def process_dataset(self):\n","        try:\n","            logging.info(\"Processing dataset...\")\n","            self.get_columns()\n","            self.dataset = self.dataset.map(self.preprocess_example, batched=True, num_proc=multiprocessing.cpu_count(), remove_columns=self.columns, load_from_cache_file=False, desc=\"Running tokenizer on dataset\")\n","            logging.info(\"Dataset processed successfully.\")\n","            return True\n","        except Exception as e:\n","            logging.error(f\"Error processing dataset: {e}\")\n","            traceback.print_exc(file=sys.stderr)\n","            return False\n","\n","    def get_columns(self):\n","        if self.columns is None:\n","            split_name = list(self.dataset.keys())[0]\n","            self.columns = self.dataset[split_name].column_names\n","\n","\n","\n","\n","logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\", handlers=[logging.StreamHandler()])\n","dataset_name='fka/awesome-chatgpt-prompts'\n","model_name_or_path='gpt2'\n","max_length=512\n","batch_size=16\n","dataset_processor_c = DatasetProcessor(dataset_name, model_name_or_path, max_length)\n","if not dataset_processor_c.load_dataset():\n","    sys.exit(1)\n","if not dataset_processor_c.initialize_tokenizer():\n","    sys.exit(1)\n","if not dataset_processor_c.process_dataset():\n","    sys.exit(1)\n","\n","train_dataset = dataset_processor_c.dataset[\"train\"]\n","train_dataloader = DataLoader(\n","    train_dataset, shuffle=True, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True\n",")\n","next(iter(train_dataloader))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BpDn_Zy3cgoM"},"outputs":[],"source":["from datasets import load_dataset\n","\n","dataset = load_dataset(\"ought/raft\", dataset_name)\n","\n","classes = [k.replace(\"_\", \" \") for k in dataset[\"train\"].features[\"Label\"].names]\n","print(classes)\n","dataset = dataset.map(\n","    lambda x: {\"text_label\": [classes[label] for label in x[\"Label\"]]},\n","    batched=True,\n","    num_proc=1,\n",")\n","print(dataset)\n","dataset[\"train\"][0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k7w4PAEycotN"},"outputs":[],"source":["# data preprocessing\n","tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n","if tokenizer.pad_token_id is None:\n","    tokenizer.pad_token_id = tokenizer.eos_token_id\n","target_max_length = max([len(tokenizer(class_label)[\"input_ids\"]) for class_label in classes])\n","print(target_max_length)\n","\n","\n","def preprocess_function(examples):\n","    batch_size = len(examples[text_column])\n","    inputs = [f\"{text_column} : {x} Label : \" for x in examples[text_column]]\n","    targets = [str(x) for x in examples[label_column]]\n","    model_inputs = tokenizer(inputs)\n","    labels = tokenizer(targets, add_special_tokens=False)  # don't add bos token because we concatenate with inputs\n","    for i in range(batch_size):\n","        sample_input_ids = model_inputs[\"input_ids\"][i]\n","        label_input_ids = labels[\"input_ids\"][i] + [tokenizer.eos_token_id]\n","        # print(i, sample_input_ids, label_input_ids)\n","        model_inputs[\"input_ids\"][i] = sample_input_ids + label_input_ids\n","        labels[\"input_ids\"][i] = [-100] * len(sample_input_ids) + label_input_ids\n","        model_inputs[\"attention_mask\"][i] = [1] * len(model_inputs[\"input_ids\"][i])\n","    # print(model_inputs)\n","    for i in range(batch_size):\n","        sample_input_ids = model_inputs[\"input_ids\"][i]\n","        label_input_ids = labels[\"input_ids\"][i]\n","        model_inputs[\"input_ids\"][i] = [tokenizer.pad_token_id] * (\n","            max_length - len(sample_input_ids)\n","        ) + sample_input_ids\n","        model_inputs[\"attention_mask\"][i] = [0] * (max_length - len(sample_input_ids)) + model_inputs[\n","            \"attention_mask\"\n","        ][i]\n","        labels[\"input_ids\"][i] = [-100] * (max_length - len(sample_input_ids)) + label_input_ids\n","        model_inputs[\"input_ids\"][i] = torch.tensor(model_inputs[\"input_ids\"][i][:max_length])\n","        model_inputs[\"attention_mask\"][i] = torch.tensor(model_inputs[\"attention_mask\"][i][:max_length])\n","        labels[\"input_ids\"][i] = torch.tensor(labels[\"input_ids\"][i][:max_length])\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","    return model_inputs\n","\n","\n","processed_datasets = dataset.map(\n","    preprocess_function,\n","    batched=True,\n","    num_proc=1,\n","    remove_columns=dataset[\"train\"].column_names,\n","    load_from_cache_file=False,\n","    desc=\"Running tokenizer on dataset\",\n",")\n","\n","train_dataset = processed_datasets[\"train\"]\n","\n","\n","train_dataloader = DataLoader(\n","    train_dataset, shuffle=True, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MlK7qcHYctS8"},"outputs":[],"source":["def test_preprocess_function(examples):\n","    batch_size = len(examples[text_column])\n","    inputs = [f\"{text_column} : {x} Label : \" for x in examples[text_column]]\n","    model_inputs = tokenizer(inputs)\n","    # print(model_inputs)\n","    for i in range(batch_size):\n","        sample_input_ids = model_inputs[\"input_ids\"][i]\n","        model_inputs[\"input_ids\"][i] = [tokenizer.pad_token_id] * (\n","            max_length - len(sample_input_ids)\n","        ) + sample_input_ids\n","        model_inputs[\"attention_mask\"][i] = [0] * (max_length - len(sample_input_ids)) + model_inputs[\n","            \"attention_mask\"\n","        ][i]\n","        model_inputs[\"input_ids\"][i] = torch.tensor(model_inputs[\"input_ids\"][i][:max_length])\n","        model_inputs[\"attention_mask\"][i] = torch.tensor(model_inputs[\"attention_mask\"][i][:max_length])\n","    return model_inputs\n","\n","\n","processed_datasets = dataset.map(\n","    test_preprocess_function,\n","    batched=True,\n","    num_proc=1,\n","    remove_columns=dataset[\"train\"].column_names,\n","    load_from_cache_file=False,\n","    desc=\"Running tokenizer on dataset\",\n",")\n","\n","eval_dataset = processed_datasets[\"train\"]\n","test_dataset = processed_datasets[\"test\"]\n","\n","eval_dataloader = DataLoader(eval_dataset, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True)\n","test_dataloader = DataLoader(test_dataset, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True)\n","print(next(iter(eval_dataloader)))\n","print(next(iter(test_dataloader)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ko0wpnv0dSDG"},"outputs":[],"source":["!pip install --upgrade peft"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DDsMuFbrfgb4"},"outputs":[],"source":["peft_model_id = \"llama2_all0.1_llama2-7B-hf_clip_lr0.0001_bs240_ip1536_op1664_ep3/checkpoint-39006\"\n","\n","peft_config = PeftConfig.from_pretrained(peft_model_id)\n","\n","# language_model = LlamaForCausalLM.from_pretrained(\n","#             peft_config.base_model_name_or_path,\n","#             load_in_8bit=True,\n","#             device_map=\"auto\",\n","#             torch_dtype=torch.float16\n","#         )\n","\n","# language_model = PeftModel(language_model, peft_config)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9GimiXMPcxzu"},"outputs":[],"source":["from peft import PeftModel, PeftConfig\n","\n","max_memory = {0: \"1GIB\", 1: \"1GIB\", 2: \"2GIB\", 3: \"10GIB\", \"cpu\": \"30GB\"}\n","peft_model_id = \"hemanthkandimalla/twitter_complaints_bigscience_bloomz-7b1_LORA_CAUSAL_LM\"\n","config = PeftConfig.from_pretrained(peft_model_id)\n","model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path, device_map=\"auto\", max_memory=max_memory)\n","model = PeftModel.from_pretrained(model, peft_model_id, device_map=\"auto\", max_memory=max_memory)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cbPddqQvufHK"},"outputs":[],"source":["%%time\n","\n","import torch\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","import numpy as np\n","import plotly.graph_objects as go\n","from tqdm import tqdm\n","import imageio\n","import os\n","\n","# Load pre-trained model\n","model_name = 'gpt2'\n","model = AutoModelForCausalLM.from_pretrained(model_name)\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","# Set model to evaluation mode\n","model.eval()\n","\n","# Define our input\n","input_text = \"I have a dream\"\n","inputs = tokenizer.encode_plus(input_text, return_tensors=\"pt\")\n","\n","# Compute the original loss\n","outputs = model(**inputs, labels=inputs[\"input_ids\"])\n","original_loss = outputs.loss.item()\n","\n","# Define two random directions\n","direction1 = [torch.randn_like(p) for p in model.parameters()]\n","direction2 = [torch.randn_like(p) for p in model.parameters()]\n","\n","# Normalize vectors\n","for d1, d2 in zip(direction1, direction2):\n","    norm_d1 = torch.linalg.norm(d1.flatten())\n","    norm_d2 = torch.linalg.norm(d2.flatten())\n","    d1.div_(norm_d1)\n","    d2.div_(norm_d2)\n","\n","# Define the range to explore\n","x = np.linspace(-1, 1, 20)\n","y = np.linspace(-1, 1, 20)\n","X, Y = np.meshgrid(x, y)\n","\n","# Prepare to collect the losses\n","Z = np.zeros_like(X)\n","\n","# Compute loss for each direction\n","for i in tqdm(range(x.size), desc=\"x progress\"):\n","    for j in tqdm(range(y.size), desc=\"y progress\", leave=False):\n","        # Perturb the model parameters\n","        for p, d1, d2 in zip(model.parameters(), direction1, direction2):\n","            p.data.add_(x[i]*d1 + y[j]*d2)\n","\n","        # Compute the loss\n","        outputs = model(**inputs, labels=inputs[\"input_ids\"])\n","        Z[i, j] = outputs.loss.item()\n","\n","        # Revert the model parameters\n","        for p, d1, d2 in zip(model.parameters(), direction1, direction2):\n","            p.data.sub_(x[i]*d1 + y[j]*d2)\n","\n","# Plot the loss landscape\n","fig = go.Figure(frames=[go.Frame(data=go.Scatter(x=X[i], y=Y[j], z=Z[i, j])) for i in range(X.shape[0])])\n","fig.update_layout(scene=dict(xaxis=dict(range=[-1, 1]), yaxis=dict(range=[-1, 1]), zaxis=dict(range=[-4, 10])))\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SVnRsGEFv5FP"},"outputs":[],"source":["%%capture\n","\n","# Install transformers and graphviz\n","!sudo apt-get install graphviz graphviz-dev\n","!pip install transformers pygraphviz\n","\n","# Make sure we're using UTF-8 as encoding\n","import locale\n","locale.getpreferredencoding = lambda: \"UTF-8\"\n","\n","# Set seed\n","import torch\n","torch.manual_seed(42)\n","torch.cuda.manual_seed(42)\n","torch.cuda.manual_seed_all(42)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PmcdjpnAwE73"},"outputs":[],"source":["from transformers import AutoModelForCausalLM,AutoTokenizer\n","import torch\n","import matplotlib.pyplot as plt\n","import networkx as nx\n","import numpy as np\n","import time\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","model = AutoModelForCausalLM.from_pretrained('gpt2').to(device)\n","tokenizer = AutoTokenizer.from_pretrained('gpt2')\n","if tokenizer.pad_token_id is None:\n","    tokenizer.pad_token_id = tokenizer.eos_token_id\n","\n","model.eval()\n","\n","text = \"I have a dream\"\n","input_ids = tokenizer.encode(text, return_tensors='pt').to(device)\n","\n","outputs = model.generate(input_ids, max_length=len(input_ids.squeeze())+5)\n","generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","print(f\"Generated text: {generated_text}\")\n","\n","\n","\n","def get_log_prob(logits, token_id):\n","    # Compute the softmax of the logits\n","    probabilities = torch.nn.functional.softmax(logits, dim=-1)\n","    log_probabilities = torch.log(probabilities)\n","\n","    # Get the log probability of the token\n","    token_log_probability = log_probabilities[token_id].item()\n","    return token_log_probability\n","\n","def greedy_search(input_ids, node, length=5):\n","    if length == 0:\n","        return input_ids\n","\n","    outputs = model(input_ids)\n","    predictions = outputs.logits\n","\n","    # Get the predicted next sub-word (here we use top-k search)\n","    logits = predictions[0, -1, :]\n","    token_id = torch.argmax(logits).unsqueeze(0)\n","\n","    # Compute the score of the predicted token\n","    token_score = get_log_prob(logits, token_id)\n","\n","    # Add the predicted token to the list of input ids\n","    new_input_ids = torch.cat([input_ids, token_id.unsqueeze(0)], dim=-1)\n","\n","    # Add node and edge to graph\n","    next_token = tokenizer.decode(token_id, skip_special_tokens=True)\n","    current_node = list(graph.successors(node))[0]\n","    graph.nodes[current_node]['tokenscore'] = np.exp(token_score) * 100\n","    graph.nodes[current_node]['token'] = next_token + f\"_{length}\"\n","\n","    # Recursive call\n","    input_ids = greedy_search(new_input_ids, current_node, length-1)\n","\n","    return input_ids\n","\n","# Parameters\n","length = 5\n","beams = 1\n","\n","# Create a balanced tree with height 'length'\n","graph = nx.balanced_tree(1, length, create_using=nx.DiGraph())\n","\n","# Add 'tokenscore', 'cumscore', and 'token' attributes to each node\n","for node in graph.nodes:\n","    graph.nodes[node]['tokenscore'] = 100\n","    graph.nodes[node]['token'] = text\n","\n","# Start generating text\n","output_ids = greedy_search(input_ids, 0, length=length)\n","output = tokenizer.decode(output_ids.squeeze().tolist(), skip_special_tokens=True)\n","print(f\"Generated text: {output}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RNeXMH7jw4n8"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import networkx as nx\n","import matplotlib.colors as mcolors\n","from matplotlib.colors import LinearSegmentedColormap\n","\n","def plot_graph(graph, length, beams, score):\n","    fig, ax = plt.subplots(figsize=(3+1.2*beams**length, max(5, 2+length)), dpi=300, facecolor='white')\n","\n","    # Create positions for each node\n","    pos = nx.nx_agraph.graphviz_layout(graph, prog=\"dot\")\n","\n","    # Normalize the colors along the range of token scores\n","    if score == 'token':\n","        scores = [data['tokenscore'] for _, data in graph.nodes(data=True) if data['token'] is not None]\n","    elif score == 'sequence':\n","        scores = [data['sequencescore'] for _, data in graph.nodes(data=True) if data['token'] is not None]\n","    vmin = min(scores)\n","    vmax = max(scores)\n","    norm = mcolors.Normalize(vmin=vmin, vmax=vmax)\n","    cmap = LinearSegmentedColormap.from_list('rg', [\"r\", \"y\", \"g\"], N=256)\n","\n","    # Draw the nodes\n","    nx.draw_networkx_nodes(graph, pos, node_size=2000, node_shape='o', alpha=1, linewidths=4,\n","                          node_color=scores, cmap=cmap)\n","\n","    # Draw the edges\n","    nx.draw_networkx_edges(graph, pos)\n","\n","    # Draw the labels\n","    if score == 'token':\n","        labels = {node: data['token'].split('_')[0] + f\"\\n{data['tokenscore']:.2f}%\" for node, data in graph.nodes(data=True) if data['token'] is not None}\n","    elif score == 'sequence':\n","        labels = {node: data['token'].split('_')[0] + f\"\\n{data['sequencescore']:.2f}\" for node, data in graph.nodes(data=True) if data['token'] is not None}\n","    nx.draw_networkx_labels(graph, pos, labels=labels, font_size=10)\n","    plt.box(False)\n","\n","    # Add a colorbar\n","    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n","    sm.set_array([])\n","    if score == 'token':\n","        fig.colorbar(sm, ax=ax, orientation='vertical', pad=0, label='Token probability (%)')\n","    elif score == 'sequence':\n","        fig.colorbar(sm, ax=ax, orientation='vertical', pad=0, label='Sequence score')\n","    plt.show()\n","\n","# Plot graph\n","plot_graph(graph, length, 1.5, 'token')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iDWqHxcIw3pf"},"outputs":[],"source":["from tqdm.notebook import tqdm\n","\n","def greedy_sampling(logits, beams):\n","    return torch.topk(logits, beams).indices\n","\n","def beam_search(input_ids, node, bar, length, beams, sampling, temperature=0.1):\n","    if length == 0:\n","        return None\n","\n","    outputs = model(input_ids)\n","    predictions = outputs.logits\n","\n","    # Get the predicted next sub-word (here we use top-k search)\n","    logits = predictions[0, -1, :]\n","\n","    if sampling == 'greedy':\n","        top_token_ids = greedy_sampling(logits, beams)\n","    elif sampling == 'top_k':\n","        top_token_ids = top_k_sampling(logits, temperature, 20, beams)\n","    elif sampling == 'nucleus':\n","        top_token_ids = nucleus_sampling(logits, temperature, 0.5, beams)\n","\n","    for j, token_id in enumerate(top_token_ids):\n","        bar.update(1)\n","\n","        # Compute the score of the predicted token\n","        token_score = get_log_prob(logits, token_id)\n","        cumulative_score = graph.nodes[node]['cumscore'] + token_score\n","\n","        # Add the predicted token to the list of input ids\n","        new_input_ids = torch.cat([input_ids, token_id.unsqueeze(0).unsqueeze(0)], dim=-1)\n","\n","        # Add node and edge to graph\n","        token = tokenizer.decode(token_id, skip_special_tokens=True)\n","        current_node = list(graph.successors(node))[j]\n","        graph.nodes[current_node]['tokenscore'] = np.exp(token_score) * 100\n","        graph.nodes[current_node]['cumscore'] = cumulative_score\n","        graph.nodes[current_node]['sequencescore'] = 1/(len(new_input_ids.squeeze())) * cumulative_score\n","        graph.nodes[current_node]['token'] = token + f\"_{length}_{j}\"\n","\n","        # Recursive call\n","        beam_search(new_input_ids, current_node, bar, length-1, beams, sampling, 1)\n","\n","# Parameters\n","length = 5\n","beams = 2\n","\n","# Create a balanced tree with height 'length' and branching factor 'k'\n","graph = nx.balanced_tree(beams, length, create_using=nx.DiGraph())\n","bar = tqdm(total=len(graph.nodes))\n","\n","# Add 'tokenscore', 'cumscore', and 'token' attributes to each node\n","for node in graph.nodes:\n","    graph.nodes[node]['tokenscore'] = 100\n","    graph.nodes[node]['cumscore'] = 0\n","    graph.nodes[node]['sequencescore'] = 0\n","    graph.nodes[node]['token'] = text\n","\n","# Start generating text\n","beam_search(input_ids, 0, bar, length, beams, 'greedy', 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"piwOBUVW8Nn9"},"outputs":[],"source":["def get_log_prob(logits, token_id):\n","    # Compute the softmax of the logits\n","    probabilities = torch.nn.functional.softmax(logits, dim=-1)\n","    log_probabilities = torch.log(probabilities)\n","    print(\"log_probabilities\",log_probabilities)\n","    # Get the log probability of the token\n","    token_log_probability = log_probabilities[token_id].item()\n","    print(\"token_log_probability \",token_log_probability )\n","    return token_log_probability\n","\n","def greedy_search(input_ids, node, length=5):\n","    if length == 0:\n","        return input_ids\n","\n","    outputs = model(input_ids)\n","    predictions = outputs.logits\n","\n","    # Get the predicted next sub-word (here we use top-k search)\n","    logits = predictions[0, -1, :]\n","    token_id = torch.argmax(logits).unsqueeze(0)\n","\n","    # Compute the score of the predicted token\n","    token_score = get_log_prob(logits, token_id)\n","\n","    # Add the predicted token to the list of input ids\n","    new_input_ids = torch.cat([input_ids, token_id.unsqueeze(0)], dim=-1)\n","\n","    # Add node and edge to graph\n","    next_token = tokenizer.decode(token_id, skip_special_tokens=True)\n","    current_node = list(graph.successors(node))[0]\n","    graph.nodes[current_node]['tokenscore'] = np.exp(token_score) * 100\n","    graph.nodes[current_node]['token'] = next_token + f\"_{length}\"\n","\n","    # Recursive call\n","    input_ids = greedy_search(new_input_ids, current_node, length-1)\n","\n","    return input_ids"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R4sFH-cL9ftd"},"outputs":[],"source":["from transformers import GPT2Tokenizer, GPT2LMHeadModel\n","import torch\n","\n","# Load the GPT-2 model and tokenizer\n","model = GPT2LMHeadModel.from_pretrained('gpt2')\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","\n","# Helper function for generating text\n","def generate_text(model, tokenizer, context, max_length, method, **kwargs):\n","    # Encode the context\n","    input_ids = tokenizer.encode(context, return_tensors='pt')\n","\n","    # Generate the text\n","    output = model.generate(\n","        input_ids,\n","        max_length=max_length,\n","        do_sample=True,\n","        method=method,\n","        **kwargs\n","    )\n","\n","    # Decode the text\n","    return tokenizer.decode(output[0])\n","\n","# Greedy Search\n","greedy_search = generate_text(model, tokenizer, 'Hello,', 50, 'greedy')\n","print(greedy_search)\n","\n","# Beam Search\n","beam_search = generate_text(model, tokenizer, 'Hello,', 50, 'beam_search', num_beams=5)\n","print(beam_search)\n","\n","# Nucleus Sampling\n","nucleus_sampling = generate_text(model, tokenizer, 'Hello,', 50, 'top_p_sample', top_p=0.9)\n","print(nucleus_sampling)\n","\n","# Top-k Sampling\n","top_k_sampling = generate_text(model, tokenizer, 'Hello,', 50, 'top_k_sample', top_k=50)\n","print(top_k_sampling)"]}],"metadata":{"accelerator":"TPU","colab":{"provenance":[],"mount_file_id":"1W9_zD76VnpeD7MqP9AhICfB45aUKH7np","authorship_tag":"ABX9TyPs56RtQZ/+CNiq5H0Qvvqw"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"00b6ccaf47b64f1eb6931e98709f5580":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"012d41c2709e4d649236795fd8e7ff0e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_91440c88c0cf46939ed7a7a358199efb","placeholder":"​","style":"IPY_MODEL_f7f92e16ed1a47feb4a9107251bd621b","value":"Map:   0%"}},"01a1dc5cebeb4092b8f23f3f67968c7e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_510e731e7350404f8ef4d2b002b2c730","placeholder":"​","style":"IPY_MODEL_48e4eb70420040c4aa34d86dde94257b","value":"vocab.json: 100%"}},"057b534405d943fba373a3940b7edc1c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0766cf953d234336997d771d45935019":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c271047f8aa49759758cac88f93dbe5","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5678540f3bf24a429f59aaf30fe0e907","value":456318}},"084dad79e6a74c39a6acfa878a01df92":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"086d80481cc54cc8b66cac4a0f482168":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"092ea2e322e94d158043b02a4906fd90":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0a16aa32bdee4bb881cabf1620f7652c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b990681454b44a0b244905ddae4b076":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0b9a692a4f6e4ed0a13a95cfa5c1b49a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0c023c51cc674c6eaba1b4fd40ac3bfc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd16f5616b7848a8a884149aff371d30","max":274,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0b9a692a4f6e4ed0a13a95cfa5c1b49a","value":274}},"0db4ef5df46d4da5b09b4e995d04336b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a6783ce49cf4f95944fbd1417654e5b","placeholder":"​","style":"IPY_MODEL_dee880c6eae749e0bec80e759ecd5808","value":"tokenizer.json: 100%"}},"1035eb0d269c450a8c78f56a86451b86":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_221481c5297042e89936ee8d923475f7","placeholder":"​","style":"IPY_MODEL_add9a3b0c00f4a7a8abc40d5d3d7240f","value":" 629000/4233923 [13:16&lt;1:49:53, 546.72 examples/s]"}},"1149502f598b4071a0ef99300aa053f9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"120b58c9d7374ec1a179b7e61f975700":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_355f77e65f1a45c9a626e24169593ff7","max":4233923,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eaaf536961034721bf2fc069b78e73bc","value":630000}},"12394e9531c04efa8fea0d5c2ed08449":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dddf8f4228a445fa82d09e94e995ac59","max":274,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e5a63c50fea94391b5f554b009c478c5","value":274}},"130a2e2d27654cbc8acd52975432a87a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"143d05a70ce440d5a02731662a226235":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_741ec9096bc0446493840207f5533fed","placeholder":"​","style":"IPY_MODEL_f7eb655f775e49eebc21e4492a381e74","value":" 74.6k/74.6k [00:00&lt;00:00, 377kB/s]"}},"156da1e906204601b0c17cef703e5f96":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15acb6c55eaf403c979a89eb3af49e86":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"16d18eee5ee147fb83f6678860e3f25c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1aa4df44e4584efea55ebb604ec8dba1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b963e8e113f42808a2c2eb2b9323516":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1c8a4b8813bd4530910fec96d2256801":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1cce0281c9b343ee94d805785c9b9eb7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_783ea92abd1b445199b7bd39c7baf1d5","placeholder":"​","style":"IPY_MODEL_f0e1ef7242de4d81918640f934ef6dac","value":"Running tokenizer on dataset (num_proc=2): 100%"}},"1ddc282a1a6345688ee16dde947210b0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_74f856199806447b870eb0c79961b0e5","placeholder":"​","style":"IPY_MODEL_7c28c799250a40169341d4e0adef2312","value":"Downloading data: 100%"}},"1e1894243d0f4eaa878d224dfe71fa2a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_130a2e2d27654cbc8acd52975432a87a","placeholder":"​","style":"IPY_MODEL_6c236ab9a98c44399d6808296d2aff7f","value":"Generating train split: "}},"1ea36f68f950405fb68d18323d8e610f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"202ebfc132b14ae8ba975aff31a63854":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_01a1dc5cebeb4092b8f23f3f67968c7e","IPY_MODEL_46d405c025b94d339da14148a1bdd827","IPY_MODEL_5c735a091c164278b60ee26632632c36"],"layout":"IPY_MODEL_44dfc57026d94018895b63c30ca04062"}},"214492bb3f2a49dfbee6446fe02eb1f4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"221481c5297042e89936ee8d923475f7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"221f0f1d33884504b12fb2bc34030214":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"223f81638c804cb19bcfe35b4f2671c3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2370c63c477c41528d0c83bc141956b5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"23ce103e80b848d1a82b01ecff71ab7c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d7050bd4cb654b04a4f4d43911317ecd","IPY_MODEL_4df0cfc1dafd44c0b5a004792267cc4a","IPY_MODEL_45f65b7cdbbb4856aa987ec15088a255"],"layout":"IPY_MODEL_86d01777c9f649deb0ec0762a75a57f5"}},"24d248d3e4fb4fb6b5e11a12b30662c8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_79ea88bea71f45f0960f678f107d9d07","max":39500,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8eea0de02cf349fa897ec1cda8a4667e","value":39500}},"26efadfdfdec43c7b11cb11695b0a26f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"29c2dfea3c4046e3a35b03759699802d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"32754634c56646cfae52252c598687a1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_847d55aed2454404812c79e3d1aa090d","IPY_MODEL_12394e9531c04efa8fea0d5c2ed08449","IPY_MODEL_3846d820343949c181ae183c0a2a415e"],"layout":"IPY_MODEL_7b751de5237e438185174a97472b60f1"}},"355f77e65f1a45c9a626e24169593ff7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"359fc8b8ae9f4ffc9e5ece9118a842a9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"364914b801e44003bea00b92557094ec":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"364dd8c71e764141a3f54f8145c35f89":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_93f65b48f30246918fdbba2f22f2404f","placeholder":"​","style":"IPY_MODEL_8e8694e9504b457f91add205c9483071","value":" 3.09G/3.09G [03:06&lt;00:00, 6.23MB/s]"}},"36fa757150cb4fa991b055372dd1367e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3777e42e035847889cae3c41ce64ecc2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3846d820343949c181ae183c0a2a415e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bbd0a537fd4346678df33b09ac9a594c","placeholder":"​","style":"IPY_MODEL_436d080fe79d4532bffea1fff23681d5","value":" 274/274 [00:00&lt;00:00, 10.8kB/s]"}},"38dc93cd639942a382310ba224290401":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_084dad79e6a74c39a6acfa878a01df92","placeholder":"​","style":"IPY_MODEL_e9bf16ab17154b1b9e26adda7cbc6d24","value":" 153/153 [00:01&lt;00:00, 163.91 examples/s]"}},"3b5bf3aa4a6e4ef68fd70c8b45ae177f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_359fc8b8ae9f4ffc9e5ece9118a842a9","placeholder":"​","style":"IPY_MODEL_753fc20470274ec781a83c0ceb9a9979","value":" 4233923/0 [01:20&lt;00:00, 128618.58 examples/s]"}},"3c6e0bf5d87341f784274d5708d27e15":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3e5ad6544d734d6d9d18b06bd2c62cb5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f9bc6d49ce54bf8b63eba51d9a20a49":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"409cc1a4d33f4744915266ddbff093a1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"421ff935419c4c8bb0598512c56fbd42":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"42f184d93e1740b3aae296e6ca42ebc7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea1c803f9065486b8eb399e311d47d09","placeholder":"​","style":"IPY_MODEL_7f2255f5df1245b1b391332d9834e07d","value":"Running tokenizer on dataset: 100%"}},"436d080fe79d4532bffea1fff23681d5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"43705c4b0f7c47c183a336353299bcf3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b9c6aacfd11a42ec95b84a1e19c3b414","IPY_MODEL_60602cb7db304c238392c750ed6eeba1","IPY_MODEL_3b5bf3aa4a6e4ef68fd70c8b45ae177f"],"layout":"IPY_MODEL_3e5ad6544d734d6d9d18b06bd2c62cb5"}},"43a1fc32cc004af690461a240cceee79":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1aa4df44e4584efea55ebb604ec8dba1","max":153,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e991183bfd3348849b306b7b30ac01ea","value":153}},"4402a33edfd14d7e8c184bcff292031f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_214492bb3f2a49dfbee6446fe02eb1f4","max":2155654,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e16e5978921f415da428cf728e27c158","value":2000}},"44dfc57026d94018895b63c30ca04062":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45f65b7cdbbb4856aa987ec15088a255":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9eba39c2ffff4d429c8df3bc6f0fb5c9","placeholder":"​","style":"IPY_MODEL_36fa757150cb4fa991b055372dd1367e","value":" 153/0 [00:00&lt;00:00, 1446.70 examples/s]"}},"4656f14044264b379508976777caf7b1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f6da555cd0bb44ec8bd629c2868814ad","placeholder":"​","style":"IPY_MODEL_a2989aee0d4943848233bed9f0928be8","value":"Running tokenizer on dataset: 100%"}},"466cbe7eabf54a5ca15a14c266441ec4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46c7bdbf5f744a7fb047299f2b97d976":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_51b41b79397944a2a9a63014a39238d8","IPY_MODEL_71cadb0c5e6747ed95d3a0bede4f1077","IPY_MODEL_4caad0d18906452da293c6f2c5b126fe"],"layout":"IPY_MODEL_e09691124fcd4d5b9cd74f58782ad013"}},"46d405c025b94d339da14148a1bdd827":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_712dca51b351454289f143b34f1a2f1f","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d4a1c11259d444f695a952ffcc8a4722","value":1042301}},"46f840feaefe4f5fb151732c420a8028":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48e4eb70420040c4aa34d86dde94257b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4bb28896417c4426a843b6d1fbe770b4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4caad0d18906452da293c6f2c5b126fe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ea36f68f950405fb68d18323d8e610f","placeholder":"​","style":"IPY_MODEL_421ff935419c4c8bb0598512c56fbd42","value":" 1.01G/1.01G [01:03&lt;00:00, 18.3MB/s]"}},"4df0cfc1dafd44c0b5a004792267cc4a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b3374b389044ad48831d2f145fac31c","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_888348ad9f9f46e193df8586c4c88c41","value":1}},"4e1414362ff54c3d8cc17c3ac4f3c2db":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d3bf4280ce55434d8036816a199d6a51","IPY_MODEL_bc55217731fb4984a588701eb009c3ca","IPY_MODEL_548adba0a93842d4bb2ea761c85277d7"],"layout":"IPY_MODEL_698e14ac93d442b8b8e415f43dee1ef0"}},"4ed79eeda328469fa05c12132653103c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4fa48ac8650b4922b64630d79a41065b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50951fe4d6f74d4db8eaf18516fd6abe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"510e731e7350404f8ef4d2b002b2c730":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51b41b79397944a2a9a63014a39238d8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_50951fe4d6f74d4db8eaf18516fd6abe","placeholder":"​","style":"IPY_MODEL_6a648ce76212466a93175e458a01aa83","value":"Downloading data: 100%"}},"5210fb3dd464499c84ea081786312b6c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"52f02ff4c7b5465986e8ec74b54fcbbe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5314a561638444c2acf6973c126184c6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_364914b801e44003bea00b92557094ec","max":153,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b601e866490946dabf4295f290f02ffc","value":153}},"548adba0a93842d4bb2ea761c85277d7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b3fa3682c6ce402b8f61f19d51365a47","placeholder":"​","style":"IPY_MODEL_2370c63c477c41528d0c83bc141956b5","value":" 12.0k/12.0k [00:00&lt;00:00, 304kB/s]"}},"55d00dc969c64ae4be2c602afd2348f9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5678540f3bf24a429f59aaf30fe0e907":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"58049287401e4c78977b7691eb91a9fe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"584fbf5d820a4e1baa3626764f21c362":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8ad84df3b2ca4bf4813eb1d776ccc5ec","IPY_MODEL_0c023c51cc674c6eaba1b4fd40ac3bfc","IPY_MODEL_c467941570764d00a3625d73e897b504"],"layout":"IPY_MODEL_f99c38bcadc34204b04506b6a9334fb8"}},"58e8188eb5764df1ac4d7d38d4d48057":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5932d43e2fe14c4eb346bba665807bba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9a52e6a48ac24ba08501fa6e5ed59965","IPY_MODEL_ec25150149164fe2bca402a556f68b0f","IPY_MODEL_ef9e6d3bd4184082b0e14e44e50dbb44"],"layout":"IPY_MODEL_46f840feaefe4f5fb151732c420a8028"}},"5aec6445934245d6b31f02233a921cc0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_409cc1a4d33f4744915266ddbff093a1","placeholder":"​","style":"IPY_MODEL_a35284c22181400f9b2f73df968be9b8","value":"Running tokenizer on dataset (num_proc=2): 100%"}},"5c735a091c164278b60ee26632632c36":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_086d80481cc54cc8b66cac4a0f482168","placeholder":"​","style":"IPY_MODEL_4bb28896417c4426a843b6d1fbe770b4","value":" 1.04M/1.04M [00:00&lt;00:00, 3.94MB/s]"}},"60602cb7db304c238392c750ed6eeba1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ac770dfe1e4441eb6dd289ef9476673","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1b963e8e113f42808a2c2eb2b9323516","value":1}},"61a9176d07944de29b8430805aa3e58d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_156da1e906204601b0c17cef703e5f96","placeholder":"​","style":"IPY_MODEL_79d095c491fb4a4985c6d9269dd3bc93","value":" 316000/316000 [03:56&lt;00:00, 1520.46 examples/s]"}},"62533339afa543b3a86b0d79fcc57acf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"62e2263a07c044759c8074ecc4ba40e0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"62ef01a30e0548b082c8a27b833bff6d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_55d00dc969c64ae4be2c602afd2348f9","placeholder":"​","style":"IPY_MODEL_d8e02a18c43b49e5afdee6303b50b6e5","value":" 2000/2155654 [00:25&lt;7:29:18, 79.89 examples/s]"}},"64a05846a0c34a66a69d5376fafe6335":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2947540aeac4fd3af421283a17818c1","max":39500,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c25c354130e64329bc9f4e79cc2470a1","value":39500}},"65f8860ccec141e2b3473515e0b8bce4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67c3cacee61643dcb7bc98fcef2fd069":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a2591614c6994246a8e14a0065b043e4","placeholder":"​","style":"IPY_MODEL_62e2263a07c044759c8074ecc4ba40e0","value":" 665/665 [00:00&lt;00:00, 10.8kB/s]"}},"691a02606aa74583ab01e16dfd1a8736":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"698e14ac93d442b8b8e415f43dee1ef0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a648ce76212466a93175e458a01aa83":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6a6783ce49cf4f95944fbd1417654e5b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b01fc56e1fb4e68815b78bdadcaa5fc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a16aa32bdee4bb881cabf1620f7652c","placeholder":"​","style":"IPY_MODEL_ef969a4e2250414ea5243c4e2be6a6b6","value":"Running tokenizer on dataset:   0%"}},"6b5bc9c04c194838aac22e8f041461d6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b1e9398d40344f592779b101d09c874","placeholder":"​","style":"IPY_MODEL_b92e16f9491045ba98eded6d34318024","value":" 39500/39500 [00:31&lt;00:00, 1508.95 examples/s]"}},"6c236ab9a98c44399d6808296d2aff7f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6d01384d51174db5b5501c17886f3893":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c89e055049da4ef69e22a1068ab20495","max":316000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_092ea2e322e94d158043b02a4906fd90","value":316000}},"6daac74d5fa44c4680b4d07b6c2bba68":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6f00ddcd825c4cba996d02f082000d48","IPY_MODEL_0766cf953d234336997d771d45935019","IPY_MODEL_7ddd1cd7d90a40ef82b35960270bbba0"],"layout":"IPY_MODEL_7ba8a400c70b4ab9a6a77792d6f7f02a"}},"6f00ddcd825c4cba996d02f082000d48":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_65f8860ccec141e2b3473515e0b8bce4","placeholder":"​","style":"IPY_MODEL_6f14bf9f327744dda29773257866396b","value":"merges.txt: 100%"}},"6f14bf9f327744dda29773257866396b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"711544b45c87413ea1a984f5bc29a606":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"712dca51b351454289f143b34f1a2f1f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71cadb0c5e6747ed95d3a0bede4f1077":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f9bc6d49ce54bf8b63eba51d9a20a49","max":1008442855,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8b167546c2cf49b6b9540a9350659ca5","value":1008442855}},"733a0727490b4b80a1ebeb8d3d024b87":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7341cdc51aa040b0b98ab5f1998253e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_00b6ccaf47b64f1eb6931e98709f5580","max":3090560834,"min":0,"orientation":"horizontal","style":"IPY_MODEL_867d0b40895c4398a604638df2d42d98","value":3090560834}},"741ec9096bc0446493840207f5533fed":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74f856199806447b870eb0c79961b0e5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"753fc20470274ec781a83c0ceb9a9979":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"764373327b3241658360fbea9aa808f0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_95c9bbbf4f904e40afbb24b684ec9f79","max":316000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_29c2dfea3c4046e3a35b03759699802d","value":0}},"7786378dd3f443c1bce8ce094e9e7b65":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4656f14044264b379508976777caf7b1","IPY_MODEL_64a05846a0c34a66a69d5376fafe6335","IPY_MODEL_b49e04d6811040a4a0c74803918ea881"],"layout":"IPY_MODEL_d4bc306133fd4f44b4c6a76815bfeeaa"}},"778e273172054af182d83b29902bd40f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"783ea92abd1b445199b7bd39c7baf1d5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79383bfa72304d4cbf388b7c87a47795":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"79d095c491fb4a4985c6d9269dd3bc93":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"79ea88bea71f45f0960f678f107d9d07":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b1e9398d40344f592779b101d09c874":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b25f5caaa56436c9640e8a027f323c5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_58049287401e4c78977b7691eb91a9fe","placeholder":"​","style":"IPY_MODEL_a3d8998ece0d4124ac2b20140c4eb4c0","value":"Running tokenizer on dataset (num_proc=2):  15%"}},"7b3374b389044ad48831d2f145fac31c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"7b751de5237e438185174a97472b60f1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ba8a400c70b4ab9a6a77792d6f7f02a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c28c799250a40169341d4e0adef2312":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7ddd1cd7d90a40ef82b35960270bbba0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a429f410050a4ff2afdd25bb78ae6ea0","placeholder":"​","style":"IPY_MODEL_3c6e0bf5d87341f784274d5708d27e15","value":" 456k/456k [00:00&lt;00:00, 2.35MB/s]"}},"7f2255f5df1245b1b391332d9834e07d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8064722977a140e991bb706caa020476":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_733a0727490b4b80a1ebeb8d3d024b87","max":665,"min":0,"orientation":"horizontal","style":"IPY_MODEL_79383bfa72304d4cbf388b7c87a47795","value":665}},"81a9953142c3457aa95965b9be72c45a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b128b5a5304a4f4d9f1556f38abe6c33","placeholder":"​","style":"IPY_MODEL_5210fb3dd464499c84ea081786312b6c","value":" 1.36M/1.36M [00:00&lt;00:00, 10.0MB/s]"}},"84567b25bd254c239ee17edf2701239d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6b01fc56e1fb4e68815b78bdadcaa5fc","IPY_MODEL_4402a33edfd14d7e8c184bcff292031f","IPY_MODEL_62ef01a30e0548b082c8a27b833bff6d"],"layout":"IPY_MODEL_3777e42e035847889cae3c41ce64ecc2"}},"847d55aed2454404812c79e3d1aa090d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c4c2a5dd751e4b7facbec083fc4a4fdf","placeholder":"​","style":"IPY_MODEL_62533339afa543b3a86b0d79fcc57acf","value":"Downloading readme: 100%"}},"867d0b40895c4398a604638df2d42d98":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"86d01777c9f649deb0ec0762a75a57f5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87c092f83b744cc68c8be592c76c0efc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88455d140d0f4e4a8305b41aca772087":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_aca5cea704a94c5c88850badc0938b18","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b592134efbdd43ec8d852ec9155c0396","value":1}},"888348ad9f9f46e193df8586c4c88c41":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8a78fe1ec72f4cb680f03b6e2a9b21c6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8ad84df3b2ca4bf4813eb1d776ccc5ec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_221f0f1d33884504b12fb2bc34030214","placeholder":"​","style":"IPY_MODEL_be974a557b354fe3888e06a2140888bf","value":"Downloading readme: 100%"}},"8b167546c2cf49b6b9540a9350659ca5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8c271047f8aa49759758cac88f93dbe5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e8694e9504b457f91add205c9483071":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8eea0de02cf349fa897ec1cda8a4667e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"90b5d78bd64f474faba7dd79cc9f93fe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90e1d7b0a8ad410d815cf221c09c9f7a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7b25f5caaa56436c9640e8a027f323c5","IPY_MODEL_120b58c9d7374ec1a179b7e61f975700","IPY_MODEL_1035eb0d269c450a8c78f56a86451b86"],"layout":"IPY_MODEL_9687edde9f19404f9fbd2236ec6bdbf5"}},"91440c88c0cf46939ed7a7a358199efb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"928ab9c982fc4c5891850aeefa902695":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93f65b48f30246918fdbba2f22f2404f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95c9bbbf4f904e40afbb24b684ec9f79":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9638a1305f7e4ba89d26f3d24274e0a1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1ddc282a1a6345688ee16dde947210b0","IPY_MODEL_bb5775e233614278bb9b97c43466bfc9","IPY_MODEL_143d05a70ce440d5a02731662a226235"],"layout":"IPY_MODEL_dfdf4fff0c76485ab9a62afbf0d49eae"}},"9687edde9f19404f9fbd2236ec6bdbf5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"971f6639a3904092ace257c035e1fe73":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98054981de6048138748c4679bc5b285":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99eff6d3f17d4239a9225e5205e8a9aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_691a02606aa74583ab01e16dfd1a8736","placeholder":"​","style":"IPY_MODEL_4ed79eeda328469fa05c12132653103c","value":"Downloading data: 100%"}},"9a52e6a48ac24ba08501fa6e5ed59965":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_90b5d78bd64f474faba7dd79cc9f93fe","placeholder":"​","style":"IPY_MODEL_26efadfdfdec43c7b11cb11695b0a26f","value":"Downloading data: 100%"}},"9ac770dfe1e4441eb6dd289ef9476673":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"9bb971a8a84d47fb881094b3ae778cfb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_df7cbcab80f94db59751c9f3babe4452","IPY_MODEL_8064722977a140e991bb706caa020476","IPY_MODEL_67c3cacee61643dcb7bc98fcef2fd069"],"layout":"IPY_MODEL_711544b45c87413ea1a984f5bc29a606"}},"9bdb85bfe2af4693ac46c17663c61b16":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1d9f7e9a13148f9a5bba5035c5d213f","max":1355256,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b65ed51167124d7999bcc4dd395b101f","value":1355256}},"9eba39c2ffff4d429c8df3bc6f0fb5c9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a197fa6bcd9341699e993ffe82b35710":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2591614c6994246a8e14a0065b043e4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2989aee0d4943848233bed9f0928be8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a35284c22181400f9b2f73df968be9b8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a3d8998ece0d4124ac2b20140c4eb4c0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a429f410050a4ff2afdd25bb78ae6ea0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4b9895360c04a46be8d42bc31ade06a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd72ac832df141c591eb4a31709e2bd9","placeholder":"​","style":"IPY_MODEL_15acb6c55eaf403c979a89eb3af49e86","value":"Running tokenizer on dataset: 100%"}},"a65709fd3aa2475f95143403caeb2591":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9f989db21bd4bb6a737ffebc6c50278":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ab7260fe494f469da37f654555282a60":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aca5cea704a94c5c88850badc0938b18":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"ad43c979a8aa4cb79517dd89303b727e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ad7a96ee3b7f4a57b8025662503b2d16":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"add9a3b0c00f4a7a8abc40d5d3d7240f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b128b5a5304a4f4d9f1556f38abe6c33":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1d9f7e9a13148f9a5bba5035c5d213f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3fa3682c6ce402b8f61f19d51365a47":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3fa37f9d7994dd2bc85d03bff4ae69d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b49e04d6811040a4a0c74803918ea881":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_778e273172054af182d83b29902bd40f","placeholder":"​","style":"IPY_MODEL_223f81638c804cb19bcfe35b4f2671c3","value":" 39500/39500 [00:29&lt;00:00, 1551.55 examples/s]"}},"b592134efbdd43ec8d852ec9155c0396":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b5e04037262749a992fe7b29be0c18e4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_99eff6d3f17d4239a9225e5205e8a9aa","IPY_MODEL_7341cdc51aa040b0b98ab5f1998253e3","IPY_MODEL_364dd8c71e764141a3f54f8145c35f89"],"layout":"IPY_MODEL_1c8a4b8813bd4530910fec96d2256801"}},"b601e866490946dabf4295f290f02ffc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b65ed51167124d7999bcc4dd395b101f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b7d594c37b724e1d95a94ad92b5df379":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b875be6a3807428094e3083b742f7ae4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b92e16f9491045ba98eded6d34318024":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b9c6aacfd11a42ec95b84a1e19c3b414":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_52f02ff4c7b5465986e8ec74b54fcbbe","placeholder":"​","style":"IPY_MODEL_c28be050deaa445987f3977e8128caf3","value":"Generating train split: "}},"bb5775e233614278bb9b97c43466bfc9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4fa48ac8650b4922b64630d79a41065b","max":74565,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8a78fe1ec72f4cb680f03b6e2a9b21c6","value":74565}},"bbd0a537fd4346678df33b09ac9a594c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc55217731fb4984a588701eb009c3ca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad7a96ee3b7f4a57b8025662503b2d16","max":11966,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c2766a2d12114eb8b6f236a44cef33b2","value":11966}},"bd72ac832df141c591eb4a31709e2bd9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bdabf5c302d34f0f955914d325171dc0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a4b9895360c04a46be8d42bc31ade06a","IPY_MODEL_6d01384d51174db5b5501c17886f3893","IPY_MODEL_61a9176d07944de29b8430805aa3e58d"],"layout":"IPY_MODEL_ec76ae25e8dd40509f440b5266e44b4f"}},"be974a557b354fe3888e06a2140888bf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bf711dbbb5994d42bbf2c8ec797e914d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bf78a7b1e66f4f6aa6f26450bb6314b3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_42f184d93e1740b3aae296e6ca42ebc7","IPY_MODEL_24d248d3e4fb4fb6b5e11a12b30662c8","IPY_MODEL_6b5bc9c04c194838aac22e8f041461d6"],"layout":"IPY_MODEL_ab7260fe494f469da37f654555282a60"}},"c25c354130e64329bc9f4e79cc2470a1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c2766a2d12114eb8b6f236a44cef33b2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c28be050deaa445987f3977e8128caf3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c467941570764d00a3625d73e897b504":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_971f6639a3904092ace257c035e1fe73","placeholder":"​","style":"IPY_MODEL_b7d594c37b724e1d95a94ad92b5df379","value":" 274/274 [00:00&lt;00:00, 14.4kB/s]"}},"c4c2a5dd751e4b7facbec083fc4a4fdf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c89e055049da4ef69e22a1068ab20495":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ca52c8bc8c6142fb8c9b1287c7c76f02":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1cce0281c9b343ee94d805785c9b9eb7","IPY_MODEL_5314a561638444c2acf6973c126184c6","IPY_MODEL_38dc93cd639942a382310ba224290401"],"layout":"IPY_MODEL_87c092f83b744cc68c8be592c76c0efc"}},"cd16f5616b7848a8a884149aff371d30":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d21c425ecd7a414d86c3940c8791ed8e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_012d41c2709e4d649236795fd8e7ff0e","IPY_MODEL_764373327b3241658360fbea9aa808f0","IPY_MODEL_f63c0ef9395a46479f0f963a1b9a5f0a"],"layout":"IPY_MODEL_928ab9c982fc4c5891850aeefa902695"}},"d273ced174c3460dbe93409ad894c20a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0db4ef5df46d4da5b09b4e995d04336b","IPY_MODEL_9bdb85bfe2af4693ac46c17663c61b16","IPY_MODEL_81a9953142c3457aa95965b9be72c45a"],"layout":"IPY_MODEL_1149502f598b4071a0ef99300aa053f9"}},"d2947540aeac4fd3af421283a17818c1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3bf4280ce55434d8036816a199d6a51":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e4a4bda583844cce9fc573eecab76e3b","placeholder":"​","style":"IPY_MODEL_df01a76a67674b5b865a33ac201cad8d","value":"Downloading readme: 100%"}},"d4252f685404401c9640402bf4a88c2f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d4a1c11259d444f695a952ffcc8a4722":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d4bc306133fd4f44b4c6a76815bfeeaa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7050bd4cb654b04a4f4d43911317ecd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a197fa6bcd9341699e993ffe82b35710","placeholder":"​","style":"IPY_MODEL_ea8d35627aed4490b83184462b0b67b4","value":"Generating train split: "}},"d85f0be2132d435db97847e39ce04644":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1e1894243d0f4eaa878d224dfe71fa2a","IPY_MODEL_88455d140d0f4e4a8305b41aca772087","IPY_MODEL_f1171cfc90d241f5b0d7449517ce82b5"],"layout":"IPY_MODEL_16d18eee5ee147fb83f6678860e3f25c"}},"d8e02a18c43b49e5afdee6303b50b6e5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dddf8f4228a445fa82d09e94e995ac59":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dee880c6eae749e0bec80e759ecd5808":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"df01a76a67674b5b865a33ac201cad8d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"df7cbcab80f94db59751c9f3babe4452":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_057b534405d943fba373a3940b7edc1c","placeholder":"​","style":"IPY_MODEL_ad43c979a8aa4cb79517dd89303b727e","value":"config.json: 100%"}},"dfdf4fff0c76485ab9a62afbf0d49eae":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e09691124fcd4d5b9cd74f58782ad013":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e16e5978921f415da428cf728e27c158":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e4a4bda583844cce9fc573eecab76e3b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5a63c50fea94391b5f554b009c478c5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e991183bfd3348849b306b7b30ac01ea":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e9bf16ab17154b1b9e26adda7cbc6d24":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ea1c803f9065486b8eb399e311d47d09":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea8d35627aed4490b83184462b0b67b4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eaaf536961034721bf2fc069b78e73bc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ec25150149164fe2bca402a556f68b0f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_98054981de6048138748c4679bc5b285","max":74565,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b3fa37f9d7994dd2bc85d03bff4ae69d","value":74565}},"ec76ae25e8dd40509f440b5266e44b4f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ecfc300a59d14654aa4eb783cb48b176":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef969a4e2250414ea5243c4e2be6a6b6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ef9e6d3bd4184082b0e14e44e50dbb44":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b875be6a3807428094e3083b742f7ae4","placeholder":"​","style":"IPY_MODEL_d4252f685404401c9640402bf4a88c2f","value":" 74.6k/74.6k [00:00&lt;00:00, 356kB/s]"}},"f0e1ef7242de4d81918640f934ef6dac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f10dbd52499c4136a69fa1b610ac9f74":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a65709fd3aa2475f95143403caeb2591","placeholder":"​","style":"IPY_MODEL_a9f989db21bd4bb6a737ffebc6c50278","value":" 153/153 [00:00&lt;00:00, 111.27 examples/s]"}},"f1171cfc90d241f5b0d7449517ce82b5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_466cbe7eabf54a5ca15a14c266441ec4","placeholder":"​","style":"IPY_MODEL_bf711dbbb5994d42bbf2c8ec797e914d","value":" 153/0 [00:00&lt;00:00, 2682.77 examples/s]"}},"f4a12d327a1742a7b0070b3bd40876fb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5aec6445934245d6b31f02233a921cc0","IPY_MODEL_43a1fc32cc004af690461a240cceee79","IPY_MODEL_f10dbd52499c4136a69fa1b610ac9f74"],"layout":"IPY_MODEL_58e8188eb5764df1ac4d7d38d4d48057"}},"f63c0ef9395a46479f0f963a1b9a5f0a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ecfc300a59d14654aa4eb783cb48b176","placeholder":"​","style":"IPY_MODEL_0b990681454b44a0b244905ddae4b076","value":" 0/316000 [00:00&lt;?, ? examples/s]"}},"f6da555cd0bb44ec8bd629c2868814ad":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7eb655f775e49eebc21e4492a381e74":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f7f92e16ed1a47feb4a9107251bd621b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f99c38bcadc34204b04506b6a9334fb8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}