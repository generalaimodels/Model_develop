{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyNB19PmClFWs2Da0ZXtZFfH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install -q -U datasets"],"metadata":{"id":"sXwcWuYhBqnt"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RFg0FuY68eki"},"outputs":[],"source":["from datasets import load_dataset, Dataset, DatasetDict\n","from typing import Any, Dict, Union, Optional\n","import logging\n","\n","# Configure logging to display only warnings and errors\n","logging.basicConfig(level=logging.WARNING)\n","\n","# Type alias for the possible return types of the load_dataset function\n","DatasetReturnType = Union[Dataset, DatasetDict]\n","\n","def load_dataset_with_config(\n","    dataset_name: str,\n","    dataset_config: Union[str, Dict[str, Any], None] = None,\n","    split: Optional[str] = None,\n","    **kwargs: Any\n",") -> Optional[DatasetReturnType]:\n","    \"\"\"\n","    Download and load a dataset by name and split with error handling and custom configuration.\n","\n","    :param dataset_name: The name of the dataset to load.\n","    :param dataset_config: The configuration of the dataset. This can be a string, a dictionary, or None.\n","    :param split: The split of the dataset to load. If None, the default split is used.\n","    :param kwargs: Additional keyword arguments to pass to the load_dataset function.\n","    :return: A Dataset or DatasetDict object containing the loaded dataset, or None if an error occurs.\n","    \"\"\"\n","    try:\n","        # Load the dataset with the specified parameters\n","        if isinstance(dataset_config, str):\n","            dataset = load_dataset(dataset_name, dataset_config, split=split, **kwargs)\n","        elif isinstance(dataset_config, dict):\n","            dataset = load_dataset(dataset_name, data_files=dataset_config, split=split, **kwargs)\n","        else:\n","            dataset = load_dataset(dataset_name, split=split, **kwargs)\n","\n","        return dataset\n","    except Exception as e:\n","        # Log the error message\n","        logging.error(f\"Failed to load dataset '{dataset_name}': {e}\")\n","        return None\n","\n","# Example usage:\n","if __name__ == \"__main__\":\n","    # Load a dataset with a specific name and split, catching any errors that might occur.\n","    dataset = load_dataset_with_config('squad', split='validation[:10%]')\n","\n","    if dataset:\n","        # Successful dataset retrieval, you can now work with the dataset\n","        print(f\"Dataset loaded successfully: {dataset}\")\n","    else:\n","        # Dataset loading failed, handle the situation appropriately\n","        print(\"Failed to load the dataset.\")"]},{"cell_type":"code","source":["from typing import List, Dict, Callable, Any, Optional\n","\n","def filter_dataset(dataset: List[Dict[str, Any]], predicate: Callable[[Dict[str, Any]], bool]) -> Optional[List[Dict[str, Any]]]:\n","    \"\"\"\n","    Filter a dataset by a predicate function.\n","\n","    :param dataset: The dataset to filter, represented as a list of dictionaries.\n","    :param predicate: A function that takes a dictionary representing a sample and returns True\n","                      if the sample should be included in the filtered dataset, False otherwise.\n","    :return: A list of dictionaries representing the filtered samples, or None if an error occurs.\n","    \"\"\"\n","    try:\n","        # Use a list comprehension to filter the dataset using the predicate\n","        filtered_dataset = [sample for sample in dataset if predicate(sample)]\n","        return filtered_dataset\n","    except Exception as e:\n","        # Log the error and return None to indicate that filtering failed\n","        print(f\"An error occurred while filtering the dataset: {e}\")\n","        return None\n","\n","# Example usage:\n","if __name__ == \"__main__\":\n","    # An example dataset consisting of dictionaries\n","    example_dataset = [\n","        {'name': 'Alice', 'age': 30},\n","        {'name': 'Bob', 'age': 25},\n","        {'name': 'Charlie', 'age': 35}\n","    ]\n","\n","    # A predicate function that filters samples based on the 'age' attribute\n","    age_predicate = lambda sample: sample['age'] > 30\n","\n","    # Filter the dataset using the predicate function\n","    filtered_dataset = filter_dataset(example_dataset, age_predicate)\n","\n","    if filtered_dataset is not None:\n","        print(\"Filtered dataset:\")\n","        for sample in filtered_dataset:\n","            print(sample)\n","    else:\n","        # Handle the situation where filtering failed\n","        print(\"Failed to filter the dataset.\")"],"metadata":{"id":"7Ugl-y-IBdAe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from typing import Callable, List\n","from datasets import Dataset\n","\n","def filter_dataset(dataset: Dataset, predicate: Callable[[dict], bool]) -> List[dict]:\n","    \"\"\"\n","    Filter a dataset by a predicate.\n","\n","    :param dataset: The dataset to filter.\n","    :param predicate: A function that takes in a dictionary representing a sample and returns True if the sample should be included in the filtered dataset and False otherwise.\n","    :return: A list of dictionaries representing the filtered samples.\n","    \"\"\"\n","    filtered_samples = []\n","    for sample in dataset:\n","        if predicate(sample):\n","            filtered_samples.append(sample)\n","    return filtered_samples"],"metadata":{"id":"Ww36kejY-GH8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from datasets import load_dataset, DatasetDict, Dataset, logging\n","from typing import Any, Dict, Optional, Tuple\n","from pprint import pprint\n","\n","# Set the logging level to warning to avoid too much verbosity\n","logging.set_verbosity_warning()\n","\n","# Define a function to safely load a dataset\n","def safe_load_dataset(name: str, split: Optional[str] = None) -> Tuple[Optional[Dataset], Optional[Dict[str, Any]]]:\n","    try:\n","        # Attempt to load the dataset\n","        dataset = load_dataset(name, split=split)\n","        info = dataset.info.dict if isinstance(dataset, Dataset) else None\n","        return dataset, info\n","    except Exception as e:\n","        # Handle exceptions that may occur during dataset loading\n","        print(f\"An error occurred while loading the dataset: {e}\")\n","        return None, None\n","\n","# Define a function to print various information about a dataset\n","def print_dataset_info(dataset: Dataset) -> None:\n","    # Print basic information about the dataset\n","    print(\"ðŸ‘‰ Dataset:\")\n","    print(dataset)\n","    print(f\"ðŸ‘‰ Dataset length: {len(dataset)}\")\n","\n","    # Print the first item of the dataset\n","    print(\"\\nðŸ‘‰ First item 'dataset[0]':\")\n","    pprint(dataset[0])\n","\n","    # Print a slice of the dataset\n","    print(\"\\nðŸ‘‰ Slice of the two items 'dataset[10:12]':\")\n","    pprint(dataset[10:12])\n","\n","    # Print column names and features\n","    print(\"\\nColumn names:\")\n","    pprint(dataset.column_names)\n","    print(\"Features:\")\n","    pprint(dataset.features)\n","\n","    # Print the length of each context string in the dataset\n","    print(\"\\nLength of context strings in the dataset:\")\n","    dataset.map(lambda example: print(len(example['context']), end=','))\n","\n","# Main function to execute the dataset operations\n","def main():\n","    dataset_name = 'squad'\n","    dataset_split = 'validation[:10%]'\n","\n","    # Load the dataset safely\n","    dataset, info = safe_load_dataset(dataset_name, split=dataset_split)\n","\n","    # If the dataset was loaded successfully, print its information\n","    if dataset is not None and info is not None:\n","        pprint(info)\n","        print_dataset_info(dataset)\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"id":"Xm2FLcOs-Wqm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","\n","def contains_keyword(sample: dict) -> bool:\n","    keyword = \"election\"\n","    return re.search(keyword, sample[\"title\"], re.IGNORECASE) is not None\n","\n","dataset = load_dataset(\"ag_news\", split=\"test\")\n","filtered_samples = filter_dataset(dataset, contains_keyword)\n","print(len(filtered_samples))"],"metadata":{"id":"pcv0E71L-Wa3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from typing import Optional, Union\n","from datasets import DatasetInfo\n","\n","def get_dataset_info(dataset_name: str,\n","                     with_details: Optional[bool] = True) -> Union[str, DatasetInfo]:\n","    \"\"\"\n","    Retrieve the details of a dataset by name.\n","\n","    :param dataset_name: The name of the dataset to retrieve.\n","    :param with_details: Whether to retrieve the full dataset details or just the name. Defaults to True.\n","    :return: The name of the dataset if with_details is False, or a DatasetInfo object containing the full dataset details if with_details is True.\n","    \"\"\"\n","    datasets = list_datasets(with_details=with_details)\n","    dataset_index = datasets.index(dataset_name)\n","    if with_details:\n","        return datasets[dataset_index]\n","    else:\n","        return dataset_name"],"metadata":{"id":"AvJBVd7u-rzG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["squad_dataset_name = 'squad'\n","squad_dataset_info = get_dataset_info(squad_dataset_name, with_details=True)\n","squad_license = extract_attribute(squad_dataset_info, 'license')\n","print(squad_license)"],"metadata":{"id":"kgj0gKjC-w6b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from typing import List, Optional, Union\n","from datasets import Dataset, DatasetDict\n","\n","def load_dataset(dataset_name: str,\n","                 dataset_config: Optional[Union[str, dict]] = None,\n","                 split: Optional[str] = None,\n","                 **kwargs) -> Union[Dataset, DatasetDict]:\n","    \"\"\"\n","    Download and load a dataset by name and split.\n","\n","    :param dataset_name: The name of the dataset to load.\n","    :param dataset_config: The configuration of the dataset. This can be a string, a dictionary, or None.\n","    :param split: The split of the dataset to load. If None, the default split is used.\n","    :param kwargs: Additional keyword arguments to pass to the load_dataset function.\n","    :return: A Dataset or DatasetDict object containing the loaded dataset.\n","    \"\"\"\n","    if dataset_config is None:\n","        return load_dataset(dataset_name, split=split, **kwargs)\n","    elif isinstance(dataset_config, str):\n","        return load_dataset(dataset_name, name=dataset_config, split=split, **kwargs)\n","    elif isinstance(dataset_config, dict):\n","        return load_dataset(dataset_name, config=dataset_config, split=split, **kwargs)\n","    else:\n","        raise ValueError(\"dataset_config must be a string, a dictionary, or None.\")"],"metadata":{"id":"0RDHaEMfAmKg"},"execution_count":null,"outputs":[]}]}