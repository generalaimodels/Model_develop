{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"mount_file_id":"1yOIHI-GHRn1Frdo6LsPUp9HGoWVr75GL","authorship_tag":"ABX9TyNLbd7byq+YBVlP8kM8tIOQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"owmjxb9S0vSw"},"outputs":[],"source":["!pip install datasets"]},{"cell_type":"code","source":["import csv\n","import json\n","\n","def csv_to_json(csv_file_path, json_file_path):\n","  \"\"\" Converts a CSV file with variable X columns and Y rows into a JSON file.\n","\n","  Args:\n","    csv_file_path (str): Path to the input CSV file.\n","    json_file_path (str): Path to the desired output JSON file.\n","  \"\"\"\n","  try:\n","    # Open the CSV file for reading\n","    with open(csv_file_path, 'r', encoding='utf-8') as csv_file:\n","      # Create a CSV reader object\n","      csv_reader = csv.DictReader(csv_file)\n","\n","      # Convert CSV rows into a list of dictionaries\n","      data = list(csv_reader)\n","\n","    # Open the JSON file for writing\n","    with open(json_file_path, 'w', encoding='utf-8') as json_file:\n","      # Dump the list of dictionaries to the JSON file\n","      json.dump(data, json_file, ensure_ascii=False, indent=4)\n","\n","    print(f'Successfully converted {csv_file_path} to {json_file_path}.')\n","\n","  except FileNotFoundError:\n","    print(f'Error: CSV file {csv_file_path} not found.')\n","\n","  except Exception as e:\n","    print(f'An error occurred: {e}')\n","\n","# Example Usage:\n","csv_file = '/content/drive/MyDrive/Adversarial_chatbot_dataset _test.csv'\n","json_file = 'hemanth_teating_adversarical.json'\n","csv_to_json(csv_file, json_file)"],"metadata":{"id":"hKcpOQSy3X2P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json\n","\n","json_file = 'hemanth_teating_adversarical.json'\n","\n","try:\n","    # Open the JSON file for reading\n","    with open(json_file, 'r', encoding='utf-8') as file:\n","        # Load the JSON content\n","        data = json.load(file)\n","        # Display the content\n","        print(data[:1][0]['input'])\n","\n","except FileNotFoundError:\n","    print(f\"File '{json_file}' not found.\")\n","\n","except Exception as e:\n","    print(f\"Error: {e}\")\n"],"metadata":{"id":"tZ04FDnV6fpS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import csv\n","import json\n","\n","def json_to_csv(json_file_path, csv_file_path):\n","  \"\"\" Converts a JSON file into a CSV file.\n","\n","  Args:\n","    json_file_path (str): Path to the input JSON file.\n","    csv_file_path (str): Path to the desired output CSV file.\n","  \"\"\"\n","  try:\n","    # Open the JSON file for reading\n","    with open(json_file_path, 'r', encoding='utf-8') as json_file:\n","      # Load the JSON data into a list of dictionaries\n","      data = json.load(json_file)\n","\n","    # Get the keys of the first dictionary to use as CSV headers\n","    headers = list(data[0].keys())\n","\n","    # Open the CSV file for writing\n","    with open(csv_file_path, 'w', encoding='utf-8', newline='') as csv_file:\n","      # Create a CSV writer object\n","      csv_writer = csv.DictWriter(csv_file, fieldnames=headers)\n","\n","      # Write the headers to the CSV file\n","      csv_writer.writeheader()\n","\n","      # Write each dictionary in the list to the CSV file\n","      for row in data:\n","        csv_writer.writerow(row)\n","\n","    print(f'Successfully converted {json_file_path} to {csv_file_path}.')\n","\n","  except FileNotFoundError:\n","    print(f'Error: JSON file {json_file_path} not found.')\n","\n","  except Exception as e:\n","    print(f'An error occurred: {e}')\n","\n","# Example Usage:\n","json_file = '/content/drive/MyDrive/MetaMathQA-395K.json'\n","csv_file = 'hemanth_adversarical.csv'\n","json_to_csv(json_file, csv_file)"],"metadata":{"id":"Ub2zRoyr7ePw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import csv\n","\n","with open('hemanth_adversarical.csv', 'r') as csv_file:\n","    csv_reader = csv.reader(csv_file)\n","\n","    for row in csv_reader:\n","        print(', '.join(row))"],"metadata":{"id":"pRXpDNFU7-wf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import csv\n","import yaml\n","\n","def csv_to_yaml(csv_file_path, yaml_file_path):\n","  \"\"\" Converts a CSV file with variable X columns and Y rows into a YAML file.\n","\n","  Args:\n","    csv_file_path (str): Path to the input CSV file.\n","    yaml_file_path (str): Path to the desired output YAML file.\n","  \"\"\"\n","  try:\n","    # Open the CSV file for reading\n","    with open(csv_file_path, 'r', encoding='utf-8') as csv_file:\n","      # Create a CSV reader object\n","      csv_reader = csv.DictReader(csv_file)\n","\n","      # Convert CSV rows into a list of dictionaries\n","      data = list(csv_reader)\n","\n","    # Open the YAML file for writing\n","    with open(yaml_file_path, 'w', encoding='utf-8') as yaml_file:\n","      # Dump the list of dictionaries to the YAML file\n","      yaml.dump(data, yaml_file, allow_unicode=True)\n","\n","    print(f'Successfully converted {csv_file_path} to {yaml_file_path}.')\n","\n","  except FileNotFoundError:\n","    print(f'Error: CSV file {csv_file_path} not found.')\n","\n","  except Exception as e:\n","    print(f'An error occurred: {e}')\n","\n","# Example Usage:\n","csv_file = '/content/drive/MyDrive/Adversarial_chatbot_dataset _test.csv'\n","yaml_file = 'hemanth_adversarial.yaml'\n","csv_to_yaml(csv_file, yaml_file)"],"metadata":{"id":"GHoUY7HD8MNI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install pyyaml\n"],"metadata":{"id":"q2N1eVqH85tU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import yaml\n","\n","yaml_file = 'hemanth_adversarial.yaml'\n","\n","try:\n","    # Open the YAML file for reading\n","    with open(yaml_file, 'r', encoding='utf-8') as file:\n","        # Load the YAML content\n","        data = yaml.safe_load(file)\n","        # Display the content\n","        print(data[:][:1][0]['output'])\n","\n","except FileNotFoundError:\n","    print(f\"File '{yaml_file}' not found.\")\n","\n","except Exception as e:\n","    print(f\"Error: {e}\")\n"],"metadata":{"id":"eMjiZKiv8_2g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import json\n","import yaml\n","\n","def read_files(folder_path, extensions):\n","  \"\"\" Reads files with specified extensions from a given folder.\n","\n","  Args:\n","    folder_path (str): Path to the folder containing the files.\n","    extensions (list): List of file extensions to filter by (e.g., '.md', '.py').\n","\n","  Returns:\n","    A dictionary of file contents, with file paths as keys and content as values.\n","  \"\"\"\n","\n","  # Validate input\n","  if not os.path.isdir(folder_path):\n","    raise ValueError(f'Invalid folder path: {folder_path}')\n","  if not extensions:\n","    raise ValueError('No file extensions specified.')\n","\n","  # Initialize dictionary to store file content\n","  file_contents = {}\n","\n","  # Iterate through files in the folder\n","  for file in os.listdir(folder_path):\n","    # Check if file has a specified extension\n","    if file.endswith(tuple(extensions)):\n","      # Get file path\n","      file_path = os.path.join(folder_path, file)\n","\n","      # Read file content based on extension\n","      try:\n","        if file.endswith('.json'):\n","          with open(file_path, 'r') as f:\n","            file_content = json.load(f)\n","        elif file.endswith('.yaml'):\n","          with open(file_path, 'r') as f:\n","            file_content = yaml.safe_load(f)\n","        else:\n","          with open(file_path, 'r') as f:\n","            file_content = f.read()\n","      except Exception as e:\n","        print(f'Error reading file {file_path}: {e}')\n","        continue\n","\n","      # Add file content to dictionary\n","      file_contents[file_path] = file_content\n","\n","  return file_contents\n","\n","\n","# Example usage\n","if __name__ == '__main__':\n","  # Folder path containing files with specified extensions\n","  folder_path = '/content/drive/MyDrive '\n","\n","  # List of file extensions to filter by\n","  extensions = ['.md', '.py', '.csv', '.json', '.yaml']\n","\n","  # Read files with specified extensions from the folder\n","  file_contents = read_files(folder_path, extensions)\n","\n","  # Print file contents\n","  for file_path, content in file_contents.items():\n","    print(f'{file_path}:\\n{content}')"],"metadata":{"id":"hrGGMdNUBQYL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import json\n","import yaml\n","\n","def read_files(folder_path, extensions, recursive=False):\n","  \"\"\" Reads files with specified extensions from a given folder and its subfolders.\n","\n","  Args:\n","    folder_path (str): Path to the folder containing the files.\n","    extensions (list): List of file extensions to filter by (e.g., '.md', '.py').\n","    recursive (bool, optional): Whether to recursively search subfolders. Defaults to False.\n","\n","  Returns:\n","    A dictionary of file contents, with file paths as keys and content as values.\n","  \"\"\"\n","\n","  # Validate input\n","  if not os.path.isdir(folder_path):\n","    raise ValueError(f'Invalid folder path: {folder_path}')\n","  if not extensions:\n","    raise ValueError('No file extensions specified.')\n","\n","  # Initialize dictionary to store file content\n","  file_contents = {}\n","\n","  # Iterate through files and subfolders in the folder\n","  for file_or_folder in os.listdir(folder_path):\n","    file_path = os.path.join(folder_path, file_or_folder)\n","\n","    # If it's a file, check if it has a specified extension and read its content\n","    if os.path.isfile(file_path):\n","      if file_path.endswith(tuple(extensions)):\n","        try:\n","          if file_path.endswith('.json'):\n","            with open(file_path, 'r') as f:\n","              file_content = json.load(f)\n","          elif file_path.endswith('.yaml'):\n","            with open(file_path, 'r') as f:\n","              file_content = yaml.safe_load(f)\n","          else:\n","            with open(file_path, 'r') as f:\n","              file_content = f.read()\n","        except Exception as e:\n","          print(f'Error reading file {file_path}: {e}')\n","          continue\n","\n","        # Add file content to dictionary\n","        file_contents[file_path] = file_content\n","\n","    # If it's a folder and recursion is enabled, recursively read files from the subfolder\n","    elif os.path.isdir(file_path) and recursive:\n","      file_contents.update(read_files(file_path, extensions, recursive))\n","\n","  return file_contents"],"metadata":{"id":"Lwkyu4mfCEQK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["folder_path = '/content/drive/MyDrive '\n","extensions = ['.md', '.py', '.csv', '.json', '.yaml']\n","\n","file_contents = read_files(folder_path, extensions, recursive=True)\n","\n","# Print file contents\n","for file_path, content in file_contents.items():\n","  print(f'{file_path}:\\n{content}')"],"metadata":{"id":"r35TK57wCxKg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install PyPDF2"],"metadata":{"id":"i1y7gAwHGWf0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from IPython.display import display, Javascript\n","\n","# Increase the data rate limit to 10 MB/s\n","display(Javascript(\"IPython.notebook.kernel.execute('config.IOPubDataRateLimit = 1000000000')\"))"],"metadata":{"id":"itl---ecG-nT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install pandas python-pptx pyyaml"],"metadata":{"id":"QECNu3w-IM_F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","import os\n","import json\n","import yaml\n","import re\n","import pandas as pd\n","from pptx import Presentation\n","from io import StringIO\n","\n","EXTENSION_READERS = {\n","    '.md': lambda f: f.read(),\n","    '.py': lambda f: f.read(),\n","    '.csv': lambda f: pd.read_csv(f),\n","    '.json': lambda f: json.load(f),\n","    '.yaml': lambda f: yaml.safe_load(f),\n","    '.txt': lambda f: f.read(),\n","    '.xml': lambda f: f.read(),\n","    '.html': lambda f: f.read(),\n","    '.css': lambda f: f.read(),\n","    '.js': lambda f: f.read(),\n","    '.java': lambda f: f.read(),\n","    '.cpp': lambda f: f.read(),\n","    '.h': lambda f: f.read(),\n","    '.php': lambda f: f.read(),\n","    '.rb': lambda f: f.read(),\n","    '.sql': lambda f: f.read(),\n","    '.xls': lambda f: pd.read_excel(f),\n","    '.xlsx': lambda f: pd.read_excel(f),\n","    '.ppt': lambda f: read_pptx(f),\n","    '.pptx': lambda f: read_pptx(f)\n","}\n","\n","def read_pptx(file):\n","    \"\"\"Custom function to read .pptx files with python-pptx\"\"\"\n","    prs = Presentation(file)\n","    text = []\n","    for slide in prs.slides:\n","        for shape in slide.shapes:\n","            if hasattr(shape, \"text\"):\n","                text.append(shape.text)\n","    return \"\\n\".join(text)\n","# Utilize regular expressions to match any of the file extensions\n","EXTENSION_PATTERN = r\".*\\.(md|py|csv|json|yaml|txt|xml|html|css|js|java|cpp|h|php|rb|sql|xls|xlsx|ppt|pptx)$\"\n","\n","def list_files_with_extensions(directory_path):\n","    try:\n","        files = os.listdir(directory_path)\n","        return [file for file in files if re.match(EXTENSION_PATTERN, file)]\n","    except FileNotFoundError:\n","        print(f\"The directory {directory_path} was not found.\")\n","        return None\n","\n","def read_file_content(directory_path, filename):\n","    try:\n","        extension = os.path.splitext(filename)[1]\n","        with open(os.path.join(directory_path, filename), 'r') as file:\n","            file_reader = EXTENSION_READERS.get(extension)\n","            return file_reader(file) if file_reader else None\n","    except Exception as e:\n","        print(f\"An error occurred while reading the file {filename}: {e}\")\n","\n","def process_files(directory_path):\n","    files = list_files_with_extensions(directory_path)\n","\n","    if files is None:\n","        return\n","\n","    for filename in files:\n","        content = read_file_content(directory_path, filename)\n","        if content is not None:\n","            print(f\"--- File: {filename} ---\")\n","            print(content)\n","            print(\"-------------------------------\\n\")\n","\n","def main():\n","    # Example usage:\n","    directory_path = \"/content/drive/MyDrive/Models \"\n","    process_files(directory_path)\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"id":"cLY4oiRbD-2Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","from collections import defaultdict\n","\n","# Step 1: Count subfolders and file types\n","def count_files_and_subfolders(starting_directory):\n","    file_types = defaultdict(int)\n","    total_subfolders = 0\n","\n","    for root, dirs, files in os.walk(starting_directory):\n","        total_subfolders += len(dirs)\n","        for file in files:\n","            extension = os.path.splitext(file)[1]\n","            file_types[extension] += 1\n","\n","    return total_subfolders, file_types\n","\n","# Step 2: Create dictionary of file paths\n","def create_extension_dictionary(starting_directory):\n","    extension_paths = defaultdict(list)\n","\n","    for root, _, files in os.walk(starting_directory):\n","        for file in files:\n","            extension = os.path.splitext(file)[1]\n","            full_path = os.path.join(root, file)\n","            extension_paths[extension].append(full_path)\n","\n","    return extension_paths\n","\n","# Step 3: User recommendations\n","def user_recommendations():\n","    recommendations = {\n","        \"organizing\": \"Consider using os.makedirs to create directories for each file type.\",\n","        \"cleanup\": \"Use os.unlink to remove files or os.rmdir/os.removedirs to remove directories.\",\n","        \"renaming\": \"Employ os.rename to rename files or directories.\",\n","        \"processes\": \"Use os.system or subprocess.run to execute shell commands.\",\n","        \"information\": \"Use os.path functions like os.path.getsize to check file sizes.\"\n","    }\n","    return recommendations\n","\n","# Example usage\n","directory_to_scan = \"/content/drive/MyDrive\"  # replace with the actual directory path\n","subfolders_count, file_type_counts = count_files_and_subfolders(directory_to_scan)\n","extension_file_paths = create_extension_dictionary(directory_to_scan)\n","\n","print(f\"Total subfolders: {subfolders_count}\")\n","print(f\"File type counts: {dict(file_type_counts)}\")\n","\n","# The paths dictionary can be huge, so be careful printing it\n","print(f\"Extension paths: {dict(extension_file_paths)}\")\n","\n","recs = user_recommendations()\n","for key, value in recs.items():\n","    print(f\"Recommendation - {key}: {value}\")"],"metadata":{"id":"y4HcrwdWG5T-"},"execution_count":null,"outputs":[]}]}