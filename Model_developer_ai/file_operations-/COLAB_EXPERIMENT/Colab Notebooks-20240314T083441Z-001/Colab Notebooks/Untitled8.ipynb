{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"gpuType":"T4","mount_file_id":"1QEu3Fz2gI2aKiku1FHlSULvbyEI2WyPf","authorship_tag":"ABX9TyPqyIv/CL10w2rpQ+EMSNzl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install transformers datasets"],"metadata":{"id":"scxc8ej-BYi9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install accelerate==0.20.1"],"metadata":{"id":"2Ec_HsIVCVC3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install transformers[torch]"],"metadata":{"id":"bThiltTgCf8e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install --upgrade transformers[torch]  accelerate -U\n"],"metadata":{"id":"kkmoswj2Fni2"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lp2Yc1aGBFYu"},"outputs":[],"source":[]},{"cell_type":"code","source":["!pip install accelerate==0.20.1"],"metadata":{"id":"qXGe3AR6DcpF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import torch\n","from datasets import load_dataset\n","from transformers import (\n","    AutoConfig,\n","    AutoModelForCausalLM,\n","    AutoTokenizer,\n","    TrainingArguments,\n","    Trainer,\n","    # is_deepspeed_zero3_enabled\n",")\n","\n","def load_custom_dataset(dataset_path: str, split: str = None):\n","    if os.path.exists(dataset_path):\n","        return load_dataset('json', data_files=dataset_path, split=split)\n","    else:\n","        return load_dataset(dataset_path, split=split)\n","\n","def load_model_and_tokenizer(\n","    model_name_or_path: str,\n","    config_kwargs: dict = None,\n","    use_fast_tokenizer: bool = True,\n","    split_special_tokens: bool = True,\n","    compute_dtype: torch.dtype = torch.float32\n","):\n","    config_kwargs = config_kwargs if config_kwargs is not None else {}\n","    config = AutoConfig.from_pretrained(model_name_or_path, **config_kwargs)\n","    model = AutoModelForCausalLM.from_pretrained(\n","        model_name_or_path,\n","        config=config,\n","        torch_dtype=compute_dtype,\n","        # low_cpu_mem_usage=(not is_deepspeed_zero3_enabled()),\n","        **config_kwargs\n","    )\n","    tokenizer = AutoTokenizer.from_pretrained(\n","        model_name_or_path,\n","        use_fast=use_fast_tokenizer,\n","        split_special_tokens=split_special_tokens,\n","        **config_kwargs\n","    )\n","    return model, tokenizer\n","training_args = TrainingArguments(\n","    output_dir=\"/content/drive/MyDrive/Models/\",\n","    learning_rate=5e-05,\n","    num_train_epochs=3.0,\n","    per_device_train_batch_size=4,\n","    gradient_accumulation_steps=4,\n","    lr_scheduler_type=\"cosine\",\n","    max_grad_norm=1.0,\n","    logging_steps=5,\n","    save_steps=100,\n","    warmup_steps=100,\n","    evaluation_strategy=\"steps\",\n","    eval_steps=100,\n","    load_best_model_at_end=True,\n","    fp16=True,\n","    dataloader_num_workers=0,\n",")\n","# Load data\n","data_path = \"nvidia/HelpSteer\"\n","train_dataset = load_custom_dataset(data_path)\n","\n","# Load model and tokenizer\n","model_path = \"mistralai/Mistral-7B-v0.1\"\n","model, tokenizer = load_model_and_tokenizer(model_path)\n","\n","# Initialize the Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n",")\n","\n","# Start training\n","trainer.train()"],"metadata":{"id":"_XSSdCOrDtkJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load data\n","data_path = \"/content/drive/MyDrive/Models /Adversarial_chatbot_dataset.txt\"\n","train_dataset = load_custom_dataset(data_path)\n","\n","# Load model and tokenizer\n","model_path = \"mistralai/Mistral-7B-v0.1\"\n","model, tokenizer = load_model_and_tokenizer(model_path)\n","\n","# Initialize the Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n",")\n","\n","# Start training\n","trainer.train()\n"],"metadata":{"id":"bYap9qcoBTJN"},"execution_count":null,"outputs":[]}]}