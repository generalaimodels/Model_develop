{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOWGfICV1tYRXl5mGz6HDaH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"HnS023ONepkj"},"outputs":[],"source":["!pip install transformers datasets"]},{"cell_type":"code","source":["!pip install datasets\n","!pip install transformers[torch]"],"metadata":{"id":"u3MP0SkMfYWQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install sentencepiece\n","!pip install accelerate>=0.20.1"],"metadata":{"id":"rLCj6QeYmG3K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import logging\n","from transformers import (\n","    AutoModelForCausalLM,\n","    AutoTokenizer,\n","    Trainer,\n","    TrainingArguments\n",")\n","from datasets import load_dataset\n","from contextlib import suppress\n","\n","\n","# Setup logging\n","logging.basicConfig(\n","    format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n","    datefmt='%m/%d/%Y %H:%M:%S',\n","    level=logging.INFO\n",")\n","logger = logging.getLogger(__name__)\n","\n","# Define parameters\n","MODEL_CKPT = os.getenv('MODEL_CKPT', 'microsoft/Orca-2-13b')\n","DATASET_NAME_OR_PATH = os.getenv('DATASET_NAME_OR_PATH', 'Open-Orca/OpenOrca')\n","OUTPUT_DIR = os.getenv('OUTPUT_DIR', './cdac_output')\n","TRAIN_BATCH_SIZE = int(os.getenv('TRAIN_BATCH_SIZE', '4'))\n","NUM_EPOCHS = float(os.getenv('NUM_EPOCHS', '3'))\n","LEARNING_RATE = float(os.getenv('LEARNING_RATE', '5e-5'))\n","WEIGHT_DECAY = float(os.getenv('WEIGHT_DECAY', '0.01'))\n","MAX_GRAD_NORM = float(os.getenv('MAX_GRAD_NORM', '1.0'))\n","LOGGING_STRATEGY = os.getenv('LOGGING_STRATEGY', 'steps') # or 'epoch'\n","LOGGING_STEPS = int(os.getenv('LOGGING_STEPS', '500'))\n","SAVE_STRATEGY = os.getenv('SAVE_STRATEGY', 'steps') # or 'epoch'\n","SAVE_STEPS = int(os.getenv('SAVE_STEPS', '1000'))\n","SAVE_TOTAL_LIMIT = int(os.getenv('SAVE_TOTAL_LIMIT', '2'))\n","WARMUP_STEPS = int(os.getenv('WARMUP_STEPS', '0'))\n","WARMUP_RATIO = float(os.getenv('WARMUP_RATIO', '0.0'))\n","LR_SCHEDULER_TYPE = os.getenv('LR_SCHEDULER_TYPE', 'linear')\n","REMOVE_UNUSED_COLUMNS = (os.getenv('REMOVE_UNUSED_COLUMNS', 'True') == 'True')\n","\n","# Ensure output directory exists\n","os.makedirs(OUTPUT_DIR, exist_ok=True)\n","\n","# Function definitions remain mostly the same\n","def load_and_prepare_dataset(dataset_name_or_path):\n","    try:\n","        dataset = load_dataset(dataset_name_or_path)\n","        if 'train' not in dataset:\n","            raise ValueError(f\"'train' split does not exist in the dataset {dataset_name_or_path}\")\n","        return dataset\n","    except Exception as e:\n","        logger.error(f\"Error loading dataset {dataset_name_or_path}: {e}\")\n","        raise\n","\n","\n","def create_training_args(output_dir, **kwargs):\n","    return TrainingArguments(\n","        output_dir=output_dir,\n","        overwrite_output_dir=True,\n","        do_train=True,\n","        do_eval=False,\n","        do_predict=False,\n","        evaluation_strategy='no',  # Change as needed\n","        per_device_train_batch_size=kwargs['train_batch_size'],\n","        per_device_eval_batch_size=kwargs.get('eval_batch_size', kwargs['train_batch_size']),\n","        learning_rate=kwargs['learning_rate'],\n","        weight_decay=kwargs['weight_decay'],\n","        max_grad_norm=kwargs['max_grad_norm'],\n","        logging_strategy=kwargs['logging_strategy'],\n","        logging_steps=kwargs['logging_steps'],\n","        save_strategy=kwargs['save_strategy'],\n","        save_steps=kwargs['save_steps'],\n","        num_train_epochs=kwargs['num_epochs'],\n","        save_total_limit=kwargs['save_total_limit'],\n","        warmup_steps=kwargs['warmup_steps'],\n","        warmup_ratio=kwargs['warmup_ratio'],\n","        lr_scheduler_type=kwargs['lr_scheduler_type'],\n","        remove_unused_columns=kwargs['remove_unused_columns'],\n","        # Additional args here\n","        fp16=True #if you want to use mixed precision\n","    )\n","\n","def train_model(dataset, model_ckpt, training_args):\n","    with suppress(FileNotFoundError):\n","        model = AutoModelForCausalLM.from_pretrained(model_ckpt)\n","        trainer = Trainer(\n","            model=model,\n","            args=training_args,\n","            train_dataset=dataset['train']\n","        )\n","        trainer.train()\n","        model.save_pretrained(OUTPUT_DIR)\n","        tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n","        tokenizer.save_pretrained(OUTPUT_DIR)\n","\n","if __name__ == '__main__':\n","    try:\n","        dataset = load_and_prepare_dataset(DATASET_NAME_OR_PATH)\n","        training_args = create_training_args(\n","        OUTPUT_DIR,\n","        train_batch_size=TRAIN_BATCH_SIZE,\n","        num_epochs=NUM_EPOCHS,\n","        logging_steps=LOGGING_STEPS,\n","        save_steps=SAVE_STEPS,\n","        save_total_limit=SAVE_TOTAL_LIMIT,\n","        learning_rate=LEARNING_RATE,\n","        weight_decay=WEIGHT_DECAY,\n","        max_grad_norm=MAX_GRAD_NORM,\n","        logging_strategy=LOGGING_STRATEGY,\n","        save_strategy=SAVE_STRATEGY,\n","        warmup_steps=WARMUP_STEPS,\n","        warmup_ratio=WARMUP_RATIO,\n","        lr_scheduler_type=LR_SCHEDULER_TYPE,\n","        remove_unused_columns=REMOVE_UNUSED_COLUMNS\n","        )\n","        train_model(dataset, MODEL_CKPT, training_args)\n","\n","        tokenizer = AutoTokenizer.from_pretrained(OUTPUT_DIR)\n","        model = AutoModelForCausalLM.from_pretrained(OUTPUT_DIR)\n","\n","        def chat_with_model(prompt):\n","            inputs = tokenizer.encode(prompt, return_tensors='pt', add_special_tokens=True)\n","            outputs = model.generate(inputs, max_length=150, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)\n","            return tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","        logger.info(\"Chat with the model (type 'quit' to exit).\")\n","        while True:\n","            user_input = input('User: ')\n","            if user_input.lower() == 'quit':\n","                logger.info(\"Exiting chat.\")\n","                break\n","            try:\n","                response = chat_with_model(user_input)\n","                print(f'Model: {response}')\n","            except Exception as e:\n","                logger.error(f\"Error during chat response generation: {e}\")\n","\n","    except Exception as e:\n","        logger.error(f\"Fatal error: {e}\")"],"metadata":{"id":"cHo9wuu6esNR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install transformers[torch]"],"metadata":{"id":"c-EVHl55jhAx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install accelerate"],"metadata":{"id":"IQSqGHZFjGXY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install sentencepiece\n"],"metadata":{"id":"O-3OKJPcl0f2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoTokenizer\n","\n","# Load tokenizer\n","tokenizer = AutoTokenizer.from_pretrained('microsoft/Orca-2-13b')\n","\n","# Example dataset\n","dataset = load_dataset('Open-Orca/OpenOrca', split='train')\n","\n","# Tokenize and encode the text features\n","tokenized = tokenizer(\n","    dataset['system_prompt'],\n","    dataset['question'],\n","    dataset['response'],\n","    padding='max_length',  # Pad to the maximum sequence length\n","    truncation=True,  # Truncate sequences longer than max_length\n","    max_length=512,  # Set your desired maximum sequence length\n","    return_tensors='pt'  # Return PyTorch tensors\n",")\n","\n","# Select input and output features\n","input_ids = tokenized['input_ids']\n","attention_mask = tokenized['attention_mask']\n","labels = input_ids.clone()  # Example: Making labels same as input for language modeling\n","\n","# Your further processing or training code using these preprocessed inputs\n"],"metadata":{"id":"2faG9U8rlIbc"},"execution_count":null,"outputs":[]}]}