{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMjBu208r+Z+TWt7RmMyIQh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"bdjt43e1cIfS"},"outputs":[],"source":["import logging\n","import os\n","import sys\n","import warnings\n","\n","from dataclasses import asdict, dataclass, field\n","from random import randint\n","from typing import  TYPE_CHECKING, Optional, Tuple\n","\n","import datasets\n","import evaluate\n","import numpy as np\n","from datasets import DatasetDict, load_dataset\n","import transformers\n","from transformers import (\n","    AutoConfig,\n","    AutoModelForCausalLM,\n","    AutoTokenizer,\n","    AutoFeatureExtractor,\n","    AutoModelForAudioClassification,\n","    HfArgumentParser,\n","    Trainer,\n","    TrainingArguments,\n","    set_seed,\n","    PreTrainedModel,\n","    PreTrainedTokenizer\n",")\n","from transformers.trainer_utils import get_last_checkpoint\n","from transformers.utils import check_min_version, send_example_telemetry\n","from transformers.utils.versions import require_version\n","\n","\n","from transformers.integrations import is_deepspeed_zero3_enabled\n","from trl import AutoModelForCausalLMWithValueHead\n","\n","logger = logging.getLogger(__name__)\n","\n","\n","\n","from typing import Any, Dict, Literal, Optional\n","import json\n","from dataclasses import asdict, dataclass, field\n","from typing import Literal, Optional\n","from dataclasses import dataclass, field\n","from typing import Literal, Optional\n","\n","import os\n","from dataclasses import dataclass, field\n","from typing import Literal, Optional\n","\n","from datasets import DownloadMode\n","\n","from dataclasses import asdict, dataclass, field\n","from typing import Any, Dict, Optional\n","\n","\n","@dataclass\n","class GeneratingArguments:\n","    r\"\"\"\n","    Arguments pertaining to specify the decoding parameters.\n","    \"\"\"\n","    do_sample: Optional[bool] = field(\n","        default=True, metadata={\"help\": \"Whether or not to use sampling, use greedy decoding otherwise.\"}\n","    )\n","    temperature: Optional[float] = field(\n","        default=0.95, metadata={\"help\": \"The value used to modulate the next token probabilities.\"}\n","    )\n","    top_p: Optional[float] = field(\n","        default=0.7,\n","        metadata={\n","            \"help\": \"The smallest set of most probable tokens with probabilities that add up to top_p or higher are kept.\"\n","        },\n","    )\n","    top_k: Optional[int] = field(\n","        default=50,\n","        metadata={\"help\": \"The number of highest probability vocabulary tokens to keep for top-k filtering.\"},\n","    )\n","    num_beams: Optional[int] = field(\n","        default=1, metadata={\"help\": \"Number of beams for beam search. 1 means no beam search.\"}\n","    )\n","    max_length: Optional[int] = field(\n","        default=512,\n","        metadata={\"help\": \"The maximum length the generated tokens can have. It can be overridden by max_new_tokens.\"},\n","    )\n","    max_new_tokens: Optional[int] = field(\n","        default=512,\n","        metadata={\"help\": \"The maximum numbers of tokens to generate, ignoring the number of tokens in the prompt.\"},\n","    )\n","    repetition_penalty: Optional[float] = field(\n","        default=1.0, metadata={\"help\": \"The parameter for repetition penalty. 1.0 means no penalty.\"}\n","    )\n","    length_penalty: Optional[float] = field(\n","        default=1.0, metadata={\"help\": \"Exponential penalty to the length that is used with beam-based generation.\"}\n","    )\n","\n","    def to_dict(self) -> Dict[str, Any]:\n","        args = asdict(self)\n","        if args.get(\"max_new_tokens\", -1) > 0:\n","            args.pop(\"max_length\", None)\n","        else:\n","            args.pop(\"max_new_tokens\", None)\n","        return args\n","@dataclass\n","class EvaluationArguments:\n","    r\"\"\"\n","    Arguments pertaining to specify the evaluation parameters.\n","    \"\"\"\n","    task: str = field(metadata={\"help\": \"Name of the evaluation task.\"})\n","    task_dir: Optional[str] = field(\n","        default=\"evaluation\", metadata={\"help\": \"Path to the folder containing the evaluation datasets.\"}\n","    )\n","    batch_size: Optional[int] = field(default=4, metadata={\"help\": \"The batch size per GPU for evaluation.\"})\n","    seed: Optional[int] = field(default=42, metadata={\"help\": \"Random seed to be used with data loaders.\"})\n","    lang: Optional[Literal[\"en\", \"zh\"]] = field(default=\"en\", metadata={\"help\": \"Language used at evaluation.\"})\n","    n_shot: Optional[int] = field(default=5, metadata={\"help\": \"Number of examplars for few-shot learning.\"})\n","    save_dir: Optional[str] = field(default=None, metadata={\"help\": \"Path to save the evaluation results.\"})\n","    download_mode: Optional[DownloadMode] = field(\n","        default=DownloadMode.REUSE_DATASET_IF_EXISTS,\n","        metadata={\"help\": \"Download mode used for the evaluation datasets.\"},\n","    )\n","\n","    def __post_init__(self):\n","        if self.save_dir is not None and os.path.exists(self.save_dir):\n","            raise ValueError(\"`save_dir` already exists, use another one.\")\n","@dataclass\n","class DataArguments:\n","    r\"\"\"\n","    Arguments pertaining to what data we are going to input our model for training and evaluation.\n","    \"\"\"\n","    template: Optional[str] = field(\n","        default=None, metadata={\"help\": \"Which template to use for constructing prompts in training and inference.\"}\n","    )\n","    dataset: Optional[str] = field(\n","        default=None,\n","        metadata={\"help\": \"The name of provided dataset(s) to use. Use commas to separate multiple datasets.\"},\n","    )\n","    dataset_dir: Optional[str] = field(\n","        default=\"data\", metadata={\"help\": \"Path to the folder containing the datasets.\"}\n","    )\n","    split: Optional[str] = field(\n","        default=\"train\", metadata={\"help\": \"Which dataset split to use for training and evaluation.\"}\n","    )\n","    cutoff_len: Optional[int] = field(\n","        default=1024, metadata={\"help\": \"The maximum length of the model inputs after tokenization.\"}\n","    )\n","    reserved_label_len: Optional[int] = field(\n","        default=1, metadata={\"help\": \"The maximum length reserved for label after tokenization.\"}\n","    )\n","    train_on_prompt: Optional[bool] = field(\n","        default=False, metadata={\"help\": \"Whether to disable the mask on the prompt or not.\"}\n","    )\n","    streaming: Optional[bool] = field(default=False, metadata={\"help\": \"Enable dataset streaming.\"})\n","    buffer_size: Optional[int] = field(\n","        default=16384, metadata={\"help\": \"Size of the buffer to randomly sample examples from in dataset streaming.\"}\n","    )\n","    mix_strategy: Optional[Literal[\"concat\", \"interleave_under\", \"interleave_over\"]] = field(\n","        default=\"concat\",\n","        metadata={\"help\": \"Strategy to use in dataset mixing (concat/interleave) (undersampling/oversampling).\"},\n","    )\n","    interleave_probs: Optional[str] = field(\n","        default=None,\n","        metadata={\"help\": \"Probabilities to sample data from datasets. Use commas to separate multiple datasets.\"},\n","    )\n","    overwrite_cache: Optional[bool] = field(\n","        default=False, metadata={\"help\": \"Overwrite the cached training and evaluation sets.\"}\n","    )\n","    preprocessing_num_workers: Optional[int] = field(\n","        default=None, metadata={\"help\": \"The number of processes to use for the preprocessing.\"}\n","    )\n","    max_samples: Optional[int] = field(\n","        default=None, metadata={\"help\": \"For debugging purposes, truncate the number of examples for each dataset.\"}\n","    )\n","    eval_num_beams: Optional[int] = field(\n","        default=None,\n","        metadata={\"help\": \"Number of beams to use for evaluation. This argument will be passed to `model.generate`\"},\n","    )\n","    ignore_pad_token_for_loss: Optional[bool] = field(\n","        default=True,\n","        metadata={\n","            \"help\": \"Whether to ignore the tokens corresponding to padded labels in the loss computation or not.\"\n","        },\n","    )\n","    val_size: Optional[float] = field(\n","        default=0, metadata={\"help\": \"Size of the development set, should be an integer or a float in range `[0,1)`.\"}\n","    )\n","    sft_packing: Optional[bool] = field(\n","        default=False, metadata={\"help\": \"Packing the questions and answers in the supervised fine-tuning stage.\"}\n","    )\n","    cache_path: Optional[str] = field(\n","        default=None, metadata={\"help\": \"Path to save or load the preprocessed datasets.\"}\n","    )\n","\n","    def __post_init__(self):\n","        if self.reserved_label_len >= self.cutoff_len:\n","            raise ValueError(\"`reserved_label_len` must be smaller than `cutoff_len`.\")\n","\n","        if self.streaming and self.val_size > 1e-6 and self.val_size < 1:\n","            raise ValueError(\"Streaming mode should have an integer val size.\")\n","\n","        if self.streaming and self.max_samples is not None:\n","            raise ValueError(\"`max_samples` is incompatible with `streaming`.\")\n","\n","@dataclass\n","class FreezeArguments:\n","    r\"\"\"\n","    Arguments pertaining to the freeze (partial-parameter) training.\n","    \"\"\"\n","    name_module_trainable: Optional[str] = field(\n","        default=\"mlp\",\n","        metadata={\n","            \"help\": 'Name of trainable modules for partial-parameter (freeze) fine-tuning. \\\n","                  Use commas to separate multiple modules. \\\n","                  LLaMA choices: [\"mlp\", \"self_attn\"], \\\n","                  BLOOM & Falcon & ChatGLM choices: [\"mlp\", \"self_attention\"], \\\n","                  Qwen choices: [\"mlp\", \"attn\"], \\\n","                  Phi choices: [\"mlp\", \"mixer\"], \\\n","                  Others choices: the same as LLaMA.'\n","        },\n","    )\n","    num_layer_trainable: Optional[int] = field(\n","        default=3, metadata={\"help\": \"The number of trainable layers for partial-parameter (freeze) fine-tuning.\"}\n","    )\n","\n","\n","@dataclass\n","class LoraArguments:\n","    r\"\"\"\n","    Arguments pertaining to the LoRA training.\n","    \"\"\"\n","    additional_target: Optional[str] = field(\n","        default=None,\n","        metadata={\n","            \"help\": \"Name(s) of modules apart from LoRA layers to be set as trainable and saved in the final checkpoint.\"\n","        },\n","    )\n","    lora_alpha: Optional[int] = field(\n","        default=None, metadata={\"help\": \"The scale factor for LoRA fine-tuning (default: lora_rank * 2).\"}\n","    )\n","    lora_dropout: Optional[float] = field(default=0.0, metadata={\"help\": \"Dropout rate for the LoRA fine-tuning.\"})\n","    lora_rank: Optional[int] = field(default=8, metadata={\"help\": \"The intrinsic dimension for LoRA fine-tuning.\"})\n","    lora_target: Optional[str] = field(\n","        default=None,\n","        metadata={\n","            \"help\": 'Name(s) of target modules to apply LoRA. Use commas to separate multiple modules. \\\n","                  LLaMA choices: [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"], \\\n","                  BLOOM & Falcon & ChatGLM choices: [\"query_key_value\", \"dense\", \"dense_h_to_4h\", \"dense_4h_to_h\"], \\\n","                  Baichuan choices: [\"W_pack\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"], \\\n","                  Qwen choices: [\"c_attn\", \"attn.c_proj\", \"w1\", \"w2\", \"mlp.c_proj\"], \\\n","                  Phi choices: [\"Wqkv\", \"out_proj\", \"fc1\", \"fc2\"], \\\n","                  Others choices: the same as LLaMA.'\n","        },\n","    )\n","    lora_bf16_mode: Optional[bool] = field(\n","        default=False, metadata={\"help\": \"Whether or not to train lora adapters in bf16 precision.\"}\n","    )\n","    create_new_adapter: Optional[bool] = field(\n","        default=False, metadata={\"help\": \"Whether or not to create a new adapter with randomly initialized weight.\"}\n","    )\n","\n","\n","@dataclass\n","class RLHFArguments:\n","    r\"\"\"\n","    Arguments pertaining to the PPO and DPO training.\n","    \"\"\"\n","    dpo_beta: Optional[float] = field(default=0.1, metadata={\"help\": \"The beta parameter for the DPO loss.\"})\n","    dpo_loss: Optional[Literal[\"sigmoid\", \"hinge\", \"ipo\", \"kto\"]] = field(\n","        default=\"sigmoid\", metadata={\"help\": \"The type of DPO loss to use.\"}\n","    )\n","    dpo_ftx: Optional[float] = field(\n","        default=0, metadata={\"help\": \"The supervised fine-tuning loss coefficient in DPO training.\"}\n","    )\n","    ppo_buffer_size: Optional[int] = field(\n","        default=1,\n","        metadata={\"help\": \"The number of mini-batches to make experience buffer in a PPO optimization step.\"},\n","    )\n","    ppo_epochs: Optional[int] = field(\n","        default=4, metadata={\"help\": \"The number of epochs to perform in a PPO optimization step.\"}\n","    )\n","    ppo_logger: Optional[str] = field(\n","        default=None, metadata={\"help\": 'Log with either \"wandb\" or \"tensorboard\" in PPO training.'}\n","    )\n","    ppo_score_norm: Optional[bool] = field(\n","        default=False, metadata={\"help\": \"Use score normalization in PPO training.\"}\n","    )\n","    ppo_target: Optional[float] = field(\n","        default=6.0, metadata={\"help\": \"Target KL value for adaptive KL control in PPO training.\"}\n","    )\n","    ppo_whiten_rewards: Optional[bool] = field(\n","        default=False, metadata={\"help\": \"Whiten the rewards before compute advantages in PPO training.\"}\n","    )\n","    ref_model: Optional[str] = field(\n","        default=None, metadata={\"help\": \"Path to the reference model used for the PPO or DPO training.\"}\n","    )\n","    ref_model_adapters: Optional[str] = field(\n","        default=None, metadata={\"help\": \"Path to the adapters of the reference model.\"}\n","    )\n","    ref_model_quantization_bit: Optional[int] = field(\n","        default=None, metadata={\"help\": \"The number of bits to quantize the reference model.\"}\n","    )\n","    reward_model: Optional[str] = field(\n","        default=None, metadata={\"help\": \"Path to the reward model used for the PPO training.\"}\n","    )\n","    reward_model_adapters: Optional[str] = field(\n","        default=None, metadata={\"help\": \"Path to the adapters of the reward model.\"}\n","    )\n","    reward_model_quantization_bit: Optional[int] = field(\n","        default=None, metadata={\"help\": \"The number of bits to quantize the reward model.\"}\n","    )\n","    reward_model_type: Optional[Literal[\"lora\", \"full\", \"api\"]] = field(\n","        default=\"lora\",\n","        metadata={\"help\": \"The type of the reward model in PPO training. Lora model only supports lora training.\"},\n","    )\n","\n","\n","@dataclass\n","class FinetuningArguments(FreezeArguments, LoraArguments, RLHFArguments):\n","    r\"\"\"\n","    Arguments pertaining to which techniques we are going to fine-tuning with.\n","    \"\"\"\n","    stage: Optional[Literal[\"pt\", \"sft\", \"rm\", \"ppo\", \"dpo\"]] = field(\n","        default=\"sft\", metadata={\"help\": \"Which stage will be performed in training.\"}\n","    )\n","    finetuning_type: Optional[Literal[\"lora\", \"freeze\", \"full\"]] = field(\n","        default=\"lora\", metadata={\"help\": \"Which fine-tuning method to use.\"}\n","    )\n","    plot_loss: Optional[bool] = field(\n","        default=False, metadata={\"help\": \"Whether or not to save the training loss curves.\"}\n","    )\n","\n","    def __post_init__(self):\n","        def split_arg(arg):\n","            if isinstance(arg, str):\n","                return [item.strip() for item in arg.split(\",\")]\n","            return arg\n","\n","        self.name_module_trainable = split_arg(self.name_module_trainable)\n","        self.lora_alpha = self.lora_alpha or self.lora_rank * 2\n","        self.lora_target = split_arg(self.lora_target)\n","        self.additional_target = split_arg(self.additional_target)\n","\n","        assert self.finetuning_type in [\"lora\", \"freeze\", \"full\"], \"Invalid fine-tuning method.\"\n","        assert self.ref_model_quantization_bit in [None, 8, 4], \"We only accept 4-bit or 8-bit quantization.\"\n","        assert self.reward_model_quantization_bit in [None, 8, 4], \"We only accept 4-bit or 8-bit quantization.\"\n","\n","        if self.stage == \"ppo\" and self.reward_model is None:\n","            raise ValueError(\"Reward model is necessary for PPO training.\")\n","\n","        if self.stage == \"ppo\" and self.reward_model_type == \"lora\" and self.finetuning_type != \"lora\":\n","            raise ValueError(\"Freeze/Full PPO training needs `reward_model_type=full`.\")\n","\n","    def save_to_json(self, json_path: str):\n","        r\"\"\"Saves the content of this instance in JSON format inside `json_path`.\"\"\"\n","        json_string = json.dumps(asdict(self), indent=2, sort_keys=True) + \"\\n\"\n","        with open(json_path, \"w\", encoding=\"utf-8\") as f:\n","            f.write(json_string)\n","\n","    @classmethod\n","    def load_from_json(cls, json_path: str):\n","        r\"\"\"Creates an instance from the content of `json_path`.\"\"\"\n","        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n","            text = f.read()\n","\n","        return cls(**json.loads(text))\n","\n","@dataclass\n","class ModelArguments:\n","    r\"\"\"\n","    Arguments pertaining to which model/config/tokenizer we are going to fine-tune.\n","    \"\"\"\n","    model_name_or_path: str = field(\n","        metadata={\"help\": \"Path to the model weight or identifier from huggingface.co/models or modelscope.cn/models.\"}\n","    )\n","    adapter_name_or_path: Optional[str] = field(\n","        default=None, metadata={\"help\": \"Path to the adapter weight or identifier from huggingface.co/models.\"}\n","    )\n","    cache_dir: Optional[str] = field(\n","        default=None,\n","        metadata={\"help\": \"Where to store the pre-trained models downloaded from huggingface.co or modelscope.cn.\"},\n","    )\n","    use_fast_tokenizer: Optional[bool] = field(\n","        default=False,\n","        metadata={\"help\": \"Whether or not to use one of the fast tokenizer (backed by the tokenizers library).\"},\n","    )\n","    resize_vocab: Optional[bool] = field(\n","        default=False, metadata={\"help\": \"Whether or not to resize the tokenizer vocab and the embedding layers.\"}\n","    )\n","    split_special_tokens: Optional[bool] = field(\n","        default=False,\n","        metadata={\"help\": \"Whether or not the special tokens should be split during the tokenization process.\"},\n","    )\n","    model_revision: Optional[str] = field(\n","        default=\"main\",\n","        metadata={\"help\": \"The specific model version to use (can be a branch name, tag name or commit id).\"},\n","    )\n","    quantization_bit: Optional[int] = field(\n","        default=None, metadata={\"help\": \"The number of bits to quantize the model.\"}\n","    )\n","    quantization_type: Optional[Literal[\"fp4\", \"nf4\"]] = field(\n","        default=\"nf4\", metadata={\"help\": \"Quantization data type to use in int4 training.\"}\n","    )\n","    double_quantization: Optional[bool] = field(\n","        default=True, metadata={\"help\": \"Whether or not to use double quantization in int4 training.\"}\n","    )\n","    rope_scaling: Optional[Literal[\"linear\", \"dynamic\"]] = field(\n","        default=None, metadata={\"help\": \"Which scaling strategy should be adopted for the RoPE embeddings.\"}\n","    )\n","    flash_attn: Optional[bool] = field(\n","        default=False, metadata={\"help\": \"Enable FlashAttention-2 for faster training.\"}\n","    )\n","    shift_attn: Optional[bool] = field(\n","        default=False, metadata={\"help\": \"Enable shift short attention (S^2-Attn) proposed by LongLoRA.\"}\n","    )\n","    use_unsloth: Optional[bool] = field(\n","        default=False, metadata={\"help\": \"Whether or not to use unsloth's optimization for the LoRA training.\"}\n","    )\n","    disable_gradient_checkpointing: Optional[bool] = field(\n","        default=False, metadata={\"help\": \"Whether or not to disable gradient checkpointing.\"}\n","    )\n","    upcast_layernorm: Optional[bool] = field(\n","        default=False, metadata={\"help\": \"Whether or not to upcast the layernorm weights in fp32.\"}\n","    )\n","    upcast_lmhead_output: Optional[bool] = field(\n","        default=False, metadata={\"help\": \"Whether or not to upcast the output of lm_head in fp32.\"}\n","    )\n","    hf_hub_token: Optional[str] = field(default=None, metadata={\"help\": \"Auth token to log in with Hugging Face Hub.\"})\n","    ms_hub_token: Optional[str] = field(default=None, metadata={\"help\": \"Auth token to log in with ModelScope Hub.\"})\n","    export_dir: Optional[str] = field(\n","        default=None, metadata={\"help\": \"Path to the directory to save the exported model.\"}\n","    )\n","    export_size: Optional[int] = field(\n","        default=1, metadata={\"help\": \"The file shard size (in GB) of the exported model.\"}\n","    )\n","    export_quantization_bit: Optional[int] = field(\n","        default=None, metadata={\"help\": \"The number of bits to quantize the exported model.\"}\n","    )\n","    export_quantization_dataset: Optional[str] = field(\n","        default=None, metadata={\"help\": \"Path to the dataset or dataset name to use in quantizing the exported model.\"}\n","    )\n","    export_quantization_nsamples: Optional[int] = field(\n","        default=128, metadata={\"help\": \"The number of samples used for quantization.\"}\n","    )\n","    export_quantization_maxlen: Optional[int] = field(\n","        default=1024, metadata={\"help\": \"The maximum length of the model inputs used for quantization.\"}\n","    )\n","    export_legacy_format: Optional[bool] = field(\n","        default=False, metadata={\"help\": \"Whether or not to save the `.bin` files instead of `.safetensors`.\"}\n","    )\n","    export_hub_model_id: Optional[str] = field(\n","        default=None, metadata={\"help\": \"The name of the repository if push the model to the Hugging Face hub.\"}\n","    )\n","\n","    def __post_init__(self):\n","        self.compute_dtype = None\n","        self.model_max_length = None\n","\n","        if self.split_special_tokens and self.use_fast_tokenizer:\n","            raise ValueError(\"`split_special_tokens` is only supported for slow tokenizers.\")\n","\n","        if self.adapter_name_or_path is not None:  # support merging multiple lora weights\n","            self.adapter_name_or_path = [path.strip() for path in self.adapter_name_or_path.split(\",\")]\n","\n","        assert self.quantization_bit in [None, 8, 4], \"We only accept 4-bit or 8-bit quantization.\"\n","        assert self.export_quantization_bit in [None, 8, 4, 3, 2], \"We only accept 2/3/4/8-bit quantization.\"\n","\n","        if self.export_quantization_bit is not None and self.export_quantization_dataset is None:\n","            raise ValueError(\"Quantization dataset is necessary for exporting.\")\n","\n","    def to_dict(self) -> Dict[str, Any]:\n","        return asdict(self)\n","def load_model_and_tokenizer(\n","    model_args: \"ModelArguments\",\n","    finetuning_args: \"FinetuningArguments\",\n","    is_trainable: Optional[bool] = False,\n","    add_valuehead: Optional[bool] = False,\n",") -> Tuple[\"PreTrainedModel\", \"PreTrainedTokenizer\"]:\n","    r\"\"\"\n","    Loads pretrained model and tokenizer.\n","\n","    Support both training and inference.\n","    \"\"\"\n","\n","    try_download_model_from_ms(model_args)\n","\n","    config_kwargs = {\n","        \"trust_remote_code\": True,\n","        \"cache_dir\": model_args.cache_dir,\n","        \"revision\": model_args.model_revision,\n","        \"token\": model_args.hf_hub_token,\n","    }\n","\n","    tokenizer = AutoTokenizer.from_pretrained(\n","        model_args.model_name_or_path,\n","        use_fast=model_args.use_fast_tokenizer,\n","        split_special_tokens=model_args.split_special_tokens,\n","        padding_side=\"right\",\n","        **config_kwargs,\n","    )\n","    patch_tokenizer(tokenizer)\n","\n","    config = AutoConfig.from_pretrained(model_args.model_name_or_path, **config_kwargs)\n","    patch_config(config, tokenizer, model_args, config_kwargs, is_trainable)\n","\n","    model = None\n","    if is_trainable and model_args.use_unsloth:\n","        require_version(\"unsloth\", \"Follow the instructions at: https://github.com/unslothai/unsloth\")\n","        from unsloth import FastLlamaModel, FastMistralModel  # type: ignore\n","\n","        unsloth_kwargs = {\n","            \"model_name\": model_args.model_name_or_path,\n","            \"max_seq_length\": model_args.model_max_length,\n","            \"dtype\": model_args.compute_dtype,\n","            \"load_in_4bit\": model_args.quantization_bit == 4,\n","            \"token\": model_args.hf_hub_token,\n","            \"device_map\": get_current_device(),\n","            \"rope_scaling\": getattr(config, \"rope_scaling\", None),\n","        }\n","        if getattr(config, \"model_type\", None) == \"llama\":\n","            model, _ = FastLlamaModel.from_pretrained(**unsloth_kwargs)\n","        elif getattr(config, \"model_type\", None) == \"mistral\":\n","            model, _ = FastMistralModel.from_pretrained(**unsloth_kwargs)\n","        else:\n","            logger.warning(\"Unsloth does not support model type {}.\".format(getattr(config, \"model_type\", None)))\n","            model_args.use_unsloth = False\n","\n","        if model_args.adapter_name_or_path:\n","            model_args.adapter_name_or_path = None\n","            logger.warning(\"Unsloth does not support loading adapters.\")\n","\n","    if model is None:\n","        model = AutoModelForCausalLM.from_pretrained(\n","            model_args.model_name_or_path,\n","            config=config,\n","            torch_dtype=model_args.compute_dtype,\n","            low_cpu_mem_usage=(not is_deepspeed_zero3_enabled()),\n","            **config_kwargs,\n","        )\n","\n","    patch_model(model, tokenizer, model_args, is_trainable)\n","    register_autoclass(config, model, tokenizer)\n","\n","    model = init_adapter(model, model_args, finetuning_args, is_trainable)\n","\n","    if add_valuehead:\n","        model: \"AutoModelForCausalLMWithValueHead\" = AutoModelForCausalLMWithValueHead.from_pretrained(model)\n","        patch_valuehead_model(model)\n","\n","        if model_args.adapter_name_or_path is not None:\n","            vhead_path = model_args.adapter_name_or_path[-1]\n","        else:\n","            vhead_path = model_args.model_name_or_path\n","\n","        vhead_params = load_valuehead_params(vhead_path, model_args)\n","        if vhead_params is not None:\n","            model.load_state_dict(vhead_params, strict=False)\n","            logger.info(\"Loaded valuehead from checkpoint: {}\".format(vhead_path))\n","\n","    if not is_trainable:\n","        model.requires_grad_(False)\n","        model = model.to(model_args.compute_dtype) if not getattr(model, \"quantization_method\", None) else model\n","        model.eval()\n","    else:\n","        model.train()\n","\n","    trainable_params, all_param = count_parameters(model)\n","    logger.info(\n","        \"trainable params: {:d} || all params: {:d} || trainable%: {:.4f}\".format(\n","            trainable_params, all_param, 100 * trainable_params / all_param\n","        )\n","    )\n","\n","    if not is_trainable:\n","        logger.info(\"This IS expected that the trainable params is 0 if you are using model for inference only.\")\n","\n","    return model, tokenizer"]},{"cell_type":"markdown","source":["The concept of entropy in information theory is fundamental for understanding the amount of uncertainty or surprise associated with a random variable. There are different types of entropy, but the two main ones are Shannon entropy and conditional entropy.\n","\n","1. **Shannon Entropy (H(X)):**\n","   Shannon entropy measures the average amount of surprise associated with an event drawn from a probability distribution. For a discrete random variable X with probability mass function P(X), Shannon entropy is given by:\n","\n","   $$ H(X) = -\\sum_{i} P(x_i) \\cdot \\log_2(P(x_i)) $$\n","\n","   where the sum is taken over all possible values $x_i$ of X.\n","\n","2. **Conditional Entropy $(H(X|Y))$:**\n","   Conditional entropy measures the average uncertainty of X given the knowledge of another random variable Y. For discrete random variables X and Y, it is defined as:\n","\n","   $$H(X|Y) = -\\sum_{j} \\sum_{i} P(x_i, y_j) \\cdot \\log_2\\left(\\frac{P(x_i, y_j)}{P(y_j)}\\right) $$\n","\n","   Here, the outer sum is over all possible values of Y, and the inner sum is over all possible values of X.\n","\n","\n","\n","3. **Joint Entropy (H(X, Y)):**\n","   Joint entropy measures the average uncertainty associated with two random variables, X and Y, considered together. For discrete random variables X and Y with a joint probability mass function P(X, Y), the joint entropy is given by:\n","\n","   $$H(X, Y) = -\\sum_{j} \\sum_{i} P(x_i, y_j) \\cdot \\log_2(P(x_i, y_j)) $$\n","\n","   Similar to Shannon entropy, the double sum is taken over all possible values of X and Y.\n","\n","4. **Relative Entropy (Kullback-Leibler Divergence) (D_{KL}(P || Q)):**\n","   Relative entropy measures the difference between two probability distributions, P and Q. For discrete random variables, it is defined as:\n","\n","   $$ D_{KL}(P || Q) = \\sum_{i} P(x_i) \\cdot \\log_2\\left(\\frac{P(x_i)}{Q(x_i)}\\right) $$\n","\n","   This provides a measure of how one probability distribution diverges from another.\n","\n","5. **Cross Entropy (H(P, Q)):**\n","   Cross entropy is the expected number of bits needed to encode events from a true probability distribution P when using a different probability distribution Q. For discrete random variables X and Y, it is defined as:\n","\n","   $$ H(P, Q) = -\\sum_{i} P(x_i) \\cdot \\log_2(Q(x_i)) $$\n","\n","   Cross entropy is closely related to relative entropy.\n","\n","Certainly! Let's explore these mathematical explanations:\n","\n","### Mutual Information (I(X; Y)):\n","\n","1. **Definition and Interpretation:**\n","   The mutual information between two random variables $X$ and $Y$ is defined as:\n","   $$I(X; Y) = \\sum_{x} \\sum_{y} P(x, y) \\cdot \\log_2\\left(\\frac{P(x, y)}{P(x)P(y)}\\right) $$\n","   This measures the reduction in uncertainty about one variable (e.g., $X$) due to the knowledge of another variable (e.g., $Y$).\n","\n","2. **Properties and Relationships with Entropy:**\n","   - Non-negativity: $I(X; Y) \\geq 0$\n","   - Symmetry: $I(X; Y) = I(Y; X)$\n","   - Chain Rule: $$I(X; Y, Z) = I(X; Y) + I(X; Z | Y)$$\n","   - Relationship with Entropy: $$I(X; Y) = H(X) - H(X|Y)$$\n","\n","3. **Applications in Feature Selection and Correlation Analysis:**\n","   - Feature Selection: Mutual information is used to quantify the information shared between features and the target variable, aiding in feature selection for machine learning models.\n","   - Correlation Analysis: It provides a measure of dependence between variables, assisting in understanding the relationships within datasets.\n","\n","### Renewal Entropy:\n","\n","1. **Analysis of Renewal Processes:**\n","   - Renewal processes involve the occurrence of events with inter-arrival times. The entropy of a renewal process characterizes the uncertainty associated with the time until the next event.\n","   - Renewal entropy $H_R$ is defined as: $$ H_R = -\\int_{0}^{\\infty} p(t) \\cdot \\log_2(p(t)) \\, dt $$\n","     where $ p(t) $ is the probability density function of inter-arrival times.\n","\n","2. **Entropy Measures for Renewal Systems:**\n","   - Renewal entropy captures the information content of the renewal process, reflecting the unpredictability of the time until the next event.\n","   - Properties such as increasing entropy with increasing variability in inter-arrival times are observed.\n","\n","3. **Renewal Entropy Applications in Queueing Theory:**\n","   - In queueing theory, renewal entropy is utilized to analyze and optimize systems where entities arrive according to a renewal process.\n","   - It helps in understanding waiting times, system stability, and resource allocation in queueing systems.\n","\n","### Differential Entropy:\n","\n","1. **Extension of Shannon Entropy to Continuous Random Variables:**\n","   - Differential entropy extends the concept of entropy to continuous random variables. For a continuous random variable $X$ with probability density function $f(x)$, the differential entropy is defined as:\n","   $$ h(X) = -\\int_{-\\infty}^{\\infty} f(x) \\cdot \\log_2(f(x)) \\, dx $$\n","\n","\n","2. **Properties and Limitations:**\n","   - Unlike Shannon entropy, differential entropy can be negative and is unbounded.\n","   - It does not always correspond to the true amount of information due to scale dependency.\n","\n","3. **Differential Entropy in Information Theory:**\n","   - Differential entropy is used in information theory to quantify the uncertainty associated with continuous random variables.\n","   - It serves as a measure of the average \"information density\" per unit, providing insights into the spread of probability mass in the continuous domain.\n","\n","\n","\n","### Algorithmic Information Theory:\n","\n","1. **Kolmogorov Complexity:**\n","   - Kolmogorov complexity measures the minimal length of a binary description of an object, and it is often denoted as $K(x)$.\n","   - The formal definition is: $$ K(x) = \\min_{p, s} \\{|p| : U(p, s) = x \\} $$\n","     where $U$ is a universal Turing machine, $p$ is a binary program, $s$ is the input to the program, and $|p|$ is the length of the program.\n","   \n","2. **Universal Turing Machines:**\n","   - A universal Turing machine $U$ is capable of simulating the behavior of any other Turing machine given an appropriate description of that machine.\n","   - Kolmogorov complexity is closely related to the existence of universal Turing machines, as it represents the shortest program that generates a particular string.\n","\n","3. **Implications for Incompleteness and Randomness:**\n","   - Algorithmic Information Theory has implications for Gödel's incompleteness theorems, demonstrating the existence of undecidable propositions.\n","   - Randomness can be characterized by strings with high Kolmogorov complexity, as they lack concise descriptions or patterns.\n","\n","### Fisher Information:\n","\n","1. **Information Content in Statistical Estimation:**\n","   - Fisher information measures the amount of information that a random variable carries about an unknown parameter in a statistical model.\n","   - For a parameter $\\theta$, the Fisher information $I(\\theta)$ is defined as: $$ I(\\theta) = -\\mathbb{E}\\left[\\frac{\\partial^2 \\log f(X|\\theta)}{\\partial \\theta^2}\\right] $$\n","\n","2. **Relationship with Cramer-Rao Bound:**\n","   - The Cramér-Rao bound provides a lower limit on the variance of unbiased estimators and is inversely proportional to the Fisher information: $$ \\text{Var}(\\hat{\\theta}) \\geq \\frac{1}{I(\\theta)} $$\n","   - Efficient estimators attain this bound when the Fisher information is maximized.\n","\n","3. **Applications in Parameter Estimation:**\n","   - Fisher information is crucial in designing efficient estimators for unknown parameters in statistical models.\n","   - It is used in various fields, such as physics, biology, and economics, for accurate and precise parameter estimation.\n","\n","### Information Bottleneck:\n","\n","1. **Balancing Compression and Relevance:**\n","   - The Information Bottleneck method aims to find a balance between compressing data while retaining relevant information.\n","   - Mathematically, it involves optimizing a Lagrangian function, often denoted as $L_\\beta(Y; X)$ , where $Y$ is the compressed representation and $X$ is the input.\n","\n","2. **Trade-offs in Information Processing:**\n","   - The Information Bottleneck algorithm introduces a trade-off parameter $\\beta$ that controls the level of compression versus information retention.\n","   - The optimization problem involves finding the optimal trade-off that aligns with the desired level of compression and relevance.\n","\n","3. **Applications in Machine Learning and Clustering:**\n","   - Information Bottleneck has applications in clustering, feature selection, and model simplification.\n","   - It is used in unsupervised learning tasks where finding a concise representation of the input data is crucial.\n","\n","### Blackwell's Information Measure:\n","\n","1. **Definition and Properties:**\n","   - Blackwell's information measure, denoted as $I(P, Q)$, quantifies the information gain when transitioning from a prior distribution $P$ to a posterior distribution $Q$.\n","   - The formula is: $$ I(P, Q) = \\sum_x P(x) \\cdot \\log\\left(\\frac{P(x)}{Q(x)}\\right) $$\n","\n","2. **Applications in Decision Theory:**\n","   - In decision theory, Blackwell's information measure is used to assess the information gained when updating beliefs based on observed data.\n","   - It plays a role in optimal decision-making and updating probability distributions after obtaining new information.\n","\n","3. **Connection with Mutual Information:**\n","   - Blackwell's information measure is related to mutual information, with mutual information being the special case when $ P$ is the joint distribution and $Q$\n","    is the product of marginal distributions.\n","   - The connection highlights its role in capturing information transfer between random variables.\n","\n"],"metadata":{"id":"xnuOaoG6vvVh"}},{"cell_type":"markdown","source":["Channel capacity, in the context of information theory, refers to the maximum rate at which information can be reliably transmitted through a communication channel. It is a fundamental concept that establishes an upper limit on the amount of data that can be conveyed through a channel without errors. The channel capacity is influenced by the characteristics of the channel itself and is subject to constraints such as noise, interference, and bandwidth limitations.\n","\n","Mathematically, channel capacity is often denoted by the Shannon-Hartley theorem, which states that the capacity C of a channel is given by the formula:\n","\n","$$ C = B \\cdot \\log_2(1 + \\frac{S}{N}) $$\n","\n","Where:\n","- $ C $ is the channel capacity in bits per second.\n","- $ B $ is the bandwidth of the channel in hertz.\n","- $ S $ is the signal power.\n","- $ N $ is the noise power.\n","\n","This formula highlights the trade-off between bandwidth and signal-to-noise ratio (SNR). Increasing bandwidth or improving SNR can enhance the channel capacity. The logarithmic term reflects the diminishing returns of increasing SNR.\n","\n","Understanding channel capacity is crucial for designing communication systems, as it provides insights into how much information can be reliably transmitted under specific conditions. It also serves as a benchmark for evaluating the efficiency of different encoding and modulation schemes. In the context of developing robust AGI systems, knowledge of channel capacity is essential for optimizing information transfer and communication strategies, ensuring reliable and secure interactions between components. Incorporating this understanding into AGI systems can lead to more effective utilization of available resources and improved overall performance."],"metadata":{"id":"Hbljrabd5EyR"}},{"cell_type":"markdown","source":["Source coding theory, often referred to as source compression or data compression, is a field within information theory that focuses on efficiently representing information sources to minimize the amount of data required for transmission or storage. The primary goal is to reduce redundancy in the data, enabling more efficient use of resources.\n","\n","The central concept in source coding theory is the source entropy, denoted by $H(X)$, which quantifies the average amount of information (in bits) required to represent symbols from the information source $X$. The entropy is given by the formula:\n","\n","$$ H(X) = - \\sum_{i} P(x_i) \\cdot \\log_2(P(x_i)) $$\n","\n","Where:\n","- $P(x_i) $ is the probability of occurrence of symbol $x_i$ in the source.\n","\n","The entropy represents the minimum average code length needed to uniquely represent symbols from the source. In practical scenarios, source coding techniques aim to design codes that approach this entropy, achieving compression without loss of information.\n","\n","One of the fundamental results in source coding is the source coding theorem, which establishes the theoretical limit of lossless compression. It states that for any uniquely decodable code, the average code length $L$ must satisfy:\n","\n","$$ L \\geq H(X) $$\n","\n","This theorem implies that no lossless code can achieve an average code length less than the source entropy. Efficiency in compression is achieved when the code length approaches the entropy, and the difference between them is referred to as the redundancy.\n","\n","The concept of entropy is extended to conditional entropy $H(X|Y)$, which measures the average amount of information needed to encode symbols from $X$ given that symbols from $Y$ are known. It is defined as:\n","\n","$$ H(X|Y) = - \\sum_{i, j} P(x_i, y_j) \\cdot \\log_2(P(x_i|y_j)) $$\n","\n","Source coding theory also encompasses the concept of rate-distortion theory, which considers lossy compression. In this case, the goal is to achieve a trade-off between compression rate and the distortion introduced by the compression process.\n","\n","Understanding source coding theory is essential for developing efficient data compression algorithms, which can be valuable in various applications, including communication systems and storage devices. In the context of AGI systems, incorporating effective source coding techniques can optimize the representation and transmission of information, contributing to overall system efficiency and performance."],"metadata":{"id":"5MssRh5K5ivw"}},{"cell_type":"markdown","source":["Directed Information, often denoted as $ I(X \\rightarrow Y) $, is a concept in information theory that quantifies the amount of information transferred from a random process or source $X$ to another random process or channel $Y$, considering the temporal order of events. It provides a measure of the causal influence or information flow from $X$ to $Y$.\n","\n","The directed information is defined as the difference between the conditional entropy of $Y$ given its past and the conditional entropy of $Y$ given both its past and the past of $X$:\n","\n","$$ I(X \\rightarrow Y) = H(Y_t|Y_{t-1}) - H(Y_t|Y_{t-1}, X_{t-1}) $$\n","\n","Here,\n","- $ I(X \\rightarrow Y) $ is the directed information from $ X$  to $ Y $.\n","- $ H(Y_t|Y_{t-1}) $ is the conditional entropy of $Y_t$ given its past $Y_{t-1}$ .\n","- $  H(Y_t|Y_{t-1}, X_{t-1}) $ is the conditional entropy of $Y_t$ given both its past $Y_{t-1}$ and the past of $X$ $(X_{t-1}$).\n","\n","Directed information provides a measure of how much uncertainty is reduced about the future of $Y$ by considering the past of $X$. If $I(X \\rightarrow Y)$ is positive, it indicates that the past of $X$ contains information about the future of $Y$, and if it is zero, there is no information flow. Negative values suggest that the past of $X$ reduces uncertainty about the future of $Y$.\n","\n","The concept is particularly relevant in the analysis of information flow in dynamic systems, such as communication channels, biological processes, and control systems. It has applications in fields like neuroscience, where understanding the directed information flow between neurons can provide insights into information processing in the brain.\n","\n","Directed information is intimately connected to the concept of Granger causality, which is a statistical hypothesis test to determine whether the past of one time series can predict the future of another.\n","\n","In summary, directed information is a valuable tool for analyzing and quantifying the directed flow of information between processes, especially in dynamic systems with temporal dependencies. Incorporating this concept into the study of AGI systems can provide a deeper understanding of information processing dynamics, aiding in the development of more effective and causally aware intelligent systems."],"metadata":{"id":"PfHBb6LV6aQU"}},{"cell_type":"markdown","source":["Entropy is a concept that appears in various fields, and there are different formulations of entropy depending on the context. Here are some of the different types of entropy:\n","\n","1. **Shannon Entropy (Information Entropy):**\n","   - Definition: Measures the average amount of surprise or uncertainty associated with a random variable.\n","   - Formula: $$ H(X) = - \\sum_{i} P(x_i) \\cdot \\log_2(P(x_i)) $$\n","\n","2. **Joint Entropy:**\n","   - Definition: Measures the average uncertainty of a pair of random variables.\n","   - Formula: $$ H(X, Y) = - \\sum_{i, j} P(x_i, y_j) \\cdot \\log_2(P(x_i, y_j)) $$\n","\n","3. **Conditional Entropy:**\n","   - Definition: Measures the average uncertainty of one random variable given the knowledge of another.\n","   - Formula: $$ H(X|Y) = - \\sum_{i, j} P(x_i, y_j) \\cdot \\log_2(P(x_i|y_j)) $$\n","\n","4. **Cross Entropy:**\n","   - Definition: Measures the average number of bits needed to encode events from one probability distribution using the optimal code for another distribution.\n","   - Formula: $$ H(X, Y) = - \\sum_{i} P(x_i) \\cdot \\log_2(Q(x_i)) $$, where $ Q $ is a different probability distribution.\n","\n","5. **Kullback-Leibler Divergence (Relative Entropy):**\n","   - Definition: Measures the information lost when using one probability distribution to approximate another.\n","   - Formula: $$ D_{KL}(P||Q) = \\sum_{i} P(x_i) \\cdot \\log_2\\left(\\frac{P(x_i)}{Q(x_i)}\\right) $$\n","\n","6. **Gibbs Entropy (Statistical Entropy):**\n","   - Definition: Used in statistical mechanics to quantify the microscopic disorder in a physical system.\n","   - Formula: $$ S = -k \\sum_{i} P(x_i) \\cdot \\log(P(x_i)) $$, where $ k $ is the Boltzmann constant.\n","\n","7. **Tsallis Entropy:**\n","   - Definition: A generalized form of entropy that includes a parameter $q $ to modify the sensitivity to rare events.\n","   - Formula: $$ H_q(X) = \\frac{1}{1-q} \\sum_{i} P(x_i)^q $$\n","8. **Rényi Entropy:**\n","   - Definition: Another generalization of Shannon entropy, parameterized by $ \\alpha $.\n","   - Formula: $$ H_\\alpha(X) = \\frac{1}{1-\\alpha} \\log_2\\left(\\sum_{i} P(x_i)^\\alpha\\right) $$\n","\n","\n","\n","9. **Rényi Divergence:**\n","   - Definition: A generalization of Kullback-Leibler Divergence based on Rényi entropy.\n","   - Formula: $$ D_\\alpha(P||Q) = \\frac{1}{\\alpha-1} \\log_2\\left(\\sum_{i} P(x_i)^\\alpha \\cdot Q(x_i)^{1-\\alpha}\\right) $$\n","\n","10. **Conditional Mutual Information:**\n","    - Definition: Measures the reduction in uncertainty about one random variable due to the knowledge of another.\n","    - Formula:  $$ I(X;Y|Z) = H(X|Z) - H(X|Y, Z) $$\n","\n","11. **Mutual Information:**\n","    - Definition: Measures the mutual dependence between two random variables.\n","    - Formula: $$ I(X;Y) = H(X) + H(Y) - H(X, Y) $$\n","\n","12. **Variational Information:**\n","    - Definition: A measure of the difference between two probability distributions.\n","    - Formula: $$ V(P,Q) = \\sup_A \\left(\\sum_{x\\in A} P(x) - \\sum_{x\\in A} Q(x)\\right) $$\n","\n","13. **Differential Entropy:**\n","    - Definition: Generalization of Shannon entropy for continuous probability distributions.\n","    - Formula: $$ h(X) = -\\int p(x) \\cdot \\log_2(p(x)) \\, dx $$\n","\n","14. **Hartley Entropy:**\n","    - Definition: A simpler form of entropy used in information theory, mainly for equiprobable events.\n","    - Formula: \\( H_H(X) = \\log_2(N) \\), where \\( N \\) is the number of possible events.\n","\n","15. **Negentropy:**\n","    - Definition: Measures the deviation of a distribution from the uniform distribution.\n","    - Formula: $$ J(X) = H_{\\text{uniform}}(X) - H(X) $$\n","\n","16. **Shannon-McMillan-Breiman Theorem Entropy:**\n","    - Definition: Relates the entropy of a process to the asymptotic behavior of its empirical distribution.\n","    - Formula: $$ H = \\lim_{n\\to\\infty} -\\frac{1}{n}\\log_2 P(x_1, x_2, \\ldots, x_n) $$\n","\n","    Certainly, here are some more types of entropy that haven't been mentioned in the previous lists:\n","\n","17. **Rényi Mutual Information:**\n","    - Definition: A generalization of mutual information based on Rényi entropy.\n","    - Formula: $$  I_\\alpha(X;Y) = \\frac{1}{1-\\alpha} \\log_2\\left(\\sum_{i, j} P(x_i, y_j)^\\alpha\\right) $$\n","\n","18. **Fisher Information:**\n","    - Definition: Measures the amount of information that an observable random variable carries about an unknown parameter in a statistical model.\n","    - Formula: $$ I(\\theta) = \\mathbb{E}\\left[\\left(\\frac{\\partial \\log f(X;\\theta)}{\\partial \\theta}\\right)^2\\right] $$\n","\n","19. **Topological Entropy:**\n","    - Definition: Used in the field of dynamical systems to quantify the rate of exponential growth of the number of distinguishable states.\n","    - Formula: $$ h_{\\text{top}}(f) = \\lim_{\\varepsilon \\to 0} \\limsup_{n \\to \\infty} \\frac{\\log_2(N_\\varepsilon(f^n))}{n} $$\n","\n","20. **Quantum Entropy:**\n","    - Definition: Entropy measures used in the context of quantum information theory.\n","    - Examples: Von Neumann Entropy, Reversed Relative Entropy, Conditional Entropy, etc.\n","\n","21. **Havrda-Charvát Tsallis Entropy:**\n","    - Definition: A specific formulation of Tsallis entropy, often used in information theory and statistics.\n","    - Formula: $$ H_q(X) = \\frac{1}{1-q} \\sum_{i} P(x_i)^q - P(x_i) $$\n","\n","22. **Information Dimension:**\n","    - Definition: A measure of the complexity of a set or sequence.\n","    - Formula: $$ D_I = \\lim_{\\varepsilon \\to 0} \\frac{\\log_2(N_\\varepsilon)}{\\log_2(1/\\varepsilon)} $$\n","\n","23. **Equivocation:**\n","    - Definition: In cryptography, it is the uncertainty about the plaintext given the ciphertext.\n","    - Formula: $$ H(K|C) = -\\sum_k \\sum_c P(k,c) \\log_2 P(k|c) $$\n","\n","24. **Multi-information:**\n","    - Definition: Measures the total amount of information shared among multiple random variables.\n","    - Formula: $$ I(X_1; X_2; \\ldots; X_n) = \\sum_{i=1}^{n} H(X_i) - H(X_1, X_2, \\ldots, X_n) $$\n","\n","25. **Shannon-Wiener Diversity Index:**\n","    - Definition: In ecology, it measures the species diversity in a community.\n","    - Formula: $$ H' = -\\sum_{i=1}^{S} \\frac{p_i}{\\ln(p_i)} $$, where $ S $ is the number of species and $ p_i $ is the proportion of individuals in the $i$-th species.\n","\n","\n","26. **Conditional Rényi Entropy:**\n","    - Definition: A generalization of conditional entropy based on Rényi entropy.\n","    - Formula: $$ H_\\alpha(X|Y) = \\frac{1}{1-\\alpha} \\log_2\\left(\\sum_{i, j} P(x_i|y_j)^\\alpha\\right) $$\n","\n","27. **Perplexity:**\n","    - Definition: Commonly used in natural language processing, it measures how well a probability distribution predicts a sample.\n","    - Formula: $$ \\text{Perplexity}(X) = 2^{H(X)} $$\n","\n","28. **Empirical Entropy:**\n","    - Definition: The entropy calculated from observed frequencies in a given dataset.\n","    - Formula: $$ H_{\\text{empirical}}(X) = -\\sum_{i} \\frac{n_i}{N} \\log_2\\left(\\frac{n_i}{N}\\right) $$ , where $ n_i $ is the frequency of observation $i$ and $ N $ is the total number of observations.\n","\n","29. **Spectral Entropy:**\n","    - Definition: Used in signal processing, it quantifies the distribution of signal energy across different frequency components.\n","    - Formula: $$ H_{\\text{spectral}}(X) = -\\sum_{i} P(f_i) \\cdot \\log_2(P(f_i)) $$, where $ P(f_i) $ is the normalized power spectrum at frequency $f_i$.\n","\n","30. **Participation Entropy:**\n","    - Definition: Used in physics, it measures the diversity of particles across different degrees of freedom.\n","    - Formula: $$ H_{\\text{participation}}(X) = -\\sum_{i} \\left(\\frac{n_i}{N}\\right)^2 $$ , where $ n_i $ is the number of particles in the $i$-th degree of freedom.\n","\n","31. **Information Entropy Rate:**\n","    - Definition: Represents the average entropy per symbol in a stochastic process.\n","    - Formula: $$ H_{\\text{rate}}(X) = \\lim_{n \\to \\infty} \\frac{1}{n} H(X_1, X_2, \\ldots, X_n) $$\n","\n","32. **Partitioned Entropy:**\n","    - Definition: Measures the uncertainty associated with a partition of a set.\n","    - Formula: $$ H_{\\text{partition}}(X) = -\\sum_{i} P(A_i) \\cdot \\log_2(P(A_i)) $$, where $ A_i $ is a partition of the set.\n","\n","33. **Hidden Markov Model Entropy:**\n","    - Definition: Represents the uncertainty in predicting the future states of a system modeled by a hidden Markov model.\n","    - Formula: $$ H_{\\text{HMM}}(X) = -\\sum_{i} P(x_i) \\cdot \\log_2(P(x_i)) $$, where $ x_i $ is a hidden state in the model.\n","\n","34. **Proportional Entropy:**\n","    - Definition: A measure of uncertainty in data proportional to the logarithm of the number of possible states.\n","    - Formula: $$ H_{\\text{proportional}}(X) = \\log_2(|X|) $$, where $ |X| $ is the size of the set $X$.\n","\n","\n","\n"],"metadata":{"id":"f7dZm4Z1AfgQ"}},{"cell_type":"code","source":[],"metadata":{"id":"QpKDVK0m1XKf"},"execution_count":null,"outputs":[]}]}