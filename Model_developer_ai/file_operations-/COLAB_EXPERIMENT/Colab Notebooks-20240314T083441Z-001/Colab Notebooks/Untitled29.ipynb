{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPQctl6cQM05UHHPdWj9fXV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["\n","\n","| **Name**                 | **Area of Interest**                            | **Company/Research Center**                          |\n","|--------------------------|--------------------------------------------------|------------------------------------------------------|\n","| Michael Jordan           | Machine Learning, Probabilistic Models          | UC Berkeley, Microsoft Research                      |\n","| Ian Goodfellow           | Generative Models, Deep Learning                | OpenAI, Google Brain                                  |\n","| Yann LeCun               | Convolutional Neural Networks, Computer Vision | Facebook AI Research, NYU                            |\n","| Stuart Russell           | Artificial Intelligence, Machine Learning      | UC Berkeley, Google                                   |\n","| Raia Hadsell             | Robotics, Deep Learning                         | DeepMind                                             |\n","| Tomas Mikolov            | Natural Language Processing, Word Embeddings    | Facebook AI Research                                 |\n","| Sebastian Thrun          | Robotics, Self-driving Cars                     | Kitty Hawk, Stanford University                      |\n","| Thomas G. Dietterich     | Machine Learning, Reinforcement Learning        | Oregon State University                              |\n","| Cynthia Breazeal         | Social Robots, Human-Robot Interaction          | MIT, Jibo                                            |\n","| Ben Goertzel             | Artificial General Intelligence, AGI           | SingularityNET, OpenCog                              |\n","| Hugo Larochelle          | Neural Networks, Deep Learning                  | Google Brain, CIFAR                                 |\n","| Toby Walsh               | Artificial Intelligence, Ethics                | University of Sydney, Data61                         |\n","| Zoubin Ghahramani        | Bayesian Machine Learning, Probabilistic Models | University of Cambridge, Uber AI                     |\n","| Kristian Kersting         | Statistical Relational Learning                  | TU Darmstadt, Germany                               |\n","| Vladimir Vapnik         | Support Vector Machines, Statistical Learning  | Facebook AI Research, Columbia University           |\n","| Jurgen Schmidhuber      | Recurrent Neural Networks, Evolutionary Computation | IDSIA, Swiss AI Lab, NNAISENSE                    |\n","| Andrew McCallum          | Natural Language Processing, Machine Learning  | University of Massachusetts Amherst, TACC            |\n","| Ruslan Salakhutdinov     | Deep Learning, Neural Networks                  | Carnegie Mellon University, Apple                    |\n","| Jeff Hawkins             | Hierarchical Temporal Memory, Neuroscience     | Numenta                                              |\n","| Richard S. Sutton        | Reinforcement Learning, AI                       | University of Alberta, DeepMind                     |\n","| Chris Olah               | Neural Networks, Deep Learning                  | OpenAI                                               |\n","| Léon Bottou              | Machine Learning, Large-scale Optimization     | Facebook AI Research, Microsoft                     |\n","| Emma Brunskill           | Machine Learning, Reinforcement Learning        | Stanford University                                  |\n","| Chris Bishop             | Neural Networks, Pattern Recognition           | Microsoft Research, University of Edinburgh         |\n","| Drew Bagnell             | Robotics, Machine Learning                      | Carnegie Mellon University, Uber ATG                 |\n","| Doina Precup             | Reinforcement Learning, Robotics               | DeepMind, McGill University                          |\n","| Dan Jurafsky             | Natural Language Processing, Computational Linguistics | Stanford University                           |\n","| Max Welling              | Machine Learning, Bayesian Deep Learning        | University of Amsterdam, Qualcomm AI Research        |\n","| Lei Deng                 | Deep Learning, Reinforcement Learning           | Stanford University                                  |\n","| David Ha                 | Generative Models, Deep Learning                | Google Brain, Stanford University                    |\n","| Heng Huang               | Machine Learning, Computer Vision               | University of Texas at Arlington                     |\n","| David Silver             | Reinforcement Learning, Deep Learning           | DeepMind, University College London                  |\n","| Zhang Wei (Megvii)      | Computer Vision, Face Recognition              | Megvii Technology, Beijing, China                    |\n","| Jun Zhu                  | Machine Learning, Bayesian Inference            | Tsinghua University, Beijing, China                   |\n","| Jian Sun (Megvii)       | Computer Vision, Deep Learning                  | Megvii Technology, Beijing, China                    |\n","| Yann Dauphin             | Natural Language Processing, Machine Learning  | Facebook AI Research                                 |\n","| Ilya Sutskever           | Deep Learning, Neural Networks                  | OpenAI                                               |\n","| Adam Coates              | Deep Learning, Computer Vision                  | Apple                                                |\n","| Wojciech Zaremba         | Machine Learning, Neural Networks               | OpenAI, Facebook                                     |\n","| Jürgen Schmidhuber       | Neural Networks, Evolutionary Computation       | IDSIA, Swiss AI Lab, NNAISENSE                       |\n","| Dileep George            | Artificial Intelligence, AGI                   | Vicarious AI                                         |\n","| Shivon Zilis             | AI Ethics, Venture Capital                      | Neuralink, Bloomberg Beta                           |\n","| Maja Pantic              | Affective Computing, Computer Vision            | Imperial College London                              |\n","| Thomas Hofmann           | Machine Learning, Probabilistic Models          | ETH Zurich, Google Research                          |\n","| Irina Rish               | Machine Learning, Neural Networks               | Google Brain                                         |\n","| Sergey Levine            | Robotics, Reinforcement Learning                | UC Berkeley, Google Brain                             |\n","| Justin Johnson           | Computer Vision, Deep Learning                  | University of Michigan                               |\n","| Karol Hausman            | Robotics, Reinforcement Learning                | UC Berkeley                                          |\n","| Kyunghyun Cho            | Natural Language Processing, Deep Learning      | New York University, Facebook AI Research            |\n","| Alex Graves               | Recurrent Neural Networks, Neural Turing Machines | Google DeepMind                                      |\n"],"metadata":{"id":"wdWKfcNv2ks1"}},{"cell_type":"markdown","source":["## Michael Jordan's\n","\n","Professor Michael Jordan is not just a distinguished professor at UC Berkeley, but a true pioneer in the realm of machine learning and probabilistic models. His influence spills over into diverse fields like statistics, computer science, cognitive science, and even engineering. This breadth is reflected in the prestigious collection of awards adorning his career, including the esteemed IEEE John von Neumann Medal, the IJCAI Research Excellence Award, and the ACM/AAAI Allen Newell Award.\n","\n","But accolades merely hint at the depth and impact of Jordan's research. Here, we delve into some of his key areas of exploration:\n","\n","**1. Statistical Machine Learning: Decisions Driven by Data**\n","\n","At the heart of Jordan's work lies the quest to bridge the gap between data and actionable insights. He spearheads the development of statistical techniques that unlock the power of machine learning predictions.\n","\n","Imagine scientific hypotheses, once shrouded in uncertainty, gaining clarity through the lens of data-driven models. Jordan envisions a future where these models inform optimal decisions, even in the face of inherent uncertainties. This pursuit has profound implications for diverse fields, from healthcare diagnoses to financial forecasting.\n","\n","**2. Learning in the Labyrinth of Matching Markets**\n","\n","Decentralized markets, like online dating platforms, pose a unique challenge. How do agents within these complex ecosystems navigate the intricate dance of learning their own preferences and strategies, all while considering the actions of others? Jordan sheds light on this fascinating puzzle.\n","\n","His research unveils how agents can leverage machine learning to refine their understanding of their own desires and adapt their approaches in response to the ever-shifting landscape of the market. This work holds immense potential for optimizing matching mechanisms, ensuring fairer and more efficient outcomes for all participants.\n","\n","**3. Momentum in the Optimization Maze**\n","\n","Optimization algorithms, the tireless workhorses behind countless machine learning endeavors, often rely on a mysterious force called \"momentum.\" Jordan delves into the heart of this phenomenon, seeking to understand how it propels these algorithms towards solutions with remarkable speed.\n","\n","His journey explores connections between seemingly disparate domains: optimization algorithms, dynamical systems, control theory, and even the elegant realm of symplectic geometry. By unraveling the intricate dance of these disciplines, Jordan aims to unlock the full potential of optimization, paving the way for even faster and more efficient learning algorithms.\n","\n","**Beyond the Headlines: A Glimpse into the Papers**\n","\n","Professor Jordan's research resonates not just in broad strokes, but also in the intricate details of his groundbreaking papers. Here's a peek into some of his notable works:\n","\n","* **Gradient Descent Only Converges to Minimizers**: This seminal paper unveils the limitations of gradient descent in non-convex optimization problems, providing crucial insights for steering these algorithms towards true solutions.\n","* **Parallel correlation clustering on big graphs**: Taming the vastness of massive graphs, this work devises a scalable algorithm for clustering them based on edge similarities, a feat previously shrouded in computational complexity.\n","* **Probabilistic independence networks for hidden Markov probability models**: Jordan introduces a powerful graphical model framework that decodes the hidden language of dependencies within these models, opening doors to a deeper understanding of complex systems.\n","\n","Professor Michael Jordan's contributions extend far beyond the confines of research papers and academic accolades. He is a visionary architect, shaping the future of machine learning by weaving together diverse disciplines, tackling real-world challenges, and illuminating the intricate pathways of data-driven insights.\n","\n","This exploration paints a more nuanced picture of Jordan's work, venturing beyond mere headlines to capture the essence of his research and its far-reaching implications. By understanding these underlying motivations and technical nuances, we gain a deeper appreciation for the exceptional mind that pushes the boundaries of machine learning and beyond.\n","\n","\n","![](https://s3.amazonaws.com/cms.ipressroom.com/401/files/202308/jordan.jpg)\n"],"metadata":{"id":"IE0UjKGs4iRu"}},{"cell_type":"markdown","source":["# Ilya Sutskever\n","Ilya Sutskever serves as the co-founder and chief scientist of OpenAI, an eminent research organization dedicated to advancing the field of artificial intelligence (AI) while ensuring its safe and responsible deployment. Regarded as a pioneering figure in deep learning and neural networks, Sutskever has significantly shaped the landscape of AI through his influential contributions.\n","\n","**Accolades and Recognition:**\n","Sutskever's profound impact is underscored by accolades such as the MIT Technology Review Innovators Under 35 and the ACM Grace Murray Hopper Award¹², acknowledging his substantial influence on the field of AI.\n","\n","**Key Research Contributions:**\n","Among his notable contributions are seminal papers that have left an indelible mark on AI research:\n","\n","- **ImageNet Classification with Deep Convolutional Neural Networks³:** Co-authored with Alex Krizhevsky and Geoffrey Hinton, this paper introduced AlexNet, a pioneering deep convolutional neural network. The model achieved state-of-the-art results on the ImageNet challenge, catalyzing the resurgence of deep learning and its application in computer vision.\n","\n","- **Sequence to Sequence Learning with Neural Networks⁴:** Collaborating with Oriol Vinyals and Quoc Le, Sutskever proposed a versatile framework for mapping sequences of variable lengths, such as sentences, to other sequences, exemplified in machine translation and text summarization tasks. The paper employed recurrent neural networks with an encoder-decoder architecture.\n","\n","- **Language Models are Few-Shot Learners⁵:** In collaboration with other researchers at OpenAI, Sutskever presented ChatGPT, a large-scale generative language model with impressive capabilities in natural language understanding and generation tasks. The model demonstrated competitive results on various benchmarks with minimal supervision.\n","\n","**Current Research Interests:**\n","Sutskever's current research interests reflect the evolving challenges in AI:\n","\n","- **Decision-making in Machine Learning:** Exploring methods to leverage machine learning model predictions for optimal decision-making under uncertainty and constraints, particularly in reinforcement learning and control problems.\n","\n","- **The Alignment Problem in AI:** Investigating and addressing the risks associated with developing and deploying AI systems that may not align with human values and goals, especially in scenarios involving artificial superintelligence.\n","\n","- **Integration of Deep Learning and Symbolic Reasoning:** Exploring the synergies between deep learning, adept at learning from vast datasets, and symbolic reasoning, proficient in abstract manipulation and logical inference. This aims to enhance the capabilities of AI systems for broader and more advanced applications.\n","\n","**Sources:**\n","- [Technology Review](https://www.technologyreview.com/2023/10/26/1082398/exclusive-ilya-sutskever-openais-chief-scientist-on-his-hopes-and-fears-for-the-future-of-ai/)\n","- [Google Scholar](https://scholar.google.com/citations?user=x04W_mMAAAAJ)\n","- [DeepAI](https://deepai.org/profile/ilya-sutskever)\n","- [Wikiquote](https://en.wikiquote.org/wiki/Ilya_Sutskever)\n","- [Stanford eCorner](https://ecorner.stanford.edu/wp-content/uploads/sites/2/2023/04/inside-openai-entire-talk-transcript.pdf)\n","- ![Ilya Sutskever](https://media.gettyimages.com/id/1258459915/photo/israel-science-technology-ai.jpg?s=1024x1024&w=gi&k=20&c=L5Fr20I7AQvSx8nGeXwX2-faK2zMZa90Cd9GLmlSXSU=)\n"],"metadata":{"id":"qABfxWJP7LfN"}},{"cell_type":"markdown","source":["### Ian Goodfellow: Pioneer in Deep Learning and Generative Models\n","\n","**Professional Background:**\n","Ian Goodfellow is a distinguished research scientist at Google and a co-founder of OpenAI, an esteemed research organization devoted to advancing artificial intelligence (AI) with a focus on safety. He stands as one of the trailblazers in the domains of deep learning and generative models, contributing significantly to the evolution of these fields.\n","\n","**Authorship of MIT Press Textbook:**\n","Ian Goodfellow has served as the lead author of the widely acclaimed MIT Press textbook, \"Deep Learning\"¹², reflecting his authority and expertise in the subject.\n","\n","**Landmark Research Papers:**\n","Ian Goodfellow's impact on AI research is exemplified by several groundbreaking papers:\n","\n","- **Generative Adversarial Networks (GANs)³:** Co-authored with a team including Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio, this paper introduced GANs, a revolutionary framework for training generative models. GANs have proven instrumental in producing realistic and diverse samples from complex data distributions, transcending limitations observed in previous methods.\n","\n","- **Explaining and Harnessing Adversarial Examples⁴:** In collaboration with Jonathon Shlens and Christian Szegedy, Goodfellow unveiled the concept of adversarial examples—inputs subtly perturbed to mislead machine learning models. The paper not only highlighted the existence and properties of adversarial examples but also proposed methods to leverage them for enhancing model robustness and generalization.\n","\n","- **TensorFlow: Large-scale machine learning on heterogeneous distributed systems⁵:** Co-authored with several researchers at Google, this paper presented TensorFlow—an open-source software library that revolutionized the design, building, and deployment of large-scale machine learning systems. The paper demonstrated TensorFlow's features and scalability across various applications, including computer vision, natural language processing, and speech recognition.\n","\n","**Sources:**\n","1. [Google Scholar](https://scholar.google.com.sg/citations?user=iYN86KEAAAAJ&hl=en)\n","2. [Research at Google](https://research.google.com/pubs/105214.html?source=post_page---------------------------)\n","3. [DeepAI](https://deepai.org/profile/ian-goodfellow)\n","4. [DeepLearning.AI](https://www.deeplearning.ai/blog/hodl-ian-goodfellow/)\n","5. [Google Books - Deep Learning](https://books.google.com/books/about/Deep_Learning.html?id=JkPtzwEACAAJ)\n","6. [Wikipedia](https://en.wikipedia.org/wiki/Ian_Goodfellow)\n","\n","![](https://wp.technologyreview.com/wp-content/uploads/2017/08/ian.goodfellow-9.jpg?fit=440,586)"],"metadata":{"id":"-OJRV3er9XF-"}},{"cell_type":"markdown","source":["### Yann LeCun: Visionary in Convolutional Neural Networks and AI\n","\n","**Renowned Researcher and Academician:**\n","Yann LeCun stands as a prominent figure in the realms of convolutional neural networks and computer vision. Currently serving as the Chief AI Scientist at Facebook and holding the prestigious position of Silver Professor at NYU, he has significantly impacted the field of deep learning with numerous groundbreaking contributions.\n","\n","**Awards and Honors:**\n","His stellar contributions have earned him several accolades, including the Turing Award, the IEEE Medal of Honor, and the ACM Prize in Computing¹², showcasing his profound influence on the AI landscape.\n","\n","**Key Research Papers:**\n","Yann LeCun's work is exemplified by several seminal papers:\n","\n","- **ImageNet Classification with Deep Convolutional Neural Networks³:** Co-authored with Alex Krizhevsky and Geoffrey Hinton, this paper introduced AlexNet, a revolutionary deep convolutional neural network that set new benchmarks in large-scale image recognition. It played a pivotal role in rekindling interest in deep learning for computer vision applications.\n","\n","- **Learning methods for generic object recognition with invariance to pose and lighting⁴:** Collaborating with Fu Jie Huang and Leon Bottou, this paper proposed a method for learning invariant features for object recognition through a hierarchical architecture of convolutional networks. The approach demonstrated superior generalization across various poses and lighting conditions.\n","\n","- **DeepFace: Closing the Gap to Human-Level Performance in Face Verification⁵:** Co-authored with researchers at Facebook, this paper presented DeepFace, a system achieving near-human accuracy in face recognition. Leveraging a deep convolutional network trained on a vast dataset of face images, the paper also introduced an innovative face alignment method based on a 3D model.\n","\n","\n","\n","**Sources:**\n","1. [Google Scholar](https://scholar.google.com/citations?user=WLN3QrAAAAAJ)\n","2. [NYU Tandon School of Engineering](https://engineering.nyu.edu/faculty/yann-lecun)\n","3. [Facebook AI Research Lab](https://cds.nyu.edu/yann-lecun-courant-institute-direct-facebooks-new-artificial-intelligence-lab/)\n","4. [Yann LeCun's Biography](http://yann.lecun.com/ex/bio.html)\n","5. [TED Speaker Profile](https://www.ted.com/speakers/yann_lecun)\n","6. [Yann LeCun's Website](http://yann.lecun.com)\n","7. [Getty Images](https://www.gettyimages.com/detail/news-photo/director-of-facebook-ai-research-yann-lecun-attends-the-news-photo/540680698)\n","\n","- ![](https://upload.wikimedia.org/wikipedia/commons/thumb/2/22/Yann_LeCun_-_2018_%28cropped%29.jpg/330px-Yann_LeCun_-_2018_%28cropped%29.jpg)\n","\n"],"metadata":{"id":"nDd0zbbY-mBb"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qg6_BGbH2duq"},"outputs":[],"source":[]}]}