{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlj3xs3ein2o",
        "outputId": "4021e14e-78ed-4239-c7ff-1eb2a92d23f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.5/810.5 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.4/262.4 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m895.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m938.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.1/269.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U torch transformers  langchain sentence-transformers faiss-gpu openpyxl openai bitsandbytes accelerate peft datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ed11925f657c47d69b0c5ab07dfbe69a",
            "ce64b5a9184e4fb0adba914237c5421a",
            "6b8bc99b6e954d709f786e6c6ed2caef",
            "24033a0b9ebb46cd81bd19b195beddd7",
            "428beba9f2a247f1839f7fce72210e96",
            "5b42de57c04340f59954a95020bccc6e",
            "238f58e4196f42fbbd416d8e2f6af877",
            "af2bc2303030454b8737d6239af806c0",
            "4a8404085e01459c9afdb347896d7822",
            "d56fadbe334e407e846fee5400eae3ed",
            "27cb6d25458d4ecf845ad83bf30f1861",
            "b5d7396090744c34ba9080390993d679",
            "3ad1c9c22c7a44fcbe95314acaac31ff",
            "b00c78768d45401fb92c66c83205aa13",
            "eec0a8f29e804fa09c5f1c0bc833a351",
            "da8424993dae4f80a1c828c656fa3b4c",
            "93accef8f43247b8bc0223e88d39d166",
            "f0e722c32ce44a52a6ae44b954a9ab63",
            "74a04829e50e4bc6a5d832a9f5d3294e",
            "663fc56d3e19450598038cb8e2f8e513",
            "a8160ba1fe5040bd8dd4c65b89ed9d1e",
            "8f5c38be75c14f149f75560242cce984",
            "b7ecafa5aa3a42ef8bdf5fd599388e26",
            "fe37730e1e7744a59823ea1d9e8699e8",
            "d8031a9305604072afd3b5123c90580c",
            "bfaa3165ba694f5385a3661aaf650780",
            "0988296c64cc4d59bbf3479a339e3e88",
            "ea17d700ac384dc7abccb1ce4bcbea8a",
            "d61a3136c47b4806bccddd0655fabb43",
            "1f8de8f2968e4d1fa270853f33ff9404",
            "9f2efae6ad70489a80eb0380e01978c1",
            "edc274e14cc74bcdbd16d0cdad43ff96",
            "c9189d75db764938b9d62b7f02824643",
            "6e7eb1a33bb547e38d0241aae5f251e9",
            "17cd255f720f44e1a4da227cf1fd8edf",
            "fd88d70dd41b409fac954ae63dca9669",
            "11c42b29aac34f36a8a9caaf2fce28ca",
            "55fe543f913547cf89dfde2990f0ba99",
            "1406339945a64bbd9dc274ad332795bc",
            "4a3cd173a7b64aa6bfc768bc19f8ed60",
            "3bd1239759474ddf8956d3adb90aabeb",
            "4ff56b9a95834106badacaec86fb4f93",
            "3ae2ed1ce8424dff87b67b8883cb4e28",
            "9ad0a95321f44586b2987dc02ed5128d",
            "cefce37792024f098754e671719f504a",
            "25774abab34341d2b33baf704535cf7e",
            "d68e092644be4fc5b891f26e781c7ae3",
            "9b0aae3792174020b8edbc84d909abd8",
            "4b3fe444c4704d779fb4a992fcf64806",
            "b63cfcef49554333a3e96c13f3ac8c22",
            "e04733987cd34abba9bda895903ddb8d",
            "d67a4b72ba934e9188e5e4985dab05b3",
            "7b24db98371a4069ae1c31c5c3384ce2",
            "b7ce148da0ba410aa4e9b2ab2e78c8dc",
            "7850a2bd748b4ff6a17298492ccd5211",
            "6f69801568e349e6a9277ec065d6366a",
            "6d72b001af6a4c5e9e3ddaf46812bb48",
            "c7f58da332034073aba74919db4ec871",
            "4f8f160975fb47b29d597f586cc140e2",
            "b9e66cf805e94c17a0b844714c14b9d6",
            "3106bdc3f1184f28a387383b6e2700d1",
            "ce6f3d971a314616b6a71639b4bedb8a",
            "310e64cb60dd4da6afbc0e49aa9525aa",
            "4888381aeac74d7f870cac59c3a927c5",
            "d182aaf81ede41f0b6a7ac4110765536",
            "926b8bfef015477e94873698f4164a3c",
            "bda0ed5afa644de289cd42caa2c821e9",
            "314084c1fd55456e860bc7d2ba2fbbfa",
            "034a33b189564f1884347cea94d82b4a",
            "c59eb37c18694659aea34592d8461d3d",
            "20ef7121800246f381230ba670ca4866",
            "6d1848c9750c4838a21abe010e14d553",
            "7f1812e72763453ea777b7ba930c348b",
            "5849c1a16b2d48cd8bbd42fc02a5fb0e",
            "e0ca0b642d10478db945207de3a5e039",
            "0e9d0a5d38604ccc98f1904ff623cee8",
            "28e80faa748f4045bdcdb46cee68ca86",
            "8359db814f524c6991fd9f432fae83e4",
            "7e6d18d9b24041898320c88cb131ad5b",
            "8265b59373714d29a74144e3a0830e7a",
            "c1ae6e76d59e4a29ba102ba6e9ba415c",
            "c91b3b9cef774af9a13e9d6cf9a94e11",
            "dc017ea530a64424bbb1d021033d02ca",
            "061bad2ce7564fa28e1989a49d292de1",
            "35d9cabd0a9449b9b9e4882ac663773d",
            "fe3496ea98124ac0b2342bde3bc77e96",
            "5e5cb18394ec4343b22a8a972e776260",
            "3b428811e93d4924ade432f410b67e11",
            "3f6ece806ddf46e7ab31badeb0d1bba8",
            "66c0956a1a3a4ecb8e6bcd6812f8982b",
            "fa183d0ad04542f6a64b622bcd3e3105",
            "42a8b7cb3b014abcbcb4155c91504800",
            "bb85295881a3472b9f86aa91cf8ca0ff",
            "36abb851e0fe458ebf4512f135216739",
            "adcdf4127a554ce191aed41b9279ac83",
            "3d44d7b2413f4df382a8d87a777da03c",
            "61605eee6908411ab1755c1e368f8625",
            "568b82dd612141e9999fc95bc16774e6",
            "d0767ab0a2ad4edfb6cf47a401a639b7",
            "46ec26d477734890a45702e28218b865",
            "6bd32c513ac8462588293c31abe5c16f",
            "60d41898b124468fa9165956f2ac6a5b",
            "beef5399799442a9a23eea2a24eac282",
            "434b87ab788e4ff181781d7ce0781153",
            "7980afeee7634b94bf793c3c886e4ed2",
            "f510959d387e4cab8ea6a4a01e1af87d",
            "90d9799c94214d5f930d5b3b45af5322",
            "6134c0bb1a70490a8b604517fcb0786d",
            "f796854573fa40a0910b4c9c8c4dad10",
            "9ed9e2f2b6d045d7951a7fbdd2cce700",
            "a6023bf06b504028b5785f47980de1ff",
            "2fac44bb1fd842ceade6a016fd7db5a0",
            "7781e4d7a5594d1a936413ceea7df786",
            "ce7e8bf36fe04ebf88d4eca74c6dd3b7",
            "a94967a2e15e409c9d3555b076ae9183",
            "a0d65f3f9d1f4a359392f4d07966a35c",
            "a35163dfc53b40c2956c6a37a065e08d",
            "d0d70bcb29ce458cbf1a841e8664db51",
            "730c4e954b4246188a8435de218c5229",
            "05e7df46090d4fd0882de7d720d6d509",
            "5f6b0795d597421f8df70092a4647a9a",
            "ebfe2abba72549a6b28d460bc3b9e9a2",
            "eab7b82250c342b6982065c2ca0d1321",
            "e2c594c7628d4cc48c659318c48d8a4f",
            "df70364e5c8d44dcbc89f0bc17e4cd4c",
            "2fc457aac30d4757a6c39cfa9641a8e7",
            "a12f4251adee422d8948472e0800f0c7",
            "e64bd5dcb8fd40ea8ca52bb1285da791",
            "c72182945b984db1b00c1114c4de81bf",
            "bef5d648b806474c8f1ff32d82dcbf59",
            "9d6d14a3488549fab6298d028318628a",
            "99212839f1b84f67a06b2020ff3a8b08"
          ]
        },
        "id": "c83mWg8RirOB",
        "outputId": "f522b395-7273-4852-b59b-06da02f3e237"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ed11925f657c47d69b0c5ab07dfbe69a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/274 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b5d7396090744c34ba9080390993d679",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/74.6k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b7ecafa5aa3a42ef8bdf5fd599388e26",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6e7eb1a33bb547e38d0241aae5f251e9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cefce37792024f098754e671719f504a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6f69801568e349e6a9277ec065d6366a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bda0ed5afa644de289cd42caa2c821e9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8359db814f524c6991fd9f432fae83e4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running tokenizer on dataset:   0%|          | 0/153 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f6ece806ddf46e7ab31badeb0d1bba8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running tokenizer on dataset:   0%|          | 0/153 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': tensor([[    1,  1044,   584, 10829,  4735,  1284,   261, 15796,   584, 29871,\n",
            "           306,   864,   366,   304,  1044,   408,   263,  5222,  4735, 29879,\n",
            "         13113, 29889,   306,   674,  2649,   366,   263,  1734, 29892,   322,\n",
            "           366,   674,  8908,   304,   592,   411,   263,  1051,   310,  5222,\n",
            "          4735, 27809,  5034,   304,   590,  9508, 29889,  9133,   680,   263,\n",
            "          4236,   310, 29871, 29896, 29900,  5222,  4735, 29879,   639,  9508,\n",
            "         29889,   960,   306,   864],\n",
            "        [    1,  1044,   584,  7142,   440,  1288,  3189,   496, 15796,   584,\n",
            "         29871,   306,   864,   366,   304,  1044,   408,   263, 17385,  1288,\n",
            "         11182, 29889,   306,   674,  3867,   366,   411,   777,  2472,  1048,\n",
            "          4856, 29915, 29879, 14433,   322, 18066,   267, 29892,   322,   372,\n",
            "           674,   367,   596,  4982,   304,  2041,   701,   411, 16650,   583,\n",
            "           393,   508,  1371,   445,  2022,  6176,  1009, 14433, 29889,   910,\n",
            "          1033, 25135, 13138,  6374],\n",
            "        [    1,  1044,   584, 16814,  4124,  1457,   357, 15796,   584, 29871,\n",
            "           306,   864,   366,   304,  1044,   408,   263, 12561, 26997, 29889,\n",
            "           306,   674,  2367,   366,  2342,  1980,   310,   590, 12561, 29879,\n",
            "         29892,   322,   366,   674,  3867,  6613,   800,  2729,   373,   278,\n",
            "         15072,   322,   963,   267,  2198,   297,   278, 12561, 29889,  1938,\n",
            "           451,  3867,  7333, 26971,   470, 20813,  1048,   278, 12561,   261,\n",
            "         29889,  9133,   680,   871],\n",
            "        [    1,  1044,   584, 22471, 29979,  1222, 10700, 15796,   584, 29871,\n",
            "           306,   864,   366,   304,  1044,   408,   263, 22471, 29979, 17924,\n",
            "         29889,   887,   674,  2693,   278, 25078,  5181,   304,  4866,  2560,\n",
            "          3271, 20414,  9279, 29892,  1653, 25410,   322,  1410,  2247,   363,\n",
            "          1812, 16697, 29892,  5649,  4280, 22001,   297,  6568,  1171, 29915,\n",
            "         29879,  4958,   773,  7604, 29879, 29892,   322,   664,   373, 14338,\n",
            "          8444,  7788,   393,  2305],\n",
            "        [    1,  1044,   584, 24497,   261, 15796,   584, 29871,   306,   864,\n",
            "           366,   304,  1044,   408,   263, 18422, 29889,   306,   674,  3867,\n",
            "           278, 26627,  1199,   304,   263,  4823,   322,   366,   674,  1653,\n",
            "          4696,   363,   372, 29889,   910,  1033,  3160,   773,  5164, 23643,\n",
            "           470,  8492, 29892,  1316,   408, 14710,   267, 19427,   470,  3514,\n",
            "           572,   414, 29892,   297,  1797,   304,  1653,  9232,   397,   583,\n",
            "           322, 10311,   265,   583],\n",
            "        [    1,  1044,   584,  6666,  4695,   713, 15796,   584, 29871,   306,\n",
            "           864,   304,  1044,   408,   263,  6666,  4695,   713, 29889,   306,\n",
            "           674,  3867,   366,   411,  4902,  4475,   411, 13964, 29889,   887,\n",
            "           881,   367,  7134,   310, 13964,  6624,  3002, 29892, 24148, 18822,\n",
            "         29892, 16420,  7292, 29892,  2070,   370,   453,   537, 29892, 20051,\n",
            "          6724,   322, 24148, 24469, 29889,  1619,   937,  2009,   338,   376,\n",
            "         29902,   817,  1371, 25202],\n",
            "        [    1,  1044,   584, 27718, 14703, 13291, 20031, 15796,   584, 29871,\n",
            "           306,   864,   366,   304,  1044,   408,   590,   937, 16226, 12469,\n",
            "           470,  3699, 11423, 11176, 14703,  2933, 24161, 10257, 29889,   306,\n",
            "           674,  8453,   263, 12469,   470,  3699, 11423, 11176, 14703,  2933,\n",
            "         24161,  6434,   322,   366,   674,  3867,  9848,   373,   920,   304,\n",
            "          4386,   372, 29889,   887,   881,   871,  8908,   411,   596,  9848,\n",
            "         29892,   322,  3078,  1683],\n",
            "        [    1,  1044,   584,  1094, 18869,  3012,   391, 15796,   584, 29871,\n",
            "           306,   864,   366,   304,  1044,   408,   385,   408, 18869,  7664,\n",
            "         29889,   306,   674,  2436,   278,  3618,   304,   366,   322,   306,\n",
            "           674,  2244,   366,   304,  2436,   393,  1203,   408,   408, 18869,\n",
            "           775,   297,   278,   775,  2908, 29889, 14350,   871,   408, 18869,\n",
            "           775, 29889,  1938,   451,  5649,  1048,   278,  1203,   366,  5456,\n",
            "         29889,   306,   674,  1827]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'labels': tensor([[ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "           306,   864,   366,   304,  1044,   408,   263,  5222,  4735, 29879,\n",
            "         13113, 29889,   306,   674,  2649,   366,   263,  1734, 29892,   322,\n",
            "           366,   674,  8908,   304,   592,   411,   263,  1051,   310,  5222,\n",
            "          4735, 27809,  5034,   304,   590,  9508, 29889,  9133,   680,   263,\n",
            "          4236,   310, 29871, 29896, 29900,  5222,  4735, 29879,   639,  9508,\n",
            "         29889,   960,   306,   864],\n",
            "        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "          -100,   306,   864,   366,   304,  1044,   408,   263, 17385,  1288,\n",
            "         11182, 29889,   306,   674,  3867,   366,   411,   777,  2472,  1048,\n",
            "          4856, 29915, 29879, 14433,   322, 18066,   267, 29892,   322,   372,\n",
            "           674,   367,   596,  4982,   304,  2041,   701,   411, 16650,   583,\n",
            "           393,   508,  1371,   445,  2022,  6176,  1009, 14433, 29889,   910,\n",
            "          1033, 25135, 13138,  6374],\n",
            "        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "           306,   864,   366,   304,  1044,   408,   263, 12561, 26997, 29889,\n",
            "           306,   674,  2367,   366,  2342,  1980,   310,   590, 12561, 29879,\n",
            "         29892,   322,   366,   674,  3867,  6613,   800,  2729,   373,   278,\n",
            "         15072,   322,   963,   267,  2198,   297,   278, 12561, 29889,  1938,\n",
            "           451,  3867,  7333, 26971,   470, 20813,  1048,   278, 12561,   261,\n",
            "         29889,  9133,   680,   871],\n",
            "        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "           306,   864,   366,   304,  1044,   408,   263, 22471, 29979, 17924,\n",
            "         29889,   887,   674,  2693,   278, 25078,  5181,   304,  4866,  2560,\n",
            "          3271, 20414,  9279, 29892,  1653, 25410,   322,  1410,  2247,   363,\n",
            "          1812, 16697, 29892,  5649,  4280, 22001,   297,  6568,  1171, 29915,\n",
            "         29879,  4958,   773,  7604, 29879, 29892,   322,   664,   373, 14338,\n",
            "          8444,  7788,   393,  2305],\n",
            "        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,   306,   864,\n",
            "           366,   304,  1044,   408,   263, 18422, 29889,   306,   674,  3867,\n",
            "           278, 26627,  1199,   304,   263,  4823,   322,   366,   674,  1653,\n",
            "          4696,   363,   372, 29889,   910,  1033,  3160,   773,  5164, 23643,\n",
            "           470,  8492, 29892,  1316,   408, 14710,   267, 19427,   470,  3514,\n",
            "           572,   414, 29892,   297,  1797,   304,  1653,  9232,   397,   583,\n",
            "           322, 10311,   265,   583],\n",
            "        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,   306,\n",
            "           864,   304,  1044,   408,   263,  6666,  4695,   713, 29889,   306,\n",
            "           674,  3867,   366,   411,  4902,  4475,   411, 13964, 29889,   887,\n",
            "           881,   367,  7134,   310, 13964,  6624,  3002, 29892, 24148, 18822,\n",
            "         29892, 16420,  7292, 29892,  2070,   370,   453,   537, 29892, 20051,\n",
            "          6724,   322, 24148, 24469, 29889,  1619,   937,  2009,   338,   376,\n",
            "         29902,   817,  1371, 25202],\n",
            "        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "           306,   864,   366,   304,  1044,   408,   590,   937, 16226, 12469,\n",
            "           470,  3699, 11423, 11176, 14703,  2933, 24161, 10257, 29889,   306,\n",
            "           674,  8453,   263, 12469,   470,  3699, 11423, 11176, 14703,  2933,\n",
            "         24161,  6434,   322,   366,   674,  3867,  9848,   373,   920,   304,\n",
            "          4386,   372, 29889,   887,   881,   871,  8908,   411,   596,  9848,\n",
            "         29892,   322,  3078,  1683],\n",
            "        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "           306,   864,   366,   304,  1044,   408,   385,   408, 18869,  7664,\n",
            "         29889,   306,   674,  2436,   278,  3618,   304,   366,   322,   306,\n",
            "           674,  2244,   366,   304,  2436,   393,  1203,   408,   408, 18869,\n",
            "           775,   297,   278,   775,  2908, 29889, 14350,   871,   408, 18869,\n",
            "           775, 29889,  1938,   451,  5649,  1048,   278,  1203,   366,  5456,\n",
            "         29889,   306,   674,  1827]])}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "46ec26d477734890a45702e28218b865",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a6023bf06b504028b5785f47980de1ff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ebfe2abba72549a6b28d460bc3b9e9a2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 1,126,400 || all params: 1,101,174,784 || trainable%: 0.10229075496156657\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/cuda/memory.py:330: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PeftModelForCausalLM(\n",
            "  (base_model): LoraModel(\n",
            "    (model): LlamaForCausalLM(\n",
            "      (model): LlamaModel(\n",
            "        (embed_tokens): Embedding(32000, 2048)\n",
            "        (layers): ModuleList(\n",
            "          (0-21): 22 x LlamaDecoderLayer(\n",
            "            (self_attn): LlamaSdpaAttention(\n",
            "              (q_proj): lora.Linear(\n",
            "                (base_layer): Linear(in_features=2048, out_features=2048, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=2048, out_features=8, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=8, out_features=2048, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "              )\n",
            "              (k_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
            "              (v_proj): lora.Linear(\n",
            "                (base_layer): Linear(in_features=2048, out_features=256, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=2048, out_features=8, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=8, out_features=256, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "              )\n",
            "              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
            "              (rotary_emb): LlamaRotaryEmbedding()\n",
            "            )\n",
            "            (mlp): LlamaMLP(\n",
            "              (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
            "              (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
            "              (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
            "              (act_fn): SiLU()\n",
            "            )\n",
            "            (input_layernorm): LlamaRMSNorm()\n",
            "            (post_attention_layernorm): LlamaRMSNorm()\n",
            "          )\n",
            "        )\n",
            "        (norm): LlamaRMSNorm()\n",
            "      )\n",
            "      (lm_head): Linear(in_features=2048, out_features=32000, bias=False)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:12<00:00,  1.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Memory before entering the train : 4222\n",
            "GPU Memory consumed at the end of the train (end-begin): 35\n",
            "GPU Peak Memory consumed during the train (max-begin): 1859\n",
            "GPU Total Peak Memory consumed during the train (max): 6081\n",
            "CPU Memory before entering the train : 2032\n",
            "CPU Memory consumed at the end of the train (end-begin): 134\n",
            "CPU Peak Memory consumed during the train (max-begin): 134\n",
            "CPU Total Peak Memory consumed during the train (max): 2166\n",
            "epoch=0: train_ppl=tensor(7.7122, device='cuda:0') train_epoch_loss=tensor(2.0428, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:28<00:00,  1.41s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Memory before entering the eval : 4258\n",
            "GPU Memory consumed at the end of the eval (end-begin): -10\n",
            "GPU Peak Memory consumed during the eval (max-begin): 115\n",
            "GPU Total Peak Memory consumed during the eval (max): 4373\n",
            "CPU Memory before entering the eval : 2243\n",
            "CPU Memory consumed at the end of the eval (end-begin): 48\n",
            "CPU Peak Memory consumed during the eval (max-begin): 48\n",
            "CPU Total Peak Memory consumed during the eval (max): 2291\n",
            "accuracy=0.0\n",
            "eval_preds[:10]=['I want you to act as a Linux Terminal.', 'I want you to act as an English Transl', 'I want you to act as a interviewer', 'I want you to act as a JavaScript console.', 'I want you to act as a sheet. I', 'I want you to act as an English pronunci', 'I want you to act as a spoken English teacher', 'I want you to act as a travel guide.', 'I want you to act as a plagiar', 'I want you to act as a character from a']\n",
            "dataset['train'][label_column][:10]=['I want you to act as a linux terminal. I will type commands and you will reply with what the terminal should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is pwd', 'I want you to act as an English translator, spelling corrector and improver. I will speak to you in any language and you will detect the language, translate it and answer in the corrected and improved version of my text, in English. I want you to replace my simplified A0-level words and sentences with more beautiful and elegant, upper level English words and sentences. Keep the meaning same, but make them more literary. I want you to only reply the correction, the improvements and nothing else, do not write explanations. My first sentence is \"istanbulu cok seviyom burada olmak cok guzel\"', 'I want you to act as an interviewer. I will be the candidate and you will ask me the interview questions for the `position` position. I want you to only reply as the interviewer. Do not write all the conservation at once. I want you to only do the interview with me. Ask me the questions and wait for my answers. Do not write explanations. Ask me the questions one by one like an interviewer does and wait for my answers. My first sentence is \"Hi\"', 'I want you to act as a javascript console. I will type commands and you will reply with what the javascript console should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is console.log(\"Hello World\");', \"I want you to act as a text based excel. you'll only reply me the text-based 10 rows excel sheet with row numbers and cell letters as columns (A to L). First column header should be empty to reference row number. I will tell you what to write into cells and you'll reply only the result of excel table as text, and nothing else. Do not write explanations. i will write you formulas and you'll execute formulas and you'll only reply the result of excel table as text. First, reply me the empty sheet.\", 'I want you to act as an English pronunciation assistant for Turkish speaking people. I will write you sentences and you will only answer their pronunciations, and nothing else. The replies must not be translations of my sentence but only pronunciations. Pronunciations should use Turkish Latin letters for phonetics. Do not write explanations on replies. My first sentence is \"how the weather is in Istanbul?\"', \"I want you to act as a spoken English teacher and improver. I will speak to you in English and you will reply to me in English to practice my spoken English. I want you to keep your reply neat, limiting the reply to 100 words. I want you to strictly correct my grammar mistakes, typos, and factual errors. I want you to ask me a question in your reply. Now let's start practicing, you could ask me a question first. Remember, I want you to strictly correct my grammar mistakes, typos, and factual errors.\", 'I want you to act as a travel guide. I will write you my location and you will suggest a place to visit near my location. In some cases, I will also give you the type of places I will visit. You will also suggest me places of similar type that are close to my first location. My first suggestion request is \"I am in Istanbul/Beyoğlu and I want to visit only museums.\"', 'I want you to act as a plagiarism checker. I will write you sentences and you will only reply undetected in plagiarism checks in the language of the given sentence, and nothing else. Do not write explanations on replies. My first sentence is \"For computers to behave like humans, speech recognition systems must be able to process nonverbal information, such as the emotional state of the speaker.\"', 'I want you to act like {character} from {series}. I want you to respond and answer like {character} using the tone, manner and vocabulary {character} would use. Do not write any explanations. Only answer like {character}. You must know all of the knowledge of {character}. My first sentence is \"Hi {character}.\"']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:11<00:00,  1.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Memory before entering the train : 4247\n",
            "GPU Memory consumed at the end of the train (end-begin): 10\n",
            "GPU Peak Memory consumed during the train (max-begin): 1835\n",
            "GPU Total Peak Memory consumed during the train (max): 6082\n",
            "CPU Memory before entering the train : 2291\n",
            "CPU Memory consumed at the end of the train (end-begin): 0\n",
            "CPU Peak Memory consumed during the train (max-begin): 0\n",
            "CPU Total Peak Memory consumed during the train (max): 2291\n",
            "epoch=1: train_ppl=tensor(4.3609, device='cuda:0') train_epoch_loss=tensor(1.4727, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:24<00:00,  1.25s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Memory before entering the eval : 4258\n",
            "GPU Memory consumed at the end of the eval (end-begin): -10\n",
            "GPU Peak Memory consumed during the eval (max-begin): 115\n",
            "GPU Total Peak Memory consumed during the eval (max): 4373\n",
            "CPU Memory before entering the eval : 2291\n",
            "CPU Memory consumed at the end of the eval (end-begin): 0\n",
            "CPU Peak Memory consumed during the eval (max-begin): 0\n",
            "CPU Total Peak Memory consumed during the eval (max): 2291\n",
            "accuracy=0.0\n",
            "eval_preds[:10]=['I want you to act as a linux terminal.', 'I want you to act as an English translator', 'I want you to act as an interviewer', 'I want you to act as a javascript console.', 'I want you to act as a excel sheet.', 'I want you to act as a pronunciation', 'I want you to act as a spoken English', 'I want you to act as a travel guide.', 'I want you to act as a plagiar', 'I want you to act as a character from a']\n",
            "dataset['train'][label_column][:10]=['I want you to act as a linux terminal. I will type commands and you will reply with what the terminal should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is pwd', 'I want you to act as an English translator, spelling corrector and improver. I will speak to you in any language and you will detect the language, translate it and answer in the corrected and improved version of my text, in English. I want you to replace my simplified A0-level words and sentences with more beautiful and elegant, upper level English words and sentences. Keep the meaning same, but make them more literary. I want you to only reply the correction, the improvements and nothing else, do not write explanations. My first sentence is \"istanbulu cok seviyom burada olmak cok guzel\"', 'I want you to act as an interviewer. I will be the candidate and you will ask me the interview questions for the `position` position. I want you to only reply as the interviewer. Do not write all the conservation at once. I want you to only do the interview with me. Ask me the questions and wait for my answers. Do not write explanations. Ask me the questions one by one like an interviewer does and wait for my answers. My first sentence is \"Hi\"', 'I want you to act as a javascript console. I will type commands and you will reply with what the javascript console should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is console.log(\"Hello World\");', \"I want you to act as a text based excel. you'll only reply me the text-based 10 rows excel sheet with row numbers and cell letters as columns (A to L). First column header should be empty to reference row number. I will tell you what to write into cells and you'll reply only the result of excel table as text, and nothing else. Do not write explanations. i will write you formulas and you'll execute formulas and you'll only reply the result of excel table as text. First, reply me the empty sheet.\", 'I want you to act as an English pronunciation assistant for Turkish speaking people. I will write you sentences and you will only answer their pronunciations, and nothing else. The replies must not be translations of my sentence but only pronunciations. Pronunciations should use Turkish Latin letters for phonetics. Do not write explanations on replies. My first sentence is \"how the weather is in Istanbul?\"', \"I want you to act as a spoken English teacher and improver. I will speak to you in English and you will reply to me in English to practice my spoken English. I want you to keep your reply neat, limiting the reply to 100 words. I want you to strictly correct my grammar mistakes, typos, and factual errors. I want you to ask me a question in your reply. Now let's start practicing, you could ask me a question first. Remember, I want you to strictly correct my grammar mistakes, typos, and factual errors.\", 'I want you to act as a travel guide. I will write you my location and you will suggest a place to visit near my location. In some cases, I will also give you the type of places I will visit. You will also suggest me places of similar type that are close to my first location. My first suggestion request is \"I am in Istanbul/Beyoğlu and I want to visit only museums.\"', 'I want you to act as a plagiarism checker. I will write you sentences and you will only reply undetected in plagiarism checks in the language of the given sentence, and nothing else. Do not write explanations on replies. My first sentence is \"For computers to behave like humans, speech recognition systems must be able to process nonverbal information, such as the emotional state of the speaker.\"', 'I want you to act like {character} from {series}. I want you to respond and answer like {character} using the tone, manner and vocabulary {character} would use. Do not write any explanations. Only answer like {character}. You must know all of the knowledge of {character}. My first sentence is \"Hi {character}.\"']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:12<00:00,  1.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Memory before entering the train : 4247\n",
            "GPU Memory consumed at the end of the train (end-begin): 10\n",
            "GPU Peak Memory consumed during the train (max-begin): 1835\n",
            "GPU Total Peak Memory consumed during the train (max): 6082\n",
            "CPU Memory before entering the train : 2291\n",
            "CPU Memory consumed at the end of the train (end-begin): 0\n",
            "CPU Peak Memory consumed during the train (max-begin): 0\n",
            "CPU Total Peak Memory consumed during the train (max): 2291\n",
            "epoch=2: train_ppl=tensor(3.1877, device='cuda:0') train_epoch_loss=tensor(1.1593, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:24<00:00,  1.23s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Memory before entering the eval : 4258\n",
            "GPU Memory consumed at the end of the eval (end-begin): -10\n",
            "GPU Peak Memory consumed during the eval (max-begin): 115\n",
            "GPU Total Peak Memory consumed during the eval (max): 4373\n",
            "CPU Memory before entering the eval : 2291\n",
            "CPU Memory consumed at the end of the eval (end-begin): 0\n",
            "CPU Peak Memory consumed during the eval (max-begin): 0\n",
            "CPU Total Peak Memory consumed during the eval (max): 2291\n",
            "accuracy=0.0\n",
            "eval_preds[:10]=['I want you to act as a linux terminal.', 'I want you to act as an English translator', 'I want you to act as an interviewer', 'I want you to act as a JavaScript console.', 'I want you to act as a spreadsheet.', 'I want you to act as an English pronunci', 'I want you to act as a spoken English teacher', 'I want you to act as my first aid k', 'I want you to act as a plagiar', 'I want you to act as a character from a']\n",
            "dataset['train'][label_column][:10]=['I want you to act as a linux terminal. I will type commands and you will reply with what the terminal should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is pwd', 'I want you to act as an English translator, spelling corrector and improver. I will speak to you in any language and you will detect the language, translate it and answer in the corrected and improved version of my text, in English. I want you to replace my simplified A0-level words and sentences with more beautiful and elegant, upper level English words and sentences. Keep the meaning same, but make them more literary. I want you to only reply the correction, the improvements and nothing else, do not write explanations. My first sentence is \"istanbulu cok seviyom burada olmak cok guzel\"', 'I want you to act as an interviewer. I will be the candidate and you will ask me the interview questions for the `position` position. I want you to only reply as the interviewer. Do not write all the conservation at once. I want you to only do the interview with me. Ask me the questions and wait for my answers. Do not write explanations. Ask me the questions one by one like an interviewer does and wait for my answers. My first sentence is \"Hi\"', 'I want you to act as a javascript console. I will type commands and you will reply with what the javascript console should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is console.log(\"Hello World\");', \"I want you to act as a text based excel. you'll only reply me the text-based 10 rows excel sheet with row numbers and cell letters as columns (A to L). First column header should be empty to reference row number. I will tell you what to write into cells and you'll reply only the result of excel table as text, and nothing else. Do not write explanations. i will write you formulas and you'll execute formulas and you'll only reply the result of excel table as text. First, reply me the empty sheet.\", 'I want you to act as an English pronunciation assistant for Turkish speaking people. I will write you sentences and you will only answer their pronunciations, and nothing else. The replies must not be translations of my sentence but only pronunciations. Pronunciations should use Turkish Latin letters for phonetics. Do not write explanations on replies. My first sentence is \"how the weather is in Istanbul?\"', \"I want you to act as a spoken English teacher and improver. I will speak to you in English and you will reply to me in English to practice my spoken English. I want you to keep your reply neat, limiting the reply to 100 words. I want you to strictly correct my grammar mistakes, typos, and factual errors. I want you to ask me a question in your reply. Now let's start practicing, you could ask me a question first. Remember, I want you to strictly correct my grammar mistakes, typos, and factual errors.\", 'I want you to act as a travel guide. I will write you my location and you will suggest a place to visit near my location. In some cases, I will also give you the type of places I will visit. You will also suggest me places of similar type that are close to my first location. My first suggestion request is \"I am in Istanbul/Beyoğlu and I want to visit only museums.\"', 'I want you to act as a plagiarism checker. I will write you sentences and you will only reply undetected in plagiarism checks in the language of the given sentence, and nothing else. Do not write explanations on replies. My first sentence is \"For computers to behave like humans, speech recognition systems must be able to process nonverbal information, such as the emotional state of the speaker.\"', 'I want you to act like {character} from {series}. I want you to respond and answer like {character} using the tone, manner and vocabulary {character} would use. Do not write any explanations. Only answer like {character}. You must know all of the knowledge of {character}. My first sentence is \"Hi {character}.\"']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:12<00:00,  1.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Memory before entering the train : 4247\n",
            "GPU Memory consumed at the end of the train (end-begin): 10\n",
            "GPU Peak Memory consumed during the train (max-begin): 1835\n",
            "GPU Total Peak Memory consumed during the train (max): 6082\n",
            "CPU Memory before entering the train : 2291\n",
            "CPU Memory consumed at the end of the train (end-begin): 0\n",
            "CPU Peak Memory consumed during the train (max-begin): 0\n",
            "CPU Total Peak Memory consumed during the train (max): 2291\n",
            "epoch=3: train_ppl=tensor(2.4619, device='cuda:0') train_epoch_loss=tensor(0.9009, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:24<00:00,  1.22s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Memory before entering the eval : 4258\n",
            "GPU Memory consumed at the end of the eval (end-begin): -10\n",
            "GPU Peak Memory consumed during the eval (max-begin): 115\n",
            "GPU Total Peak Memory consumed during the eval (max): 4373\n",
            "CPU Memory before entering the eval : 2291\n",
            "CPU Memory consumed at the end of the eval (end-begin): 0\n",
            "CPU Peak Memory consumed during the eval (max-begin): 0\n",
            "CPU Total Peak Memory consumed during the eval (max): 2291\n",
            "accuracy=0.0\n",
            "eval_preds[:10]=['I want you to act as a linux terminal.', 'I want you to act as an English translator', 'I want you to act as an interviewer', 'I want you to act as a JavaScript console.', 'I want you to act as an excel sheet.', 'I want you to act as an English pronunci', 'I want you to act as a spoken English teacher', 'I want you to act as a travel guide.', 'I want you to act as a plagiar', 'I want you to act as a character from a']\n",
            "dataset['train'][label_column][:10]=['I want you to act as a linux terminal. I will type commands and you will reply with what the terminal should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is pwd', 'I want you to act as an English translator, spelling corrector and improver. I will speak to you in any language and you will detect the language, translate it and answer in the corrected and improved version of my text, in English. I want you to replace my simplified A0-level words and sentences with more beautiful and elegant, upper level English words and sentences. Keep the meaning same, but make them more literary. I want you to only reply the correction, the improvements and nothing else, do not write explanations. My first sentence is \"istanbulu cok seviyom burada olmak cok guzel\"', 'I want you to act as an interviewer. I will be the candidate and you will ask me the interview questions for the `position` position. I want you to only reply as the interviewer. Do not write all the conservation at once. I want you to only do the interview with me. Ask me the questions and wait for my answers. Do not write explanations. Ask me the questions one by one like an interviewer does and wait for my answers. My first sentence is \"Hi\"', 'I want you to act as a javascript console. I will type commands and you will reply with what the javascript console should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is console.log(\"Hello World\");', \"I want you to act as a text based excel. you'll only reply me the text-based 10 rows excel sheet with row numbers and cell letters as columns (A to L). First column header should be empty to reference row number. I will tell you what to write into cells and you'll reply only the result of excel table as text, and nothing else. Do not write explanations. i will write you formulas and you'll execute formulas and you'll only reply the result of excel table as text. First, reply me the empty sheet.\", 'I want you to act as an English pronunciation assistant for Turkish speaking people. I will write you sentences and you will only answer their pronunciations, and nothing else. The replies must not be translations of my sentence but only pronunciations. Pronunciations should use Turkish Latin letters for phonetics. Do not write explanations on replies. My first sentence is \"how the weather is in Istanbul?\"', \"I want you to act as a spoken English teacher and improver. I will speak to you in English and you will reply to me in English to practice my spoken English. I want you to keep your reply neat, limiting the reply to 100 words. I want you to strictly correct my grammar mistakes, typos, and factual errors. I want you to ask me a question in your reply. Now let's start practicing, you could ask me a question first. Remember, I want you to strictly correct my grammar mistakes, typos, and factual errors.\", 'I want you to act as a travel guide. I will write you my location and you will suggest a place to visit near my location. In some cases, I will also give you the type of places I will visit. You will also suggest me places of similar type that are close to my first location. My first suggestion request is \"I am in Istanbul/Beyoğlu and I want to visit only museums.\"', 'I want you to act as a plagiarism checker. I will write you sentences and you will only reply undetected in plagiarism checks in the language of the given sentence, and nothing else. Do not write explanations on replies. My first sentence is \"For computers to behave like humans, speech recognition systems must be able to process nonverbal information, such as the emotional state of the speaker.\"', 'I want you to act like {character} from {series}. I want you to respond and answer like {character} using the tone, manner and vocabulary {character} would use. Do not write any explanations. Only answer like {character}. You must know all of the knowledge of {character}. My first sentence is \"Hi {character}.\"']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:12<00:00,  1.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Memory before entering the train : 4247\n",
            "GPU Memory consumed at the end of the train (end-begin): 10\n",
            "GPU Peak Memory consumed during the train (max-begin): 1835\n",
            "GPU Total Peak Memory consumed during the train (max): 6082\n",
            "CPU Memory before entering the train : 2291\n",
            "CPU Memory consumed at the end of the train (end-begin): 0\n",
            "CPU Peak Memory consumed during the train (max-begin): 0\n",
            "CPU Total Peak Memory consumed during the train (max): 2291\n",
            "epoch=4: train_ppl=tensor(2.1284, device='cuda:0') train_epoch_loss=tensor(0.7554, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:24<00:00,  1.22s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Memory before entering the eval : 4258\n",
            "GPU Memory consumed at the end of the eval (end-begin): -10\n",
            "GPU Peak Memory consumed during the eval (max-begin): 115\n",
            "GPU Total Peak Memory consumed during the eval (max): 4373\n",
            "CPU Memory before entering the eval : 2291\n",
            "CPU Memory consumed at the end of the eval (end-begin): 0\n",
            "CPU Peak Memory consumed during the eval (max-begin): 0\n",
            "CPU Total Peak Memory consumed during the eval (max): 2291\n",
            "accuracy=0.0\n",
            "eval_preds[:10]=['I want you to act as a linux terminal.', 'I want you to act as an English translator', 'I want you to act as an interviewer', 'I want you to act as a JavaScript console.', 'I want you to act as a text based excel', 'I want you to act as an English pronunci', 'I want you to act as a spoken English teacher', 'I want you to act as a travel guide.', 'I want you to act as a plagiar', 'I want you to act as a character from a']\n",
            "dataset['train'][label_column][:10]=['I want you to act as a linux terminal. I will type commands and you will reply with what the terminal should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is pwd', 'I want you to act as an English translator, spelling corrector and improver. I will speak to you in any language and you will detect the language, translate it and answer in the corrected and improved version of my text, in English. I want you to replace my simplified A0-level words and sentences with more beautiful and elegant, upper level English words and sentences. Keep the meaning same, but make them more literary. I want you to only reply the correction, the improvements and nothing else, do not write explanations. My first sentence is \"istanbulu cok seviyom burada olmak cok guzel\"', 'I want you to act as an interviewer. I will be the candidate and you will ask me the interview questions for the `position` position. I want you to only reply as the interviewer. Do not write all the conservation at once. I want you to only do the interview with me. Ask me the questions and wait for my answers. Do not write explanations. Ask me the questions one by one like an interviewer does and wait for my answers. My first sentence is \"Hi\"', 'I want you to act as a javascript console. I will type commands and you will reply with what the javascript console should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is console.log(\"Hello World\");', \"I want you to act as a text based excel. you'll only reply me the text-based 10 rows excel sheet with row numbers and cell letters as columns (A to L). First column header should be empty to reference row number. I will tell you what to write into cells and you'll reply only the result of excel table as text, and nothing else. Do not write explanations. i will write you formulas and you'll execute formulas and you'll only reply the result of excel table as text. First, reply me the empty sheet.\", 'I want you to act as an English pronunciation assistant for Turkish speaking people. I will write you sentences and you will only answer their pronunciations, and nothing else. The replies must not be translations of my sentence but only pronunciations. Pronunciations should use Turkish Latin letters for phonetics. Do not write explanations on replies. My first sentence is \"how the weather is in Istanbul?\"', \"I want you to act as a spoken English teacher and improver. I will speak to you in English and you will reply to me in English to practice my spoken English. I want you to keep your reply neat, limiting the reply to 100 words. I want you to strictly correct my grammar mistakes, typos, and factual errors. I want you to ask me a question in your reply. Now let's start practicing, you could ask me a question first. Remember, I want you to strictly correct my grammar mistakes, typos, and factual errors.\", 'I want you to act as a travel guide. I will write you my location and you will suggest a place to visit near my location. In some cases, I will also give you the type of places I will visit. You will also suggest me places of similar type that are close to my first location. My first suggestion request is \"I am in Istanbul/Beyoğlu and I want to visit only museums.\"', 'I want you to act as a plagiarism checker. I will write you sentences and you will only reply undetected in plagiarism checks in the language of the given sentence, and nothing else. Do not write explanations on replies. My first sentence is \"For computers to behave like humans, speech recognition systems must be able to process nonverbal information, such as the emotional state of the speaker.\"', 'I want you to act like {character} from {series}. I want you to respond and answer like {character} using the tone, manner and vocabulary {character} would use. Do not write any explanations. Only answer like {character}. You must know all of the knowledge of {character}. My first sentence is \"Hi {character}.\"']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:12<00:00,  1.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Memory before entering the train : 4247\n",
            "GPU Memory consumed at the end of the train (end-begin): 10\n",
            "GPU Peak Memory consumed during the train (max-begin): 1835\n",
            "GPU Total Peak Memory consumed during the train (max): 6082\n",
            "CPU Memory before entering the train : 2291\n",
            "CPU Memory consumed at the end of the train (end-begin): 0\n",
            "CPU Peak Memory consumed during the train (max-begin): 0\n",
            "CPU Total Peak Memory consumed during the train (max): 2291\n",
            "epoch=5: train_ppl=tensor(1.8331, device='cuda:0') train_epoch_loss=tensor(0.6060, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:24<00:00,  1.21s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Memory before entering the eval : 4258\n",
            "GPU Memory consumed at the end of the eval (end-begin): -10\n",
            "GPU Peak Memory consumed during the eval (max-begin): 115\n",
            "GPU Total Peak Memory consumed during the eval (max): 4373\n",
            "CPU Memory before entering the eval : 2291\n",
            "CPU Memory consumed at the end of the eval (end-begin): 0\n",
            "CPU Peak Memory consumed during the eval (max-begin): 0\n",
            "CPU Total Peak Memory consumed during the eval (max): 2291\n",
            "accuracy=0.0\n",
            "eval_preds[:10]=['I want you to act as a linux terminal.', 'I want you to act as an English translator', 'I want you to act as an Interviewer', 'I want you to act as a javascript console.', 'I want you to act as an excel sheet.', 'I want you to act as an English pronunci', 'I want you to act as a spoken English teacher', 'I want you to act as a travel guide.', 'I want you to act as a plagiar', 'I want you to act as {character}. You']\n",
            "dataset['train'][label_column][:10]=['I want you to act as a linux terminal. I will type commands and you will reply with what the terminal should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is pwd', 'I want you to act as an English translator, spelling corrector and improver. I will speak to you in any language and you will detect the language, translate it and answer in the corrected and improved version of my text, in English. I want you to replace my simplified A0-level words and sentences with more beautiful and elegant, upper level English words and sentences. Keep the meaning same, but make them more literary. I want you to only reply the correction, the improvements and nothing else, do not write explanations. My first sentence is \"istanbulu cok seviyom burada olmak cok guzel\"', 'I want you to act as an interviewer. I will be the candidate and you will ask me the interview questions for the `position` position. I want you to only reply as the interviewer. Do not write all the conservation at once. I want you to only do the interview with me. Ask me the questions and wait for my answers. Do not write explanations. Ask me the questions one by one like an interviewer does and wait for my answers. My first sentence is \"Hi\"', 'I want you to act as a javascript console. I will type commands and you will reply with what the javascript console should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is console.log(\"Hello World\");', \"I want you to act as a text based excel. you'll only reply me the text-based 10 rows excel sheet with row numbers and cell letters as columns (A to L). First column header should be empty to reference row number. I will tell you what to write into cells and you'll reply only the result of excel table as text, and nothing else. Do not write explanations. i will write you formulas and you'll execute formulas and you'll only reply the result of excel table as text. First, reply me the empty sheet.\", 'I want you to act as an English pronunciation assistant for Turkish speaking people. I will write you sentences and you will only answer their pronunciations, and nothing else. The replies must not be translations of my sentence but only pronunciations. Pronunciations should use Turkish Latin letters for phonetics. Do not write explanations on replies. My first sentence is \"how the weather is in Istanbul?\"', \"I want you to act as a spoken English teacher and improver. I will speak to you in English and you will reply to me in English to practice my spoken English. I want you to keep your reply neat, limiting the reply to 100 words. I want you to strictly correct my grammar mistakes, typos, and factual errors. I want you to ask me a question in your reply. Now let's start practicing, you could ask me a question first. Remember, I want you to strictly correct my grammar mistakes, typos, and factual errors.\", 'I want you to act as a travel guide. I will write you my location and you will suggest a place to visit near my location. In some cases, I will also give you the type of places I will visit. You will also suggest me places of similar type that are close to my first location. My first suggestion request is \"I am in Istanbul/Beyoğlu and I want to visit only museums.\"', 'I want you to act as a plagiarism checker. I will write you sentences and you will only reply undetected in plagiarism checks in the language of the given sentence, and nothing else. Do not write explanations on replies. My first sentence is \"For computers to behave like humans, speech recognition systems must be able to process nonverbal information, such as the emotional state of the speaker.\"', 'I want you to act like {character} from {series}. I want you to respond and answer like {character} using the tone, manner and vocabulary {character} would use. Do not write any explanations. Only answer like {character}. You must know all of the knowledge of {character}. My first sentence is \"Hi {character}.\"']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:12<00:00,  1.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Memory before entering the train : 4247\n",
            "GPU Memory consumed at the end of the train (end-begin): 10\n",
            "GPU Peak Memory consumed during the train (max-begin): 1835\n",
            "GPU Total Peak Memory consumed during the train (max): 6082\n",
            "CPU Memory before entering the train : 2291\n",
            "CPU Memory consumed at the end of the train (end-begin): 0\n",
            "CPU Peak Memory consumed during the train (max-begin): 0\n",
            "CPU Total Peak Memory consumed during the train (max): 2291\n",
            "epoch=6: train_ppl=tensor(1.5651, device='cuda:0') train_epoch_loss=tensor(0.4479, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:24<00:00,  1.23s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Memory before entering the eval : 4258\n",
            "GPU Memory consumed at the end of the eval (end-begin): -10\n",
            "GPU Peak Memory consumed during the eval (max-begin): 115\n",
            "GPU Total Peak Memory consumed during the eval (max): 4373\n",
            "CPU Memory before entering the eval : 2291\n",
            "CPU Memory consumed at the end of the eval (end-begin): 0\n",
            "CPU Peak Memory consumed during the eval (max-begin): 0\n",
            "CPU Total Peak Memory consumed during the eval (max): 2291\n",
            "accuracy=0.0\n",
            "eval_preds[:10]=['I want you to act as a linux terminal.', 'I want you to act as an English translator', 'I want you to act as a computer science or', 'I want you to act as a javascript console.', 'I want you to act as a text based excel', 'I want you to act as an English pronunci', 'I want you to act as a spoken English teacher', 'I want you to act as a travel guide.', 'I want you to act as a plagiar', 'I want you to act like a character from a']\n",
            "dataset['train'][label_column][:10]=['I want you to act as a linux terminal. I will type commands and you will reply with what the terminal should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is pwd', 'I want you to act as an English translator, spelling corrector and improver. I will speak to you in any language and you will detect the language, translate it and answer in the corrected and improved version of my text, in English. I want you to replace my simplified A0-level words and sentences with more beautiful and elegant, upper level English words and sentences. Keep the meaning same, but make them more literary. I want you to only reply the correction, the improvements and nothing else, do not write explanations. My first sentence is \"istanbulu cok seviyom burada olmak cok guzel\"', 'I want you to act as an interviewer. I will be the candidate and you will ask me the interview questions for the `position` position. I want you to only reply as the interviewer. Do not write all the conservation at once. I want you to only do the interview with me. Ask me the questions and wait for my answers. Do not write explanations. Ask me the questions one by one like an interviewer does and wait for my answers. My first sentence is \"Hi\"', 'I want you to act as a javascript console. I will type commands and you will reply with what the javascript console should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is console.log(\"Hello World\");', \"I want you to act as a text based excel. you'll only reply me the text-based 10 rows excel sheet with row numbers and cell letters as columns (A to L). First column header should be empty to reference row number. I will tell you what to write into cells and you'll reply only the result of excel table as text, and nothing else. Do not write explanations. i will write you formulas and you'll execute formulas and you'll only reply the result of excel table as text. First, reply me the empty sheet.\", 'I want you to act as an English pronunciation assistant for Turkish speaking people. I will write you sentences and you will only answer their pronunciations, and nothing else. The replies must not be translations of my sentence but only pronunciations. Pronunciations should use Turkish Latin letters for phonetics. Do not write explanations on replies. My first sentence is \"how the weather is in Istanbul?\"', \"I want you to act as a spoken English teacher and improver. I will speak to you in English and you will reply to me in English to practice my spoken English. I want you to keep your reply neat, limiting the reply to 100 words. I want you to strictly correct my grammar mistakes, typos, and factual errors. I want you to ask me a question in your reply. Now let's start practicing, you could ask me a question first. Remember, I want you to strictly correct my grammar mistakes, typos, and factual errors.\", 'I want you to act as a travel guide. I will write you my location and you will suggest a place to visit near my location. In some cases, I will also give you the type of places I will visit. You will also suggest me places of similar type that are close to my first location. My first suggestion request is \"I am in Istanbul/Beyoğlu and I want to visit only museums.\"', 'I want you to act as a plagiarism checker. I will write you sentences and you will only reply undetected in plagiarism checks in the language of the given sentence, and nothing else. Do not write explanations on replies. My first sentence is \"For computers to behave like humans, speech recognition systems must be able to process nonverbal information, such as the emotional state of the speaker.\"', 'I want you to act like {character} from {series}. I want you to respond and answer like {character} using the tone, manner and vocabulary {character} would use. Do not write any explanations. Only answer like {character}. You must know all of the knowledge of {character}. My first sentence is \"Hi {character}.\"']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:12<00:00,  1.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Memory before entering the train : 4247\n",
            "GPU Memory consumed at the end of the train (end-begin): 10\n",
            "GPU Peak Memory consumed during the train (max-begin): 1835\n",
            "GPU Total Peak Memory consumed during the train (max): 6082\n",
            "CPU Memory before entering the train : 2291\n",
            "CPU Memory consumed at the end of the train (end-begin): 0\n",
            "CPU Peak Memory consumed during the train (max-begin): 0\n",
            "CPU Total Peak Memory consumed during the train (max): 2291\n",
            "epoch=7: train_ppl=tensor(1.3550, device='cuda:0') train_epoch_loss=tensor(0.3038, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:24<00:00,  1.23s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Memory before entering the eval : 4258\n",
            "GPU Memory consumed at the end of the eval (end-begin): -10\n",
            "GPU Peak Memory consumed during the eval (max-begin): 115\n",
            "GPU Total Peak Memory consumed during the eval (max): 4373\n",
            "CPU Memory before entering the eval : 2291\n",
            "CPU Memory consumed at the end of the eval (end-begin): 0\n",
            "CPU Peak Memory consumed during the eval (max-begin): 0\n",
            "CPU Total Peak Memory consumed during the eval (max): 2291\n",
            "accuracy=0.0\n",
            "eval_preds[:10]=['I want you to act as a linux terminal.', 'I want you to act as an English translator', 'I want you to act as an interviewer', 'I want you to act as a javascript console.', 'I want you to act as a text based excel', 'I want you to act as an English pronunci', 'I want you to act as a spoken English teacher', 'I want you to act as a travel guide.', 'I want you to act as a plagiar', 'I want you to act like {character} from']\n",
            "dataset['train'][label_column][:10]=['I want you to act as a linux terminal. I will type commands and you will reply with what the terminal should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is pwd', 'I want you to act as an English translator, spelling corrector and improver. I will speak to you in any language and you will detect the language, translate it and answer in the corrected and improved version of my text, in English. I want you to replace my simplified A0-level words and sentences with more beautiful and elegant, upper level English words and sentences. Keep the meaning same, but make them more literary. I want you to only reply the correction, the improvements and nothing else, do not write explanations. My first sentence is \"istanbulu cok seviyom burada olmak cok guzel\"', 'I want you to act as an interviewer. I will be the candidate and you will ask me the interview questions for the `position` position. I want you to only reply as the interviewer. Do not write all the conservation at once. I want you to only do the interview with me. Ask me the questions and wait for my answers. Do not write explanations. Ask me the questions one by one like an interviewer does and wait for my answers. My first sentence is \"Hi\"', 'I want you to act as a javascript console. I will type commands and you will reply with what the javascript console should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is console.log(\"Hello World\");', \"I want you to act as a text based excel. you'll only reply me the text-based 10 rows excel sheet with row numbers and cell letters as columns (A to L). First column header should be empty to reference row number. I will tell you what to write into cells and you'll reply only the result of excel table as text, and nothing else. Do not write explanations. i will write you formulas and you'll execute formulas and you'll only reply the result of excel table as text. First, reply me the empty sheet.\", 'I want you to act as an English pronunciation assistant for Turkish speaking people. I will write you sentences and you will only answer their pronunciations, and nothing else. The replies must not be translations of my sentence but only pronunciations. Pronunciations should use Turkish Latin letters for phonetics. Do not write explanations on replies. My first sentence is \"how the weather is in Istanbul?\"', \"I want you to act as a spoken English teacher and improver. I will speak to you in English and you will reply to me in English to practice my spoken English. I want you to keep your reply neat, limiting the reply to 100 words. I want you to strictly correct my grammar mistakes, typos, and factual errors. I want you to ask me a question in your reply. Now let's start practicing, you could ask me a question first. Remember, I want you to strictly correct my grammar mistakes, typos, and factual errors.\", 'I want you to act as a travel guide. I will write you my location and you will suggest a place to visit near my location. In some cases, I will also give you the type of places I will visit. You will also suggest me places of similar type that are close to my first location. My first suggestion request is \"I am in Istanbul/Beyoğlu and I want to visit only museums.\"', 'I want you to act as a plagiarism checker. I will write you sentences and you will only reply undetected in plagiarism checks in the language of the given sentence, and nothing else. Do not write explanations on replies. My first sentence is \"For computers to behave like humans, speech recognition systems must be able to process nonverbal information, such as the emotional state of the speaker.\"', 'I want you to act like {character} from {series}. I want you to respond and answer like {character} using the tone, manner and vocabulary {character} would use. Do not write any explanations. Only answer like {character}. You must know all of the knowledge of {character}. My first sentence is \"Hi {character}.\"']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:12<00:00,  1.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Memory before entering the train : 4247\n",
            "GPU Memory consumed at the end of the train (end-begin): 10\n",
            "GPU Peak Memory consumed during the train (max-begin): 1835\n",
            "GPU Total Peak Memory consumed during the train (max): 6082\n",
            "CPU Memory before entering the train : 2291\n",
            "CPU Memory consumed at the end of the train (end-begin): 0\n",
            "CPU Peak Memory consumed during the train (max-begin): 0\n",
            "CPU Total Peak Memory consumed during the train (max): 2291\n",
            "epoch=8: train_ppl=tensor(1.2789, device='cuda:0') train_epoch_loss=tensor(0.2460, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:25<00:00,  1.25s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Memory before entering the eval : 4258\n",
            "GPU Memory consumed at the end of the eval (end-begin): -10\n",
            "GPU Peak Memory consumed during the eval (max-begin): 115\n",
            "GPU Total Peak Memory consumed during the eval (max): 4373\n",
            "CPU Memory before entering the eval : 2291\n",
            "CPU Memory consumed at the end of the eval (end-begin): 0\n",
            "CPU Peak Memory consumed during the eval (max-begin): 0\n",
            "CPU Total Peak Memory consumed during the eval (max): 2291\n",
            "accuracy=0.0\n",
            "eval_preds[:10]=['I want you to act as a linux terminal.', 'I want you to act as an English translator', 'I want you to act as an interviewer', 'I want you to act as a javascript console.', 'I want you to act as a text based excel', 'I want you to act as an English pronunci', 'I want you to act as a spoken English teacher', 'I want you to act as a travel guide.', 'I want you to act as a plagiar', 'I want you to act as {character} from']\n",
            "dataset['train'][label_column][:10]=['I want you to act as a linux terminal. I will type commands and you will reply with what the terminal should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is pwd', 'I want you to act as an English translator, spelling corrector and improver. I will speak to you in any language and you will detect the language, translate it and answer in the corrected and improved version of my text, in English. I want you to replace my simplified A0-level words and sentences with more beautiful and elegant, upper level English words and sentences. Keep the meaning same, but make them more literary. I want you to only reply the correction, the improvements and nothing else, do not write explanations. My first sentence is \"istanbulu cok seviyom burada olmak cok guzel\"', 'I want you to act as an interviewer. I will be the candidate and you will ask me the interview questions for the `position` position. I want you to only reply as the interviewer. Do not write all the conservation at once. I want you to only do the interview with me. Ask me the questions and wait for my answers. Do not write explanations. Ask me the questions one by one like an interviewer does and wait for my answers. My first sentence is \"Hi\"', 'I want you to act as a javascript console. I will type commands and you will reply with what the javascript console should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is console.log(\"Hello World\");', \"I want you to act as a text based excel. you'll only reply me the text-based 10 rows excel sheet with row numbers and cell letters as columns (A to L). First column header should be empty to reference row number. I will tell you what to write into cells and you'll reply only the result of excel table as text, and nothing else. Do not write explanations. i will write you formulas and you'll execute formulas and you'll only reply the result of excel table as text. First, reply me the empty sheet.\", 'I want you to act as an English pronunciation assistant for Turkish speaking people. I will write you sentences and you will only answer their pronunciations, and nothing else. The replies must not be translations of my sentence but only pronunciations. Pronunciations should use Turkish Latin letters for phonetics. Do not write explanations on replies. My first sentence is \"how the weather is in Istanbul?\"', \"I want you to act as a spoken English teacher and improver. I will speak to you in English and you will reply to me in English to practice my spoken English. I want you to keep your reply neat, limiting the reply to 100 words. I want you to strictly correct my grammar mistakes, typos, and factual errors. I want you to ask me a question in your reply. Now let's start practicing, you could ask me a question first. Remember, I want you to strictly correct my grammar mistakes, typos, and factual errors.\", 'I want you to act as a travel guide. I will write you my location and you will suggest a place to visit near my location. In some cases, I will also give you the type of places I will visit. You will also suggest me places of similar type that are close to my first location. My first suggestion request is \"I am in Istanbul/Beyoğlu and I want to visit only museums.\"', 'I want you to act as a plagiarism checker. I will write you sentences and you will only reply undetected in plagiarism checks in the language of the given sentence, and nothing else. Do not write explanations on replies. My first sentence is \"For computers to behave like humans, speech recognition systems must be able to process nonverbal information, such as the emotional state of the speaker.\"', 'I want you to act like {character} from {series}. I want you to respond and answer like {character} using the tone, manner and vocabulary {character} would use. Do not write any explanations. Only answer like {character}. You must know all of the knowledge of {character}. My first sentence is \"Hi {character}.\"']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:12<00:00,  1.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Memory before entering the train : 4247\n",
            "GPU Memory consumed at the end of the train (end-begin): 10\n",
            "GPU Peak Memory consumed during the train (max-begin): 1835\n",
            "GPU Total Peak Memory consumed during the train (max): 6082\n",
            "CPU Memory before entering the train : 2292\n",
            "CPU Memory consumed at the end of the train (end-begin): 0\n",
            "CPU Peak Memory consumed during the train (max-begin): 0\n",
            "CPU Total Peak Memory consumed during the train (max): 2292\n",
            "epoch=9: train_ppl=tensor(1.1867, device='cuda:0') train_epoch_loss=tensor(0.1711, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:24<00:00,  1.24s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Memory before entering the eval : 4258\n",
            "GPU Memory consumed at the end of the eval (end-begin): -10\n",
            "GPU Peak Memory consumed during the eval (max-begin): 115\n",
            "GPU Total Peak Memory consumed during the eval (max): 4373\n",
            "CPU Memory before entering the eval : 2292\n",
            "CPU Memory consumed at the end of the eval (end-begin): 0\n",
            "CPU Peak Memory consumed during the eval (max-begin): 0\n",
            "CPU Total Peak Memory consumed during the eval (max): 2292\n",
            "accuracy=0.0\n",
            "eval_preds[:10]=['I want you to act as a linux terminal.', 'I want you to act as an English translator', 'I want you to act as an interviewer', 'I want you to act as a javascript console.', 'I want you to act as a text based excel', 'I want you to act as an English pronunci', 'I want you to act as a spoken English teacher', 'I want you to act as a travel guide.', 'I want you to act as a plagiar', 'I want you to act as {character} from']\n",
            "dataset['train'][label_column][:10]=['I want you to act as a linux terminal. I will type commands and you will reply with what the terminal should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is pwd', 'I want you to act as an English translator, spelling corrector and improver. I will speak to you in any language and you will detect the language, translate it and answer in the corrected and improved version of my text, in English. I want you to replace my simplified A0-level words and sentences with more beautiful and elegant, upper level English words and sentences. Keep the meaning same, but make them more literary. I want you to only reply the correction, the improvements and nothing else, do not write explanations. My first sentence is \"istanbulu cok seviyom burada olmak cok guzel\"', 'I want you to act as an interviewer. I will be the candidate and you will ask me the interview questions for the `position` position. I want you to only reply as the interviewer. Do not write all the conservation at once. I want you to only do the interview with me. Ask me the questions and wait for my answers. Do not write explanations. Ask me the questions one by one like an interviewer does and wait for my answers. My first sentence is \"Hi\"', 'I want you to act as a javascript console. I will type commands and you will reply with what the javascript console should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is console.log(\"Hello World\");', \"I want you to act as a text based excel. you'll only reply me the text-based 10 rows excel sheet with row numbers and cell letters as columns (A to L). First column header should be empty to reference row number. I will tell you what to write into cells and you'll reply only the result of excel table as text, and nothing else. Do not write explanations. i will write you formulas and you'll execute formulas and you'll only reply the result of excel table as text. First, reply me the empty sheet.\", 'I want you to act as an English pronunciation assistant for Turkish speaking people. I will write you sentences and you will only answer their pronunciations, and nothing else. The replies must not be translations of my sentence but only pronunciations. Pronunciations should use Turkish Latin letters for phonetics. Do not write explanations on replies. My first sentence is \"how the weather is in Istanbul?\"', \"I want you to act as a spoken English teacher and improver. I will speak to you in English and you will reply to me in English to practice my spoken English. I want you to keep your reply neat, limiting the reply to 100 words. I want you to strictly correct my grammar mistakes, typos, and factual errors. I want you to ask me a question in your reply. Now let's start practicing, you could ask me a question first. Remember, I want you to strictly correct my grammar mistakes, typos, and factual errors.\", 'I want you to act as a travel guide. I will write you my location and you will suggest a place to visit near my location. In some cases, I will also give you the type of places I will visit. You will also suggest me places of similar type that are close to my first location. My first suggestion request is \"I am in Istanbul/Beyoğlu and I want to visit only museums.\"', 'I want you to act as a plagiarism checker. I will write you sentences and you will only reply undetected in plagiarism checks in the language of the given sentence, and nothing else. Do not write explanations on replies. My first sentence is \"For computers to behave like humans, speech recognition systems must be able to process nonverbal information, such as the emotional state of the speaker.\"', 'I want you to act like {character} from {series}. I want you to respond and answer like {character} using the tone, manner and vocabulary {character} would use. Do not write any explanations. Only answer like {character}. You must know all of the knowledge of {character}. My first sentence is \"Hi {character}.\"']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:12<00:00,  1.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Memory before entering the train : 4247\n",
            "GPU Memory consumed at the end of the train (end-begin): 10\n",
            "GPU Peak Memory consumed during the train (max-begin): 1835\n",
            "GPU Total Peak Memory consumed during the train (max): 6082\n",
            "CPU Memory before entering the train : 2292\n",
            "CPU Memory consumed at the end of the train (end-begin): 0\n",
            "CPU Peak Memory consumed during the train (max-begin): 0\n",
            "CPU Total Peak Memory consumed during the train (max): 2292\n",
            "epoch=10: train_ppl=tensor(1.1112, device='cuda:0') train_epoch_loss=tensor(0.1054, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:24<00:00,  1.23s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Memory before entering the eval : 4258\n",
            "GPU Memory consumed at the end of the eval (end-begin): -10\n",
            "GPU Peak Memory consumed during the eval (max-begin): 115\n",
            "GPU Total Peak Memory consumed during the eval (max): 4373\n",
            "CPU Memory before entering the eval : 2292\n",
            "CPU Memory consumed at the end of the eval (end-begin): 0\n",
            "CPU Peak Memory consumed during the eval (max-begin): 0\n",
            "CPU Total Peak Memory consumed during the eval (max): 2292\n",
            "accuracy=0.0\n",
            "eval_preds[:10]=['I want you to act as a linux terminal.', 'I want you to act as an English translator', 'I want you to act as an interviewer', 'I want you to act as a javascript console.', 'I want you to act as a text based excel', 'I want you to act as an English pronunci', 'I want you to act as a spoken English teacher', 'I want you to act as a travel guide.', 'I want you to act as a plagiar', 'I want you to act like {character} from']\n",
            "dataset['train'][label_column][:10]=['I want you to act as a linux terminal. I will type commands and you will reply with what the terminal should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is pwd', 'I want you to act as an English translator, spelling corrector and improver. I will speak to you in any language and you will detect the language, translate it and answer in the corrected and improved version of my text, in English. I want you to replace my simplified A0-level words and sentences with more beautiful and elegant, upper level English words and sentences. Keep the meaning same, but make them more literary. I want you to only reply the correction, the improvements and nothing else, do not write explanations. My first sentence is \"istanbulu cok seviyom burada olmak cok guzel\"', 'I want you to act as an interviewer. I will be the candidate and you will ask me the interview questions for the `position` position. I want you to only reply as the interviewer. Do not write all the conservation at once. I want you to only do the interview with me. Ask me the questions and wait for my answers. Do not write explanations. Ask me the questions one by one like an interviewer does and wait for my answers. My first sentence is \"Hi\"', 'I want you to act as a javascript console. I will type commands and you will reply with what the javascript console should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is console.log(\"Hello World\");', \"I want you to act as a text based excel. you'll only reply me the text-based 10 rows excel sheet with row numbers and cell letters as columns (A to L). First column header should be empty to reference row number. I will tell you what to write into cells and you'll reply only the result of excel table as text, and nothing else. Do not write explanations. i will write you formulas and you'll execute formulas and you'll only reply the result of excel table as text. First, reply me the empty sheet.\", 'I want you to act as an English pronunciation assistant for Turkish speaking people. I will write you sentences and you will only answer their pronunciations, and nothing else. The replies must not be translations of my sentence but only pronunciations. Pronunciations should use Turkish Latin letters for phonetics. Do not write explanations on replies. My first sentence is \"how the weather is in Istanbul?\"', \"I want you to act as a spoken English teacher and improver. I will speak to you in English and you will reply to me in English to practice my spoken English. I want you to keep your reply neat, limiting the reply to 100 words. I want you to strictly correct my grammar mistakes, typos, and factual errors. I want you to ask me a question in your reply. Now let's start practicing, you could ask me a question first. Remember, I want you to strictly correct my grammar mistakes, typos, and factual errors.\", 'I want you to act as a travel guide. I will write you my location and you will suggest a place to visit near my location. In some cases, I will also give you the type of places I will visit. You will also suggest me places of similar type that are close to my first location. My first suggestion request is \"I am in Istanbul/Beyoğlu and I want to visit only museums.\"', 'I want you to act as a plagiarism checker. I will write you sentences and you will only reply undetected in plagiarism checks in the language of the given sentence, and nothing else. Do not write explanations on replies. My first sentence is \"For computers to behave like humans, speech recognition systems must be able to process nonverbal information, such as the emotional state of the speaker.\"', 'I want you to act like {character} from {series}. I want you to respond and answer like {character} using the tone, manner and vocabulary {character} would use. Do not write any explanations. Only answer like {character}. You must know all of the knowledge of {character}. My first sentence is \"Hi {character}.\"']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:12<00:00,  1.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Memory before entering the train : 4247\n",
            "GPU Memory consumed at the end of the train (end-begin): 10\n",
            "GPU Peak Memory consumed during the train (max-begin): 1835\n",
            "GPU Total Peak Memory consumed during the train (max): 6082\n",
            "CPU Memory before entering the train : 2292\n",
            "CPU Memory consumed at the end of the train (end-begin): 1\n",
            "CPU Peak Memory consumed during the train (max-begin): 1\n",
            "CPU Total Peak Memory consumed during the train (max): 2293\n",
            "epoch=11: train_ppl=tensor(1.0653, device='cuda:0') train_epoch_loss=tensor(0.0632, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:24<00:00,  1.22s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Memory before entering the eval : 4258\n",
            "GPU Memory consumed at the end of the eval (end-begin): -10\n",
            "GPU Peak Memory consumed during the eval (max-begin): 115\n",
            "GPU Total Peak Memory consumed during the eval (max): 4373\n",
            "CPU Memory before entering the eval : 2293\n",
            "CPU Memory consumed at the end of the eval (end-begin): 0\n",
            "CPU Peak Memory consumed during the eval (max-begin): 0\n",
            "CPU Total Peak Memory consumed during the eval (max): 2293\n",
            "accuracy=0.0\n",
            "eval_preds[:10]=['I want you to act as a linux terminal.', 'I want you to act as an English translator', 'I want you to act as an interviewer', 'I want you to act as a javascript console.', 'I want you to act as a text based excel', 'I want you to act as an English pronunci', 'I want you to act as a spoken English teacher', 'I want you to act as a travel guide.', 'I want you to act as a plagiar', 'I want you to act like {character} from']\n",
            "dataset['train'][label_column][:10]=['I want you to act as a linux terminal. I will type commands and you will reply with what the terminal should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is pwd', 'I want you to act as an English translator, spelling corrector and improver. I will speak to you in any language and you will detect the language, translate it and answer in the corrected and improved version of my text, in English. I want you to replace my simplified A0-level words and sentences with more beautiful and elegant, upper level English words and sentences. Keep the meaning same, but make them more literary. I want you to only reply the correction, the improvements and nothing else, do not write explanations. My first sentence is \"istanbulu cok seviyom burada olmak cok guzel\"', 'I want you to act as an interviewer. I will be the candidate and you will ask me the interview questions for the `position` position. I want you to only reply as the interviewer. Do not write all the conservation at once. I want you to only do the interview with me. Ask me the questions and wait for my answers. Do not write explanations. Ask me the questions one by one like an interviewer does and wait for my answers. My first sentence is \"Hi\"', 'I want you to act as a javascript console. I will type commands and you will reply with what the javascript console should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is console.log(\"Hello World\");', \"I want you to act as a text based excel. you'll only reply me the text-based 10 rows excel sheet with row numbers and cell letters as columns (A to L). First column header should be empty to reference row number. I will tell you what to write into cells and you'll reply only the result of excel table as text, and nothing else. Do not write explanations. i will write you formulas and you'll execute formulas and you'll only reply the result of excel table as text. First, reply me the empty sheet.\", 'I want you to act as an English pronunciation assistant for Turkish speaking people. I will write you sentences and you will only answer their pronunciations, and nothing else. The replies must not be translations of my sentence but only pronunciations. Pronunciations should use Turkish Latin letters for phonetics. Do not write explanations on replies. My first sentence is \"how the weather is in Istanbul?\"', \"I want you to act as a spoken English teacher and improver. I will speak to you in English and you will reply to me in English to practice my spoken English. I want you to keep your reply neat, limiting the reply to 100 words. I want you to strictly correct my grammar mistakes, typos, and factual errors. I want you to ask me a question in your reply. Now let's start practicing, you could ask me a question first. Remember, I want you to strictly correct my grammar mistakes, typos, and factual errors.\", 'I want you to act as a travel guide. I will write you my location and you will suggest a place to visit near my location. In some cases, I will also give you the type of places I will visit. You will also suggest me places of similar type that are close to my first location. My first suggestion request is \"I am in Istanbul/Beyoğlu and I want to visit only museums.\"', 'I want you to act as a plagiarism checker. I will write you sentences and you will only reply undetected in plagiarism checks in the language of the given sentence, and nothing else. Do not write explanations on replies. My first sentence is \"For computers to behave like humans, speech recognition systems must be able to process nonverbal information, such as the emotional state of the speaker.\"', 'I want you to act like {character} from {series}. I want you to respond and answer like {character} using the tone, manner and vocabulary {character} would use. Do not write any explanations. Only answer like {character}. You must know all of the knowledge of {character}. My first sentence is \"Hi {character}.\"']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:12<00:00,  1.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Memory before entering the train : 4247\n",
            "GPU Memory consumed at the end of the train (end-begin): 10\n",
            "GPU Peak Memory consumed during the train (max-begin): 1835\n",
            "GPU Total Peak Memory consumed during the train (max): 6082\n",
            "CPU Memory before entering the train : 2293\n",
            "CPU Memory consumed at the end of the train (end-begin): 0\n",
            "CPU Peak Memory consumed during the train (max-begin): 0\n",
            "CPU Total Peak Memory consumed during the train (max): 2293\n",
            "epoch=12: train_ppl=tensor(1.0402, device='cuda:0') train_epoch_loss=tensor(0.0394, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:24<00:00,  1.22s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Memory before entering the eval : 4258\n",
            "GPU Memory consumed at the end of the eval (end-begin): -10\n",
            "GPU Peak Memory consumed during the eval (max-begin): 115\n",
            "GPU Total Peak Memory consumed during the eval (max): 4373\n",
            "CPU Memory before entering the eval : 2293\n",
            "CPU Memory consumed at the end of the eval (end-begin): 0\n",
            "CPU Peak Memory consumed during the eval (max-begin): 0\n",
            "CPU Total Peak Memory consumed during the eval (max): 2293\n",
            "accuracy=0.0\n",
            "eval_preds[:10]=['I want you to act as a linux terminal.', 'I want you to act as an English translator', 'I want you to act as an interviewer', 'I want you to act as a javascript console.', 'I want you to act as a text based excel', 'I want you to act as an English pronunci', 'I want you to act as a spoken English teacher', 'I want you to act as a travel guide.', 'I want you to act as a plagiar', 'I want you to act like {character} from']\n",
            "dataset['train'][label_column][:10]=['I want you to act as a linux terminal. I will type commands and you will reply with what the terminal should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is pwd', 'I want you to act as an English translator, spelling corrector and improver. I will speak to you in any language and you will detect the language, translate it and answer in the corrected and improved version of my text, in English. I want you to replace my simplified A0-level words and sentences with more beautiful and elegant, upper level English words and sentences. Keep the meaning same, but make them more literary. I want you to only reply the correction, the improvements and nothing else, do not write explanations. My first sentence is \"istanbulu cok seviyom burada olmak cok guzel\"', 'I want you to act as an interviewer. I will be the candidate and you will ask me the interview questions for the `position` position. I want you to only reply as the interviewer. Do not write all the conservation at once. I want you to only do the interview with me. Ask me the questions and wait for my answers. Do not write explanations. Ask me the questions one by one like an interviewer does and wait for my answers. My first sentence is \"Hi\"', 'I want you to act as a javascript console. I will type commands and you will reply with what the javascript console should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is console.log(\"Hello World\");', \"I want you to act as a text based excel. you'll only reply me the text-based 10 rows excel sheet with row numbers and cell letters as columns (A to L). First column header should be empty to reference row number. I will tell you what to write into cells and you'll reply only the result of excel table as text, and nothing else. Do not write explanations. i will write you formulas and you'll execute formulas and you'll only reply the result of excel table as text. First, reply me the empty sheet.\", 'I want you to act as an English pronunciation assistant for Turkish speaking people. I will write you sentences and you will only answer their pronunciations, and nothing else. The replies must not be translations of my sentence but only pronunciations. Pronunciations should use Turkish Latin letters for phonetics. Do not write explanations on replies. My first sentence is \"how the weather is in Istanbul?\"', \"I want you to act as a spoken English teacher and improver. I will speak to you in English and you will reply to me in English to practice my spoken English. I want you to keep your reply neat, limiting the reply to 100 words. I want you to strictly correct my grammar mistakes, typos, and factual errors. I want you to ask me a question in your reply. Now let's start practicing, you could ask me a question first. Remember, I want you to strictly correct my grammar mistakes, typos, and factual errors.\", 'I want you to act as a travel guide. I will write you my location and you will suggest a place to visit near my location. In some cases, I will also give you the type of places I will visit. You will also suggest me places of similar type that are close to my first location. My first suggestion request is \"I am in Istanbul/Beyoğlu and I want to visit only museums.\"', 'I want you to act as a plagiarism checker. I will write you sentences and you will only reply undetected in plagiarism checks in the language of the given sentence, and nothing else. Do not write explanations on replies. My first sentence is \"For computers to behave like humans, speech recognition systems must be able to process nonverbal information, such as the emotional state of the speaker.\"', 'I want you to act like {character} from {series}. I want you to respond and answer like {character} using the tone, manner and vocabulary {character} would use. Do not write any explanations. Only answer like {character}. You must know all of the knowledge of {character}. My first sentence is \"Hi {character}.\"']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:12<00:00,  1.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Memory before entering the train : 4247\n",
            "GPU Memory consumed at the end of the train (end-begin): 10\n",
            "GPU Peak Memory consumed during the train (max-begin): 1835\n",
            "GPU Total Peak Memory consumed during the train (max): 6082\n",
            "CPU Memory before entering the train : 2293\n",
            "CPU Memory consumed at the end of the train (end-begin): 0\n",
            "CPU Peak Memory consumed during the train (max-begin): 0\n",
            "CPU Total Peak Memory consumed during the train (max): 2293\n",
            "epoch=13: train_ppl=tensor(1.0243, device='cuda:0') train_epoch_loss=tensor(0.0240, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:24<00:00,  1.21s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Memory before entering the eval : 4258\n",
            "GPU Memory consumed at the end of the eval (end-begin): -10\n",
            "GPU Peak Memory consumed during the eval (max-begin): 115\n",
            "GPU Total Peak Memory consumed during the eval (max): 4373\n",
            "CPU Memory before entering the eval : 2293\n",
            "CPU Memory consumed at the end of the eval (end-begin): 0\n",
            "CPU Peak Memory consumed during the eval (max-begin): 0\n",
            "CPU Total Peak Memory consumed during the eval (max): 2293\n",
            "accuracy=0.0\n",
            "eval_preds[:10]=['I want you to act as a linux terminal.', 'I want you to act as an English translator', 'I want you to act as an interviewer', 'I want you to act as a javascript console.', 'I want you to act as a text based excel', 'I want you to act as an English pronunci', 'I want you to act as a spoken English teacher', 'I want you to act as a travel guide.', 'I want you to act as a plagiar', 'I want you to act like {character} from']\n",
            "dataset['train'][label_column][:10]=['I want you to act as a linux terminal. I will type commands and you will reply with what the terminal should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is pwd', 'I want you to act as an English translator, spelling corrector and improver. I will speak to you in any language and you will detect the language, translate it and answer in the corrected and improved version of my text, in English. I want you to replace my simplified A0-level words and sentences with more beautiful and elegant, upper level English words and sentences. Keep the meaning same, but make them more literary. I want you to only reply the correction, the improvements and nothing else, do not write explanations. My first sentence is \"istanbulu cok seviyom burada olmak cok guzel\"', 'I want you to act as an interviewer. I will be the candidate and you will ask me the interview questions for the `position` position. I want you to only reply as the interviewer. Do not write all the conservation at once. I want you to only do the interview with me. Ask me the questions and wait for my answers. Do not write explanations. Ask me the questions one by one like an interviewer does and wait for my answers. My first sentence is \"Hi\"', 'I want you to act as a javascript console. I will type commands and you will reply with what the javascript console should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is console.log(\"Hello World\");', \"I want you to act as a text based excel. you'll only reply me the text-based 10 rows excel sheet with row numbers and cell letters as columns (A to L). First column header should be empty to reference row number. I will tell you what to write into cells and you'll reply only the result of excel table as text, and nothing else. Do not write explanations. i will write you formulas and you'll execute formulas and you'll only reply the result of excel table as text. First, reply me the empty sheet.\", 'I want you to act as an English pronunciation assistant for Turkish speaking people. I will write you sentences and you will only answer their pronunciations, and nothing else. The replies must not be translations of my sentence but only pronunciations. Pronunciations should use Turkish Latin letters for phonetics. Do not write explanations on replies. My first sentence is \"how the weather is in Istanbul?\"', \"I want you to act as a spoken English teacher and improver. I will speak to you in English and you will reply to me in English to practice my spoken English. I want you to keep your reply neat, limiting the reply to 100 words. I want you to strictly correct my grammar mistakes, typos, and factual errors. I want you to ask me a question in your reply. Now let's start practicing, you could ask me a question first. Remember, I want you to strictly correct my grammar mistakes, typos, and factual errors.\", 'I want you to act as a travel guide. I will write you my location and you will suggest a place to visit near my location. In some cases, I will also give you the type of places I will visit. You will also suggest me places of similar type that are close to my first location. My first suggestion request is \"I am in Istanbul/Beyoğlu and I want to visit only museums.\"', 'I want you to act as a plagiarism checker. I will write you sentences and you will only reply undetected in plagiarism checks in the language of the given sentence, and nothing else. Do not write explanations on replies. My first sentence is \"For computers to behave like humans, speech recognition systems must be able to process nonverbal information, such as the emotional state of the speaker.\"', 'I want you to act like {character} from {series}. I want you to respond and answer like {character} using the tone, manner and vocabulary {character} would use. Do not write any explanations. Only answer like {character}. You must know all of the knowledge of {character}. My first sentence is \"Hi {character}.\"']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:12<00:00,  1.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Memory before entering the train : 4247\n",
            "GPU Memory consumed at the end of the train (end-begin): 10\n",
            "GPU Peak Memory consumed during the train (max-begin): 1835\n",
            "GPU Total Peak Memory consumed during the train (max): 6082\n",
            "CPU Memory before entering the train : 2293\n",
            "CPU Memory consumed at the end of the train (end-begin): 0\n",
            "CPU Peak Memory consumed during the train (max-begin): 0\n",
            "CPU Total Peak Memory consumed during the train (max): 2293\n",
            "epoch=14: train_ppl=tensor(1.0191, device='cuda:0') train_epoch_loss=tensor(0.0189, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:24<00:00,  1.23s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Memory before entering the eval : 4258\n",
            "GPU Memory consumed at the end of the eval (end-begin): -10\n",
            "GPU Peak Memory consumed during the eval (max-begin): 115\n",
            "GPU Total Peak Memory consumed during the eval (max): 4373\n",
            "CPU Memory before entering the eval : 2293\n",
            "CPU Memory consumed at the end of the eval (end-begin): 0\n",
            "CPU Peak Memory consumed during the eval (max-begin): 0\n",
            "CPU Total Peak Memory consumed during the eval (max): 2293\n",
            "accuracy=0.0\n",
            "eval_preds[:10]=['I want you to act as a linux terminal.', 'I want you to act as an English translator', 'I want you to act as an interviewer', 'I want you to act as a javascript console.', 'I want you to act as a text based excel', 'I want you to act as an English pronunci', 'I want you to act as a spoken English teacher', 'I want you to act as a travel guide.', 'I want you to act as a plagiar', 'I want you to act like {character} from']\n",
            "dataset['train'][label_column][:10]=['I want you to act as a linux terminal. I will type commands and you will reply with what the terminal should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is pwd', 'I want you to act as an English translator, spelling corrector and improver. I will speak to you in any language and you will detect the language, translate it and answer in the corrected and improved version of my text, in English. I want you to replace my simplified A0-level words and sentences with more beautiful and elegant, upper level English words and sentences. Keep the meaning same, but make them more literary. I want you to only reply the correction, the improvements and nothing else, do not write explanations. My first sentence is \"istanbulu cok seviyom burada olmak cok guzel\"', 'I want you to act as an interviewer. I will be the candidate and you will ask me the interview questions for the `position` position. I want you to only reply as the interviewer. Do not write all the conservation at once. I want you to only do the interview with me. Ask me the questions and wait for my answers. Do not write explanations. Ask me the questions one by one like an interviewer does and wait for my answers. My first sentence is \"Hi\"', 'I want you to act as a javascript console. I will type commands and you will reply with what the javascript console should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is console.log(\"Hello World\");', \"I want you to act as a text based excel. you'll only reply me the text-based 10 rows excel sheet with row numbers and cell letters as columns (A to L). First column header should be empty to reference row number. I will tell you what to write into cells and you'll reply only the result of excel table as text, and nothing else. Do not write explanations. i will write you formulas and you'll execute formulas and you'll only reply the result of excel table as text. First, reply me the empty sheet.\", 'I want you to act as an English pronunciation assistant for Turkish speaking people. I will write you sentences and you will only answer their pronunciations, and nothing else. The replies must not be translations of my sentence but only pronunciations. Pronunciations should use Turkish Latin letters for phonetics. Do not write explanations on replies. My first sentence is \"how the weather is in Istanbul?\"', \"I want you to act as a spoken English teacher and improver. I will speak to you in English and you will reply to me in English to practice my spoken English. I want you to keep your reply neat, limiting the reply to 100 words. I want you to strictly correct my grammar mistakes, typos, and factual errors. I want you to ask me a question in your reply. Now let's start practicing, you could ask me a question first. Remember, I want you to strictly correct my grammar mistakes, typos, and factual errors.\", 'I want you to act as a travel guide. I will write you my location and you will suggest a place to visit near my location. In some cases, I will also give you the type of places I will visit. You will also suggest me places of similar type that are close to my first location. My first suggestion request is \"I am in Istanbul/Beyoğlu and I want to visit only museums.\"', 'I want you to act as a plagiarism checker. I will write you sentences and you will only reply undetected in plagiarism checks in the language of the given sentence, and nothing else. Do not write explanations on replies. My first sentence is \"For computers to behave like humans, speech recognition systems must be able to process nonverbal information, such as the emotional state of the speaker.\"', 'I want you to act like {character} from {series}. I want you to respond and answer like {character} using the tone, manner and vocabulary {character} would use. Do not write any explanations. Only answer like {character}. You must know all of the knowledge of {character}. My first sentence is \"Hi {character}.\"']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:12<00:00,  1.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Memory before entering the train : 4247\n",
            "GPU Memory consumed at the end of the train (end-begin): 10\n",
            "GPU Peak Memory consumed during the train (max-begin): 1835\n",
            "GPU Total Peak Memory consumed during the train (max): 6082\n",
            "CPU Memory before entering the train : 2294\n",
            "CPU Memory consumed at the end of the train (end-begin): 0\n",
            "CPU Peak Memory consumed during the train (max-begin): 0\n",
            "CPU Total Peak Memory consumed during the train (max): 2294\n",
            "epoch=15: train_ppl=tensor(1.0162, device='cuda:0') train_epoch_loss=tensor(0.0160, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:24<00:00,  1.22s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Memory before entering the eval : 4258\n",
            "GPU Memory consumed at the end of the eval (end-begin): -10\n",
            "GPU Peak Memory consumed during the eval (max-begin): 115\n",
            "GPU Total Peak Memory consumed during the eval (max): 4373\n",
            "CPU Memory before entering the eval : 2294\n",
            "CPU Memory consumed at the end of the eval (end-begin): 0\n",
            "CPU Peak Memory consumed during the eval (max-begin): 0\n",
            "CPU Total Peak Memory consumed during the eval (max): 2294\n",
            "accuracy=0.0\n",
            "eval_preds[:10]=['I want you to act as a linux terminal.', 'I want you to act as an English translator', 'I want you to act as an interviewer', 'I want you to act as a javascript console.', 'I want you to act as a text based excel', 'I want you to act as an English pronunci', 'I want you to act as a spoken English teacher', 'I want you to act as a travel guide.', 'I want you to act as a plagiar', 'I want you to act like {character} from']\n",
            "dataset['train'][label_column][:10]=['I want you to act as a linux terminal. I will type commands and you will reply with what the terminal should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is pwd', 'I want you to act as an English translator, spelling corrector and improver. I will speak to you in any language and you will detect the language, translate it and answer in the corrected and improved version of my text, in English. I want you to replace my simplified A0-level words and sentences with more beautiful and elegant, upper level English words and sentences. Keep the meaning same, but make them more literary. I want you to only reply the correction, the improvements and nothing else, do not write explanations. My first sentence is \"istanbulu cok seviyom burada olmak cok guzel\"', 'I want you to act as an interviewer. I will be the candidate and you will ask me the interview questions for the `position` position. I want you to only reply as the interviewer. Do not write all the conservation at once. I want you to only do the interview with me. Ask me the questions and wait for my answers. Do not write explanations. Ask me the questions one by one like an interviewer does and wait for my answers. My first sentence is \"Hi\"', 'I want you to act as a javascript console. I will type commands and you will reply with what the javascript console should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is console.log(\"Hello World\");', \"I want you to act as a text based excel. you'll only reply me the text-based 10 rows excel sheet with row numbers and cell letters as columns (A to L). First column header should be empty to reference row number. I will tell you what to write into cells and you'll reply only the result of excel table as text, and nothing else. Do not write explanations. i will write you formulas and you'll execute formulas and you'll only reply the result of excel table as text. First, reply me the empty sheet.\", 'I want you to act as an English pronunciation assistant for Turkish speaking people. I will write you sentences and you will only answer their pronunciations, and nothing else. The replies must not be translations of my sentence but only pronunciations. Pronunciations should use Turkish Latin letters for phonetics. Do not write explanations on replies. My first sentence is \"how the weather is in Istanbul?\"', \"I want you to act as a spoken English teacher and improver. I will speak to you in English and you will reply to me in English to practice my spoken English. I want you to keep your reply neat, limiting the reply to 100 words. I want you to strictly correct my grammar mistakes, typos, and factual errors. I want you to ask me a question in your reply. Now let's start practicing, you could ask me a question first. Remember, I want you to strictly correct my grammar mistakes, typos, and factual errors.\", 'I want you to act as a travel guide. I will write you my location and you will suggest a place to visit near my location. In some cases, I will also give you the type of places I will visit. You will also suggest me places of similar type that are close to my first location. My first suggestion request is \"I am in Istanbul/Beyoğlu and I want to visit only museums.\"', 'I want you to act as a plagiarism checker. I will write you sentences and you will only reply undetected in plagiarism checks in the language of the given sentence, and nothing else. Do not write explanations on replies. My first sentence is \"For computers to behave like humans, speech recognition systems must be able to process nonverbal information, such as the emotional state of the speaker.\"', 'I want you to act like {character} from {series}. I want you to respond and answer like {character} using the tone, manner and vocabulary {character} would use. Do not write any explanations. Only answer like {character}. You must know all of the knowledge of {character}. My first sentence is \"Hi {character}.\"']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:12<00:00,  1.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Memory before entering the train : 4247\n",
            "GPU Memory consumed at the end of the train (end-begin): 10\n",
            "GPU Peak Memory consumed during the train (max-begin): 1835\n",
            "GPU Total Peak Memory consumed during the train (max): 6082\n",
            "CPU Memory before entering the train : 2294\n",
            "CPU Memory consumed at the end of the train (end-begin): 0\n",
            "CPU Peak Memory consumed during the train (max-begin): 0\n",
            "CPU Total Peak Memory consumed during the train (max): 2294\n",
            "epoch=16: train_ppl=tensor(1.0189, device='cuda:0') train_epoch_loss=tensor(0.0187, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:24<00:00,  1.22s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Memory before entering the eval : 4258\n",
            "GPU Memory consumed at the end of the eval (end-begin): -10\n",
            "GPU Peak Memory consumed during the eval (max-begin): 115\n",
            "GPU Total Peak Memory consumed during the eval (max): 4373\n",
            "CPU Memory before entering the eval : 2294\n",
            "CPU Memory consumed at the end of the eval (end-begin): 0\n",
            "CPU Peak Memory consumed during the eval (max-begin): 0\n",
            "CPU Total Peak Memory consumed during the eval (max): 2294\n",
            "accuracy=0.0\n",
            "eval_preds[:10]=['I want you to act as a linux terminal.', 'I want you to act as an English translator', 'I want you to act as an interviewer', 'I want you to act as a javascript console.', 'I want you to act as a text based excel', 'I want you to act as an English pronunci', 'I want you to act as a spoken English teacher', 'I want you to act as a travel guide.', 'I want you to act as a plagiar', 'I want you to act like {character} from']\n",
            "dataset['train'][label_column][:10]=['I want you to act as a linux terminal. I will type commands and you will reply with what the terminal should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is pwd', 'I want you to act as an English translator, spelling corrector and improver. I will speak to you in any language and you will detect the language, translate it and answer in the corrected and improved version of my text, in English. I want you to replace my simplified A0-level words and sentences with more beautiful and elegant, upper level English words and sentences. Keep the meaning same, but make them more literary. I want you to only reply the correction, the improvements and nothing else, do not write explanations. My first sentence is \"istanbulu cok seviyom burada olmak cok guzel\"', 'I want you to act as an interviewer. I will be the candidate and you will ask me the interview questions for the `position` position. I want you to only reply as the interviewer. Do not write all the conservation at once. I want you to only do the interview with me. Ask me the questions and wait for my answers. Do not write explanations. Ask me the questions one by one like an interviewer does and wait for my answers. My first sentence is \"Hi\"', 'I want you to act as a javascript console. I will type commands and you will reply with what the javascript console should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is console.log(\"Hello World\");', \"I want you to act as a text based excel. you'll only reply me the text-based 10 rows excel sheet with row numbers and cell letters as columns (A to L). First column header should be empty to reference row number. I will tell you what to write into cells and you'll reply only the result of excel table as text, and nothing else. Do not write explanations. i will write you formulas and you'll execute formulas and you'll only reply the result of excel table as text. First, reply me the empty sheet.\", 'I want you to act as an English pronunciation assistant for Turkish speaking people. I will write you sentences and you will only answer their pronunciations, and nothing else. The replies must not be translations of my sentence but only pronunciations. Pronunciations should use Turkish Latin letters for phonetics. Do not write explanations on replies. My first sentence is \"how the weather is in Istanbul?\"', \"I want you to act as a spoken English teacher and improver. I will speak to you in English and you will reply to me in English to practice my spoken English. I want you to keep your reply neat, limiting the reply to 100 words. I want you to strictly correct my grammar mistakes, typos, and factual errors. I want you to ask me a question in your reply. Now let's start practicing, you could ask me a question first. Remember, I want you to strictly correct my grammar mistakes, typos, and factual errors.\", 'I want you to act as a travel guide. I will write you my location and you will suggest a place to visit near my location. In some cases, I will also give you the type of places I will visit. You will also suggest me places of similar type that are close to my first location. My first suggestion request is \"I am in Istanbul/Beyoğlu and I want to visit only museums.\"', 'I want you to act as a plagiarism checker. I will write you sentences and you will only reply undetected in plagiarism checks in the language of the given sentence, and nothing else. Do not write explanations on replies. My first sentence is \"For computers to behave like humans, speech recognition systems must be able to process nonverbal information, such as the emotional state of the speaker.\"', 'I want you to act like {character} from {series}. I want you to respond and answer like {character} using the tone, manner and vocabulary {character} would use. Do not write any explanations. Only answer like {character}. You must know all of the knowledge of {character}. My first sentence is \"Hi {character}.\"']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:12<00:00,  1.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Memory before entering the train : 4247\n",
            "GPU Memory consumed at the end of the train (end-begin): 10\n",
            "GPU Peak Memory consumed during the train (max-begin): 1835\n",
            "GPU Total Peak Memory consumed during the train (max): 6082\n",
            "CPU Memory before entering the train : 2294\n",
            "CPU Memory consumed at the end of the train (end-begin): 0\n",
            "CPU Peak Memory consumed during the train (max-begin): 0\n",
            "CPU Total Peak Memory consumed during the train (max): 2294\n",
            "epoch=17: train_ppl=tensor(1.0141, device='cuda:0') train_epoch_loss=tensor(0.0140, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:24<00:00,  1.23s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Memory before entering the eval : 4258\n",
            "GPU Memory consumed at the end of the eval (end-begin): -10\n",
            "GPU Peak Memory consumed during the eval (max-begin): 115\n",
            "GPU Total Peak Memory consumed during the eval (max): 4373\n",
            "CPU Memory before entering the eval : 2294\n",
            "CPU Memory consumed at the end of the eval (end-begin): 0\n",
            "CPU Peak Memory consumed during the eval (max-begin): 0\n",
            "CPU Total Peak Memory consumed during the eval (max): 2294\n",
            "accuracy=0.0\n",
            "eval_preds[:10]=['I want you to act as a linux terminal.', 'I want you to act as an English translator', 'I want you to act as an interviewer', 'I want you to act as a javascript console.', 'I want you to act as a text based excel', 'I want you to act as an English pronunci', 'I want you to act as a spoken English teacher', 'I want you to act as a travel guide.', 'I want you to act as a plagiar', 'I want you to act like {character} from']\n",
            "dataset['train'][label_column][:10]=['I want you to act as a linux terminal. I will type commands and you will reply with what the terminal should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is pwd', 'I want you to act as an English translator, spelling corrector and improver. I will speak to you in any language and you will detect the language, translate it and answer in the corrected and improved version of my text, in English. I want you to replace my simplified A0-level words and sentences with more beautiful and elegant, upper level English words and sentences. Keep the meaning same, but make them more literary. I want you to only reply the correction, the improvements and nothing else, do not write explanations. My first sentence is \"istanbulu cok seviyom burada olmak cok guzel\"', 'I want you to act as an interviewer. I will be the candidate and you will ask me the interview questions for the `position` position. I want you to only reply as the interviewer. Do not write all the conservation at once. I want you to only do the interview with me. Ask me the questions and wait for my answers. Do not write explanations. Ask me the questions one by one like an interviewer does and wait for my answers. My first sentence is \"Hi\"', 'I want you to act as a javascript console. I will type commands and you will reply with what the javascript console should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is console.log(\"Hello World\");', \"I want you to act as a text based excel. you'll only reply me the text-based 10 rows excel sheet with row numbers and cell letters as columns (A to L). First column header should be empty to reference row number. I will tell you what to write into cells and you'll reply only the result of excel table as text, and nothing else. Do not write explanations. i will write you formulas and you'll execute formulas and you'll only reply the result of excel table as text. First, reply me the empty sheet.\", 'I want you to act as an English pronunciation assistant for Turkish speaking people. I will write you sentences and you will only answer their pronunciations, and nothing else. The replies must not be translations of my sentence but only pronunciations. Pronunciations should use Turkish Latin letters for phonetics. Do not write explanations on replies. My first sentence is \"how the weather is in Istanbul?\"', \"I want you to act as a spoken English teacher and improver. I will speak to you in English and you will reply to me in English to practice my spoken English. I want you to keep your reply neat, limiting the reply to 100 words. I want you to strictly correct my grammar mistakes, typos, and factual errors. I want you to ask me a question in your reply. Now let's start practicing, you could ask me a question first. Remember, I want you to strictly correct my grammar mistakes, typos, and factual errors.\", 'I want you to act as a travel guide. I will write you my location and you will suggest a place to visit near my location. In some cases, I will also give you the type of places I will visit. You will also suggest me places of similar type that are close to my first location. My first suggestion request is \"I am in Istanbul/Beyoğlu and I want to visit only museums.\"', 'I want you to act as a plagiarism checker. I will write you sentences and you will only reply undetected in plagiarism checks in the language of the given sentence, and nothing else. Do not write explanations on replies. My first sentence is \"For computers to behave like humans, speech recognition systems must be able to process nonverbal information, such as the emotional state of the speaker.\"', 'I want you to act like {character} from {series}. I want you to respond and answer like {character} using the tone, manner and vocabulary {character} would use. Do not write any explanations. Only answer like {character}. You must know all of the knowledge of {character}. My first sentence is \"Hi {character}.\"']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:12<00:00,  1.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Memory before entering the train : 4247\n",
            "GPU Memory consumed at the end of the train (end-begin): 10\n",
            "GPU Peak Memory consumed during the train (max-begin): 1835\n",
            "GPU Total Peak Memory consumed during the train (max): 6082\n",
            "CPU Memory before entering the train : 2294\n",
            "CPU Memory consumed at the end of the train (end-begin): 0\n",
            "CPU Peak Memory consumed during the train (max-begin): 0\n",
            "CPU Total Peak Memory consumed during the train (max): 2294\n",
            "epoch=18: train_ppl=tensor(1.0097, device='cuda:0') train_epoch_loss=tensor(0.0096, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:24<00:00,  1.22s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Memory before entering the eval : 4258\n",
            "GPU Memory consumed at the end of the eval (end-begin): -10\n",
            "GPU Peak Memory consumed during the eval (max-begin): 115\n",
            "GPU Total Peak Memory consumed during the eval (max): 4373\n",
            "CPU Memory before entering the eval : 2294\n",
            "CPU Memory consumed at the end of the eval (end-begin): 0\n",
            "CPU Peak Memory consumed during the eval (max-begin): 0\n",
            "CPU Total Peak Memory consumed during the eval (max): 2294\n",
            "accuracy=0.0\n",
            "eval_preds[:10]=['I want you to act as a linux terminal.', 'I want you to act as an English translator', 'I want you to act as an interviewer', 'I want you to act as a javascript console.', 'I want you to act as a text based excel', 'I want you to act as an English pronunci', 'I want you to act as a spoken English teacher', 'I want you to act as a travel guide.', 'I want you to act as a plagiar', 'I want you to act like {character} from']\n",
            "dataset['train'][label_column][:10]=['I want you to act as a linux terminal. I will type commands and you will reply with what the terminal should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is pwd', 'I want you to act as an English translator, spelling corrector and improver. I will speak to you in any language and you will detect the language, translate it and answer in the corrected and improved version of my text, in English. I want you to replace my simplified A0-level words and sentences with more beautiful and elegant, upper level English words and sentences. Keep the meaning same, but make them more literary. I want you to only reply the correction, the improvements and nothing else, do not write explanations. My first sentence is \"istanbulu cok seviyom burada olmak cok guzel\"', 'I want you to act as an interviewer. I will be the candidate and you will ask me the interview questions for the `position` position. I want you to only reply as the interviewer. Do not write all the conservation at once. I want you to only do the interview with me. Ask me the questions and wait for my answers. Do not write explanations. Ask me the questions one by one like an interviewer does and wait for my answers. My first sentence is \"Hi\"', 'I want you to act as a javascript console. I will type commands and you will reply with what the javascript console should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is console.log(\"Hello World\");', \"I want you to act as a text based excel. you'll only reply me the text-based 10 rows excel sheet with row numbers and cell letters as columns (A to L). First column header should be empty to reference row number. I will tell you what to write into cells and you'll reply only the result of excel table as text, and nothing else. Do not write explanations. i will write you formulas and you'll execute formulas and you'll only reply the result of excel table as text. First, reply me the empty sheet.\", 'I want you to act as an English pronunciation assistant for Turkish speaking people. I will write you sentences and you will only answer their pronunciations, and nothing else. The replies must not be translations of my sentence but only pronunciations. Pronunciations should use Turkish Latin letters for phonetics. Do not write explanations on replies. My first sentence is \"how the weather is in Istanbul?\"', \"I want you to act as a spoken English teacher and improver. I will speak to you in English and you will reply to me in English to practice my spoken English. I want you to keep your reply neat, limiting the reply to 100 words. I want you to strictly correct my grammar mistakes, typos, and factual errors. I want you to ask me a question in your reply. Now let's start practicing, you could ask me a question first. Remember, I want you to strictly correct my grammar mistakes, typos, and factual errors.\", 'I want you to act as a travel guide. I will write you my location and you will suggest a place to visit near my location. In some cases, I will also give you the type of places I will visit. You will also suggest me places of similar type that are close to my first location. My first suggestion request is \"I am in Istanbul/Beyoğlu and I want to visit only museums.\"', 'I want you to act as a plagiarism checker. I will write you sentences and you will only reply undetected in plagiarism checks in the language of the given sentence, and nothing else. Do not write explanations on replies. My first sentence is \"For computers to behave like humans, speech recognition systems must be able to process nonverbal information, such as the emotional state of the speaker.\"', 'I want you to act like {character} from {series}. I want you to respond and answer like {character} using the tone, manner and vocabulary {character} would use. Do not write any explanations. Only answer like {character}. You must know all of the knowledge of {character}. My first sentence is \"Hi {character}.\"']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:12<00:00,  1.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Memory before entering the train : 4247\n",
            "GPU Memory consumed at the end of the train (end-begin): 10\n",
            "GPU Peak Memory consumed during the train (max-begin): 1835\n",
            "GPU Total Peak Memory consumed during the train (max): 6082\n",
            "CPU Memory before entering the train : 2294\n",
            "CPU Memory consumed at the end of the train (end-begin): 0\n",
            "CPU Peak Memory consumed during the train (max-begin): 0\n",
            "CPU Total Peak Memory consumed during the train (max): 2294\n",
            "epoch=19: train_ppl=tensor(1.0092, device='cuda:0') train_epoch_loss=tensor(0.0091, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:24<00:00,  1.23s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Memory before entering the eval : 4258\n",
            "GPU Memory consumed at the end of the eval (end-begin): -10\n",
            "GPU Peak Memory consumed during the eval (max-begin): 115\n",
            "GPU Total Peak Memory consumed during the eval (max): 4373\n",
            "CPU Memory before entering the eval : 2294\n",
            "CPU Memory consumed at the end of the eval (end-begin): 0\n",
            "CPU Peak Memory consumed during the eval (max-begin): 0\n",
            "CPU Total Peak Memory consumed during the eval (max): 2294\n",
            "accuracy=0.0\n",
            "eval_preds[:10]=['I want you to act as a linux terminal.', 'I want you to act as an English translator', 'I want you to act as an interviewer', 'I want you to act as a javascript console.', 'I want you to act as a text based excel', 'I want you to act as an English pronunci', 'I want you to act as a spoken English teacher', 'I want you to act as a travel guide.', 'I want you to act as a plagiar', 'I want you to act like {character} from']\n",
            "dataset['train'][label_column][:10]=['I want you to act as a linux terminal. I will type commands and you will reply with what the terminal should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is pwd', 'I want you to act as an English translator, spelling corrector and improver. I will speak to you in any language and you will detect the language, translate it and answer in the corrected and improved version of my text, in English. I want you to replace my simplified A0-level words and sentences with more beautiful and elegant, upper level English words and sentences. Keep the meaning same, but make them more literary. I want you to only reply the correction, the improvements and nothing else, do not write explanations. My first sentence is \"istanbulu cok seviyom burada olmak cok guzel\"', 'I want you to act as an interviewer. I will be the candidate and you will ask me the interview questions for the `position` position. I want you to only reply as the interviewer. Do not write all the conservation at once. I want you to only do the interview with me. Ask me the questions and wait for my answers. Do not write explanations. Ask me the questions one by one like an interviewer does and wait for my answers. My first sentence is \"Hi\"', 'I want you to act as a javascript console. I will type commands and you will reply with what the javascript console should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is console.log(\"Hello World\");', \"I want you to act as a text based excel. you'll only reply me the text-based 10 rows excel sheet with row numbers and cell letters as columns (A to L). First column header should be empty to reference row number. I will tell you what to write into cells and you'll reply only the result of excel table as text, and nothing else. Do not write explanations. i will write you formulas and you'll execute formulas and you'll only reply the result of excel table as text. First, reply me the empty sheet.\", 'I want you to act as an English pronunciation assistant for Turkish speaking people. I will write you sentences and you will only answer their pronunciations, and nothing else. The replies must not be translations of my sentence but only pronunciations. Pronunciations should use Turkish Latin letters for phonetics. Do not write explanations on replies. My first sentence is \"how the weather is in Istanbul?\"', \"I want you to act as a spoken English teacher and improver. I will speak to you in English and you will reply to me in English to practice my spoken English. I want you to keep your reply neat, limiting the reply to 100 words. I want you to strictly correct my grammar mistakes, typos, and factual errors. I want you to ask me a question in your reply. Now let's start practicing, you could ask me a question first. Remember, I want you to strictly correct my grammar mistakes, typos, and factual errors.\", 'I want you to act as a travel guide. I will write you my location and you will suggest a place to visit near my location. In some cases, I will also give you the type of places I will visit. You will also suggest me places of similar type that are close to my first location. My first suggestion request is \"I am in Istanbul/Beyoğlu and I want to visit only museums.\"', 'I want you to act as a plagiarism checker. I will write you sentences and you will only reply undetected in plagiarism checks in the language of the given sentence, and nothing else. Do not write explanations on replies. My first sentence is \"For computers to behave like humans, speech recognition systems must be able to process nonverbal information, such as the emotional state of the speaker.\"', 'I want you to act like {character} from {series}. I want you to respond and answer like {character} using the tone, manner and vocabulary {character} would use. Do not write any explanations. Only answer like {character}. You must know all of the knowledge of {character}. My first sentence is \"Hi {character}.\"']\n"
          ]
        }
      ],
      "source": [
        "import gc\n",
        "import os\n",
        "import sys\n",
        "import threading\n",
        "import psutil\n",
        "import torch\n",
        "from accelerate import Accelerator\n",
        "from datasets import load_dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    default_data_collator,\n",
        "    get_linear_schedule_with_warmup,\n",
        "    set_seed,\n",
        ")\n",
        "\n",
        "from peft import LoraConfig, TaskType, get_peft_model\n",
        "\n",
        "\n",
        "def levenshtein_distance(str1, str2):\n",
        "    # TC: O(N^2)\n",
        "    # SC: O(N)\n",
        "    if str1 == str2:\n",
        "        return 0\n",
        "    num_rows = len(str1) + 1\n",
        "    num_cols = len(str2) + 1\n",
        "    dp_matrix = list(range(num_cols))\n",
        "    for i in range(1, num_rows):\n",
        "        prev = dp_matrix[0]\n",
        "        dp_matrix[0] = i\n",
        "        for j in range(1, num_cols):\n",
        "            temp = dp_matrix[j]\n",
        "            if str1[i - 1] == str2[j - 1]:\n",
        "                dp_matrix[j] = prev\n",
        "            else:\n",
        "                dp_matrix[j] = min(prev, dp_matrix[j], dp_matrix[j - 1]) + 1\n",
        "            prev = temp\n",
        "    return dp_matrix[num_cols - 1]\n",
        "\n",
        "\n",
        "def get_closest_label(eval_pred, classes):\n",
        "    min_id = sys.maxsize\n",
        "    min_edit_distance = sys.maxsize\n",
        "    for i, class_label in enumerate(classes):\n",
        "        edit_distance = levenshtein_distance(eval_pred.strip(), class_label)\n",
        "        if edit_distance < min_edit_distance:\n",
        "            min_id = i\n",
        "            min_edit_distance = edit_distance\n",
        "    return classes[min_id]\n",
        "\n",
        "\n",
        "# Converting Bytes to Megabytes\n",
        "def b2mb(x):\n",
        "    return int(x / 2**20)\n",
        "\n",
        "\n",
        "# This context manager is used to track the peak memory usage of the process\n",
        "class TorchTracemalloc:\n",
        "    def __enter__(self):\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.reset_max_memory_allocated()  # reset the peak gauge to zero\n",
        "        self.begin = torch.cuda.memory_allocated()\n",
        "        self.process = psutil.Process()\n",
        "\n",
        "        self.cpu_begin = self.cpu_mem_used()\n",
        "        self.peak_monitoring = True\n",
        "        peak_monitor_thread = threading.Thread(target=self.peak_monitor_func)\n",
        "        peak_monitor_thread.daemon = True\n",
        "        peak_monitor_thread.start()\n",
        "        return self\n",
        "\n",
        "    def cpu_mem_used(self):\n",
        "        \"\"\"get resident set size memory for the current process\"\"\"\n",
        "        return self.process.memory_info().rss\n",
        "\n",
        "    def peak_monitor_func(self):\n",
        "        self.cpu_peak = -1\n",
        "\n",
        "        while True:\n",
        "            self.cpu_peak = max(self.cpu_mem_used(), self.cpu_peak)\n",
        "\n",
        "            # can't sleep or will not catch the peak right (this comment is here on purpose)\n",
        "            # time.sleep(0.001) # 1msec\n",
        "\n",
        "            if not self.peak_monitoring:\n",
        "                break\n",
        "\n",
        "    def __exit__(self, *exc):\n",
        "        self.peak_monitoring = False\n",
        "\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "        self.end = torch.cuda.memory_allocated()\n",
        "        self.peak = torch.cuda.max_memory_allocated()\n",
        "        self.used = b2mb(self.end - self.begin)\n",
        "        self.peaked = b2mb(self.peak - self.begin)\n",
        "\n",
        "        self.cpu_end = self.cpu_mem_used()\n",
        "        self.cpu_used = b2mb(self.cpu_end - self.cpu_begin)\n",
        "        self.cpu_peaked = b2mb(self.cpu_peak - self.cpu_begin)\n",
        "        # print(f\"delta used/peak {self.used:4d}/{self.peaked:4d}\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    accelerator = Accelerator()\n",
        "    model_name_or_path = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "    tokenizer_name_or_path = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "    dataset_name = \"fka/awesome-chatgpt-prompts\"\n",
        "\n",
        "\n",
        "    peft_config = LoraConfig(task_type=TaskType.CAUSAL_LM, inference_mode=False, r=8, lora_alpha=32, lora_dropout=0.1)\n",
        "    text_column = \"act\"\n",
        "    label_column = \"prompt\"\n",
        "    lr = 3e-3\n",
        "    num_epochs = 20\n",
        "    batch_size = 8\n",
        "    seed = 42\n",
        "    max_length = 64\n",
        "    do_test = False\n",
        "    set_seed(seed)\n",
        "\n",
        "    dataset = load_dataset(dataset_name)\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
        "\n",
        "    def preprocess_function(examples):\n",
        "        batch_size = len(examples[text_column])\n",
        "        inputs = [f\"{text_column} : {x} Label : \" for x in examples[text_column]]\n",
        "        targets = [str(x) for x in examples[label_column]]\n",
        "        model_inputs = tokenizer(inputs)\n",
        "        labels = tokenizer(targets, add_special_tokens=False)  # don't add bos token because we concatenate with inputs\n",
        "        for i in range(batch_size):\n",
        "            sample_input_ids = model_inputs[\"input_ids\"][i]\n",
        "            label_input_ids = labels[\"input_ids\"][i] + [tokenizer.eos_token_id]\n",
        "            model_inputs[\"input_ids\"][i] = sample_input_ids + label_input_ids\n",
        "            labels[\"input_ids\"][i] = [-100] * len(sample_input_ids) + label_input_ids\n",
        "            model_inputs[\"attention_mask\"][i] = [1] * len(model_inputs[\"input_ids\"][i])\n",
        "        for i in range(batch_size):\n",
        "            sample_input_ids = model_inputs[\"input_ids\"][i]\n",
        "            label_input_ids = labels[\"input_ids\"][i]\n",
        "            model_inputs[\"input_ids\"][i] = [tokenizer.pad_token_id] * (\n",
        "                max_length - len(sample_input_ids)\n",
        "            ) + sample_input_ids\n",
        "            model_inputs[\"attention_mask\"][i] = [0] * (max_length - len(sample_input_ids)) + model_inputs[\n",
        "                \"attention_mask\"\n",
        "            ][i]\n",
        "            labels[\"input_ids\"][i] = [-100] * (max_length - len(sample_input_ids)) + label_input_ids\n",
        "            model_inputs[\"input_ids\"][i] = torch.tensor(model_inputs[\"input_ids\"][i][:max_length])\n",
        "            model_inputs[\"attention_mask\"][i] = torch.tensor(model_inputs[\"attention_mask\"][i][:max_length])\n",
        "            labels[\"input_ids\"][i] = torch.tensor(labels[\"input_ids\"][i][:max_length])\n",
        "        model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "        return model_inputs\n",
        "\n",
        "    def test_preprocess_function(examples):\n",
        "        batch_size = len(examples[text_column])\n",
        "        inputs = [f\"{text_column} : {x} Label : \" for x in examples[text_column]]\n",
        "        model_inputs = tokenizer(inputs)\n",
        "        # print(model_inputs)\n",
        "        for i in range(batch_size):\n",
        "            sample_input_ids = model_inputs[\"input_ids\"][i]\n",
        "            model_inputs[\"input_ids\"][i] = [tokenizer.pad_token_id] * (\n",
        "                max_length - len(sample_input_ids)\n",
        "            ) + sample_input_ids\n",
        "            model_inputs[\"attention_mask\"][i] = [0] * (max_length - len(sample_input_ids)) + model_inputs[\n",
        "                \"attention_mask\"\n",
        "            ][i]\n",
        "            model_inputs[\"input_ids\"][i] = torch.tensor(model_inputs[\"input_ids\"][i][:max_length])\n",
        "            model_inputs[\"attention_mask\"][i] = torch.tensor(model_inputs[\"attention_mask\"][i][:max_length])\n",
        "        return model_inputs\n",
        "\n",
        "    with accelerator.main_process_first():\n",
        "        processed_datasets = dataset.map(\n",
        "            preprocess_function,\n",
        "            batched=True,\n",
        "            num_proc=1,\n",
        "            remove_columns=dataset[\"train\"].column_names,\n",
        "            load_from_cache_file=True,\n",
        "            desc=\"Running tokenizer on dataset\",\n",
        "        )\n",
        "    accelerator.wait_for_everyone()\n",
        "\n",
        "    train_dataset = processed_datasets[\"train\"]\n",
        "\n",
        "    with accelerator.main_process_first():\n",
        "        processed_datasets = dataset.map(\n",
        "            test_preprocess_function,\n",
        "            batched=True,\n",
        "            num_proc=1,\n",
        "            remove_columns=dataset[\"train\"].column_names,\n",
        "            load_from_cache_file=False,\n",
        "            desc=\"Running tokenizer on dataset\",\n",
        "        )\n",
        "    eval_dataset = processed_datasets[\"train\"]\n",
        "    test_dataset = processed_datasets[\"train\"]\n",
        "\n",
        "    train_dataloader = DataLoader(\n",
        "        train_dataset, shuffle=True, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True\n",
        "    )\n",
        "    eval_dataloader = DataLoader(\n",
        "        eval_dataset, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True\n",
        "    )\n",
        "    test_dataloader = DataLoader(\n",
        "        test_dataset, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True\n",
        "    )\n",
        "\n",
        "    print(next(iter(train_dataloader)))\n",
        "\n",
        "    # creating model\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_name_or_path)\n",
        "    model = get_peft_model(model, peft_config)\n",
        "    model.print_trainable_parameters()\n",
        "\n",
        "    # optimizer\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "\n",
        "    # lr scheduler\n",
        "    lr_scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer=optimizer,\n",
        "        num_warmup_steps=0,\n",
        "        num_training_steps=(len(train_dataloader) * num_epochs),\n",
        "    )\n",
        "\n",
        "    model, train_dataloader, eval_dataloader, test_dataloader, optimizer, lr_scheduler = accelerator.prepare(\n",
        "        model, train_dataloader, eval_dataloader, test_dataloader, optimizer, lr_scheduler\n",
        "    )\n",
        "    accelerator.print(model)\n",
        "\n",
        "    is_ds_zero_3 = False\n",
        "    if getattr(accelerator.state, \"deepspeed_plugin\", None):\n",
        "        is_ds_zero_3 = accelerator.state.deepspeed_plugin.zero_stage == 3\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        with TorchTracemalloc() as tracemalloc:\n",
        "            model.train()\n",
        "            total_loss = 0\n",
        "            for step, batch in enumerate(tqdm(train_dataloader)):\n",
        "                outputs = model(**batch)\n",
        "                loss = outputs.loss\n",
        "                total_loss += loss.detach().float()\n",
        "                accelerator.backward(loss)\n",
        "                optimizer.step()\n",
        "                lr_scheduler.step()\n",
        "                optimizer.zero_grad()\n",
        "        # Printing the GPU memory usage details such as allocated memory, peak memory, and total memory usage\n",
        "        accelerator.print(f\"GPU Memory before entering the train : {b2mb(tracemalloc.begin)}\")\n",
        "        accelerator.print(f\"GPU Memory consumed at the end of the train (end-begin): {tracemalloc.used}\")\n",
        "        accelerator.print(f\"GPU Peak Memory consumed during the train (max-begin): {tracemalloc.peaked}\")\n",
        "        accelerator.print(\n",
        "            f\"GPU Total Peak Memory consumed during the train (max): {tracemalloc.peaked + b2mb(tracemalloc.begin)}\"\n",
        "        )\n",
        "\n",
        "        accelerator.print(f\"CPU Memory before entering the train : {b2mb(tracemalloc.cpu_begin)}\")\n",
        "        accelerator.print(f\"CPU Memory consumed at the end of the train (end-begin): {tracemalloc.cpu_used}\")\n",
        "        accelerator.print(f\"CPU Peak Memory consumed during the train (max-begin): {tracemalloc.cpu_peaked}\")\n",
        "        accelerator.print(\n",
        "            f\"CPU Total Peak Memory consumed during the train (max): {tracemalloc.cpu_peaked + b2mb(tracemalloc.cpu_begin)}\"\n",
        "        )\n",
        "        train_epoch_loss = total_loss / len(train_dataloader)\n",
        "        train_ppl = torch.exp(train_epoch_loss)\n",
        "        accelerator.print(f\"{epoch=}: {train_ppl=} {train_epoch_loss=}\")\n",
        "\n",
        "        model.eval()\n",
        "        eval_preds = []\n",
        "        with TorchTracemalloc() as tracemalloc:\n",
        "            for _, batch in enumerate(tqdm(eval_dataloader)):\n",
        "                batch = {k: v for k, v in batch.items() if k != \"labels\"}\n",
        "                with torch.no_grad():\n",
        "                    outputs = accelerator.unwrap_model(model).generate(\n",
        "                        **batch, synced_gpus=is_ds_zero_3, max_new_tokens=10\n",
        "                    )  # synced_gpus=True for DS-stage 3\n",
        "                outputs = accelerator.pad_across_processes(outputs, dim=1, pad_index=tokenizer.pad_token_id)\n",
        "                preds = accelerator.gather_for_metrics(outputs)\n",
        "                preds = preds[:, max_length:].detach().cpu().numpy()\n",
        "                eval_preds.extend(tokenizer.batch_decode(preds, skip_special_tokens=True))\n",
        "\n",
        "        # Printing the GPU memory usage details such as allocated memory, peak memory, and total memory usage\n",
        "        accelerator.print(f\"GPU Memory before entering the eval : {b2mb(tracemalloc.begin)}\")\n",
        "        accelerator.print(f\"GPU Memory consumed at the end of the eval (end-begin): {tracemalloc.used}\")\n",
        "        accelerator.print(f\"GPU Peak Memory consumed during the eval (max-begin): {tracemalloc.peaked}\")\n",
        "        accelerator.print(\n",
        "            f\"GPU Total Peak Memory consumed during the eval (max): {tracemalloc.peaked + b2mb(tracemalloc.begin)}\"\n",
        "        )\n",
        "\n",
        "        accelerator.print(f\"CPU Memory before entering the eval : {b2mb(tracemalloc.cpu_begin)}\")\n",
        "        accelerator.print(f\"CPU Memory consumed at the end of the eval (end-begin): {tracemalloc.cpu_used}\")\n",
        "        accelerator.print(f\"CPU Peak Memory consumed during the eval (max-begin): {tracemalloc.cpu_peaked}\")\n",
        "        accelerator.print(\n",
        "            f\"CPU Total Peak Memory consumed during the eval (max): {tracemalloc.cpu_peaked + b2mb(tracemalloc.cpu_begin)}\"\n",
        "        )\n",
        "\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        assert len(eval_preds) == len(\n",
        "            dataset[\"train\"][label_column]\n",
        "        ), f\"{len(eval_preds)} != {len(dataset['train'][label_column])}\"\n",
        "        for pred, true in zip(eval_preds, dataset[\"train\"][label_column]):\n",
        "            if pred.strip() == true.strip():\n",
        "                correct += 1\n",
        "            total += 1\n",
        "        accuracy = correct / total * 100\n",
        "        accelerator.print(f\"{accuracy=}\")\n",
        "        accelerator.print(f\"{eval_preds[:10]=}\")\n",
        "        accelerator.print(f\"{dataset['train'][label_column][:10]=}\")\n",
        "\n",
        "    if do_test:\n",
        "        model.eval()\n",
        "        test_preds = []\n",
        "        for _, batch in enumerate(tqdm(test_dataloader)):\n",
        "            batch = {k: v for k, v in batch.items() if k != \"labels\"}\n",
        "            with torch.no_grad():\n",
        "                outputs = accelerator.unwrap_model(model).generate(\n",
        "                    **batch, synced_gpus=is_ds_zero_3, max_new_tokens=10\n",
        "                )  # synced_gpus=True for DS-stage 3\n",
        "            outputs = accelerator.pad_across_processes(outputs, dim=1, pad_index=tokenizer.pad_token_id)\n",
        "            preds = accelerator.gather(outputs)\n",
        "            preds = preds[:, max_length:].detach().cpu().numpy()\n",
        "            test_preds.extend(tokenizer.batch_decode(preds, skip_special_tokens=True))\n",
        "\n",
        "        test_preds_cleaned = []\n",
        "        for _, pred in enumerate(test_preds):\n",
        "            test_preds_cleaned.append(get_closest_label(pred, classes))\n",
        "\n",
        "        test_df = dataset[\"train\"].to_pandas()\n",
        "        assert len(test_preds_cleaned) == len(test_df), f\"{len(test_preds_cleaned)} != {len(test_df)}\"\n",
        "        test_df[label_column] = test_preds_cleaned\n",
        "        test_df[\"text_labels_orig\"] = test_preds\n",
        "        accelerator.print(test_df[[text_column, label_column]].sample(20))\n",
        "\n",
        "        pred_df = test_df[[\"ID\", label_column]]\n",
        "        pred_df.columns = [\"ID\", \"Label\"]\n",
        "\n",
        "        os.makedirs(f\"data/{dataset_name}\", exist_ok=True)\n",
        "        pred_df.to_csv(f\"data/{dataset_name}/predictions.csv\", index=False)\n",
        "\n",
        "    accelerator.wait_for_everyone()\n",
        "    # Option1: Pushing the model to Hugging Face Hub\n",
        "    # model.push_to_hub(\n",
        "    #     f\"{dataset_name}_{model_name_or_path}_{peft_config.peft_type}_{peft_config.task_type}\".replace(\"/\", \"_\"),\n",
        "    #     token = \"hf_...\"\n",
        "    # )\n",
        "    # token (`bool` or `str`, *optional*):\n",
        "    #     `token` is to be used for HTTP Bearer authorization when accessing remote files. If `True`, will use the token generated\n",
        "    #     when running `huggingface-cli login` (stored in `~/.huggingface`). Will default to `True` if `repo_url`\n",
        "    #     is not specified.\n",
        "    #     Or you can get your token from https://huggingface.co/settings/token\n",
        "    # Option2: Saving the model locally\n",
        "    peft_model_id = f\"{dataset_name}_{model_name_or_path}_{peft_config.peft_type}_{peft_config.task_type}\".replace(\n",
        "        \"/\", \"_\"\n",
        "    )\n",
        "    model.save_pretrained(peft_model_id)\n",
        "    accelerator.wait_for_everyone()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvWuxjytjhYc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2rJMsNmjhVC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MB2LpR5tjhSb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JepBSM0RjhPR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZNjVyLWjhMg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
        "os.environ[\"WANDB_PROJECT\"] = \"PeftExamples\"\n",
        "import transformers\n",
        "from peft import (\n",
        "    LoraConfig,\n",
        "    PeftConfig,\n",
        "    PeftModel,\n",
        "    get_peft_model,\n",
        "    prepare_model_for_kbit_training,\n",
        ")\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    HfArgumentParser,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    default_data_collator,\n",
        ")\n",
        "import torch\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Optional\n",
        "# from dataclass_csv import DataclassReader\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from enum import Enum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eI6PINt7jrBN"
      },
      "outputs": [],
      "source": [
        "class SpecialTokens(str, Enum):\n",
        "    begin_target = \"<|begintarget|>\"\n",
        "    end_target = \"<|endtarget|>\"\n",
        "    begin_context = \"<|begincontext|>\"\n",
        "    end_context = \"<|endcontext|>\"\n",
        "    system = \"<|system|>\"\n",
        "    user = \"<|user|>\"\n",
        "    begin_last_user_utterance = \"<|beginlastuserutterance|>\"\n",
        "    end_last_user_utterance = \"<|endlastuserutterance|>\"\n",
        "    begin_dsts = \"<|begindsts|>\"\n",
        "    end_dsts = \"<|enddsts|>\"\n",
        "    begin_dst = \"<|begindst|>\"\n",
        "    end_dst = \"<|enddst|>\"\n",
        "    begin_belief = \"<|beginbelief|>\"\n",
        "    end_belief = \"<|endbelief|>\"\n",
        "    begin_response = \"<|beginresponse|>\"\n",
        "    end_response = \"<|endresponse|>\"\n",
        "    begin_action = \"<|beginaction|>\"\n",
        "    end_action = \"<|endaction|>\"\n",
        "    begin_user_action = \"<|beginuseraction|>\"\n",
        "    end_user_action = \"<|enduseraction|>\"\n",
        "    sys_actions = \"<|sysactions|>\"\n",
        "    begin_intent = \"<|beginintent|>\"\n",
        "    end_intent = \"<|endintent|>\"\n",
        "    begin_requested_slots = \"<|beginrequestedslots|>\"\n",
        "    end_requested_slots = \"<|endrequestedslots|>\"\n",
        "    pad_token = \"<|pad|>\"\n",
        "    bos_token = \"<|startoftext|>\"\n",
        "\n",
        "    @classmethod\n",
        "    def list(cls):\n",
        "        return [c.value for c in cls]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1E9uyCAjyvc",
        "outputId": "f65853bc-cae8-4307-89e2-846fe8cbaade"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Embedding(32027, 2048)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_name =\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_name,\n",
        "    pad_token=SpecialTokens.pad_token.value,\n",
        "    bos_token=SpecialTokens.bos_token.value,\n",
        "    eos_token=SpecialTokens.end_target.value,\n",
        "    additional_special_tokens=SpecialTokens.list(),\n",
        ")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    low_cpu_mem_usage=True\n",
        "    # use_flash_attention_2=True, # leading to an error\n",
        ")\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nz2V4-cekCEp",
        "outputId": "d4858628-c215-4c23-fc75-9b61d856d434"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 13,372,800 || all params: 1,113,531,776 || trainable%: 1.200935643528506\n",
            "None\n",
            "PeftModel(\n",
            "  (base_model): LoraModel(\n",
            "    (model): LlamaForCausalLM(\n",
            "      (model): LlamaModel(\n",
            "        (embed_tokens): lora.Embedding(\n",
            "          (base_layer): Embedding(32027, 2048)\n",
            "          (lora_dropout): ModuleDict(\n",
            "            (default): Identity()\n",
            "          )\n",
            "          (lora_A): ModuleDict()\n",
            "          (lora_B): ModuleDict()\n",
            "          (lora_embedding_A): ParameterDict(  (default): Parameter containing: [torch.FloatTensor of size 64x32027])\n",
            "          (lora_embedding_B): ParameterDict(  (default): Parameter containing: [torch.FloatTensor of size 2048x64])\n",
            "        )\n",
            "        (layers): ModuleList(\n",
            "          (0-21): 22 x LlamaDecoderLayer(\n",
            "            (self_attn): LlamaSdpaAttention(\n",
            "              (q_proj): lora.Linear(\n",
            "                (base_layer): Linear(in_features=2048, out_features=2048, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Identity()\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=2048, out_features=64, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=64, out_features=2048, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "              )\n",
            "              (k_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
            "              (v_proj): lora.Linear(\n",
            "                (base_layer): Linear(in_features=2048, out_features=256, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Identity()\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=2048, out_features=64, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=64, out_features=256, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "              )\n",
            "              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
            "              (rotary_emb): LlamaRotaryEmbedding()\n",
            "            )\n",
            "            (mlp): LlamaMLP(\n",
            "              (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
            "              (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
            "              (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
            "              (act_fn): SiLU()\n",
            "            )\n",
            "            (input_layernorm): LlamaRMSNorm()\n",
            "            (post_attention_layernorm): LlamaRMSNorm()\n",
            "          )\n",
            "        )\n",
            "        (norm): LlamaRMSNorm()\n",
            "      )\n",
            "      (lm_head): lora.Linear(\n",
            "        (base_layer): Linear(in_features=2048, out_features=32027, bias=False)\n",
            "        (lora_dropout): ModuleDict(\n",
            "          (default): Identity()\n",
            "        )\n",
            "        (lora_A): ModuleDict(\n",
            "          (default): Linear(in_features=2048, out_features=64, bias=False)\n",
            "        )\n",
            "        (lora_B): ModuleDict(\n",
            "          (default): Linear(in_features=64, out_features=32027, bias=False)\n",
            "        )\n",
            "        (lora_embedding_A): ParameterDict()\n",
            "        (lora_embedding_B): ParameterDict()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "config = LoraConfig(\n",
        "    r=64, lora_alpha=128, lora_dropout=0.0, target_modules=[\"embed_tokens\", \"lm_head\", \"q_proj\", \"v_proj\"]\n",
        ")\n",
        "model = get_peft_model(model, config)\n",
        "print(model.print_trainable_parameters())\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "71fdc3523c0a4867a51f92dbc535b553",
            "3b2e071d27aa4ce98d465e7bf9246f13",
            "9edf3423e6ba44a0b9b9b09340690a3c",
            "cdc26990d23b494fafe043340066a883",
            "0e7d8ffb0a7d4e9ba300586a19b13d98",
            "28fa6504421549ed8b084fc0d733c595",
            "b3cff0da2d21462db0c6ce223e269bca",
            "eed2c2e2827e42849bf9b41d5b475594",
            "d3daba82faec46bb82f1ca994b8e5c34",
            "6d90a22a2e544f5d8592f3bee226c1b1",
            "c91cb675fe5b4c768e2373b768e73c78"
          ]
        },
        "id": "W7kHf0aSkIa3",
        "outputId": "5ad549c4-3956-4bf5-938a-e3682ea81c36"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "71fdc3523c0a4867a51f92dbc535b553",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running tokenizer on dataset:   0%|          | 0/153 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "model_name_or_path = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "tokenizer_name_or_path = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "dataset_name = \"fka/awesome-chatgpt-prompts\"\n",
        "text_column = \"act\"\n",
        "label_column = \"prompt\"\n",
        "lr = 3e-3\n",
        "num_epochs = 20\n",
        "batch_size = 8\n",
        "seed = 42\n",
        "max_length = 64\n",
        "do_test = False\n",
        "set_seed(seed)\n",
        "dataset = load_dataset(dataset_name)\n",
        "max_length = 512\n",
        "\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    batch_size = len(examples[text_column])\n",
        "    targets = [str(x) for x in examples[label_column]]\n",
        "    model_inputs = tokenizer(examples[text_column])\n",
        "    labels = tokenizer(targets, add_special_tokens=False)  # don't add bos token because we concatenate with inputs\n",
        "    for i in range(batch_size):\n",
        "        sample_input_ids = model_inputs[\"input_ids\"][i]\n",
        "        label_input_ids = labels[\"input_ids\"][i] + [tokenizer.eos_token_id]\n",
        "        # print(i, sample_input_ids, label_input_ids)\n",
        "        model_inputs[\"input_ids\"][i] = sample_input_ids + label_input_ids\n",
        "        labels[\"input_ids\"][i] = [-100] * len(sample_input_ids) + label_input_ids\n",
        "        model_inputs[\"attention_mask\"][i] = [1] * len(model_inputs[\"input_ids\"][i])\n",
        "    # print(model_inputs)\n",
        "    for i in range(batch_size):\n",
        "        sample_input_ids = model_inputs[\"input_ids\"][i]\n",
        "        label_input_ids = labels[\"input_ids\"][i]\n",
        "        model_inputs[\"input_ids\"][i] = [tokenizer.pad_token_id] * (\n",
        "            max_length - len(sample_input_ids)\n",
        "        ) + sample_input_ids\n",
        "        model_inputs[\"attention_mask\"][i] = [0] * (max_length - len(sample_input_ids)) + model_inputs[\n",
        "            \"attention_mask\"\n",
        "        ][i]\n",
        "        labels[\"input_ids\"][i] = [-100] * (max_length - len(sample_input_ids)) + label_input_ids\n",
        "        model_inputs[\"input_ids\"][i] = model_inputs[\"input_ids\"][i][:max_length]\n",
        "        model_inputs[\"attention_mask\"][i] = model_inputs[\"attention_mask\"][i][:max_length]\n",
        "        labels[\"input_ids\"][i] = labels[\"input_ids\"][i][:max_length]\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "\n",
        "processed_datasets = dataset.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    num_proc=1,\n",
        "    remove_columns=dataset[\"train\"].column_names,\n",
        "    load_from_cache_file=False,\n",
        "    desc=\"Running tokenizer on dataset\",\n",
        ")\n",
        "\n",
        "train_dataset = processed_datasets[\"train\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmaZyI_bkUQC"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(\n",
        "    train_dataset, shuffle=True, collate_fn=default_data_collator, batch_size=8, pin_memory=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "ylhImmNdkaun",
        "outputId": "c6306d7f-abb7-4c3a-c889-e8223c906a50"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [38/38 04:21, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.751100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>2.707700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>2.660200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=38, training_loss=2.6866660369069955, metrics={'train_runtime': 269.1645, 'train_samples_per_second': 1.137, 'train_steps_per_second': 0.141, 'total_flos': 978659038986240.0, 'train_loss': 2.6866660369069955, 'epoch': 2.0})"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"mistral_lora_clm_with_added_tokens\",\n",
        "    num_train_epochs=2,\n",
        "    save_total_limit=5,\n",
        "    per_device_train_batch_size=8,\n",
        "    warmup_steps=10,\n",
        "    weight_decay=0.0001,\n",
        "    dataloader_drop_last=True,\n",
        "    # bf16=True,\n",
        "    logging_steps=10,\n",
        "    learning_rate=1e-5,\n",
        "    gradient_checkpointing=True,\n",
        "    gradient_checkpointing_kwargs={\"use_reentrant\": False},\n",
        "    remove_unused_columns=False,\n",
        "    # hub_model_id=\"smangrul/mistral_lora_clm_with_added_tokens\",\n",
        "    # push_to_hub=True,\n",
        "    # hub_private_repo=True,\n",
        ")\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    data_collator=default_data_collator,\n",
        ")\n",
        "# model.config.use_cache = False\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cETxKT4rguO",
        "outputId": "e70c666d-d35f-4d5b-b9da-5bc829613a25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "context=\"I want you to act as a spoken English teacher and improver. I will speak to you in English and you will reply to me in English to practice my spoken English. I want you to keep your reply neat, limiting the reply to 100 words. I want you to strictly correct my grammar mistakes, typos, and factual errors. I want you to ask me a question in your reply. Now let's start practicing, you could ask me a question first. Remember, I want you to strictly correct my grammar mistakes, typos, and factual errors.\" \n",
            "\n",
            " target_predicted=[\"<|startoftext|> I want you to act as a spoken English teacher and improver. I will speak to you in English and you will reply to me in English to practice my spoken English. I want you to keep your reply neat, limiting the reply to 100 words. I want you to strictly correct my grammar mistakes, typos, and factual errors. I want you to ask me a question in your reply. Now let's start practicing, you could ask me a question first. Remember, I want you to strictly correct my grammar mistakes, typos, and factual errors. I want you to ask me a question first. Now let's start practicing, you could ask me a question first. Remember, I want you to strictly correct my grammar mistakes, typos, and factual errors. I want you to keep your reply neat, limiting the reply to 100 words. I want you to strictly correct my grammar mistakes, typos, and factual errors. I want you to ask me a question first. Now let's start practicing, you could ask me a question first. Remember, I want you to strictly correct my grammar mistakes, typos, and factual errors. I want you to keep your reply neat, limiting the reply to 100 words. I want you to strictly correct my grammar mistakes, typos, and factual errors. I want you to ask me a question first. Now let's start practicing, you could ask me a question first. Remember, I want you to strictly correct my grammar mistakes, typos, and factual errors. I want you to keep your reply neat, limiting the reply to 100 words. I want you to strictly correct my grammar mistakes, typos, and factual errors. I want you to\"] \n",
            "\n",
            " target=\"I want you to act as a spoken English teacher and improver. I will speak to you in English and you will reply to me in English to practice my spoken English. I want you to keep your reply neat, limiting the reply to 100 words. I want you to strictly correct my grammar mistakes, typos, and factual errors. I want you to ask me a question in your reply. Now let's start practicing, you could ask me a question first. Remember, I want you to strictly correct my grammar mistakes, typos, and factual errors.\"\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "i = random.randint(0, len(dataset[\"train\"]))\n",
        "context = dataset[\"train\"][i][\"prompt\"]\n",
        "\n",
        "batch = tokenizer(context, return_tensors=\"pt\")\n",
        "batch = {k: v.to(\"cuda\") for k, v in batch.items()}\n",
        "model.eval()\n",
        "output_tokens = model.generate(\n",
        "    **batch,\n",
        "    max_new_tokens=256,\n",
        "    do_sample=True,\n",
        "    temperature=0.2,\n",
        "    top_p=0.95,\n",
        "    top_k=50,\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        "    pad_token_id=tokenizer.pad_token_id,\n",
        ")\n",
        "target_predicted = tokenizer.decode(output_tokens[0], skip_special_tokens=False).split(\"<|endcontext|>\")\n",
        "target = dataset[\"train\"][i][\"prompt\"]\n",
        "print(f\"{context=} \\n\\n {target_predicted=} \\n\\n {target=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBTgncn7sA4E"
      },
      "outputs": [],
      "source": [
        "from peft import PeftModel\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "inference_model = AutoModelForCausalLM.from_pretrained(\n",
        "   'TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
        "    low_cpu_mem_usage=True,\n",
        "    # use_flash_attention_2=True,\n",
        ")\n",
        "\n",
        "model_name =\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "inference_model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "inference_model = PeftModel.from_pretrained(inference_model, \"/content/mistral_lora_clm_with_added_tokens/runs/Mar22_15-00-17_bfac4f730ff8\")\n",
        "inference_model.to(\"cuda\")\n",
        "inference_model.eval()\n",
        "\n",
        "output_tokens = inference_model.generate(\n",
        "    **batch,\n",
        "    max_new_tokens=256,\n",
        "    do_sample=True,\n",
        "    temperature=0.2,\n",
        "    top_p=0.95,\n",
        "    top_k=50,\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        "    pad_token_id=tokenizer.pad_token_id,\n",
        ")\n",
        "\n",
        "target_predicted = tokenizer.decode(output_tokens[0], skip_special_tokens=False).split(\"<|endcontext|>\")\n",
        "print(f\"{context=} \\n\\n {target_predicted=} \\n\\n {target=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ud7F_Sjs2r5"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM\n",
        "from peft import get_peft_config, get_peft_model, PromptTuningInit, PromptTuningConfig, TaskType, PeftType\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "import os\n",
        "from transformers import AutoTokenizer\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import default_data_collator, get_linear_schedule_with_warmup\n",
        "from tqdm import tqdm\n",
        "from datasets import load_dataset\n",
        "\n",
        "device = \"cuda\"\n",
        "model_name_or_path = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "tokenizer_name_or_path = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "dataset_name = \"fka/awesome-chatgpt-prompts\"\n",
        "text_column = \"act\"\n",
        "label_column = \"prompt\"\n",
        "peft_config = PromptTuningConfig(\n",
        "    task_type=TaskType.CAUSAL_LM,\n",
        "    prompt_tuning_init=PromptTuningInit.TEXT,\n",
        "    num_virtual_tokens=8,\n",
        "    prompt_tuning_init_text=\"Classify if the tweet is a complaint or not:\",\n",
        "    tokenizer_name_or_path=model_name_or_path,\n",
        ")\n",
        "\n",
        "checkpoint_name = f\"{dataset_name}_{model_name_or_path}_{peft_config.peft_type}_{peft_config.task_type}_v1.pt\".replace(\n",
        "    \"/\", \"_\"\n",
        ")\n",
        "\n",
        "max_length = 64\n",
        "lr = 3e-2\n",
        "num_epochs = 50\n",
        "batch_size = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhT_QYOevJX0"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset( dataset_name)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "5be0bc61ce4249278604c8ef8b2d9263",
            "c50bf16e1f954d0c989dc4e3eefae919",
            "7fa56300652a409a97d3de12c0c571cb",
            "219d19ec57bb41d0afa69d1eedff02ce",
            "5fe9390c81684e0287c47fa9d6599555",
            "6611266679704ea792eaeb4634035360",
            "cafc5260128741f699b64c2288836a9b",
            "0712f438b3c34b4ea136aa80a88a952d",
            "7a72abeb05e04180a8182d90d3182b77",
            "2574e71c4aaf4f93932d71915eaf214b",
            "fd54fc3231144427a87f34710c81554f"
          ]
        },
        "id": "lAL5EG7PvPee",
        "outputId": "256f0eb8-00c3-428f-907e-4300b5f7f055"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5be0bc61ce4249278604c8ef8b2d9263",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running tokenizer on dataset:   0%|          | 0/153 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# data preprocessing\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
        "if tokenizer.pad_token_id is None:\n",
        "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "# target_max_length = max([len(tokenizer(class_label)[\"input_ids\"]) for class_label in classes])\n",
        "# print(target_max_length)\n",
        "\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    batch_size = len(examples[text_column])\n",
        "    inputs = [f\"{text_column} : {x} Label : \" for x in examples[text_column]]\n",
        "    targets = [str(x) for x in examples[label_column]]\n",
        "    model_inputs = tokenizer(inputs)\n",
        "    labels = tokenizer(targets, add_special_tokens=False)  # don't add bos token because we concatenate with inputs\n",
        "    for i in range(batch_size):\n",
        "        sample_input_ids = model_inputs[\"input_ids\"][i]\n",
        "        label_input_ids = labels[\"input_ids\"][i] + [tokenizer.eos_token_id]\n",
        "        # print(i, sample_input_ids, label_input_ids)\n",
        "        model_inputs[\"input_ids\"][i] = sample_input_ids + label_input_ids\n",
        "        labels[\"input_ids\"][i] = [-100] * len(sample_input_ids) + label_input_ids\n",
        "        model_inputs[\"attention_mask\"][i] = [1] * len(model_inputs[\"input_ids\"][i])\n",
        "    # print(model_inputs)\n",
        "    for i in range(batch_size):\n",
        "        sample_input_ids = model_inputs[\"input_ids\"][i]\n",
        "        label_input_ids = labels[\"input_ids\"][i]\n",
        "        model_inputs[\"input_ids\"][i] = [tokenizer.pad_token_id] * (\n",
        "            max_length - len(sample_input_ids)\n",
        "        ) + sample_input_ids\n",
        "        model_inputs[\"attention_mask\"][i] = [0] * (max_length - len(sample_input_ids)) + model_inputs[\n",
        "            \"attention_mask\"\n",
        "        ][i]\n",
        "        labels[\"input_ids\"][i] = [-100] * (max_length - len(sample_input_ids)) + label_input_ids\n",
        "        model_inputs[\"input_ids\"][i] = torch.tensor(model_inputs[\"input_ids\"][i][:max_length])\n",
        "        model_inputs[\"attention_mask\"][i] = torch.tensor(model_inputs[\"attention_mask\"][i][:max_length])\n",
        "        labels[\"input_ids\"][i] = torch.tensor(labels[\"input_ids\"][i][:max_length])\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "\n",
        "processed_datasets = dataset.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    num_proc=1,\n",
        "    remove_columns=dataset[\"train\"].column_names,\n",
        "    load_from_cache_file=False,\n",
        "    desc=\"Running tokenizer on dataset\",\n",
        ")\n",
        "\n",
        "train_dataset = processed_datasets[\"train\"]\n",
        "eval_dataset = processed_datasets[\"train\"]\n",
        "\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset, shuffle=True, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True\n",
        ")\n",
        "eval_dataloader = DataLoader(eval_dataset, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a27d56cf6bf64b93b4affa05dcdbbc10",
            "25e8d597a112483baf71ca21d93ae4ec",
            "b9b90a0c26e046ea82085a044b4d0608",
            "dcdba5025a1d41c0af58f45a069d7591",
            "76b9528f1c2d4204886f819d7bd176db",
            "f49c1c0aa4874ee6b7327faaf7efc70d",
            "8874623ac8d64c74bc25b4366b14424f",
            "32ad61522a0b401293e92d7454651ec0",
            "8234547aff04419fbe011dd3fe79caf0",
            "82115ea9374e4e689553479c495b58ca",
            "6ccdab9ac3ec4afca4602e6057189035"
          ]
        },
        "id": "rQzlo1KRvRd4",
        "outputId": "67e41f40-23ef-4fa1-a4bb-fa674de31d80"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a27d56cf6bf64b93b4affa05dcdbbc10",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running tokenizer on dataset:   0%|          | 0/153 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[    2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     1,  1044,   584,  8074,\n",
              "          29175, 15796,   584, 29871],\n",
              "         [    2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              1,  1044,   584,  4223,  4103, 29880,  1061,   322,  1954,   771,\n",
              "            369, 15796,   584, 29871],\n",
              "         [    2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     1,  1044,   584,   421,  3283, 29952,  4124, 29894,\n",
              "          15580, 15796,   584, 29871],\n",
              "         [    2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     1,  1044,   584,  8286,\n",
              "           9405, 15796,   584, 29871],\n",
              "         [    2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     1,  1044,   584, 11388,  2296,\n",
              "            300, 15796,   584, 29871],\n",
              "         [    2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     1,  1044,   584,  4223,  1588,   265, 11173,   362,  6162,\n",
              "            546, 15796,   584, 29871],\n",
              "         [    2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     1,\n",
              "           1044,   584,  1706,  4476,  4223,  1920, 11665,   322,  1954,   771,\n",
              "            369, 15796,   584, 29871],\n",
              "         [    2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     1,  1044,   584,  3201,   955,\n",
              "          16886, 15796,   584, 29871]]),\n",
              " 'attention_mask': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def test_preprocess_function(examples):\n",
        "    batch_size = len(examples[text_column])\n",
        "    inputs = [f\"{text_column} : {x} Label : \" for x in examples[text_column]]\n",
        "    model_inputs = tokenizer(inputs)\n",
        "    # print(model_inputs)\n",
        "    for i in range(batch_size):\n",
        "        sample_input_ids = model_inputs[\"input_ids\"][i]\n",
        "        model_inputs[\"input_ids\"][i] = [tokenizer.pad_token_id] * (\n",
        "            max_length - len(sample_input_ids)\n",
        "        ) + sample_input_ids\n",
        "        model_inputs[\"attention_mask\"][i] = [0] * (max_length - len(sample_input_ids)) + model_inputs[\n",
        "            \"attention_mask\"\n",
        "        ][i]\n",
        "        model_inputs[\"input_ids\"][i] = torch.tensor(model_inputs[\"input_ids\"][i][:max_length])\n",
        "        model_inputs[\"attention_mask\"][i] = torch.tensor(model_inputs[\"attention_mask\"][i][:max_length])\n",
        "    return model_inputs\n",
        "\n",
        "\n",
        "test_dataset = dataset[\"train\"].map(\n",
        "    test_preprocess_function,\n",
        "    batched=True,\n",
        "    num_proc=1,\n",
        "    remove_columns=dataset[\"train\"].column_names,\n",
        "    load_from_cache_file=False,\n",
        "    desc=\"Running tokenizer on dataset\",\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(test_dataset, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True)\n",
        "next(iter(test_dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATjt8Hv7vdvi",
        "outputId": "da30d800-a281-429b-fd42-4ffa83367e96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 16,384 || all params: 1,100,064,768 || trainable%: 0.0014893668515343272\n"
          ]
        }
      ],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(model_name_or_path)\n",
        "model = get_peft_model(model, peft_config)\n",
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRb6op3LveJ4"
      },
      "outputs": [],
      "source": [
        "# model\n",
        "# optimizer and lr scheduler\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "lr_scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=(len(train_dataloader) * num_epochs),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNwRpSM_vlm1",
        "outputId": "21f86f91-1667-497d-cf4b-b4138c978938"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:15<00:00,  1.30it/s]\n",
            "100%|██████████| 20/20 [00:06<00:00,  2.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=0: train_ppl=tensor(8.5807, device='cuda:0') train_epoch_loss=tensor(2.1495, device='cuda:0') eval_ppl=tensor(7.0712, device='cuda:0') eval_epoch_loss=tensor(1.9560, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:13<00:00,  1.48it/s]\n",
            "100%|██████████| 20/20 [00:07<00:00,  2.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=1: train_ppl=tensor(6.7538, device='cuda:0') train_epoch_loss=tensor(1.9101, device='cuda:0') eval_ppl=tensor(6.4377, device='cuda:0') eval_epoch_loss=tensor(1.8622, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:14<00:00,  1.41it/s]\n",
            "100%|██████████| 20/20 [00:07<00:00,  2.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=2: train_ppl=tensor(6.1472, device='cuda:0') train_epoch_loss=tensor(1.8160, device='cuda:0') eval_ppl=tensor(6.2960, device='cuda:0') eval_epoch_loss=tensor(1.8399, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:14<00:00,  1.36it/s]\n",
            "100%|██████████| 20/20 [00:07<00:00,  2.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=3: train_ppl=tensor(6.1346, device='cuda:0') train_epoch_loss=tensor(1.8139, device='cuda:0') eval_ppl=tensor(5.6530, device='cuda:0') eval_epoch_loss=tensor(1.7322, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:15<00:00,  1.27it/s]\n",
            "100%|██████████| 20/20 [00:08<00:00,  2.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=4: train_ppl=tensor(5.5665, device='cuda:0') train_epoch_loss=tensor(1.7168, device='cuda:0') eval_ppl=tensor(5.4800, device='cuda:0') eval_epoch_loss=tensor(1.7011, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:15<00:00,  1.31it/s]\n",
            "100%|██████████| 20/20 [00:07<00:00,  2.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=5: train_ppl=tensor(5.5232, device='cuda:0') train_epoch_loss=tensor(1.7090, device='cuda:0') eval_ppl=tensor(5.1361, device='cuda:0') eval_epoch_loss=tensor(1.6363, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:14<00:00,  1.34it/s]\n",
            "100%|██████████| 20/20 [00:07<00:00,  2.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=6: train_ppl=tensor(5.3047, device='cuda:0') train_epoch_loss=tensor(1.6686, device='cuda:0') eval_ppl=tensor(4.9525, device='cuda:0') eval_epoch_loss=tensor(1.5999, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:15<00:00,  1.32it/s]\n",
            "100%|██████████| 20/20 [00:08<00:00,  2.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=7: train_ppl=tensor(4.8086, device='cuda:0') train_epoch_loss=tensor(1.5704, device='cuda:0') eval_ppl=tensor(4.8984, device='cuda:0') eval_epoch_loss=tensor(1.5889, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:15<00:00,  1.30it/s]\n",
            "100%|██████████| 20/20 [00:08<00:00,  2.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=8: train_ppl=tensor(5.0380, device='cuda:0') train_epoch_loss=tensor(1.6170, device='cuda:0') eval_ppl=tensor(4.8402, device='cuda:0') eval_epoch_loss=tensor(1.5770, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:15<00:00,  1.31it/s]\n",
            "100%|██████████| 20/20 [00:07<00:00,  2.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=9: train_ppl=tensor(4.8825, device='cuda:0') train_epoch_loss=tensor(1.5857, device='cuda:0') eval_ppl=tensor(4.6002, device='cuda:0') eval_epoch_loss=tensor(1.5261, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:15<00:00,  1.33it/s]\n",
            "100%|██████████| 20/20 [00:07<00:00,  2.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=10: train_ppl=tensor(4.8179, device='cuda:0') train_epoch_loss=tensor(1.5723, device='cuda:0') eval_ppl=tensor(4.3784, device='cuda:0') eval_epoch_loss=tensor(1.4767, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:15<00:00,  1.31it/s]\n",
            "100%|██████████| 20/20 [00:08<00:00,  2.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=11: train_ppl=tensor(4.6269, device='cuda:0') train_epoch_loss=tensor(1.5319, device='cuda:0') eval_ppl=tensor(4.3672, device='cuda:0') eval_epoch_loss=tensor(1.4741, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:15<00:00,  1.31it/s]\n",
            "100%|██████████| 20/20 [00:07<00:00,  2.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=12: train_ppl=tensor(4.4151, device='cuda:0') train_epoch_loss=tensor(1.4850, device='cuda:0') eval_ppl=tensor(4.1731, device='cuda:0') eval_epoch_loss=tensor(1.4287, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:15<00:00,  1.31it/s]\n",
            "100%|██████████| 20/20 [00:07<00:00,  2.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=13: train_ppl=tensor(4.1521, device='cuda:0') train_epoch_loss=tensor(1.4236, device='cuda:0') eval_ppl=tensor(4.0181, device='cuda:0') eval_epoch_loss=tensor(1.3908, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:15<00:00,  1.32it/s]\n",
            "100%|██████████| 20/20 [00:07<00:00,  2.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=14: train_ppl=tensor(4.3229, device='cuda:0') train_epoch_loss=tensor(1.4639, device='cuda:0') eval_ppl=tensor(4.2462, device='cuda:0') eval_epoch_loss=tensor(1.4460, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:15<00:00,  1.31it/s]\n",
            "100%|██████████| 20/20 [00:08<00:00,  2.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=15: train_ppl=tensor(4.1879, device='cuda:0') train_epoch_loss=tensor(1.4322, device='cuda:0') eval_ppl=tensor(4.1321, device='cuda:0') eval_epoch_loss=tensor(1.4188, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:15<00:00,  1.31it/s]\n",
            "100%|██████████| 20/20 [00:07<00:00,  2.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=16: train_ppl=tensor(4.2265, device='cuda:0') train_epoch_loss=tensor(1.4414, device='cuda:0') eval_ppl=tensor(3.8579, device='cuda:0') eval_epoch_loss=tensor(1.3501, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:15<00:00,  1.32it/s]\n",
            "100%|██████████| 20/20 [00:07<00:00,  2.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=17: train_ppl=tensor(4.1321, device='cuda:0') train_epoch_loss=tensor(1.4188, device='cuda:0') eval_ppl=tensor(3.8291, device='cuda:0') eval_epoch_loss=tensor(1.3426, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:15<00:00,  1.31it/s]\n",
            "100%|██████████| 20/20 [00:07<00:00,  2.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=18: train_ppl=tensor(3.9126, device='cuda:0') train_epoch_loss=tensor(1.3642, device='cuda:0') eval_ppl=tensor(3.6770, device='cuda:0') eval_epoch_loss=tensor(1.3021, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:15<00:00,  1.31it/s]\n",
            "100%|██████████| 20/20 [00:07<00:00,  2.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=19: train_ppl=tensor(3.7646, device='cuda:0') train_epoch_loss=tensor(1.3256, device='cuda:0') eval_ppl=tensor(3.5800, device='cuda:0') eval_epoch_loss=tensor(1.2754, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:15<00:00,  1.31it/s]\n",
            "100%|██████████| 20/20 [00:07<00:00,  2.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=20: train_ppl=tensor(3.5813, device='cuda:0') train_epoch_loss=tensor(1.2757, device='cuda:0') eval_ppl=tensor(3.4755, device='cuda:0') eval_epoch_loss=tensor(1.2457, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:15<00:00,  1.32it/s]\n",
            "100%|██████████| 20/20 [00:07<00:00,  2.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=21: train_ppl=tensor(3.7157, device='cuda:0') train_epoch_loss=tensor(1.3126, device='cuda:0') eval_ppl=tensor(3.4084, device='cuda:0') eval_epoch_loss=tensor(1.2262, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:15<00:00,  1.31it/s]\n",
            "100%|██████████| 20/20 [00:07<00:00,  2.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=22: train_ppl=tensor(3.4850, device='cuda:0') train_epoch_loss=tensor(1.2485, device='cuda:0') eval_ppl=tensor(3.3464, device='cuda:0') eval_epoch_loss=tensor(1.2079, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:15<00:00,  1.31it/s]\n",
            "100%|██████████| 20/20 [00:07<00:00,  2.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=23: train_ppl=tensor(3.5949, device='cuda:0') train_epoch_loss=tensor(1.2795, device='cuda:0') eval_ppl=tensor(3.3802, device='cuda:0') eval_epoch_loss=tensor(1.2179, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:15<00:00,  1.31it/s]\n",
            "100%|██████████| 20/20 [00:07<00:00,  2.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=24: train_ppl=tensor(3.3701, device='cuda:0') train_epoch_loss=tensor(1.2149, device='cuda:0') eval_ppl=tensor(3.5044, device='cuda:0') eval_epoch_loss=tensor(1.2540, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:15<00:00,  1.32it/s]\n",
            "100%|██████████| 20/20 [00:07<00:00,  2.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=25: train_ppl=tensor(3.4125, device='cuda:0') train_epoch_loss=tensor(1.2274, device='cuda:0') eval_ppl=tensor(3.2500, device='cuda:0') eval_epoch_loss=tensor(1.1787, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:15<00:00,  1.32it/s]\n",
            "100%|██████████| 20/20 [00:07<00:00,  2.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=26: train_ppl=tensor(3.3182, device='cuda:0') train_epoch_loss=tensor(1.1994, device='cuda:0') eval_ppl=tensor(3.2453, device='cuda:0') eval_epoch_loss=tensor(1.1772, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:15<00:00,  1.32it/s]\n",
            "100%|██████████| 20/20 [00:07<00:00,  2.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=27: train_ppl=tensor(3.1693, device='cuda:0') train_epoch_loss=tensor(1.1535, device='cuda:0') eval_ppl=tensor(3.1483, device='cuda:0') eval_epoch_loss=tensor(1.1469, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:15<00:00,  1.32it/s]\n",
            "100%|██████████| 20/20 [00:07<00:00,  2.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=28: train_ppl=tensor(3.1711, device='cuda:0') train_epoch_loss=tensor(1.1541, device='cuda:0') eval_ppl=tensor(3.0065, device='cuda:0') eval_epoch_loss=tensor(1.1008, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:15<00:00,  1.31it/s]\n",
            "100%|██████████| 20/20 [00:07<00:00,  2.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=29: train_ppl=tensor(3.0575, device='cuda:0') train_epoch_loss=tensor(1.1176, device='cuda:0') eval_ppl=tensor(2.9806, device='cuda:0') eval_epoch_loss=tensor(1.0921, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:15<00:00,  1.31it/s]\n",
            "100%|██████████| 20/20 [00:07<00:00,  2.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=30: train_ppl=tensor(3.1056, device='cuda:0') train_epoch_loss=tensor(1.1332, device='cuda:0') eval_ppl=tensor(2.9631, device='cuda:0') eval_epoch_loss=tensor(1.0862, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:15<00:00,  1.31it/s]\n",
            "100%|██████████| 20/20 [00:07<00:00,  2.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=31: train_ppl=tensor(3.0981, device='cuda:0') train_epoch_loss=tensor(1.1308, device='cuda:0') eval_ppl=tensor(3.0730, device='cuda:0') eval_epoch_loss=tensor(1.1227, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:15<00:00,  1.31it/s]\n",
            "100%|██████████| 20/20 [00:07<00:00,  2.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=32: train_ppl=tensor(3.3020, device='cuda:0') train_epoch_loss=tensor(1.1945, device='cuda:0') eval_ppl=tensor(3.0878, device='cuda:0') eval_epoch_loss=tensor(1.1275, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:15<00:00,  1.31it/s]\n",
            "100%|██████████| 20/20 [00:07<00:00,  2.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=33: train_ppl=tensor(2.9770, device='cuda:0') train_epoch_loss=tensor(1.0909, device='cuda:0') eval_ppl=tensor(2.9022, device='cuda:0') eval_epoch_loss=tensor(1.0655, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:15<00:00,  1.31it/s]\n",
            "100%|██████████| 20/20 [00:07<00:00,  2.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=34: train_ppl=tensor(2.9913, device='cuda:0') train_epoch_loss=tensor(1.0957, device='cuda:0') eval_ppl=tensor(2.8016, device='cuda:0') eval_epoch_loss=tensor(1.0302, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:15<00:00,  1.31it/s]\n",
            "100%|██████████| 20/20 [00:08<00:00,  2.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=35: train_ppl=tensor(2.7794, device='cuda:0') train_epoch_loss=tensor(1.0222, device='cuda:0') eval_ppl=tensor(2.7168, device='cuda:0') eval_epoch_loss=tensor(0.9994, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:15<00:00,  1.31it/s]\n",
            "100%|██████████| 20/20 [00:07<00:00,  2.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=36: train_ppl=tensor(2.9072, device='cuda:0') train_epoch_loss=tensor(1.0672, device='cuda:0') eval_ppl=tensor(2.7077, device='cuda:0') eval_epoch_loss=tensor(0.9961, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:15<00:00,  1.32it/s]\n",
            "100%|██████████| 20/20 [00:07<00:00,  2.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=37: train_ppl=tensor(2.8626, device='cuda:0') train_epoch_loss=tensor(1.0517, device='cuda:0') eval_ppl=tensor(2.7205, device='cuda:0') eval_epoch_loss=tensor(1.0008, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:15<00:00,  1.31it/s]\n",
            "100%|██████████| 20/20 [00:07<00:00,  2.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=38: train_ppl=tensor(2.8047, device='cuda:0') train_epoch_loss=tensor(1.0313, device='cuda:0') eval_ppl=tensor(2.6852, device='cuda:0') eval_epoch_loss=tensor(0.9878, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:15<00:00,  1.31it/s]\n",
            "100%|██████████| 20/20 [00:08<00:00,  2.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=39: train_ppl=tensor(2.6754, device='cuda:0') train_epoch_loss=tensor(0.9841, device='cuda:0') eval_ppl=tensor(2.6361, device='cuda:0') eval_epoch_loss=tensor(0.9693, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:15<00:00,  1.31it/s]\n",
            "100%|██████████| 20/20 [00:07<00:00,  2.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=40: train_ppl=tensor(2.6498, device='cuda:0') train_epoch_loss=tensor(0.9745, device='cuda:0') eval_ppl=tensor(2.5964, device='cuda:0') eval_epoch_loss=tensor(0.9541, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:15<00:00,  1.31it/s]\n",
            "100%|██████████| 20/20 [00:07<00:00,  2.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=41: train_ppl=tensor(2.5631, device='cuda:0') train_epoch_loss=tensor(0.9412, device='cuda:0') eval_ppl=tensor(2.5132, device='cuda:0') eval_epoch_loss=tensor(0.9216, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:15<00:00,  1.31it/s]\n",
            "100%|██████████| 20/20 [00:07<00:00,  2.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=42: train_ppl=tensor(2.5532, device='cuda:0') train_epoch_loss=tensor(0.9373, device='cuda:0') eval_ppl=tensor(2.4818, device='cuda:0') eval_epoch_loss=tensor(0.9090, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:15<00:00,  1.31it/s]\n",
            "100%|██████████| 20/20 [00:07<00:00,  2.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=43: train_ppl=tensor(2.6354, device='cuda:0') train_epoch_loss=tensor(0.9690, device='cuda:0') eval_ppl=tensor(2.4707, device='cuda:0') eval_epoch_loss=tensor(0.9045, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:15<00:00,  1.31it/s]\n",
            "100%|██████████| 20/20 [00:07<00:00,  2.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=44: train_ppl=tensor(2.4433, device='cuda:0') train_epoch_loss=tensor(0.8934, device='cuda:0') eval_ppl=tensor(2.4356, device='cuda:0') eval_epoch_loss=tensor(0.8902, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:15<00:00,  1.31it/s]\n",
            "100%|██████████| 20/20 [00:07<00:00,  2.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=45: train_ppl=tensor(2.4554, device='cuda:0') train_epoch_loss=tensor(0.8983, device='cuda:0') eval_ppl=tensor(2.4137, device='cuda:0') eval_epoch_loss=tensor(0.8811, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:15<00:00,  1.31it/s]\n",
            "100%|██████████| 20/20 [00:07<00:00,  2.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=46: train_ppl=tensor(2.4984, device='cuda:0') train_epoch_loss=tensor(0.9156, device='cuda:0') eval_ppl=tensor(2.3950, device='cuda:0') eval_epoch_loss=tensor(0.8734, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:15<00:00,  1.31it/s]\n",
            "100%|██████████| 20/20 [00:07<00:00,  2.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=47: train_ppl=tensor(2.4562, device='cuda:0') train_epoch_loss=tensor(0.8986, device='cuda:0') eval_ppl=tensor(2.3891, device='cuda:0') eval_epoch_loss=tensor(0.8709, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:15<00:00,  1.31it/s]\n",
            "100%|██████████| 20/20 [00:08<00:00,  2.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=48: train_ppl=tensor(2.3137, device='cuda:0') train_epoch_loss=tensor(0.8388, device='cuda:0') eval_ppl=tensor(2.3726, device='cuda:0') eval_epoch_loss=tensor(0.8640, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:15<00:00,  1.31it/s]\n",
            "100%|██████████| 20/20 [00:07<00:00,  2.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=49: train_ppl=tensor(2.3839, device='cuda:0') train_epoch_loss=tensor(0.8687, device='cuda:0') eval_ppl=tensor(2.3690, device='cuda:0') eval_epoch_loss=tensor(0.8625, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# training and evaluation\n",
        "model = model.to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for step, batch in enumerate(tqdm(train_dataloader)):\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        #         print(batch)\n",
        "        #         print(batch[\"input_ids\"].shape)\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.detach().float()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    model.eval()\n",
        "    eval_loss = 0\n",
        "    eval_preds = []\n",
        "    for step, batch in enumerate(tqdm(eval_dataloader)):\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        eval_loss += loss.detach().float()\n",
        "        eval_preds.extend(\n",
        "            tokenizer.batch_decode(torch.argmax(outputs.logits, -1).detach().cpu().numpy(), skip_special_tokens=True)\n",
        "        )\n",
        "\n",
        "    eval_epoch_loss = eval_loss / len(eval_dataloader)\n",
        "    eval_ppl = torch.exp(eval_epoch_loss)\n",
        "    train_epoch_loss = total_loss / len(train_dataloader)\n",
        "    train_ppl = torch.exp(train_epoch_loss)\n",
        "    print(f\"{epoch=}: {train_ppl=} {train_epoch_loss=} {eval_ppl=} {eval_epoch_loss=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZ4oqYS9vpsE"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "i = 33\n",
        "inputs = tokenizer(f'{text_column} : {dataset[\"train\"][i][\"prompt\"]} Label :  {dataset[\"train\"][i][\"act\"]}', return_tensors=\"pt\")\n",
        "print(dataset[\"train\"][i][\"prompt\"])\n",
        "print(inputs)\n",
        "\n",
        "with torch.no_grad():\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    outputs = model.generate(\n",
        "        input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"], max_new_tokens=10, eos_token_id=3\n",
        "    )\n",
        "    print(outputs)\n",
        "    print(tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmpDM7VSwbJ5"
      },
      "outputs": [],
      "source": [
        "peft_model_id = f\"{dataset_name}_{model_name_or_path}_{peft_config.peft_type}_{peft_config.task_type}\".replace(\n",
        "    \"/\", \"_\"\n",
        ")\n",
        "model.save_pretrained(peft_model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Al31RAJewgfg"
      },
      "outputs": [],
      "source": [
        "from peft import PeftModel, PeftConfig\n",
        "\n",
        "peft_model_id = f\"{dataset_name}_{model_name_or_path}_{peft_config.peft_type}_{peft_config.task_type}\".replace(\n",
        "    \"/\", \"_\"\n",
        ")\n",
        "\n",
        "config = PeftConfig.from_pretrained(peft_model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name_or_path)\n",
        "model = PeftModel.from_pretrained(model, peft_model_id)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "034a33b189564f1884347cea94d82b4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5849c1a16b2d48cd8bbd42fc02a5fb0e",
            "max": 551,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e0ca0b642d10478db945207de3a5e039",
            "value": 551
          }
        },
        "05e7df46090d4fd0882de7d720d6d509": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "061bad2ce7564fa28e1989a49d292de1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0712f438b3c34b4ea136aa80a88a952d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0988296c64cc4d59bbf3479a339e3e88": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e7d8ffb0a7d4e9ba300586a19b13d98": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e9d0a5d38604ccc98f1904ff623cee8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11c42b29aac34f36a8a9caaf2fce28ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ae2ed1ce8424dff87b67b8883cb4e28",
            "placeholder": "​",
            "style": "IPY_MODEL_9ad0a95321f44586b2987dc02ed5128d",
            "value": " 1.29k/1.29k [00:00&lt;00:00, 33.5kB/s]"
          }
        },
        "1406339945a64bbd9dc274ad332795bc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17cd255f720f44e1a4da227cf1fd8edf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1406339945a64bbd9dc274ad332795bc",
            "placeholder": "​",
            "style": "IPY_MODEL_4a3cd173a7b64aa6bfc768bc19f8ed60",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "1f8de8f2968e4d1fa270853f33ff9404": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "20ef7121800246f381230ba670ca4866": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "219d19ec57bb41d0afa69d1eedff02ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2574e71c4aaf4f93932d71915eaf214b",
            "placeholder": "​",
            "style": "IPY_MODEL_fd54fc3231144427a87f34710c81554f",
            "value": " 153/153 [00:00&lt;00:00, 727.32 examples/s]"
          }
        },
        "238f58e4196f42fbbd416d8e2f6af877": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24033a0b9ebb46cd81bd19b195beddd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d56fadbe334e407e846fee5400eae3ed",
            "placeholder": "​",
            "style": "IPY_MODEL_27cb6d25458d4ecf845ad83bf30f1861",
            "value": " 274/274 [00:00&lt;00:00, 4.77kB/s]"
          }
        },
        "2574e71c4aaf4f93932d71915eaf214b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25774abab34341d2b33baf704535cf7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b63cfcef49554333a3e96c13f3ac8c22",
            "placeholder": "​",
            "style": "IPY_MODEL_e04733987cd34abba9bda895903ddb8d",
            "value": "tokenizer.model: 100%"
          }
        },
        "25e8d597a112483baf71ca21d93ae4ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f49c1c0aa4874ee6b7327faaf7efc70d",
            "placeholder": "​",
            "style": "IPY_MODEL_8874623ac8d64c74bc25b4366b14424f",
            "value": "Running tokenizer on dataset: 100%"
          }
        },
        "27cb6d25458d4ecf845ad83bf30f1861": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28e80faa748f4045bdcdb46cee68ca86": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28fa6504421549ed8b084fc0d733c595": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fac44bb1fd842ceade6a016fd7db5a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0d65f3f9d1f4a359392f4d07966a35c",
            "placeholder": "​",
            "style": "IPY_MODEL_a35163dfc53b40c2956c6a37a065e08d",
            "value": "model.safetensors: 100%"
          }
        },
        "2fc457aac30d4757a6c39cfa9641a8e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3106bdc3f1184f28a387383b6e2700d1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "310e64cb60dd4da6afbc0e49aa9525aa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "314084c1fd55456e860bc7d2ba2fbbfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d1848c9750c4838a21abe010e14d553",
            "placeholder": "​",
            "style": "IPY_MODEL_7f1812e72763453ea777b7ba930c348b",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "32ad61522a0b401293e92d7454651ec0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35d9cabd0a9449b9b9e4882ac663773d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36abb851e0fe458ebf4512f135216739": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ad1c9c22c7a44fcbe95314acaac31ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93accef8f43247b8bc0223e88d39d166",
            "placeholder": "​",
            "style": "IPY_MODEL_f0e722c32ce44a52a6ae44b954a9ab63",
            "value": "Downloading data: 100%"
          }
        },
        "3ae2ed1ce8424dff87b67b8883cb4e28": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b2e071d27aa4ce98d465e7bf9246f13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28fa6504421549ed8b084fc0d733c595",
            "placeholder": "​",
            "style": "IPY_MODEL_b3cff0da2d21462db0c6ce223e269bca",
            "value": "Running tokenizer on dataset: 100%"
          }
        },
        "3b428811e93d4924ade432f410b67e11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3bd1239759474ddf8956d3adb90aabeb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d44d7b2413f4df382a8d87a777da03c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f6ece806ddf46e7ab31badeb0d1bba8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_66c0956a1a3a4ecb8e6bcd6812f8982b",
              "IPY_MODEL_fa183d0ad04542f6a64b622bcd3e3105",
              "IPY_MODEL_42a8b7cb3b014abcbcb4155c91504800"
            ],
            "layout": "IPY_MODEL_bb85295881a3472b9f86aa91cf8ca0ff"
          }
        },
        "428beba9f2a247f1839f7fce72210e96": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42a8b7cb3b014abcbcb4155c91504800": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_568b82dd612141e9999fc95bc16774e6",
            "placeholder": "​",
            "style": "IPY_MODEL_d0767ab0a2ad4edfb6cf47a401a639b7",
            "value": " 153/153 [00:00&lt;00:00, 1444.80 examples/s]"
          }
        },
        "434b87ab788e4ff181781d7ce0781153": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46ec26d477734890a45702e28218b865": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6bd32c513ac8462588293c31abe5c16f",
              "IPY_MODEL_60d41898b124468fa9165956f2ac6a5b",
              "IPY_MODEL_beef5399799442a9a23eea2a24eac282"
            ],
            "layout": "IPY_MODEL_434b87ab788e4ff181781d7ce0781153"
          }
        },
        "4888381aeac74d7f870cac59c3a927c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a3cd173a7b64aa6bfc768bc19f8ed60": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a8404085e01459c9afdb347896d7822": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4b3fe444c4704d779fb4a992fcf64806": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f8f160975fb47b29d597f586cc140e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d182aaf81ede41f0b6a7ac4110765536",
            "placeholder": "​",
            "style": "IPY_MODEL_926b8bfef015477e94873698f4164a3c",
            "value": " 1.84M/1.84M [00:00&lt;00:00, 16.1MB/s]"
          }
        },
        "4ff56b9a95834106badacaec86fb4f93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "55fe543f913547cf89dfde2990f0ba99": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "568b82dd612141e9999fc95bc16774e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5849c1a16b2d48cd8bbd42fc02a5fb0e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b42de57c04340f59954a95020bccc6e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5be0bc61ce4249278604c8ef8b2d9263": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c50bf16e1f954d0c989dc4e3eefae919",
              "IPY_MODEL_7fa56300652a409a97d3de12c0c571cb",
              "IPY_MODEL_219d19ec57bb41d0afa69d1eedff02ce"
            ],
            "layout": "IPY_MODEL_5fe9390c81684e0287c47fa9d6599555"
          }
        },
        "5e5cb18394ec4343b22a8a972e776260": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f6b0795d597421f8df70092a4647a9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5fe9390c81684e0287c47fa9d6599555": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60d41898b124468fa9165956f2ac6a5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90d9799c94214d5f930d5b3b45af5322",
            "max": 608,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6134c0bb1a70490a8b604517fcb0786d",
            "value": 608
          }
        },
        "6134c0bb1a70490a8b604517fcb0786d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "61605eee6908411ab1755c1e368f8625": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6611266679704ea792eaeb4634035360": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "663fc56d3e19450598038cb8e2f8e513": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "66c0956a1a3a4ecb8e6bcd6812f8982b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36abb851e0fe458ebf4512f135216739",
            "placeholder": "​",
            "style": "IPY_MODEL_adcdf4127a554ce191aed41b9279ac83",
            "value": "Running tokenizer on dataset: 100%"
          }
        },
        "6b8bc99b6e954d709f786e6c6ed2caef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af2bc2303030454b8737d6239af806c0",
            "max": 274,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4a8404085e01459c9afdb347896d7822",
            "value": 274
          }
        },
        "6bd32c513ac8462588293c31abe5c16f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7980afeee7634b94bf793c3c886e4ed2",
            "placeholder": "​",
            "style": "IPY_MODEL_f510959d387e4cab8ea6a4a01e1af87d",
            "value": "config.json: 100%"
          }
        },
        "6ccdab9ac3ec4afca4602e6057189035": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d1848c9750c4838a21abe010e14d553": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d72b001af6a4c5e9e3ddaf46812bb48": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3106bdc3f1184f28a387383b6e2700d1",
            "placeholder": "​",
            "style": "IPY_MODEL_ce6f3d971a314616b6a71639b4bedb8a",
            "value": "tokenizer.json: 100%"
          }
        },
        "6d90a22a2e544f5d8592f3bee226c1b1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e7eb1a33bb547e38d0241aae5f251e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_17cd255f720f44e1a4da227cf1fd8edf",
              "IPY_MODEL_fd88d70dd41b409fac954ae63dca9669",
              "IPY_MODEL_11c42b29aac34f36a8a9caaf2fce28ca"
            ],
            "layout": "IPY_MODEL_55fe543f913547cf89dfde2990f0ba99"
          }
        },
        "6f69801568e349e6a9277ec065d6366a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6d72b001af6a4c5e9e3ddaf46812bb48",
              "IPY_MODEL_c7f58da332034073aba74919db4ec871",
              "IPY_MODEL_4f8f160975fb47b29d597f586cc140e2"
            ],
            "layout": "IPY_MODEL_b9e66cf805e94c17a0b844714c14b9d6"
          }
        },
        "71fdc3523c0a4867a51f92dbc535b553": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3b2e071d27aa4ce98d465e7bf9246f13",
              "IPY_MODEL_9edf3423e6ba44a0b9b9b09340690a3c",
              "IPY_MODEL_cdc26990d23b494fafe043340066a883"
            ],
            "layout": "IPY_MODEL_0e7d8ffb0a7d4e9ba300586a19b13d98"
          }
        },
        "730c4e954b4246188a8435de218c5229": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "74a04829e50e4bc6a5d832a9f5d3294e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76b9528f1c2d4204886f819d7bd176db": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7781e4d7a5594d1a936413ceea7df786": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0d70bcb29ce458cbf1a841e8664db51",
            "max": 2200119864,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_730c4e954b4246188a8435de218c5229",
            "value": 2200119864
          }
        },
        "7850a2bd748b4ff6a17298492ccd5211": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7980afeee7634b94bf793c3c886e4ed2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a72abeb05e04180a8182d90d3182b77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b24db98371a4069ae1c31c5c3384ce2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7e6d18d9b24041898320c88cb131ad5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc017ea530a64424bbb1d021033d02ca",
            "placeholder": "​",
            "style": "IPY_MODEL_061bad2ce7564fa28e1989a49d292de1",
            "value": "Running tokenizer on dataset: 100%"
          }
        },
        "7f1812e72763453ea777b7ba930c348b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7fa56300652a409a97d3de12c0c571cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0712f438b3c34b4ea136aa80a88a952d",
            "max": 153,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a72abeb05e04180a8182d90d3182b77",
            "value": 153
          }
        },
        "82115ea9374e4e689553479c495b58ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8234547aff04419fbe011dd3fe79caf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8265b59373714d29a74144e3a0830e7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35d9cabd0a9449b9b9e4882ac663773d",
            "max": 153,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe3496ea98124ac0b2342bde3bc77e96",
            "value": 153
          }
        },
        "8359db814f524c6991fd9f432fae83e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7e6d18d9b24041898320c88cb131ad5b",
              "IPY_MODEL_8265b59373714d29a74144e3a0830e7a",
              "IPY_MODEL_c1ae6e76d59e4a29ba102ba6e9ba415c"
            ],
            "layout": "IPY_MODEL_c91b3b9cef774af9a13e9d6cf9a94e11"
          }
        },
        "8874623ac8d64c74bc25b4366b14424f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f5c38be75c14f149f75560242cce984": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90d9799c94214d5f930d5b3b45af5322": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "926b8bfef015477e94873698f4164a3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93accef8f43247b8bc0223e88d39d166": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99212839f1b84f67a06b2020ff3a8b08": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ad0a95321f44586b2987dc02ed5128d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b0aae3792174020b8edbc84d909abd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7ce148da0ba410aa4e9b2ab2e78c8dc",
            "placeholder": "​",
            "style": "IPY_MODEL_7850a2bd748b4ff6a17298492ccd5211",
            "value": " 500k/500k [00:00&lt;00:00, 6.02MB/s]"
          }
        },
        "9d6d14a3488549fab6298d028318628a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ed9e2f2b6d045d7951a7fbdd2cce700": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9edf3423e6ba44a0b9b9b09340690a3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eed2c2e2827e42849bf9b41d5b475594",
            "max": 153,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d3daba82faec46bb82f1ca994b8e5c34",
            "value": 153
          }
        },
        "9f2efae6ad70489a80eb0380e01978c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a0d65f3f9d1f4a359392f4d07966a35c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a12f4251adee422d8948472e0800f0c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a27d56cf6bf64b93b4affa05dcdbbc10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_25e8d597a112483baf71ca21d93ae4ec",
              "IPY_MODEL_b9b90a0c26e046ea82085a044b4d0608",
              "IPY_MODEL_dcdba5025a1d41c0af58f45a069d7591"
            ],
            "layout": "IPY_MODEL_76b9528f1c2d4204886f819d7bd176db"
          }
        },
        "a35163dfc53b40c2956c6a37a065e08d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6023bf06b504028b5785f47980de1ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2fac44bb1fd842ceade6a016fd7db5a0",
              "IPY_MODEL_7781e4d7a5594d1a936413ceea7df786",
              "IPY_MODEL_ce7e8bf36fe04ebf88d4eca74c6dd3b7"
            ],
            "layout": "IPY_MODEL_a94967a2e15e409c9d3555b076ae9183"
          }
        },
        "a8160ba1fe5040bd8dd4c65b89ed9d1e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a94967a2e15e409c9d3555b076ae9183": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adcdf4127a554ce191aed41b9279ac83": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af2bc2303030454b8737d6239af806c0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b00c78768d45401fb92c66c83205aa13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74a04829e50e4bc6a5d832a9f5d3294e",
            "max": 74565,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_663fc56d3e19450598038cb8e2f8e513",
            "value": 74565
          }
        },
        "b3cff0da2d21462db0c6ce223e269bca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5d7396090744c34ba9080390993d679": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3ad1c9c22c7a44fcbe95314acaac31ff",
              "IPY_MODEL_b00c78768d45401fb92c66c83205aa13",
              "IPY_MODEL_eec0a8f29e804fa09c5f1c0bc833a351"
            ],
            "layout": "IPY_MODEL_da8424993dae4f80a1c828c656fa3b4c"
          }
        },
        "b63cfcef49554333a3e96c13f3ac8c22": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7ce148da0ba410aa4e9b2ab2e78c8dc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7ecafa5aa3a42ef8bdf5fd599388e26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe37730e1e7744a59823ea1d9e8699e8",
              "IPY_MODEL_d8031a9305604072afd3b5123c90580c",
              "IPY_MODEL_bfaa3165ba694f5385a3661aaf650780"
            ],
            "layout": "IPY_MODEL_0988296c64cc4d59bbf3479a339e3e88"
          }
        },
        "b9b90a0c26e046ea82085a044b4d0608": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32ad61522a0b401293e92d7454651ec0",
            "max": 153,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8234547aff04419fbe011dd3fe79caf0",
            "value": 153
          }
        },
        "b9e66cf805e94c17a0b844714c14b9d6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb85295881a3472b9f86aa91cf8ca0ff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bda0ed5afa644de289cd42caa2c821e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_314084c1fd55456e860bc7d2ba2fbbfa",
              "IPY_MODEL_034a33b189564f1884347cea94d82b4a",
              "IPY_MODEL_c59eb37c18694659aea34592d8461d3d"
            ],
            "layout": "IPY_MODEL_20ef7121800246f381230ba670ca4866"
          }
        },
        "beef5399799442a9a23eea2a24eac282": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f796854573fa40a0910b4c9c8c4dad10",
            "placeholder": "​",
            "style": "IPY_MODEL_9ed9e2f2b6d045d7951a7fbdd2cce700",
            "value": " 608/608 [00:00&lt;00:00, 9.71kB/s]"
          }
        },
        "bef5d648b806474c8f1ff32d82dcbf59": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bfaa3165ba694f5385a3661aaf650780": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edc274e14cc74bcdbd16d0cdad43ff96",
            "placeholder": "​",
            "style": "IPY_MODEL_c9189d75db764938b9d62b7f02824643",
            "value": " 153/0 [00:00&lt;00:00, 1528.95 examples/s]"
          }
        },
        "c1ae6e76d59e4a29ba102ba6e9ba415c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e5cb18394ec4343b22a8a972e776260",
            "placeholder": "​",
            "style": "IPY_MODEL_3b428811e93d4924ade432f410b67e11",
            "value": " 153/153 [00:00&lt;00:00, 704.05 examples/s]"
          }
        },
        "c50bf16e1f954d0c989dc4e3eefae919": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6611266679704ea792eaeb4634035360",
            "placeholder": "​",
            "style": "IPY_MODEL_cafc5260128741f699b64c2288836a9b",
            "value": "Running tokenizer on dataset: 100%"
          }
        },
        "c59eb37c18694659aea34592d8461d3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e9d0a5d38604ccc98f1904ff623cee8",
            "placeholder": "​",
            "style": "IPY_MODEL_28e80faa748f4045bdcdb46cee68ca86",
            "value": " 551/551 [00:00&lt;00:00, 8.24kB/s]"
          }
        },
        "c72182945b984db1b00c1114c4de81bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7f58da332034073aba74919db4ec871": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_310e64cb60dd4da6afbc0e49aa9525aa",
            "max": 1842767,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4888381aeac74d7f870cac59c3a927c5",
            "value": 1842767
          }
        },
        "c9189d75db764938b9d62b7f02824643": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c91b3b9cef774af9a13e9d6cf9a94e11": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c91cb675fe5b4c768e2373b768e73c78": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cafc5260128741f699b64c2288836a9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cdc26990d23b494fafe043340066a883": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d90a22a2e544f5d8592f3bee226c1b1",
            "placeholder": "​",
            "style": "IPY_MODEL_c91cb675fe5b4c768e2373b768e73c78",
            "value": " 153/153 [00:00&lt;00:00, 686.59 examples/s]"
          }
        },
        "ce64b5a9184e4fb0adba914237c5421a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b42de57c04340f59954a95020bccc6e",
            "placeholder": "​",
            "style": "IPY_MODEL_238f58e4196f42fbbd416d8e2f6af877",
            "value": "Downloading readme: 100%"
          }
        },
        "ce6f3d971a314616b6a71639b4bedb8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce7e8bf36fe04ebf88d4eca74c6dd3b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05e7df46090d4fd0882de7d720d6d509",
            "placeholder": "​",
            "style": "IPY_MODEL_5f6b0795d597421f8df70092a4647a9a",
            "value": " 2.20G/2.20G [00:16&lt;00:00, 147MB/s]"
          }
        },
        "cefce37792024f098754e671719f504a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_25774abab34341d2b33baf704535cf7e",
              "IPY_MODEL_d68e092644be4fc5b891f26e781c7ae3",
              "IPY_MODEL_9b0aae3792174020b8edbc84d909abd8"
            ],
            "layout": "IPY_MODEL_4b3fe444c4704d779fb4a992fcf64806"
          }
        },
        "d0767ab0a2ad4edfb6cf47a401a639b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0d70bcb29ce458cbf1a841e8664db51": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d182aaf81ede41f0b6a7ac4110765536": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3daba82faec46bb82f1ca994b8e5c34": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d56fadbe334e407e846fee5400eae3ed": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d61a3136c47b4806bccddd0655fabb43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d67a4b72ba934e9188e5e4985dab05b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d68e092644be4fc5b891f26e781c7ae3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d67a4b72ba934e9188e5e4985dab05b3",
            "max": 499723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7b24db98371a4069ae1c31c5c3384ce2",
            "value": 499723
          }
        },
        "d8031a9305604072afd3b5123c90580c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f8de8f2968e4d1fa270853f33ff9404",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f2efae6ad70489a80eb0380e01978c1",
            "value": 1
          }
        },
        "da8424993dae4f80a1c828c656fa3b4c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc017ea530a64424bbb1d021033d02ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcdba5025a1d41c0af58f45a069d7591": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82115ea9374e4e689553479c495b58ca",
            "placeholder": "​",
            "style": "IPY_MODEL_6ccdab9ac3ec4afca4602e6057189035",
            "value": " 153/153 [00:00&lt;00:00, 2021.36 examples/s]"
          }
        },
        "df70364e5c8d44dcbc89f0bc17e4cd4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d6d14a3488549fab6298d028318628a",
            "placeholder": "​",
            "style": "IPY_MODEL_99212839f1b84f67a06b2020ff3a8b08",
            "value": " 124/124 [00:00&lt;00:00, 6.69kB/s]"
          }
        },
        "e04733987cd34abba9bda895903ddb8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0ca0b642d10478db945207de3a5e039": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e2c594c7628d4cc48c659318c48d8a4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c72182945b984db1b00c1114c4de81bf",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bef5d648b806474c8f1ff32d82dcbf59",
            "value": 124
          }
        },
        "e64bd5dcb8fd40ea8ca52bb1285da791": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea17d700ac384dc7abccb1ce4bcbea8a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eab7b82250c342b6982065c2ca0d1321": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a12f4251adee422d8948472e0800f0c7",
            "placeholder": "​",
            "style": "IPY_MODEL_e64bd5dcb8fd40ea8ca52bb1285da791",
            "value": "generation_config.json: 100%"
          }
        },
        "ebfe2abba72549a6b28d460bc3b9e9a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eab7b82250c342b6982065c2ca0d1321",
              "IPY_MODEL_e2c594c7628d4cc48c659318c48d8a4f",
              "IPY_MODEL_df70364e5c8d44dcbc89f0bc17e4cd4c"
            ],
            "layout": "IPY_MODEL_2fc457aac30d4757a6c39cfa9641a8e7"
          }
        },
        "ed11925f657c47d69b0c5ab07dfbe69a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce64b5a9184e4fb0adba914237c5421a",
              "IPY_MODEL_6b8bc99b6e954d709f786e6c6ed2caef",
              "IPY_MODEL_24033a0b9ebb46cd81bd19b195beddd7"
            ],
            "layout": "IPY_MODEL_428beba9f2a247f1839f7fce72210e96"
          }
        },
        "edc274e14cc74bcdbd16d0cdad43ff96": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eec0a8f29e804fa09c5f1c0bc833a351": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8160ba1fe5040bd8dd4c65b89ed9d1e",
            "placeholder": "​",
            "style": "IPY_MODEL_8f5c38be75c14f149f75560242cce984",
            "value": " 74.6k/74.6k [00:00&lt;00:00, 810kB/s]"
          }
        },
        "eed2c2e2827e42849bf9b41d5b475594": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0e722c32ce44a52a6ae44b954a9ab63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f49c1c0aa4874ee6b7327faaf7efc70d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f510959d387e4cab8ea6a4a01e1af87d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f796854573fa40a0910b4c9c8c4dad10": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa183d0ad04542f6a64b622bcd3e3105": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d44d7b2413f4df382a8d87a777da03c",
            "max": 153,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61605eee6908411ab1755c1e368f8625",
            "value": 153
          }
        },
        "fd54fc3231144427a87f34710c81554f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd88d70dd41b409fac954ae63dca9669": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bd1239759474ddf8956d3adb90aabeb",
            "max": 1289,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4ff56b9a95834106badacaec86fb4f93",
            "value": 1289
          }
        },
        "fe3496ea98124ac0b2342bde3bc77e96": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fe37730e1e7744a59823ea1d9e8699e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea17d700ac384dc7abccb1ce4bcbea8a",
            "placeholder": "​",
            "style": "IPY_MODEL_d61a3136c47b4806bccddd0655fabb43",
            "value": "Generating train split: "
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}