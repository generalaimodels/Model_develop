{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pacmap\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "from typing import List, Dict, Union\n",
        "\n",
        "\n",
        "def generate_random_samples(num_samples: int, embedding_dim: int) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Generate random sample embeddings.\n",
        "\n",
        "    Args:\n",
        "        num_samples (int): Number of random samples to generate.\n",
        "        embedding_dim (int): Dimension of the embeddings.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Array of random sample embeddings.\n",
        "    \"\"\"\n",
        "    return np.random.rand(num_samples, embedding_dim)\n",
        "\n",
        "\n",
        "def generate_3d_plot(embeddings: np.ndarray, user_query: str) -> None:\n",
        "    \"\"\"\n",
        "    Generate a 3D plot of embeddings using PaCMAP.\n",
        "\n",
        "    Args:\n",
        "        embeddings (np.ndarray): Array of embeddings.\n",
        "        user_query (str): User query text.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    try:\n",
        "        embedding_projector = pacmap.PaCMAP(\n",
        "            n_components=3, n_neighbors=None, MN_ratio=0.5, FP_ratio=2.0, random_state=1\n",
        "        )\n",
        "\n",
        "        query_vector = np.random.rand(1, embeddings.shape[1])\n",
        "        embeddings_with_query = np.vstack((embeddings, query_vector))\n",
        "\n",
        "        embeddings_projected = embedding_projector.fit_transform(\n",
        "            embeddings_with_query, init=\"pca\"\n",
        "        )\n",
        "\n",
        "        df = pd.DataFrame(\n",
        "            [\n",
        "                {\n",
        "                    \"x\": embeddings_projected[i, 0],\n",
        "                    \"y\": embeddings_projected[i, 1],\n",
        "                    \"z\": embeddings_projected[i, 2],\n",
        "                    \"source\": f\"Sample {i}\",\n",
        "                    \"extract\": f\"Sample {i} embedding\",\n",
        "                    \"symbol\": \"circle\",\n",
        "                    \"size_col\": 100,\n",
        "                }\n",
        "                for i in range(embeddings.shape[0])\n",
        "            ]\n",
        "            + [\n",
        "                {\n",
        "                    \"x\": embeddings_projected[-1, 0],\n",
        "                    \"y\": embeddings_projected[-1, 1],\n",
        "                    \"z\": embeddings_projected[-1, 2],\n",
        "                    \"source\": \"User query\",\n",
        "                    \"extract\": user_query,\n",
        "                    \"size_col\": 500,\n",
        "                    \"symbol\": \"star\",\n",
        "                }\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        fig = px.scatter_3d(\n",
        "            df,\n",
        "            x=\"x\",\n",
        "            y=\"y\",\n",
        "            z=\"z\",\n",
        "            color=\"source\",\n",
        "            hover_data=\"extract\",\n",
        "            size=\"size_col\",\n",
        "            symbol=\"symbol\",\n",
        "            color_discrete_map={\"User query\": \"black\"},\n",
        "            width=1000,\n",
        "            height=700,\n",
        "        )\n",
        "        fig.update_traces(\n",
        "            marker=dict(opacity=1, line=dict(width=0, color=\"DarkSlateGrey\")),\n",
        "            selector=dict(mode=\"markers\"),\n",
        "        )\n",
        "        fig.update_layout(\n",
        "            legend_title_text=\"<b>Sample source</b>\",\n",
        "            title=\"<b>3D Projection of Random Embeddings via PaCMAP</b>\",\n",
        "        )\n",
        "        fig.show()\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {str(e)}\")\n",
        "\n",
        "\n",
        "# Example usage\n",
        "num_samples = 1000\n",
        "embedding_dim = 50\n",
        "user_query = \"What is the meaning of life?\"\n",
        "\n",
        "random_embeddings = generate_random_samples(num_samples, embedding_dim)\n",
        "generate_3d_plot(random_embeddings, user_query)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  error: subprocess-exited-with-error\n",
            "  \n",
            "  × python setup.py bdist_wheel did not run successfully.\n",
            "  │ exit code: 1\n",
            "  ╰─> [14 lines of output]\n",
            "      C:\\Users\\hemanthk.LAP53-FJS.000\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\setuptools\\installer.py:27: SetuptoolsDeprecationWarning: setuptools.installer is deprecated. Requirements should be satisfied by a PEP 517 installer.\n",
            "        warnings.warn(\n",
            "      running bdist_wheel\n",
            "      running build\n",
            "      running build_py\n",
            "      creating build\n",
            "      creating build\\lib.win-amd64-cpython-310\n",
            "      creating build\\lib.win-amd64-cpython-310\\annoy\n",
            "      copying annoy\\__init__.py -> build\\lib.win-amd64-cpython-310\\annoy\n",
            "      copying annoy\\__init__.pyi -> build\\lib.win-amd64-cpython-310\\annoy\n",
            "      copying annoy\\py.typed -> build\\lib.win-amd64-cpython-310\\annoy\n",
            "      running build_ext\n",
            "      building 'annoy.annoylib' extension\n",
            "      error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
            "      [end of output]\n",
            "  \n",
            "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  ERROR: Failed building wheel for annoy\n",
            "ERROR: Could not build wheels for annoy, which is required to install pyproject.toml-based projects\n",
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install -q pacmap\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# TASK : we have create the 3 dim tensor of (we have generate to random samples of 100) below code 2d we have extent to 3d plot\n",
        "\n",
        "import pacmap\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "embedding_projector = pacmap.PaCMAP(\n",
        "    n_components=2, n_neighbors=None, MN_ratio=0.5, FP_ratio=2.0, random_state=1\n",
        ")\n",
        "\n",
        "embeddings_2d = [\n",
        "    list(KNOWLEDGE_VECTOR_DATABASE.index.reconstruct_n(idx, 1)[0])\n",
        "    for idx in range(len(docs_processed))\n",
        "] + [query_vector]\n",
        "\n",
        "# fit the data (The index of transformed data corresponds to the index of the original data)\n",
        "documents_projected = embedding_projector.fit_transform(\n",
        "    np.array(embeddings_2d), init=\"pca\"\n",
        ")\n",
        "\n",
        "df = pd.DataFrame.from_dict(\n",
        "    [\n",
        "        {\n",
        "            \"x\": documents_projected[i, 0],\n",
        "            \"y\": documents_projected[i, 1],\n",
        "            \"source\": docs_processed[i].metadata[\"source\"].split(\"/\")[1],\n",
        "            \"extract\": docs_processed[i].page_content[:100] + \"...\",\n",
        "            \"symbol\": \"circle\",\n",
        "            \"size_col\": 4,\n",
        "        }\n",
        "        for i in range(len(docs_processed))\n",
        "    ]\n",
        "    + [\n",
        "        {\n",
        "            \"x\": documents_projected[-1, 0],\n",
        "            \"y\": documents_projected[-1, 1],\n",
        "            \"source\": \"User query\",\n",
        "            \"extract\": user_query,\n",
        "            \"size_col\": 100,\n",
        "            \"symbol\": \"star\",\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "# visualize the embedding\n",
        "fig = px.scatter(\n",
        "    df,\n",
        "    x=\"x\",\n",
        "    y=\"y\",\n",
        "    color=\"source\",\n",
        "    hover_data=\"extract\",\n",
        "    size=\"size_col\",\n",
        "    symbol=\"symbol\",\n",
        "    color_discrete_map={\"User query\": \"black\"},\n",
        "    width=1000,\n",
        "    height=700,\n",
        ")\n",
        "fig.update_traces(\n",
        "    marker=dict(opacity=1, line=dict(width=0, color=\"DarkSlateGrey\")),\n",
        "    selector=dict(mode=\"markers\"),\n",
        ")\n",
        "fig.update_layout(\n",
        "    legend_title_text=\"<b>Chunk source</b>\",\n",
        "    title=\"<b>2D Projection of Chunk Embeddings via PaCMAP</b>\",\n",
        ")\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "M4sKZdVrSsx7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install -q -U dash plotly \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "! pip install nbformat>=4.2.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tv48C9jqci8l"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "fig = px.scatter(x=[\"a\", \"b\", \"c\"], y=[1, 3, 2])\n",
        "# fig.show()\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFWW2Hu0cDPm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from dash import Dash, dcc, html\n",
        "from typing import Union\n",
        "\n",
        "\n",
        "def load_data(file_path: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Load data from a CSV file.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the CSV file.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Loaded data as a DataFrame.\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: If the specified file is not found.\n",
        "        pd.errors.EmptyDataError: If the loaded data is empty.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        data = pd.read_csv(file_path)\n",
        "        if data.empty:\n",
        "            raise pd.errors.EmptyDataError(\"Loaded data is empty.\")\n",
        "        return data\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: File '{file_path}' not found.\")\n",
        "        raise e\n",
        "\n",
        "\n",
        "def create_scatter_plot(data: pd.DataFrame, x_column: str, y_column: str, color_column: Union[str, None] = None) -> px.scatter:\n",
        "    \"\"\"\n",
        "    Create a scatter plot using Plotly Express.\n",
        "\n",
        "    Args:\n",
        "        data (pd.DataFrame): Data for the chart.\n",
        "        x_column (str): Column name for the x-axis.\n",
        "        y_column (str): Column name for the y-axis.\n",
        "        color_column (str, optional): Column name for color encoding. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        px.scatter: Plotly Express scatter plot figure.\n",
        "    \"\"\"\n",
        "    fig = px.scatter(data, x=x_column, y=y_column, color=color_column)\n",
        "    return fig\n",
        "\n",
        "\n",
        "def create_dash_app(data: pd.DataFrame, x_column: str, y_column: str, color_column: Union[str, None] = None) -> Dash:\n",
        "    \"\"\"\n",
        "    Create a Dash application with a scatter plot.\n",
        "\n",
        "    Args:\n",
        "        data (pd.DataFrame): Data for the chart.\n",
        "        x_column (str): Column name for the x-axis.\n",
        "        y_column (str): Column name for the y-axis.\n",
        "        color_column (str, optional): Column name for color encoding. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        Dash: Dash application instance.\n",
        "    \"\"\"\n",
        "    app = Dash(__name__)\n",
        "    fig = create_scatter_plot(data, x_column, y_column, color_column)\n",
        "\n",
        "    app.layout = html.Div(children=[\n",
        "        html.H1(children='Data Visualization'),\n",
        "        html.Div(children='A scatter plot showing the data.'),\n",
        "        dcc.Graph(id='scatter-plot', figure=fig)\n",
        "    ])\n",
        "\n",
        "    return app\n",
        "\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        file_path = '/content/sample_data/california_housing_test.csv'\n",
        "        data = load_data(file_path)\n",
        "\n",
        "        # Specify the column names for the scatter plot\n",
        "        x_column = 'longitude'\n",
        "        y_column = 'latitude'\n",
        "        color_column = 'median_house_value'\n",
        "\n",
        "        app = create_dash_app(data, x_column, y_column, color_column)\n",
        "        app.run_server(debug=True)\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {str(e)}\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObnHVtWKSCom"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from dash import Dash, dcc, html\n",
        "\n",
        "\n",
        "def load_data(file_path: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Load data from a CSV file.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the CSV file.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Loaded data as a DataFrame.\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: If the specified file is not found.\n",
        "        pd.errors.EmptyDataError: If the loaded data is empty.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        data = pd.read_csv(file_path)\n",
        "        if data.empty:\n",
        "            raise pd.errors.EmptyDataError(\"Loaded data is empty.\")\n",
        "        return data\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: File '{file_path}' not found.\")\n",
        "        raise e\n",
        "\n",
        "\n",
        "def create_bar_chart(data: pd.DataFrame) -> px.bar:\n",
        "    \"\"\"\n",
        "    Create a bar chart using Plotly Express.\n",
        "\n",
        "    Args:\n",
        "        data (pd.DataFrame): Data for the chart.\n",
        "\n",
        "    Returns:\n",
        "        px.bar: Plotly Express bar chart figure.\n",
        "    \"\"\"\n",
        "    # Automatically detect the column names\n",
        "    numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
        "    if len(numeric_columns) < 2:\n",
        "        raise ValueError(\"Insufficient numeric columns for creating a bar chart.\")\n",
        "    x_column = numeric_columns[0]\n",
        "    y_column = numeric_columns[1]\n",
        "    color_column = data.select_dtypes(include=['object']).columns[0] if len(data.select_dtypes(include=['object']).columns) > 0 else None\n",
        "\n",
        "    fig = px.bar(data, x=x_column, y=y_column, color=color_column, barmode=\"group\")\n",
        "    fig.show()\n",
        "    return fig\n",
        "\n",
        "def create_dash_app(data: pd.DataFrame) -> Dash:\n",
        "    \"\"\"\n",
        "    Create a Dash application with a bar chart.\n",
        "\n",
        "    Args:\n",
        "        data (pd.DataFrame): Data for the chart.\n",
        "\n",
        "    Returns:\n",
        "        Dash: Dash application instance.\n",
        "    \"\"\"\n",
        "    app = Dash(__name__)\n",
        "    fig = create_bar_chart(data)\n",
        "\n",
        "    app.layout = html.Div(children=[\n",
        "        html.H1(children='Data Visualization'),\n",
        "        html.Div(children='A bar chart showing the data.'),\n",
        "        dcc.Graph(id='bar-chart', figure=fig)\n",
        "    ])\n",
        "\n",
        "    return app\n",
        "\n",
        "x = load_data('/content/sample_data/california_housing_test.csv')\n",
        "app = create_dash_app(x)\n",
        "app.run_server(debug=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ivCoZipHUbXC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from dash import Dash, dcc, html\n",
        "\n",
        "\n",
        "def load_data(file_path: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Load data from a CSV file.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the CSV file.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Loaded data as a DataFrame.\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: If the specified file is not found.\n",
        "        pd.errors.EmptyDataError: If the loaded data is empty.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        data = pd.read_csv(file_path)\n",
        "        if data.empty:\n",
        "            raise pd.errors.EmptyDataError(\"Loaded data is empty.\")\n",
        "        return data\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: File '{file_path}' not found.\")\n",
        "        raise e\n",
        "\n",
        "\n",
        "def create_scatter_plot(data: pd.DataFrame) -> px.scatter:\n",
        "    \"\"\"\n",
        "    Create a scatter plot using Plotly Express.\n",
        "\n",
        "    Args:\n",
        "        data (pd.DataFrame): Data for the chart.\n",
        "\n",
        "    Returns:\n",
        "        px.scatter: Plotly Express scatter plot figure.\n",
        "    \"\"\"\n",
        "    # Automatically detect the column names\n",
        "    numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
        "    if len(numeric_columns) < 2:\n",
        "        raise ValueError(\"Insufficient numeric columns for creating a scatter plot.\")\n",
        "    x_column = numeric_columns[0]\n",
        "    y_column = numeric_columns[1]\n",
        "    color_column = data.select_dtypes(include=['object']).columns[0] if len(data.select_dtypes(include=['object']).columns) > 0 else None\n",
        "\n",
        "    fig = px.scatter(data, x=x_column, y=y_column, color=color_column)\n",
        "    return fig\n",
        "\n",
        "def create_dash_app(data: pd.DataFrame) -> Dash:\n",
        "    \"\"\"\n",
        "    Create a Dash application with a scatter plot.\n",
        "\n",
        "    Args:\n",
        "        data (pd.DataFrame): Data for the chart.\n",
        "\n",
        "    Returns:\n",
        "        Dash: Dash application instance.\n",
        "    \"\"\"\n",
        "    app = Dash(__name__)\n",
        "    fig = create_scatter_plot(data)\n",
        "\n",
        "    app.layout = html.Div(children=[\n",
        "        html.H1(children='Data Visualization'),\n",
        "        html.Div(children='A scatter plot showing the data.'),\n",
        "        dcc.Graph(id='scatter-plot', figure=fig)\n",
        "    ])\n",
        "\n",
        "    return app\n",
        "\n",
        "x = load_data('/content/sample_data/california_housing_test.csv')\n",
        "app = create_dash_app(x)\n",
        "app.run_server(debug=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGZ-1OnyV9nL"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from dash import Dash, dcc, html\n",
        "from dash.dependencies import Input, Output\n",
        "\n",
        "\n",
        "def load_data(file_path: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Load data from a CSV file.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the CSV file.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Loaded data as a DataFrame.\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: If the specified file is not found.\n",
        "        pd.errors.EmptyDataError: If the loaded data is empty.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        data = pd.read_csv(file_path)\n",
        "        if data.empty:\n",
        "            raise pd.errors.EmptyDataError(\"Loaded data is empty.\")\n",
        "        return data\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: File '{file_path}' not found.\")\n",
        "        raise e\n",
        "\n",
        "\n",
        "def create_scatter_plot(data: pd.DataFrame) -> px.scatter:\n",
        "    \"\"\"\n",
        "    Create a scatter plot using Plotly Express.\n",
        "\n",
        "    Args:\n",
        "        data (pd.DataFrame): Data for the chart.\n",
        "\n",
        "    Returns:\n",
        "        px.scatter: Plotly Express scatter plot figure.\n",
        "    \"\"\"\n",
        "    # Automatically detect the column names\n",
        "    numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
        "    if len(numeric_columns) < 2:\n",
        "        raise ValueError(\"Insufficient numeric columns for creating a scatter plot.\")\n",
        "    x_column = numeric_columns[0]\n",
        "    y_column = numeric_columns[1]\n",
        "    color_column = data.select_dtypes(include=['object']).columns[0] if len(data.select_dtypes(include=['object']).columns) > 0 else None\n",
        "\n",
        "    fig = px.scatter(data, x=x_column, y=y_column, color=color_column)\n",
        "    fig.update_layout(clickmode='event+select')\n",
        "    fig.update_traces(marker_size=20)\n",
        "    return fig\n",
        "\n",
        "def create_dash_app(data: pd.DataFrame) -> Dash:\n",
        "    \"\"\"\n",
        "    Create a Dash application with a scatter plot.\n",
        "\n",
        "    Args:\n",
        "        data (pd.DataFrame): Data for the chart.\n",
        "\n",
        "    Returns:\n",
        "        Dash: Dash application instance.\n",
        "    \"\"\"\n",
        "    app = Dash(__name__)\n",
        "    fig = create_scatter_plot(data)\n",
        "\n",
        "    styles = {\n",
        "        'pre': {\n",
        "            'border': 'thin lightgrey solid',\n",
        "            'overflowX': 'scroll'\n",
        "        }\n",
        "    }\n",
        "\n",
        "    app.layout = html.Div([\n",
        "        dcc.Graph(\n",
        "            id='basic-interactions',\n",
        "            figure=fig\n",
        "        ),\n",
        "\n",
        "        html.Div(className='row', children=[\n",
        "            html.Div([\n",
        "                dcc.Markdown(\"\"\"\n",
        "                    **Hover Data**\n",
        "\n",
        "                    Mouse over values in the graph.\n",
        "                \"\"\"),\n",
        "                html.Pre(id='hover-data', style=styles['pre'])\n",
        "            ], className='three columns'),\n",
        "\n",
        "            html.Div([\n",
        "                dcc.Markdown(\"\"\"\n",
        "                    **Click Data**\n",
        "\n",
        "                    Click on points in the graph.\n",
        "                \"\"\"),\n",
        "                html.Pre(id='click-data', style=styles['pre']),\n",
        "            ], className='three columns'),\n",
        "\n",
        "            html.Div([\n",
        "                dcc.Markdown(\"\"\"\n",
        "                    **Selection Data**\n",
        "\n",
        "                    Choose the lasso or rectangle tool in the graph's menu\n",
        "                    bar and then select points in the graph.\n",
        "\n",
        "                    Note that if `layout.clickmode = 'event+select'`, selection data also\n",
        "                    accumulates (or un-accumulates) selected data if you hold down the shift\n",
        "                    button while clicking.\n",
        "                \"\"\"),\n",
        "                html.Pre(id='selected-data', style=styles['pre']),\n",
        "            ], className='three columns'),\n",
        "\n",
        "            html.Div([\n",
        "                dcc.Markdown(\"\"\"\n",
        "                    **Zoom and Relayout Data**\n",
        "\n",
        "                    Click and drag on the graph to zoom or click on the zoom\n",
        "                    buttons in the graph's menu bar.\n",
        "                    Clicking on legend items will also fire\n",
        "                    this event.\n",
        "                \"\"\"),\n",
        "                html.Pre(id='relayout-data', style=styles['pre']),\n",
        "            ], className='three columns')\n",
        "        ])\n",
        "    ])\n",
        "\n",
        "    @app.callback(\n",
        "        Output('hover-data', 'children'),\n",
        "        Input('basic-interactions', 'hoverData'))\n",
        "    def display_hover_data(hoverData):\n",
        "        return json.dumps(hoverData, indent=2)\n",
        "\n",
        "    @app.callback(\n",
        "        Output('click-data', 'children'),\n",
        "        Input('basic-interactions', 'clickData'))\n",
        "    def display_click_data(clickData):\n",
        "        return json.dumps(clickData, indent=2)\n",
        "\n",
        "    @app.callback(\n",
        "        Output('selected-data', 'children'),\n",
        "        Input('basic-interactions', 'selectedData'))\n",
        "    def display_selected_data(selectedData):\n",
        "        return json.dumps(selectedData, indent=2)\n",
        "\n",
        "    @app.callback(\n",
        "        Output('relayout-data', 'children'),\n",
        "        Input('basic-interactions', 'relayoutData'))\n",
        "    def display_relayout_data(relayoutData):\n",
        "        return json.dumps(relayoutData, indent=2)\n",
        "\n",
        "    return app\n",
        "\n",
        "x = load_data('/content/sample_data/california_housing_test.csv')\n",
        "app = create_dash_app(x)\n",
        "app.run_server(debug=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cpv9sLbyRtQ4"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import sys\n",
        "from typing import List, Tuple\n",
        "\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from dash import Dash, dcc, html\n",
        "\n",
        "def load_data(file_path: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Load data from a CSV file.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the CSV file.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Loaded data as a DataFrame.\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: If the specified file is not found.\n",
        "        pd.errors.EmptyDataError: If the loaded data is empty.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        data = pd.read_csv(file_path)\n",
        "        if data.empty:\n",
        "            raise pd.errors.EmptyDataError(\"Loaded data is empty.\")\n",
        "        return data\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: File '{file_path}' not found.\")\n",
        "        raise e\n",
        "\n",
        "def create_bar_chart(data: pd.DataFrame, x: str, y: str, color: str) -> px.bar:\n",
        "    \"\"\"\n",
        "    Create a bar chart using Plotly Express.\n",
        "\n",
        "    Args:\n",
        "        data (pd.DataFrame): Data for the chart.\n",
        "        x (str): Column name for the x-axis.\n",
        "        y (str): Column name for the y-axis.\n",
        "        color (str): Column name for color encoding.\n",
        "\n",
        "    Returns:\n",
        "        px.bar: Plotly Express bar chart figure.\n",
        "    \"\"\"\n",
        "    fig = px.bar(data, x=x, y=y, color=color, barmode=\"group\")\n",
        "    return fig\n",
        "\n",
        "def create_dash_app(data: pd.DataFrame) -> Dash:\n",
        "    \"\"\"\n",
        "    Create a Dash application with a bar chart.\n",
        "\n",
        "    Args:\n",
        "        data (pd.DataFrame): Data for the chart.\n",
        "\n",
        "    Returns:\n",
        "        Dash: Dash application instance.\n",
        "    \"\"\"\n",
        "    app = Dash(__name__)\n",
        "    fig = create_bar_chart(data, x=\"Fruit\", y=\"Amount\", color=\"City\")\n",
        "\n",
        "    app.layout = html.Div(children=[\n",
        "        html.H1(children='Fruit Amount by City'),\n",
        "        html.Div(children='A bar chart showing fruit amounts in different cities.'),\n",
        "        dcc.Graph(id='bar-chart', figure=fig)\n",
        "    ])\n",
        "\n",
        "    return app\n",
        "\n",
        "def parse_arguments(args: List[str]) -> argparse.Namespace:\n",
        "    \"\"\"\n",
        "    Parse command-line arguments.\n",
        "\n",
        "    Args:\n",
        "        args (List[str]): List of command-line arguments.\n",
        "\n",
        "    Returns:\n",
        "        argparse.Namespace: Parsed arguments.\n",
        "    \"\"\"\n",
        "    parser = argparse.ArgumentParser(description='Visualize data using Dash.')\n",
        "    parser.add_argument('file_path', type=str, help='Path to the CSV file')\n",
        "    return parser.parse_args(args)\n",
        "\n",
        "def main(args: List[str]) -> None:\n",
        "    \"\"\"\n",
        "    Main function to run the Dash application.\n",
        "\n",
        "    Args:\n",
        "        args (List[str]): List of command-line arguments.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        parsed_args = parse_arguments(args)\n",
        "        data = load_data(parsed_args.file_path)\n",
        "        app = create_dash_app(data)\n",
        "        app.run_server(debug=True)\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {str(e)}\")\n",
        "        sys.exit(1)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main(sys.argv[1:])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9f7BQTjRtNg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bAjtw4KRtK5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgQ0obUIRtIX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rUc9XeVRtF9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYx_ieRqRtDV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Y8h514ZRtAz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPms_kPPRs-n"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwGJ3OwcRs8j"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6PVBUKmRs6l"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4eyZKz4Rs4N"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_h3mPfGRs2I"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4XE2lk-Rszv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OV7ByHHOFMkk"
      },
      "outputs": [],
      "source": [
        "pip install pacmap\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1aux7_chFaUN"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/YingfanWang/PaCMAP.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6wRmdroFgBI"
      },
      "outputs": [],
      "source": [
        "%cd PaCMAP\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tOUsS-3lJJ2r"
      },
      "outputs": [],
      "source": [
        "!python /content/PaCMAP/demo/basic_demo.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlZ4KoZiJOYj"
      },
      "outputs": [],
      "source": [
        "!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vsvow_cVFRV5"
      },
      "outputs": [],
      "source": [
        "import pacmap\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# loading preprocessed coil_20 dataset\n",
        "# you can change it with any dataset that is in the ndarray format, with the shape (N, D)\n",
        "# where N is the number of samples and D is the dimension of each sample\n",
        "X = np.load(\"./data/coil_20.npy\", allow_pickle=True)\n",
        "X = X.reshape(X.shape[0], -1)\n",
        "y = np.load(\"./data/coil_20_labels.npy\", allow_pickle=True)\n",
        "\n",
        "# initializing the pacmap instance\n",
        "# Setting n_neighbors to \"None\" leads to a default choice shown below in \"parameter\" section\n",
        "embedding = pacmap.PaCMAP(n_components=2, n_neighbors=None, MN_ratio=0.5, FP_ratio=2.0)\n",
        "\n",
        "# fit the data (The index of transformed data corresponds to the index of the original data)\n",
        "X_transformed = embedding.fit_transform(X, init=\"pca\")\n",
        "\n",
        "# visualize the embedding\n",
        "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
        "ax.scatter(X_transformed[:, 0], X_transformed[:, 1], cmap=\"Spectral\", c=y, s=0.6)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQ8eXXIpJk2L"
      },
      "outputs": [],
      "source": [
        "import pacmap\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from annoy import AnnoyIndex\n",
        "\n",
        "# loading preprocessed coil_20 dataset\n",
        "X = np.load(\"./data/coil_20.npy\", allow_pickle=True)\n",
        "X = X.reshape(X.shape[0], -1)\n",
        "y = np.load(\"./data/coil_20_labels.npy\", allow_pickle=True)\n",
        "\n",
        "# create nearest neighbor pairs\n",
        "# here we use AnnoyIndex as an example, but the process can be done by any\n",
        "# external NN library that provides neighbors into a matrix of the shape\n",
        "# (n, n_neighbors_extra), where n_neighbors_extra is greater or equal to\n",
        "# n_neighbors in the following example.\n",
        "\n",
        "n, dim = X.shape\n",
        "n_neighbors = 10\n",
        "tree = AnnoyIndex(dim, metric='euclidean')\n",
        "for i in range(n):\n",
        "    tree.add_item(i, X[i, :])\n",
        "tree.build(20)\n",
        "\n",
        "nbrs = np.zeros((n, 20), dtype=np.int32)\n",
        "for i in range(n):\n",
        "    nbrs_ = tree.get_nns_by_item(i, 20 + 1) # The first nbr is always the point itself\n",
        "    nbrs[i, :] = nbrs_[1:]\n",
        "\n",
        "scaled_dist = np.ones((n, n_neighbors)) # No scaling is needed\n",
        "\n",
        "# Type casting is needed for numba acceleration\n",
        "X = X.astype(np.float32)\n",
        "scaled_dist = scaled_dist.astype(np.float32)\n",
        "\n",
        "# make sure n_neighbors is the same number you want when fitting the data\n",
        "pair_neighbors = pacmap.sample_neighbors_pair(X, scaled_dist, nbrs, np.int32(n_neighbors))\n",
        "\n",
        "# initializing the pacmap instance\n",
        "# feed the pair_neighbors into the instance\n",
        "embedding = pacmap.PaCMAP(n_components=2, n_neighbors=n_neighbors, MN_ratio=0.5, FP_ratio=2.0, pair_neighbors=pair_neighbors)\n",
        "\n",
        "# fit the data (The index of transformed data corresponds to the index of the original data)\n",
        "X_transformed = embedding.fit_transform(X, init=\"pca\")\n",
        "\n",
        "# visualize the embedding\n",
        "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
        "ax.scatter(X_transformed[:, 0], X_transformed[:, 1], cmap=\"Spectral\", c=y, s=0.6)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aiJHshQAKInQ"
      },
      "outputs": [],
      "source": [
        "!pip install -q umap trimap FlowCal  PaCMAP\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5a7y1SnaKhfp"
      },
      "outputs": [],
      "source": [
        "!pip install PaCMAP\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3KPUtClLwZk"
      },
      "outputs": [],
      "source": [
        "import pacmap\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# loading preprocessed coil_20 dataset\n",
        "# you can change it with any dataset that is in the ndarray format, with the shape (N, D)\n",
        "# where N is the number of samples and D is the dimension of each sample\n",
        "X = np.load(\"./data/coil_20.npy\", allow_pickle=True)\n",
        "X = X.reshape(X.shape[0], -1)\n",
        "y = np.load(\"./data/coil_20_labels.npy\", allow_pickle=True)\n",
        "\n",
        "# Initialize the pacmap instance\n",
        "# By default, the n_neighbors is set to 10.\n",
        "# Setting n_neighbors to \"None\" can enable an automatic parameter selection\n",
        "# choice shown in \"parameter\" section of the README file.\n",
        "# Notice that from v0.6.0 on, we rename the n_dims parameter to n_components.\n",
        "reducer = pacmap.PaCMAP(n_components=2, n_neighbors=10, MN_ratio=0.5, FP_ratio=2.0)\n",
        "\n",
        "# fit the data (The index of transformed data corresponds to the index of the original data)\n",
        "X_transformed = reducer.fit_transform(X, init=\"pca\")\n",
        "\n",
        "# visualize the embedding\n",
        "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
        "ax.scatter(X_transformed[:, 0], X_transformed[:, 1], cmap=\"Spectral\", c=y, s=0.6)\n",
        "\n",
        "# saving the reducer\n",
        "pacmap.save(reducer, \"./coil_20_reducer\")\n",
        "\n",
        "# loading the reducer\n",
        "pacmap.load(\"./coil_20_reducer\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BfJpPyDoKEX_"
      },
      "outputs": [],
      "source": [
        "import umap\n",
        "import trimap\n",
        "import FlowCal\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import manifold, datasets\n",
        "from time import time\n",
        "from tqdm import tqdm\n",
        "from sklearn.decomposition import PCA\n",
        "import pacmap\n",
        "from sklearn.datasets import make_swiss_roll, make_s_curve\n",
        "\n",
        "\n",
        "def data_prep(data_path, dataset='MNIST', size=10000):\n",
        "    '''\n",
        "    This function loads the dataset as numpy array.\n",
        "    Input:\n",
        "        data_path: path of the folder you store all the data needed.\n",
        "        dataset: the name of the dataset.\n",
        "        size: the size of the dataset. This is useful when you only\n",
        "              want to pick a subset of the data\n",
        "    Output:\n",
        "        X: the dataset in numpy array\n",
        "        labels: the labels of the dataset.\n",
        "    '''\n",
        "\n",
        "    if dataset == 'MNIST':\n",
        "        X = np.load(data_path + '/mnist_images.npy', allow_pickle=True).reshape(70000, 28*28)\n",
        "        labels = np.load(data_path + '/mnist_labels.npy', allow_pickle=True)\n",
        "    elif dataset == 'FMNIST':\n",
        "        X = np.load(data_path + '/fmnist_images.npy', allow_pickle=True).reshape(70000, 28*28)\n",
        "        labels = np.load(data_path + '/fmnist_labels.npy', allow_pickle=True)\n",
        "    elif dataset == 'coil_20':\n",
        "        X = np.load(data_path + '/coil_20.npy', allow_pickle=True).reshape(1440, 128*128)\n",
        "        labels = np.load(data_path + '/coil_20_labels.npy', allow_pickle=True)\n",
        "    elif dataset == 'coil_100':\n",
        "        X = np.load(data_path + '/coil_100.npy', allow_pickle=True).reshape(7200, -1)\n",
        "        labels = np.load(data_path + '/coil_100_labels.npy', allow_pickle=True)\n",
        "    elif dataset == 'Flow_cytometry':\n",
        "        X = FlowCal.io.FCSData(data_path + '/11-12-15_314.fcs')\n",
        "        X = np.array(X)\n",
        "        labels = np.zeros(10)\n",
        "    elif dataset == 'mammoth':\n",
        "        with open(data_path + '/mammoth_3d.json', 'r') as f:\n",
        "            X = json.load(f)\n",
        "        X = np.array(X)\n",
        "        with open(data_path + '/mammoth_umap.json', 'r') as f:\n",
        "            labels = json.load(f)\n",
        "        labels = labels['labels']\n",
        "        labels = np.array(labels)\n",
        "    elif dataset == 'mammoth_50k':\n",
        "        with open(data_path + '/mammoth_3d_50k.json', 'r') as f:\n",
        "            X = json.load(f)\n",
        "        X = np.array(X)\n",
        "        labels = np.zeros(10)\n",
        "    elif dataset == 'kddcup99':\n",
        "        X = np.load(data_path + '/KDDcup99_float.npy', allow_pickle=True)\n",
        "        labels = np.load(data_path + '/KDDcup99_labels_int.npy', allow_pickle=True)\n",
        "    elif dataset == '20NG':\n",
        "        X = np.load(data_path + '/20NG.npy', allow_pickle=True)\n",
        "        labels = np.load(data_path + '/20NG_labels.npy', allow_pickle=True)\n",
        "    elif dataset == 'USPS':\n",
        "        X = np.load(data_path + '/USPS.npy', allow_pickle=True)\n",
        "        labels = np.load(data_path + '/USPS_labels.npy', allow_pickle=True)\n",
        "    elif dataset == 'cifar10':\n",
        "        X = np.load(data_path + '/cifar10_imgs.npy', allow_pickle=True)\n",
        "        labels = np.load(data_path + '/cifar10_labels.npy', allow_pickle=True)\n",
        "    elif dataset == 'cifar100':\n",
        "        X = np.load(data_path + '/cifar100_imgs.npy', allow_pickle=True)\n",
        "        labels = np.load(data_path + '/cifar100_labels.npy', allow_pickle=True)\n",
        "    elif dataset == 'Mouse_scRNA':\n",
        "        data = pd.read_csv(data_path + '/GSE93374_Merged_all_020816_BatchCorrected_LNtransformed_doubletsremoved_Data.txt', sep='\\t')\n",
        "        X = data.to_numpy()\n",
        "        labels = pd.read_csv(data_path + '/GSE93374_cell_metadata.txt', sep='\\t')\n",
        "    elif dataset == 'swiss_roll':\n",
        "        X, labels = make_swiss_roll(n_samples=size, random_state=20200202)\n",
        "    elif dataset == 's_curve':\n",
        "        X, labels = make_s_curve(n_samples=size, random_state=20200202)\n",
        "    elif dataset == 's_curve_hole':\n",
        "        X, labels = make_s_curve(n_samples=size, random_state=20200202)\n",
        "        anchor = np.array([0, 1, 0])\n",
        "        indices = np.sum(np.square(X-anchor), axis=1) > 0.3\n",
        "        X, labels = X[indices], labels[indices]\n",
        "    elif dataset == 'swiss_roll_hole':\n",
        "        X, labels = make_swiss_roll(n_samples=size, random_state=20200202)\n",
        "        anchor = np.array([-10, 10, 0])\n",
        "        indices = np.sum(np.square(X-anchor), axis=1) > 20\n",
        "        X, labels = X[indices], labels[indices]\n",
        "    elif dataset == '2D_curve':\n",
        "        x = np.arange(-5.5, 9, 0.01)\n",
        "        y = 0.01 * (x + 5) * (x + 2) * (x - 2) * (x - 6) * (x - 8)\n",
        "        noise = np.random.randn(x.shape[0]) * 0.01\n",
        "        y += noise\n",
        "        x = np.reshape(x, (-1, 1))\n",
        "        y = np.reshape(y, (-1, 1))\n",
        "        X = np.hstack((x, y))\n",
        "        labels = x\n",
        "    else:\n",
        "        print('Unsupported dataset')\n",
        "        assert(False)\n",
        "    return X[:size], labels[:size]\n",
        "\n",
        "def experiment_five(X, method='PaCMAP', **kwargs):\n",
        "    length = X.shape[0]\n",
        "    X_lows, all_times = [], []\n",
        "    for i in range(5):\n",
        "        X_low, all_time = experiment(X, method, **kwargs)\n",
        "        X_lows.append(X_low)\n",
        "        all_times.append(all_time)\n",
        "    X_lows = np.array(X_lows)\n",
        "    all_times = np.array(all_times)\n",
        "    return X_lows, all_times\n",
        "\n",
        "def experiment(X, method='PaCMAP', **kwargs):\n",
        "    if method == 'PaCMAP':\n",
        "        transformer = PaCMAP(**kwargs)\n",
        "    elif method == 'UMAP':\n",
        "        transformer = umap.UMAP(**kwargs)\n",
        "    elif method == 'TriMAP':\n",
        "        transformer = trimap.TRIMAP(**kwargs)\n",
        "    else:\n",
        "        print(\"Incorrect method specified\")\n",
        "        assert(False)\n",
        "    start_time = time()\n",
        "    X_low = transformer.fit_transform(X)\n",
        "    total_time = time() - start_time\n",
        "    return X_low, total_time\n",
        "\n",
        "\n",
        "def main(data_path, output_path, dataset_name = 'MNIST', size=10000, data_pca=True):\n",
        "    X, labels = data_prep(dataset=dataset_name, size=size)\n",
        "    if data_pca:\n",
        "        if dataset_name == 'Mouse_scRNA':\n",
        "            pca = PCA(n_components=1000)\n",
        "            X = pca.fit_transform(X)\n",
        "        elif X.shape[1] > 100:\n",
        "            pca = PCA(n_components=100)\n",
        "            X = pca.fit_transform(X)\n",
        "    print(\"Data loaded successfully\")\n",
        "    # do experiment\n",
        "    methods = ['PaCMAP', 'UMAP', 'TriMAP']\n",
        "\n",
        "    args = {'TriMAP':[{'n_inliers':20}],\n",
        "        'UMAP':[{'n_neighbors':10}, {'n_neighbors':20}, {'n_neighbors':40}],\n",
        "        'PaCMAP':[{'num_NN':5, 'num_FP': 10, 'num_mid': 2},\n",
        "        {'num_NN':10, 'num_FP': 20, 'num_mid': 5},\n",
        "        {'num_NN':20, 'num_FP': 40, 'num_mid': 10}]}\n",
        "\n",
        "    print(\"Experiment started\")\n",
        "    for method in methods:\n",
        "        parameters = args[method]\n",
        "        for parameter in parameters:\n",
        "            X_low, total_time = experiment_five(X, method, **parameter)\n",
        "            if 'n_neighbors' in parameter:\n",
        "                n_neighbors = parameter['n_neighbors']\n",
        "            elif 'n_inliers' in parameter:\n",
        "                n_neighbors = parameter['n_inliers']\n",
        "            elif 'num_NN' in parameter:\n",
        "                n_neighbors = parameter['num_NN']\n",
        "            elif 'perplexity' in parameter:\n",
        "                n_neighbors = parameter['perplexity']\n",
        "            else:\n",
        "                n_neighbors = 'default' # Default value\n",
        "            np.save(f'/home/home1/hh219/PaCMAP/output_5/{dataset_name}_{method}_{n_neighbors}', X_low)\n",
        "            avg_time = np.mean(total_time)\n",
        "            print(f'Average time for method {method} on {dataset_name} with param={n_neighbors} is {avg_time}')\n",
        "            print(f'The detailed time is {total_time}')\n",
        "    return 0\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Please define the data_path and output_path here\n",
        "    data_path = \"/content/PaCMAP/data/\"\n",
        "    output_path = \"/content/PaCMAP/data/output/\"\n",
        "    main(data_path, output_path,'MNIST', 10000000)\n",
        "    main(data_path, output_path,'FMNIST', 10000000)\n",
        "    main(data_path, output_path,'coil_20', 10000000)\n",
        "    main(data_path, output_path,'coil_100', 10000000)\n",
        "\n",
        "    main(data_path, output_path,'Mouse_scRNA', 10000000)\n",
        "    main(data_path, output_path,'mammoth', 10000000)\n",
        "    main(data_path, output_path,'s_curve_hole', 10000)\n",
        "    main(data_path, output_path,'20NG', 20000)\n",
        "    main(data_path, output_path,'USPS', 20000)\n",
        "\n",
        "\n",
        "    main(data_path, output_path,'Flow_cytometry', 10000000)\n",
        "    main(data_path, output_path,'kddcup99', 10000000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTQ9R3RdJ8XQ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import umap\n",
        "from scipy import integrate\n",
        "from pacmap import PaCMAP\n",
        "\n",
        "\n",
        "\n",
        "cmap_fig = plt.cm.get_cmap(\"Spectral\")\n",
        "cmap = plt.cm.get_cmap(\"RdYlGn_r\")\n",
        "cmap_ = plt.cm.get_cmap(\"gist_yarg\")\n",
        "\n",
        "\n",
        "# If you would like discrete ladders, use ladder_map\n",
        "# Otherwise, just leave it, see examples below\n",
        "def ladder_map(grids, ladder_range):\n",
        "    l_map = np.zeros(grids.shape)\n",
        "    for thres in ladder_range:\n",
        "        l_map += (grids > thres).astype(np.float32)\n",
        "    l_map /= len(ladder_range)\n",
        "    return l_map\n",
        "\n",
        "# parameter \"a\" and \"b\" use default values as below\n",
        "def attr(x):\n",
        "    return -pow(x, 0.79)/(1 + pow(x, 2))\n",
        "\n",
        "def repul(x):\n",
        "    return 0.895 * x/(1 + pow(x, 2))/(0.001 + pow(x, 2))\n",
        "\n",
        "def integ_attr(b):\n",
        "    res = np.zeros(b.shape)\n",
        "    for i in range(b.shape[1]):\n",
        "        res[0][i] = integrate.quad(attr, 0, b[0][i], points=[0])[0]\n",
        "    return res\n",
        "\n",
        "def integ_repul(b):\n",
        "    res = np.zeros(b.shape)\n",
        "    for i in range(b.shape[0]):\n",
        "        res[i][0] = integrate.quad(repul, 0, b[i][0], points=[0])[0]\n",
        "    return res\n",
        "\n",
        "# For t-SNE we choose a neighbor and further point to visualize forces on them (using COIL20 dataset, 300 iterations)\n",
        "def t_attr(x):\n",
        "    qij = 1.0 / (x ** 2 + 1.0) / 11500\n",
        "    qij = np.maximum(qij, 1e-12)\n",
        "    force = - (8.58 * 1e-5 - qij) * x / (1.0 + x ** 2)\n",
        "    return force\n",
        "\n",
        "def t_repul(x):\n",
        "    qij = 1.0 / (x ** 2 + 1.0) / 11500\n",
        "    qij = np.maximum(qij, 1e-12)\n",
        "    force = - 10 * (1.19 * 1e-8 - qij) * x / (1.0 + x ** 2)\n",
        "    return force\n",
        "\n",
        "def t_integ_attr(b):\n",
        "    res = np.zeros(b.shape[0])\n",
        "    for i in range(b.shape[0]):\n",
        "        res[i] = integrate.quad(t_attr, 0, b[i], points=[0])[0]\n",
        "    return res\n",
        "\n",
        "def t_integ_repul(b):\n",
        "    res = np.zeros(b.shape[0])\n",
        "    for i in range(b.shape[0]):\n",
        "        res[i] = integrate.quad(t_repul, 0, b[i], points=[0])[0]\n",
        "    return res\n",
        "\n",
        "def t_integ_attr_(b):\n",
        "    res = np.zeros(b.shape)\n",
        "    for i in range(b.shape[1]):\n",
        "        res[0][i] = integrate.quad(t_attr, 0, b[0][i], points=[0])[0]\n",
        "    return res\n",
        "\n",
        "def t_integ_repul_(b):\n",
        "    res = np.zeros(b.shape)\n",
        "    for i in range(b.shape[0]):\n",
        "        res[i][0] = integrate.quad(t_repul, 0, b[i][0], points=[0])[0]\n",
        "    return res\n",
        "\n",
        "\n",
        "plt.figure(figsize=(28, 15))\n",
        "\n",
        "\n",
        "\n",
        "plt.axes([0.047, 0.52, 0.2, 0.44])\n",
        "x = np.linspace(0.0001, 100, num=7000)# d_ij\n",
        "y = np.linspace(0.0001, 100, num=7000)# d_ik\n",
        "xx, yy = np.meshgrid(x, y, sparse=True)\n",
        "tsne_loss = -t_integ_attr_(xx) - t_integ_repul_(yy)\n",
        "tsne_U = t_attr(xx) + 0 * yy\n",
        "tsne_V = t_repul(yy) + 0 * xx\n",
        "plt.streamplot(xx, yy, tsne_U, tsne_V, density=(2.4, 1.0), linewidth=0.8, arrowsize=2.5, maxlength=1.)\n",
        "im = plt.imshow(tsne_loss, origin='lower', extent=(0.0001, 100, 0.0001, 100), cmap=cmap)\n",
        "cb = plt.colorbar(im)\n",
        "cb.ax.tick_params(labelsize=23)\n",
        "plt.title('Loss (t-SNE)', fontsize=38)\n",
        "plt.xticks(fontsize=23)\n",
        "plt.yticks(fontsize=23)\n",
        "plt.xlabel(r'$d_{ij}$', fontsize=38)\n",
        "plt.ylabel(r'$d_{ik}$', fontsize=38)\n",
        "\n",
        "plt.axes([0.047, 0.03, 0.2, 0.44])\n",
        "tsne_grad_inten = np.sqrt(tsne_U ** 2 + tsne_V ** 2)\n",
        "tsne_grad_inten = np.array(tsne_grad_inten)\n",
        "for i in range(tsne_grad_inten.shape[0]):\n",
        "    for j in range(tsne_grad_inten.shape[1]):\n",
        "        if tsne_grad_inten[i, j] > 0.00005:\n",
        "            tsne_grad_inten[i, j] = 0.00005\n",
        "plt.streamplot(xx, yy, tsne_U, tsne_V, density=(2.4, 1.0), linewidth=0.8, arrowsize=2.5, maxlength=1.)\n",
        "im = plt.imshow(tsne_grad_inten, origin='lower', extent=(0.0001, 100, 0.0001, 100), cmap=cmap_)\n",
        "cb = plt.colorbar(im)\n",
        "cb.ax.tick_params(labelsize=23)\n",
        "plt.title('Gradient magnitude', fontsize=34)\n",
        "plt.xticks(fontsize=23)\n",
        "plt.yticks(fontsize=23)\n",
        "plt.xlabel(r'$d_{ij}$', fontsize=38)\n",
        "plt.ylabel(r'$d_{ik}$', fontsize=38)\n",
        "\n",
        "\n",
        "\n",
        "plt.axes([0.293, 0.52, 0.2, 0.44])\n",
        "x = np.linspace(0.0001, 25, num=7000) # d_ij\n",
        "y = np.linspace(0.0001, 25, num=7000) # d_ik\n",
        "xx, yy = np.meshgrid(x, y, sparse=True)\n",
        "u_loss = -integ_attr(xx) -integ_repul(yy)\n",
        "u_U = attr(xx) + 0*yy\n",
        "u_V = repul(yy) + 0*xx\n",
        "plt.streamplot(xx, yy, u_U, u_V, density=(2.4, 1.0), linewidth=0.8, arrowsize=2.5, maxlength=1.)\n",
        "im = plt.imshow(u_loss, origin='lower', extent=(0.0001, 25, 0.0001, 25), cmap=cmap)\n",
        "cb = plt.colorbar(im)\n",
        "cb.ax.tick_params(labelsize=23)\n",
        "plt.title('Loss (UMAP)', fontsize=38)\n",
        "plt.xticks(fontsize=23)\n",
        "plt.yticks(fontsize=23)\n",
        "plt.xlabel(r'$d_{ij}$', fontsize=38)\n",
        "plt.ylabel(r'$d_{ik}$', fontsize=38)\n",
        "\n",
        "plt.axes([0.293, 0.03, 0.2, 0.44])\n",
        "u_grad_inten = np.sqrt(u_U ** 2 + u_V ** 2)\n",
        "for i in range(u_grad_inten.shape[0]):\n",
        "    for j in range(u_grad_inten.shape[1]):\n",
        "        if u_grad_inten[i, j] > 1:\n",
        "            u_grad_inten[i, j] = 1\n",
        "plt.streamplot(xx, yy, u_U, u_V, density=(2.4, 1.0), linewidth=0.8, arrowsize=2.5, maxlength=1.)\n",
        "im = plt.imshow(u_grad_inten, origin='lower', extent=(0.0001, 25, 0.0001, 25), cmap=cmap_)\n",
        "cb = plt.colorbar(im)\n",
        "cb.ax.tick_params(labelsize=23)\n",
        "plt.title('Gradient magnitude', fontsize=34)\n",
        "plt.xticks(fontsize=23)\n",
        "plt.yticks(fontsize=23)\n",
        "plt.xlabel(r'$d_{ij}$', fontsize=38)\n",
        "plt.ylabel(r'$d_{ik}$', fontsize=38)\n",
        "\n",
        "\n",
        "plt.axes([0.543, 0.52, 0.2, 0.44])\n",
        "x = np.linspace(0.0001, 200, num=7000) # d_ij\n",
        "y = np.linspace(0.0001, 200, num=7000) # d_ik\n",
        "xx, yy = np.meshgrid(x, y, sparse=True)\n",
        "t_loss = (1.0 + xx**2)/(2.0 + xx**2 + yy**2)\n",
        "t_U = (2*xx + 2 * xx * yy**2)/(2 + xx**2 + yy**2)**2\n",
        "t_V = (-2*yy*(1 + xx**2))/(2 + xx**2 + yy**2)**2\n",
        "plt.streamplot(xx, yy, -t_U, -t_V, density=(2.4, 1.0), linewidth=0.8, arrowsize=2.4, maxlength=1.)\n",
        "im = plt.imshow(t_loss, origin='lower', extent=(0.0001, 200, 0.0001, 200), cmap=cmap)\n",
        "cb = plt.colorbar(im)\n",
        "cb.ax.tick_params(labelsize=23)\n",
        "plt.title('Loss (TriMAP)', fontsize=38)\n",
        "plt.xticks([50, 100, 150, 200], fontsize=23)\n",
        "plt.yticks([50, 100, 150, 200], fontsize=23)\n",
        "plt.xlabel(r'$d_{ij}$', fontsize=38)\n",
        "plt.ylabel(r'$d_{ik}$', fontsize=38)\n",
        "\n",
        "plt.axes([0.543, 0.03, 0.2, 0.44])\n",
        "t_grad_inten = np.sqrt(t_U ** 2 + t_V ** 2)\n",
        "for i in range(t_grad_inten.shape[0]):\n",
        "    for j in range(t_grad_inten.shape[1]):\n",
        "        if t_grad_inten[i, j] > 0.012:\n",
        "            t_grad_inten[i,j] = 0.012\n",
        "plt.streamplot(xx, yy, -t_U, -t_V, density=(2.4, 1.0), linewidth=0.8, arrowsize=2.5, maxlength=1.)\n",
        "im = plt.imshow(t_grad_inten, origin='lower', extent=(0.0001, 200, 0.0001, 200), cmap=cmap_)\n",
        "cb = plt.colorbar(im)\n",
        "cb.ax.tick_params(labelsize=23)\n",
        "plt.title('Gradient magnitude', fontsize=34)\n",
        "plt.xticks([50, 100, 150, 200],fontsize=23)\n",
        "plt.yticks([50, 100, 150, 200], fontsize=23)\n",
        "plt.xlabel(r'$d_{ij}$', fontsize=38)\n",
        "plt.ylabel(r'$d_{ik}$', fontsize=38)\n",
        "\n",
        "\n",
        "plt.axes([0.795, 0.52, 0.2, 0.44])\n",
        "x = np.linspace(0.0001, 50, num=7000) # d_ij\n",
        "y = np.linspace(0.0001, 50, num=7000) # d_ik\n",
        "xx, yy = np.meshgrid(x, y, sparse=True)\n",
        "p_loss = 1.5 * (xx**2 + 1)/(11.0 + xx**2) + 3.0/(2.0 + yy**2)\n",
        "p_U = -1.5 * (20*xx)/(11.0 + xx**2)**2 + (0 * yy)\n",
        "p_V = 3 * (2*yy)/(2 + yy**2)**2 + (0 * xx)\n",
        "plt.streamplot(xx, yy, p_U, p_V, density=(2.4, 1.0), linewidth=0.8, arrowsize=2.4, maxlength=1.)\n",
        "im = plt.imshow(p_loss, origin='lower', extent=(0.01, 50, 0.01, 50), cmap=cmap)\n",
        "cb = plt.colorbar(im)\n",
        "cb.ax.tick_params(labelsize=23)\n",
        "plt.title('Loss (PaCMAP)', fontsize=38)\n",
        "plt.xticks(fontsize=23)\n",
        "plt.yticks(fontsize=23)\n",
        "plt.xlabel(r'$d_{ij}$', fontsize=38)\n",
        "plt.ylabel(r'$d_{ik}$', fontsize=38)\n",
        "\n",
        "plt.axes([0.795, 0.03, 0.2, 0.44])\n",
        "p_grad_inten = np.sqrt(p_U ** 2 + p_V ** 2)\n",
        "plt.streamplot(xx, yy, p_U, p_V, density=(2.4, 1.0), linewidth=0.8, arrowsize=2.5, maxlength=1.)\n",
        "for i in range(p_grad_inten.shape[0]):\n",
        "    for j in range(p_grad_inten.shape[1]):\n",
        "        if p_grad_inten[i, j] > 0.5:\n",
        "            p_grad_inten[i,j] = 0.5\n",
        "im = plt.imshow(p_grad_inten, origin='lower', extent=(0.0001, 50, 0.0001, 50), cmap=cmap_)\n",
        "cb = plt.colorbar(im)\n",
        "cb.ax.tick_params(labelsize=23)\n",
        "plt.title('Gradient magnitude', fontsize=34)\n",
        "plt.xticks(fontsize=23)\n",
        "plt.yticks(fontsize=23)\n",
        "plt.xlabel(r'$d_{ij}$', fontsize=38)\n",
        "plt.ylabel(r'$d_{ik}$', fontsize=38)\n",
        "\n",
        "\n",
        "plt.savefig('rainbow_good_loss')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hy82AH2ZGo0A"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "from typing import Optional\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pacmap\n",
        "\n",
        "def load_data(data_path: str, labels_path: str) -> tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Load preprocessed data and labels from the specified file paths.\n",
        "\n",
        "    Args:\n",
        "        data_path (str): Path to the data file in .npy format.\n",
        "        labels_path (str): Path to the labels file in .npy format.\n",
        "\n",
        "    Returns:\n",
        "        tuple[np.ndarray, np.ndarray]: A tuple containing the loaded data and labels.\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: If the specified data or labels file is not found.\n",
        "        ValueError: If the loaded data or labels have an invalid shape.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        data = np.load(data_path, allow_pickle=True)\n",
        "        labels = np.load(labels_path, allow_pickle=True)\n",
        "    except FileNotFoundError as e:\n",
        "        raise FileNotFoundError(f\"Data or labels file not found: {e}\")\n",
        "\n",
        "    if data.ndim != 2:\n",
        "        raise ValueError(f\"Invalid data shape. Expected 2D array, got {data.ndim}D.\")\n",
        "    if labels.ndim != 1:\n",
        "        raise ValueError(f\"Invalid labels shape. Expected 1D array, got {labels.ndim}D.\")\n",
        "\n",
        "    return data.reshape(data.shape[0], -1), labels\n",
        "\n",
        "def visualize_embedding(embedding: np.ndarray, labels: np.ndarray, figsize: tuple[int, int] = (6, 6)) -> None:\n",
        "    \"\"\"\n",
        "    Visualize the embedding using a scatter plot.\n",
        "\n",
        "    Args:\n",
        "        embedding (np.ndarray): The transformed embedding data.\n",
        "        labels (np.ndarray): The corresponding labels for each data point.\n",
        "        figsize (tuple[int, int], optional): The figure size. Defaults to (6, 6).\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
        "    ax.scatter(embedding[:, 0], embedding[:, 1], cmap=\"Spectral\", c=labels, s=0.6)\n",
        "    plt.show()\n",
        "\n",
        "def main(data_path: str, labels_path: str, n_components: int, n_neighbors: Optional[int],\n",
        "         mn_ratio: float, fp_ratio: float) -> None:\n",
        "    \"\"\"\n",
        "    Main function to run the PaCMAP embedding and visualization.\n",
        "\n",
        "    Args:\n",
        "        data_path (str): Path to the data file in .npy format.\n",
        "        labels_path (str): Path to the labels file in .npy format.\n",
        "        n_components (int): Number of components for the embedding.\n",
        "        n_neighbors (Optional[int]): Number of nearest neighbors to consider. None for default.\n",
        "        mn_ratio (float): Ratio of mid-near pairs to sample.\n",
        "        fp_ratio (float): Ratio of further pairs to sample.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        data, labels = load_data(data_path, labels_path)\n",
        "    except (FileNotFoundError, ValueError) as e:\n",
        "        print(f\"Error loading data: {e}\")\n",
        "        return\n",
        "\n",
        "    embedding = pacmap.PaCMAP(n_components=n_components, n_neighbors=n_neighbors,\n",
        "                              MN_ratio=mn_ratio, FP_ratio=fp_ratio)\n",
        "    transformed_data = embedding.fit_transform(data, init=\"pca\")\n",
        "    visualize_embedding(transformed_data, labels)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser(description=\"PaCMAP embedding and visualization\")\n",
        "    parser.add_argument(\"--data_path\", type=str, default=\"./data/coil_20.npy\", help=\"Path to the data file\")\n",
        "    parser.add_argument(\"--labels_path\", type=str, default=\"./data/coil_20_labels.npy\", help=\"Path to the labels file\")\n",
        "    parser.add_argument(\"--n_components\", type=int, default=2, help=\"Number of components for the embedding\")\n",
        "    parser.add_argument(\"--n_neighbors\", type=int, default=None, help=\"Number of nearest neighbors to consider\")\n",
        "    parser.add_argument(\"--mn_ratio\", type=float, default=0.5, help=\"Ratio of mid-near pairs to sample\")\n",
        "    parser.add_argument(\"--fp_ratio\", type=float, default=2.0, help=\"Ratio of further pairs to sample\")\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    main(args.data_path, args.labels_path, args.n_components, args.n_neighbors, args.mn_ratio, args.fp_ratio)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9O6zCTrGXOJ"
      },
      "outputs": [],
      "source": [
        "import pacmap\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# loading preprocessed coil_20 dataset\n",
        "# you can change it with any dataset that is in the ndarray format, with the shape (N, D)\n",
        "# where N is the number of samples and D is the dimension of each sample\n",
        "X = np.load(\"./data/coil_20.npy\", allow_pickle=True)\n",
        "X = X.reshape(X.shape[0], -1)\n",
        "y = np.load(\"./data/coil_20_labels.npy\", allow_pickle=True)\n",
        "\n",
        "# initializing the pacmap instance\n",
        "# Setting n_neighbors to \"None\" leads to a default choice shown below in \"parameter\" section\n",
        "embedding = pacmap.PaCMAP(n_components=2, n_neighbors=None, MN_ratio=0.5, FP_ratio=2.0)\n",
        "\n",
        "# fit the data (The index of transformed data corresponds to the index of the original data)\n",
        "X_transformed = embedding.fit_transform(X, init=\"pca\")\n",
        "\n",
        "# visualize the embedding\n",
        "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
        "ax.scatter(X_transformed[:, 0], X_transformed[:, 1], cmap=\"Spectral\", c=y, s=0.6)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4q6kCe-NjBq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pacmap\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "\n",
        "pd.set_option(\"display.max_colwidth\", None)\n",
        "\n",
        "# Generate random test data\n",
        "num_samples = 100000\n",
        "num_features = 2\n",
        "num_classes = 5\n",
        "\n",
        "data = np.random.rand(num_samples, num_features)\n",
        "labels = np.random.randint(0, num_classes, size=num_samples)\n",
        "\n",
        "# Create a PaCMAP instance\n",
        "embedding_projector = pacmap.PaCMAP(\n",
        "    n_components=2, n_neighbors=None, MN_ratio=0.5, FP_ratio=2.0, random_state=1\n",
        ")\n",
        "\n",
        "# Fit the data\n",
        "embedding_projector.fit(data, init=\"pca\")\n",
        "\n",
        "# Transform the data and the query point\n",
        "documents_projected = embedding_projector.transform(data)\n",
        "query_point = np.random.rand(1, num_features)\n",
        "query_projected = embedding_projector.transform(query_point)\n",
        "\n",
        "# Create a DataFrame for visualization\n",
        "df = pd.DataFrame({\n",
        "    \"x\": documents_projected[:, 0],\n",
        "    \"y\": documents_projected[:, 1],\n",
        "    \"class\": labels,\n",
        "    \"size_col\": 4,\n",
        "    \"symbol\": \"circle\"\n",
        "})\n",
        "\n",
        "query_df = pd.DataFrame({\n",
        "    \"x\": query_projected[0, 0],\n",
        "    \"y\": query_projected[0, 1],\n",
        "    \"class\": \"Query\",\n",
        "    \"size_col\": 100,\n",
        "    \"symbol\": \"star\"\n",
        "}, index=[0])\n",
        "\n",
        "df = pd.concat([df, query_df], ignore_index=True)\n",
        "\n",
        "# Visualize the embedding\n",
        "fig = px.scatter(\n",
        "    df,\n",
        "    x=\"x\",\n",
        "    y=\"y\",\n",
        "    color=\"class\",\n",
        "    size=\"size_col\",\n",
        "    symbol=\"symbol\",\n",
        "    color_discrete_map={\"Query\": \"black\"},\n",
        "    width=1000,\n",
        "    height=700,\n",
        ")\n",
        "fig.update_traces(\n",
        "    marker=dict(opacity=1, line=dict(width=0, color=\"DarkSlateGrey\")), selector=dict(mode=\"markers\")\n",
        ")\n",
        "fig.update_layout(\n",
        "    legend_title_text=\"<b>Class</b>\",\n",
        "    title=\"<b>2D Projection of Test Data via PaCMAP</b>\",\n",
        ")\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZMDCNxhOydo"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
