{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio as audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AudioMetaData',\n",
       " 'backend',\n",
       " 'compliance',\n",
       " 'datasets',\n",
       " 'functional',\n",
       " 'get_audio_backend',\n",
       " 'git_version',\n",
       " 'info',\n",
       " 'io',\n",
       " 'kaldi_io',\n",
       " 'lib',\n",
       " 'list_audio_backends',\n",
       " 'load',\n",
       " 'models',\n",
       " 'pipelines',\n",
       " 'save',\n",
       " 'set_audio_backend',\n",
       " 'sox_effects',\n",
       " 'transforms',\n",
       " 'utils',\n",
       " 'version']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchaudio\n",
    "\n",
    "functionality=dir(torchaudio)\n",
    "\n",
    "func=[f for f in functionality if not f.startswith('_')]\n",
    "\n",
    "func\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: 'charmap' codec can't decode byte 0x9d in position 3520: character maps to <undefined>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "from typing import List\n",
    "from pptx import Presentation\n",
    "from pptx.util import Inches\n",
    "\n",
    "def create_slides(presentation: Presentation, lines: List[str]) -> None:\n",
    "    \"\"\"\n",
    "    Create slides from the given lines of text.\n",
    "\n",
    "    :param presentation: The PowerPoint presentation object.\n",
    "    :param lines: A list of strings representing the lines of text.\n",
    "    \"\"\"\n",
    "    for line in lines:\n",
    "        slide = presentation.slides.add_slide(presentation.slide_layouts[1])\n",
    "        title = slide.shapes.title\n",
    "        title.text = line\n",
    "\n",
    "def convert_txt_to_ppt(file_path: str, output_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Convert a .txt file into a PowerPoint presentation.\n",
    "\n",
    "    :param file_path: The path to the input .txt file.\n",
    "    :param output_path: The path to save the output PowerPoint presentation.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        presentation = Presentation()\n",
    "        create_slides(presentation, lines)\n",
    "        presentation.save(output_path)\n",
    "\n",
    "        print(f\"Successfully converted {file_path} to {output_path}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "\n",
    "\n",
    "txt_files = 'E:/LLMS/hemanth/Hemanth/file_operations-/File_and_Operations/Coding_from_colab/pytorch/pdf_content.txt'\n",
    "output_file = 'presentation1.pptx'\n",
    "convert_txt_to_ppt(txt_files, output_file)\n",
    "# if __name__ == '__main__':\n",
    "#     parser = argparse.ArgumentParser(description='Convert .txt file to PowerPoint presentation')\n",
    "#     parser.add_argument('file_path', type=str, help='Path to the input .txt file')\n",
    "#     parser.add_argument('output_path', type=str, help='Path to save the output PowerPoint presentation')\n",
    "#     args = parser.parse_args()\n",
    "\n",
    "#     convert_txt_to_ppt(args.file_path, args.output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PowerPoint presentation created: presentation.pptx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import List\n",
    "from pptx import Presentation\n",
    "from pptx.util import Inches, Pt\n",
    "\n",
    "def create_ppt_from_txt(txt_files: List[str], output_file: str) -> None:\n",
    "    \"\"\"\n",
    "    Create a PowerPoint presentation from a list of .txt files.\n",
    "\n",
    "    Args:\n",
    "        txt_files (List[str]): A list of file paths to .txt files.\n",
    "        output_file (str): The file path for the output PowerPoint presentation.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If a specified .txt file does not exist.\n",
    "        PermissionError: If there is insufficient permission to create the output file.\n",
    "    \"\"\"\n",
    "    prs = Presentation()\n",
    "    default_layout = prs.slide_layouts[1]  # Title and Content layout\n",
    "\n",
    "    for txt_file in txt_files:\n",
    "        if not os.path.isfile(txt_file):\n",
    "            raise FileNotFoundError(f\"File not found: {txt_file}\")\n",
    "\n",
    "        with open(txt_file, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "\n",
    "        slide = prs.slides.add_slide(default_layout)\n",
    "        title = slide.shapes.title\n",
    "        title.text = os.path.basename(txt_file)\n",
    "\n",
    "        text_box = slide.shapes.add_textbox(Inches(1), Inches(2), Inches(8), Inches(5))\n",
    "        text_frame = text_box.text_frame\n",
    "        text_frame.text = content\n",
    "        text_frame.paragraphs[0].font.size = Pt(18)\n",
    "\n",
    "    try:\n",
    "        prs.save(output_file)\n",
    "        print(f\"PowerPoint presentation created: {output_file}\")\n",
    "    except PermissionError:\n",
    "        raise PermissionError(f\"Insufficient permission to create file: {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    txt_files = ['E:/LLMS/hemanth/Hemanth/file_operations-/File_and_Operations/Coding_from_colab/pytorch/pdf_content.txt']\n",
    "    output_file = 'presentation.pptx'\n",
    "    create_ppt_from_txt(txt_files, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted E:/LLMS/hemanth/Hemanth/file_operations-/File_and_Operations/Coding_from_colab/pytorch/pdf_content.txt to path_to_save_ppt_file.pptx successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pptx import Presentation\n",
    "from pptx.util import Inches, Pt\n",
    "from typing import List\n",
    "\n",
    "def read_txt_file(file_path: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Reads a .txt file and returns a list of lines.\n",
    "\n",
    "    :param file_path: str, path to the .txt file\n",
    "    :return: List[str], list of lines in the file\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"{file_path} does not exist.\")\n",
    "    with open(file_path, 'r',encoding='utf-8') as file:\n",
    "        while True:\n",
    "            line = file.readline()\n",
    "            if not line:\n",
    "                break  # EOF\n",
    "            yield line\n",
    "\n",
    "def convert_to_ppt(lines: List[str], ppt_file_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Converts a list of lines into a PowerPoint presentation.\n",
    "\n",
    "    :param lines: List[str], list of lines to be converted\n",
    "    :param ppt_file_path: str, path to save the .pptx file\n",
    "    \"\"\"\n",
    "    prs = Presentation()\n",
    "    for line in lines:\n",
    "        slide = prs.slides.add_slide(prs.slide_layouts[5])\n",
    "        left = top = width = height = Inches(1)\n",
    "        txBox = slide.shapes.add_textbox(left, top, width, height)\n",
    "        tf = txBox.text_frame\n",
    "        p = tf.add_paragraph()\n",
    "        p.text = line\n",
    "        p.font.bold = True\n",
    "        p.font.size = Pt(40)\n",
    "    prs.save(ppt_file_path)\n",
    "\n",
    "def main(txt_file_path: str, ppt_file_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Main function to read a .txt file and convert it into a .pptx file.\n",
    "\n",
    "    :param txt_file_path: str, path to the .txt file\n",
    "    :param ppt_file_path: str, path to save the .pptx file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        lines = read_txt_file(txt_file_path)\n",
    "        convert_to_ppt(lines, ppt_file_path)\n",
    "        print(f\"Converted {txt_file_path} to {ppt_file_path} successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main('E:/LLMS/hemanth/Hemanth/file_operations-/File_and_Operations/Coding_from_colab/pytorch/pdf_content.txt', 'path_to_save_ppt_file.pptx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text saved successfully to 'pdf_content.txt'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from typing import List\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def download_pdf(url: str) -> bytes:\n",
    "    \"\"\"\n",
    "    Download a PDF file from the given URL and return its content as bytes.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the PDF file to download.\n",
    "\n",
    "    Returns:\n",
    "        bytes: The content of the downloaded PDF file as bytes.\n",
    "\n",
    "    Raises:\n",
    "        requests.exceptions.RequestException: If there is an error while downloading the PDF file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        return response.content\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error downloading PDF: {e}\")\n",
    "        raise\n",
    "\n",
    "def extract_text_from_pdf(pdf_content: bytes) -> str:\n",
    "    \"\"\"\n",
    "    Extract text from each page of a PDF file and return it as a single string.\n",
    "\n",
    "    Args:\n",
    "        pdf_content (bytes): The content of the PDF file as bytes.\n",
    "\n",
    "    Returns:\n",
    "        str: A single string containing the text from all pages of the PDF.\n",
    "    \"\"\"\n",
    "    pdf_reader = PdfReader(BytesIO(pdf_content))\n",
    "    text = \"\"\n",
    "    for page in pdf_reader.pages:\n",
    "        text += page.extract_text() + \"\\n\"\n",
    "    return text.strip()\n",
    "\n",
    "def save_text_to_file(text: str, file_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Save the text to a single .txt file at the specified file path.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to be saved to the file.\n",
    "        file_path (str): The path to the .txt file where the text will be saved.\n",
    "\n",
    "    Raises:\n",
    "        OSError: If there is an error while writing the file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text)\n",
    "    except OSError as e:\n",
    "        print(f\"Error saving text to file: {e}\")\n",
    "        raise\n",
    "\n",
    "def main() -> None:\n",
    "    \"\"\"\n",
    "    The main function that orchestrates the process of downloading the PDF, extracting text, and saving it to a file.\n",
    "    \"\"\"\n",
    "    url = \"https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-2e2023.pdf\"\n",
    "    file_path = \"pdf_content.txt\"\n",
    "\n",
    "    try:\n",
    "        pdf_content = download_pdf(url)\n",
    "        text = extract_text_from_pdf(pdf_content)\n",
    "        save_text_to_file(text, file_path)\n",
    "        print(f\"Text saved successfully to '{file_path}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text from each page saved successfully in the 'pdf_text_files' folder.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from typing import List\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def download_pdf(url: str) -> bytes:\n",
    "    \"\"\"\n",
    "    Download a PDF file from the given URL and return its content as bytes.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the PDF file to download.\n",
    "\n",
    "    Returns:\n",
    "        bytes: The content of the downloaded PDF file as bytes.\n",
    "\n",
    "    Raises:\n",
    "        requests.exceptions.RequestException: If there is an error while downloading the PDF file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        return response.content\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error downloading PDF: {e}\")\n",
    "        raise\n",
    "\n",
    "def extract_text_from_pdf(pdf_content: bytes) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extract text from each page of a PDF file and return it as a list of strings.\n",
    "\n",
    "    Args:\n",
    "        pdf_content (bytes): The content of the PDF file as bytes.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: A list of strings, where each string represents the text from a page of the PDF.\n",
    "    \"\"\"\n",
    "    pdf_reader = PdfReader(BytesIO(pdf_content))\n",
    "    text_pages = []\n",
    "    for page in pdf_reader.pages:\n",
    "        text = page.extract_text()\n",
    "        text_pages.append(text)\n",
    "    return text_pages\n",
    "\n",
    "def save_text_to_files(text_pages: List[str], folder_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Save the text from each page of a PDF to separate .txt files in the specified folder.\n",
    "\n",
    "    Args:\n",
    "        text_pages (List[str]): A list of strings, where each string represents the text from a page of the PDF.\n",
    "        folder_path (str): The path to the folder where the .txt files will be saved.\n",
    "\n",
    "    Raises:\n",
    "        OSError: If there is an error while creating the folder or writing the files.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "        for i, text in enumerate(text_pages, start=1):\n",
    "            file_path = os.path.join(folder_path, f\"page_{i}.txt\")\n",
    "            with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "                file.write(text)\n",
    "    except OSError as e:\n",
    "        print(f\"Error saving text to files: {e}\")\n",
    "        raise\n",
    "\n",
    "def main() -> None:\n",
    "    \"\"\"\n",
    "    The main function that orchestrates the process of downloading the PDF, extracting text, and saving it to files.\n",
    "    \"\"\"\n",
    "    url = \"https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-2e2023.pdf\"\n",
    "    folder_path = \"pdf_text_files\"\n",
    "\n",
    "    try:\n",
    "        pdf_content = download_pdf(url)\n",
    "        text_pages = extract_text_from_pdf(pdf_content)\n",
    "        save_text_to_files(text_pages, folder_path)\n",
    "        print(f\"Text from each page saved successfully in the '{folder_path}' folder.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Tuple, Optional\n",
    "\n",
    "def generate_rotational_matrix(num_pos_feats: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Generate a rotational matrix for positional embeddings.\n",
    "\n",
    "    Args:\n",
    "        num_pos_feats (int): Number of positional features (channels).\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Rotational matrix of shape (num_pos_feats, num_pos_feats).\n",
    "\n",
    "    Example:\n",
    "        >>> num_pos_feats = 1024\n",
    "        >>> rotational_matrix = generate_rotational_matrix(num_pos_feats)\n",
    "        >>> rotational_matrix.shape\n",
    "        torch.Size([1024, 1024])\n",
    "    \"\"\"\n",
    "    # Initialize the rotational matrix as an identity matrix\n",
    "    rotation_matrix = torch.eye(num_pos_feats)\n",
    "    return rotation_matrix\n",
    "\n",
    "def rotational_sinusoidal_positional_embeddings(\n",
    "    tensor: torch.Tensor,\n",
    "    num_pos_feats: int = 1024,\n",
    "    temperature: float = 10000,\n",
    "    normalize: bool = False,\n",
    "    scale: Optional[float] = None,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Generate rotational sinusoidal positional embeddings for an input tensor.\n",
    "\n",
    "    Args:\n",
    "        tensor (torch.Tensor): Input tensor of any dimensions.\n",
    "        num_pos_feats (int, optional): Number of positional features (channels) to generate. Defaults to 1024.\n",
    "        temperature (float, optional): Temperature for scaling the embeddings. Defaults to 10000.\n",
    "        normalize (bool, optional): Whether to normalize the embeddings. Defaults to False.\n",
    "        scale (float, optional): Scale factor for the embeddings. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Positional embeddings with the same shape as the input tensor.\n",
    "\n",
    "    Example:\n",
    "        >>> tensor = torch.randn(512)\n",
    "        >>> pos_embeddings = rotational_sinusoidal_positional_embeddings(tensor, normalize=True)\n",
    "        >>> pos_embeddings.shape\n",
    "        torch.Size([512, 1024])\n",
    "    \"\"\"\n",
    "    if scale is None:\n",
    "        scale = 2 * torch.pi\n",
    "\n",
    "    shape = tensor.shape\n",
    "    dim_t = torch.arange(num_pos_feats, dtype=torch.float32, device=tensor.device)\n",
    "    dim_t = temperature ** (2 * (dim_t // 2) / num_pos_feats)\n",
    "\n",
    "    pos_embeddings = []\n",
    "    for dim in range(len(shape)):\n",
    "        pos = torch.arange(shape[dim], dtype=torch.float32, device=tensor.device)\n",
    "        pos_embed = pos[:, None] / dim_t[None, :]\n",
    "        pos_embed[:, 0::2] = torch.sin(pos_embed[:, 0::2])\n",
    "        pos_embed[:, 1::2] = torch.cos(pos_embed[:, 1::2])\n",
    "        pos_embeddings.append(pos_embed)\n",
    "\n",
    "    # Reshape each positional embedding to match the input tensor shape\n",
    "    reshaped_embeddings = []\n",
    "    for i, embedding in enumerate(pos_embeddings):\n",
    "        dims = [1] * len(shape)\n",
    "        dims[i] = shape[i]\n",
    "        reshaped_embeddings.append(embedding.view(*dims, -1).expand(*shape, -1))\n",
    "\n",
    "    pos_embeddings = torch.cat(reshaped_embeddings, dim=-1)\n",
    "\n",
    "    # Apply self-attention to the positional embeddings\n",
    "    try:\n",
    "        attention_weights = torch.softmax(\n",
    "            torch.matmul(pos_embeddings, pos_embeddings.transpose(-1, -2))\n",
    "            / torch.sqrt(torch.tensor(num_pos_feats, dtype=torch.float32)),\n",
    "            dim=-1,\n",
    "        )\n",
    "        pos_embeddings = torch.matmul(attention_weights, pos_embeddings)\n",
    "    except RuntimeError as e:\n",
    "        raise ValueError(f\"Error in self-attention calculation: {str(e)}\") from e\n",
    "\n",
    "    # Apply a rotational block\n",
    "    rotation_matrix = generate_rotational_matrix(pos_embeddings.shape[-1])\n",
    "    pos_embeddings = torch.matmul(\n",
    "        pos_embeddings.view(-1, pos_embeddings.shape[-1]), rotation_matrix\n",
    "    )\n",
    "    pos_embeddings = pos_embeddings.view(*shape, -1)\n",
    "\n",
    "    if normalize:\n",
    "        # Apply square root mean normalization\n",
    "        pos_embeddings = pos_embeddings / torch.sqrt(\n",
    "            torch.mean(pos_embeddings**2, dim=-1, keepdim=True)\n",
    "        )\n",
    "        pos_embeddings = pos_embeddings * scale\n",
    "\n",
    "    return pos_embeddings\n",
    "\n",
    "# Example usage\n",
    "torch.manual_seed(seed=100)\n",
    "tensor = torch.randn(512)\n",
    "pos_embeddings = rotational_sinusoidal_positional_embeddings(tensor, normalize=True)\n",
    "print(pos_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AdaptiveAvgPool1d',\n",
       " 'AdaptiveAvgPool2d',\n",
       " 'AdaptiveAvgPool3d',\n",
       " 'AdaptiveLogSoftmaxWithLoss',\n",
       " 'AdaptiveMaxPool1d',\n",
       " 'AdaptiveMaxPool2d',\n",
       " 'AdaptiveMaxPool3d',\n",
       " 'AlphaDropout',\n",
       " 'AvgPool1d',\n",
       " 'AvgPool2d',\n",
       " 'AvgPool3d',\n",
       " 'BCELoss',\n",
       " 'BCEWithLogitsLoss',\n",
       " 'BatchNorm1d',\n",
       " 'BatchNorm2d',\n",
       " 'BatchNorm3d',\n",
       " 'Bilinear',\n",
       " 'CELU',\n",
       " 'CTCLoss',\n",
       " 'ChannelShuffle',\n",
       " 'CircularPad1d',\n",
       " 'CircularPad2d',\n",
       " 'CircularPad3d',\n",
       " 'ConstantPad1d',\n",
       " 'ConstantPad2d',\n",
       " 'ConstantPad3d',\n",
       " 'Container',\n",
       " 'Conv1d',\n",
       " 'Conv2d',\n",
       " 'Conv3d',\n",
       " 'ConvTranspose1d',\n",
       " 'ConvTranspose2d',\n",
       " 'ConvTranspose3d',\n",
       " 'CosineEmbeddingLoss',\n",
       " 'CosineSimilarity',\n",
       " 'CrossEntropyLoss',\n",
       " 'CrossMapLRN2d',\n",
       " 'DataParallel',\n",
       " 'Dropout',\n",
       " 'Dropout1d',\n",
       " 'Dropout2d',\n",
       " 'Dropout3d',\n",
       " 'ELU',\n",
       " 'Embedding',\n",
       " 'EmbeddingBag',\n",
       " 'FeatureAlphaDropout',\n",
       " 'Flatten',\n",
       " 'Fold',\n",
       " 'FractionalMaxPool2d',\n",
       " 'FractionalMaxPool3d',\n",
       " 'GELU',\n",
       " 'GLU',\n",
       " 'GRU',\n",
       " 'GRUCell',\n",
       " 'GaussianNLLLoss',\n",
       " 'GroupNorm',\n",
       " 'Hardshrink',\n",
       " 'Hardsigmoid',\n",
       " 'Hardswish',\n",
       " 'Hardtanh',\n",
       " 'HingeEmbeddingLoss',\n",
       " 'HuberLoss',\n",
       " 'Identity',\n",
       " 'InstanceNorm1d',\n",
       " 'InstanceNorm2d',\n",
       " 'InstanceNorm3d',\n",
       " 'KLDivLoss',\n",
       " 'L1Loss',\n",
       " 'LPPool1d',\n",
       " 'LPPool2d',\n",
       " 'LSTM',\n",
       " 'LSTMCell',\n",
       " 'LayerNorm',\n",
       " 'LazyBatchNorm1d',\n",
       " 'LazyBatchNorm2d',\n",
       " 'LazyBatchNorm3d',\n",
       " 'LazyConv1d',\n",
       " 'LazyConv2d',\n",
       " 'LazyConv3d',\n",
       " 'LazyConvTranspose1d',\n",
       " 'LazyConvTranspose2d',\n",
       " 'LazyConvTranspose3d',\n",
       " 'LazyInstanceNorm1d',\n",
       " 'LazyInstanceNorm2d',\n",
       " 'LazyInstanceNorm3d',\n",
       " 'LazyLinear',\n",
       " 'LeakyReLU',\n",
       " 'Linear',\n",
       " 'LocalResponseNorm',\n",
       " 'LogSigmoid',\n",
       " 'LogSoftmax',\n",
       " 'MSELoss',\n",
       " 'MarginRankingLoss',\n",
       " 'MaxPool1d',\n",
       " 'MaxPool2d',\n",
       " 'MaxPool3d',\n",
       " 'MaxUnpool1d',\n",
       " 'MaxUnpool2d',\n",
       " 'MaxUnpool3d',\n",
       " 'Mish',\n",
       " 'Module',\n",
       " 'ModuleDict',\n",
       " 'ModuleList',\n",
       " 'MultiLabelMarginLoss',\n",
       " 'MultiLabelSoftMarginLoss',\n",
       " 'MultiMarginLoss',\n",
       " 'MultiheadAttention',\n",
       " 'NLLLoss',\n",
       " 'NLLLoss2d',\n",
       " 'PReLU',\n",
       " 'PairwiseDistance',\n",
       " 'Parameter',\n",
       " 'ParameterDict',\n",
       " 'ParameterList',\n",
       " 'PixelShuffle',\n",
       " 'PixelUnshuffle',\n",
       " 'PoissonNLLLoss',\n",
       " 'RNN',\n",
       " 'RNNBase',\n",
       " 'RNNCell',\n",
       " 'RNNCellBase',\n",
       " 'RReLU',\n",
       " 'ReLU',\n",
       " 'ReLU6',\n",
       " 'ReflectionPad1d',\n",
       " 'ReflectionPad2d',\n",
       " 'ReflectionPad3d',\n",
       " 'ReplicationPad1d',\n",
       " 'ReplicationPad2d',\n",
       " 'ReplicationPad3d',\n",
       " 'SELU',\n",
       " 'Sequential',\n",
       " 'SiLU',\n",
       " 'Sigmoid',\n",
       " 'SmoothL1Loss',\n",
       " 'SoftMarginLoss',\n",
       " 'Softmax',\n",
       " 'Softmax2d',\n",
       " 'Softmin',\n",
       " 'Softplus',\n",
       " 'Softshrink',\n",
       " 'Softsign',\n",
       " 'SyncBatchNorm',\n",
       " 'Tanh',\n",
       " 'Tanhshrink',\n",
       " 'Threshold',\n",
       " 'Transformer',\n",
       " 'TransformerDecoder',\n",
       " 'TransformerDecoderLayer',\n",
       " 'TransformerEncoder',\n",
       " 'TransformerEncoderLayer',\n",
       " 'TripletMarginLoss',\n",
       " 'TripletMarginWithDistanceLoss',\n",
       " 'Unflatten',\n",
       " 'Unfold',\n",
       " 'UninitializedBuffer',\n",
       " 'UninitializedParameter',\n",
       " 'Upsample',\n",
       " 'UpsamplingBilinear2d',\n",
       " 'UpsamplingNearest2d',\n",
       " 'ZeroPad1d',\n",
       " 'ZeroPad2d',\n",
       " 'ZeroPad3d',\n",
       " '_reduction',\n",
       " 'common_types',\n",
       " 'factory_kwargs',\n",
       " 'functional',\n",
       " 'grad',\n",
       " 'init',\n",
       " 'intrinsic',\n",
       " 'modules',\n",
       " 'parallel',\n",
       " 'parameter',\n",
       " 'qat',\n",
       " 'quantizable',\n",
       " 'quantized',\n",
       " 'utils']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import  nn\n",
    "import torch\n",
    "functionality=dir(nn)\n",
    "\n",
    "func=[f for f in functionality if not f.startswith('_' and '__')]\n",
    "func\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import  nn\n",
    "import torch\n",
    "\n",
    "m=nn.AdaptiveAvgPool1d\n",
    "\n",
    "# target output size of 5\n",
    "m = nn.AdaptiveAvgPool1d(5)\n",
    "input = torch.randn(1, 64, 8)\n",
    "output = m(input)\n",
    "output.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# target output size of 5x7\n",
    "m = nn.AdaptiveAvgPool2d((5, 7))\n",
    "input = torch.randn(1, 64, 8, 9)\n",
    "output = m(input)\n",
    "# target output size of 7x7 (square)\n",
    "m = nn.AdaptiveAvgPool2d(7)\n",
    "input = torch.randn(1, 64, 10, 9)\n",
    "output = m(input)\n",
    "# target output size of 10x7\n",
    "m = nn.AdaptiveAvgPool2d((None, 7))\n",
    "input = torch.randn(1, 64, 10, 9)\n",
    "output = m(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "Functionality=dir(torch)\n",
    "\n",
    "func=[f for f in Functionality if f.startswith('a')]\n",
    "func\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 2., 3., 4.],\n",
       "          [1., 2., 3., 4.],\n",
       "          [1., 2., 3., 4.]],\n",
       "\n",
       "         [[1., 2., 3., 4.],\n",
       "          [1., 2., 3., 4.],\n",
       "          [1., 2., 3., 4.]],\n",
       "\n",
       "         [[1., 2., 3., 4.],\n",
       "          [1., 2., 3., 4.],\n",
       "          [1., 2., 3., 4.]]],\n",
       "\n",
       "\n",
       "        [[[1., 2., 3., 4.],\n",
       "          [1., 2., 3., 4.],\n",
       "          [1., 2., 3., 4.]],\n",
       "\n",
       "         [[1., 2., 3., 4.],\n",
       "          [1., 2., 3., 4.],\n",
       "          [1., 2., 3., 4.]],\n",
       "\n",
       "         [[1., 2., 3., 4.],\n",
       "          [1., 2., 3., 4.],\n",
       "          [1., 2., 3., 4.]]]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "tensor=torch.rand(4,4,4)\n",
    "\n",
    "tensor1=torch.tensor(\n",
    "    [[[[1.0,2.0,3.0,4.0],[1.0,2.0,3.0,4.0],[1.0,2.0,3.0,4.0]],[[1.0,2.0,3.0,4.0],[1.0,2.0,3.0,4.0],[1.0,2.0,3.0,4.0]],[[1.0,2.0,3.0,4.0],[1.0,2.0,3.0,4.0],[1.0,2.0,3.0,4.0]]],[[[1.0,2.0,3.0,4.0],[1.0,2.0,3.0,4.0],[1.0,2.0,3.0,4.0]],[[1.0,2.0,3.0,4.0],[1.0,2.0,3.0,4.0],[1.0,2.0,3.0,4.0]],[[1.0,2.0,3.0,4.0],[1.0,2.0,3.0,4.0],[1.0,2.0,3.0,4.0]]]],dtype=torch.float32\n",
    ")\n",
    "tensor1.abs_()\n",
    "torch.acos(tensor)\n",
    "\n",
    "tensor1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "input_tensor =tensor1\n",
    "output_size = (5,5,5)\n",
    "output_tensor = F.adaptive_max_pool3d(input_tensor, output_size)\n",
    "print(\"Adaptive average pooling of input tensor:\", output_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=torch.add(tensor1, tensor1)\n",
    "\n",
    "output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.5942, 4.3511, 4.4219],\n",
       "        [3.6532, 4.1450, 4.1980],\n",
       "        [3.7101, 4.1979, 5.1637]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create two matrices and a batch containing two matrices\n",
    "mat1 = torch.rand(3, 3)\n",
    "mat2 = torch.rand(3, 3)\n",
    "batch1 = torch.rand(10, 3, 3)\n",
    "batch2 = torch.rand(10, 3, 3)\n",
    "\n",
    "# Add batch1 and batch2 element-wise to mat1 and mat2 respectively\n",
    "# The beta parameter is 1 and the alpha parameter is 1 by default\n",
    "result = torch.addbmm(mat1, batch1, batch2)\n",
    "\n",
    "# Alternatively, you can specify the beta and alpha parameters\n",
    "result = torch.addbmm(mat1, batch1, batch2, beta=0.5, alpha=0.5)\n",
    "\n",
    "result \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9241, 1.5405, 1.2781],\n",
       "        [0.8939, 1.6532, 0.3698],\n",
       "        [0.9018, 1.7482, 1.2343]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create two matrices and a batch containing two matrices\n",
    "mat1 = torch.rand(3, 3)\n",
    "mat2 = torch.rand(3, 3)\n",
    "mat3 = torch.rand(3, 3)\n",
    "\n",
    "# Add mat1 to mat2, element-wise divided by mat3\n",
    "# The value parameter is 1 by default\n",
    "result = torch.addcdiv(mat1, mat2, mat3)\n",
    "\n",
    "# Alternatively, you can specify the value parameter\n",
    "result = torch.addcdiv(mat1, mat2, mat3, value=0.5)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8520, 0.7058, 0.7211],\n",
       "        [0.9487, 0.5162, 0.8121],\n",
       "        [0.6552, 0.3609, 0.3623]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create two matrices and a batch containing two matrices\n",
    "mat1 = torch.rand(3, 3)\n",
    "mat2 = torch.rand(3, 3)\n",
    "mat3 = torch.rand(3, 3)\n",
    "\n",
    "# Add mat1 to mat2, element-wise multiplied by mat3\n",
    "# The value parameter is 1 by default\n",
    "result = torch.addcmul(mat1, mat2, mat3)\n",
    "\n",
    "# Alternatively, you can specify the value parameter\n",
    "result = torch.addcmul(mat1, mat2, mat3, value=0.5)\n",
    "\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive average pooling of input tensor: torch.Size([10, 5, 5])\n",
      "Adaptive max pooling of input tensor: torch.Size([10, 5])\n",
      "Adaptive max pooling of input tensor: torch.Size([10, 5, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Example usage of adaptive_avg_pool1d() function\n",
    "input_tensor = torch.randn(10, 10, 10)\n",
    "output_size = (5,5)\n",
    "output_tensor = F.adaptive_avg_pool2d(input_tensor, output_size)\n",
    "print(\"Adaptive average pooling of input tensor:\", output_tensor.shape)\n",
    "\n",
    "# Example usage of adaptive_max_pool1d() function\n",
    "input_tensor =  torch.randn(10, 10)\n",
    "output_size = 5\n",
    "output_tensor = F.adaptive_max_pool1d(input_tensor, output_size)\n",
    "print(\"Adaptive max pooling of input tensor:\", output_tensor.shape)\n",
    "\n",
    "# Example usage of adaptive_max_pool1d() function\n",
    "input_tensor =  torch.randn(10,10, 10, 10)\n",
    "output_size = 5,5,5\n",
    "output_tensor = F.adaptive_max_pool3d(input_tensor, output_size)\n",
    "print(\"Adaptive max pooling of input tensor:\", output_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
