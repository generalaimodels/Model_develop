{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Union, List, Dict\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "from transformers.quantization import QuantizationConfig\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import evaluate\n",
    "\n",
    "class AdvancedModelLoader:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name_or_path: str,\n",
    "        quantize_bits: Optional[int] = None,\n",
    "        num_labels: int = 2,\n",
    "        task_name: str = \"text-classification\",\n",
    "    ):\n",
    "        self.model_name_or_path = model_name_or_path\n",
    "        self.quantize_bits = quantize_bits\n",
    "        self.num_labels = num_labels\n",
    "        self.task_name = task_name\n",
    "        self.model = None\n",
    "        self.tokenizer = None\n",
    "        self.data_collator = None\n",
    "        self.compute_metrics = None\n",
    "\n",
    "    def load_model(self):\n",
    "        quantization_config = None\n",
    "        if self.quantize_bits:\n",
    "            if self.quantize_bits not in [4, 8]:\n",
    "                raise ValueError(\"Quantization bits must be either 4 or 8.\")\n",
    "            quantization_config = QuantizationConfig(bits=self.quantize_bits)\n",
    "\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            self.model_name_or_path,\n",
    "            num_labels=self.num_labels,\n",
    "            quantization_config=quantization_config,\n",
    "            device_map=\"auto\",\n",
    "        )\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name_or_path)\n",
    "        self.data_collator = DataCollatorWithPadding(self.tokenizer)\n",
    "\n",
    "        if self.task_name == \"text-classification\":\n",
    "            self.compute_metrics = self._compute_metrics_text_classification\n",
    "\n",
    "    def _compute_metrics_text_classification(self, eval_pred):\n",
    "        load_accuracy = evaluate.load(\"accuracy\")\n",
    "        load_f1 = evaluate.load(\"f1\")\n",
    "\n",
    "        logits, labels = eval_pred\n",
    "        predictions = torch.argmax(torch.from_numpy(logits), dim=-1)\n",
    "\n",
    "        accuracy = load_accuracy.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "        f1 = load_f1.compute(predictions=predictions, references=labels, average=\"weighted\")[\"f1\"]\n",
    "\n",
    "        return {\"accuracy\": accuracy, \"f1\": f1}\n",
    "\n",
    "    def train(self, train_dataset, eval_dataset, training_args: TrainingArguments):\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model has not been loaded. Call load_model() first.\")\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=self.model,\n",
    "            args=training_args,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=eval_dataset,\n",
    "            data_collator=self.data_collator,\n",
    "            compute_metrics=self.compute_metrics,\n",
    "        )\n",
    "        trainer.train()\n",
    "\n",
    "    def evaluate(self, eval_dataset):\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model has not been loaded. Call load_model() first.\")\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=self.model,\n",
    "            data_collator=self.data_collator,\n",
    "            compute_metrics=self.compute_metrics,\n",
    "        # ) <span class=\"cursor\"></span>\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
