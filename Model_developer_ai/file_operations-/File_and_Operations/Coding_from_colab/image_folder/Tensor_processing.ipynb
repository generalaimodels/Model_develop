{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Tuple, List\n",
    "\n",
    "def chunk_tensor(tensor: torch.Tensor, chunk_size: Tuple[int, ...]) -> List[torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Chunk a tensor into smaller tensors of a specified size.\n",
    "    \n",
    "    Args:\n",
    "    tensor (torch.Tensor): The input tensor to chunk.\n",
    "    chunk_size (Tuple[int, ...]): The size of each chunk tensor.\n",
    "    \n",
    "    Returns:\n",
    "    List[torch.Tensor]: List of tensor chunks.\n",
    "    \"\"\"\n",
    "    if not all(size > 0 for size in chunk_size):\n",
    "        raise ValueError(\"All dimensions of chunk size must be positive\")\n",
    "\n",
    "    chunks = tensor.unfold(0, chunk_size[0], chunk_size[0] // 2)\n",
    "    for dim, size in enumerate(chunk_size[1:], 1):\n",
    "        chunks = chunks.unfold(dim, size, size // 2)\n",
    "    chunks = chunks.contiguous().view(-1, *chunk_size)\n",
    "    return list(chunks)\n",
    "\n",
    "def sliding_window(tensor_chunks: List[torch.Tensor]) -> List[torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Create a sliding window with a 50% overlap over the tensor chunks.\n",
    "    \n",
    "    Args:\n",
    "    tensor_chunks (List[torch.Tensor]): List of tensor chunks.\n",
    "    \n",
    "    Returns:\n",
    "    List[torch.Tensor]: List of windowed tensor chunks.\n",
    "    \"\"\"\n",
    "    # Assuming a 50% overlap, the stride will be half the size of the chunk\n",
    "    stride = tuple(chunk_size // 2 for chunk_size in tensor_chunks[0].shape)\n",
    "    windowed_chunks = [chunk.unfold(0, stride[0], stride[0]).contiguous() for chunk in tensor_chunks]\n",
    "    return windowed_chunks\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "# Define a tensor of any dimension, for example, a 3D tensor\n",
    "input_tensor = torch.arange(1000).reshape(10, 10, 10).float()\n",
    "\n",
    "# Define the size of each chunk, for example, (2, 2, 2)\n",
    "chunk_sizes = (5,  5, 5)\n",
    "\n",
    "# Chunk the tensor\n",
    "chunks = chunk_tensor(input_tensor, chunk_sizes)\n",
    "\n",
    "# Apply sliding window to each chunk with a 50% overlap\n",
    "windowed_chunks = sliding_window(chunks)\n",
    "\n",
    "# Print the windowed chunks for demonstration\n",
    "for i, chunk in enumerate(windowed_chunks):\n",
    "    print(f\"Chunk {i}:\\n{chunk.shape}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Tuple, List\n",
    "\n",
    "def chunk_and_slide_tensor(tensor: torch.Tensor, \n",
    "                           chunk_size: Tuple[int, ...], \n",
    "                           overlap_percentage: float) -> List[torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Chunk a tensor into smaller tensors of a specified size and slide a window over \n",
    "    these chunks with a specified overlap percentage.\n",
    "    \n",
    "    Args:\n",
    "        tensor (torch.Tensor): The input tensor to chunk and slide.\n",
    "        chunk_size (Tuple[int, ...]): The size of each chunk tensor.\n",
    "        overlap_percentage (float): The percentage of overlap between windows (0 to 1).\n",
    "        \n",
    "    Returns:\n",
    "        List[torch.Tensor]: List of tensors after sliding window with overlap.\n",
    "    \"\"\"\n",
    "    if not (0 <= overlap_percentage <= 1):\n",
    "        raise ValueError(\"Overlap percentage must be between 0 and 1\")\n",
    "    \n",
    "    if not all(size > 0 for size in chunk_size):\n",
    "        raise ValueError(\"All dimensions of chunk size must be positive\")\n",
    "\n",
    "    # Calculate stride based on the overlap percentage\n",
    "    stride = tuple(int(size * (1 - overlap_percentage)) for size in chunk_size)\n",
    "    \n",
    "    # Ensure that the stride is not zero in any dimension\n",
    "    stride = tuple(max(1, s) for s in stride)\n",
    "    \n",
    "    # Calculate the number of chunks along each dimension\n",
    "    chunks = [tensor.unfold(dim, size, stride[dim]) for dim, size in enumerate(chunk_size)]\n",
    "    \n",
    "    # Use the calculated stride to slide the window over the tensor\n",
    "    for i, _ in enumerate(chunk_size[1:], 1):\n",
    "        chunks = [chunk.contiguous().view(-1, *chunk.size()[i + 1:]) for chunk in chunks]\n",
    "        chunks = [chunk.unfold(0, chunk_size[i], stride[i]) for chunk in chunks]\n",
    "    \n",
    "    # Flatten the list of chunks\n",
    "    windowed_chunks = [chunk.reshape(-1 ,*chunk_size) for sublist in chunks for chunk in sublist]\n",
    "    \n",
    "    return windowed_chunks\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "# Define a tensor of any dimension, for example, a 3D tensor\n",
    "input_tensor = torch.arange(64).reshape(4, 4, 4).float()\n",
    "\n",
    "# Define the size of each chunk, for example, (2, 2, 2)\n",
    "chunk_sizes = (2, 2, 2)\n",
    "\n",
    "# Define the overlap percentage, for example, 0.5 for 50%\n",
    "overlap_percentage = 0.5\n",
    "\n",
    "# Chunk the tensor and apply sliding window with the specified overlap\n",
    "windowed_chunks = chunk_and_slide_tensor(input_tensor, chunk_sizes, overlap_percentage)\n",
    "\n",
    "# Print the windowed chunks for demonstration\n",
    "for i, chunk in enumerate(windowed_chunks):\n",
    "    print(f\"Chunk {i}:\\n{chunk}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Tuple, List\n",
    "\n",
    "def chunk_and_slide_tensor(tensor: torch.Tensor, \n",
    "                           chunk_size: Tuple[int, ...], \n",
    "                           overlap_percentage: float) -> List[torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Chunk a tensor into smaller tensors of a specified size and slide a window over \n",
    "    these chunks with a specified overlap percentage.\n",
    "    \n",
    "    Args:\n",
    "        tensor (torch.Tensor): The input tensor to chunk and slide.\n",
    "        chunk_size (Tuple[int, ...]): The size of each chunk tensor.\n",
    "        overlap_percentage (float): The percentage of overlap between windows (0 to 1).\n",
    "        \n",
    "    Returns:\n",
    "        List[torch.Tensor]: List of tensors after sliding window with overlap.\n",
    "    \"\"\"\n",
    "    if not (0 <= overlap_percentage <= 1):\n",
    "        raise ValueError(\"Overlap percentage must be between 0 and 1\")\n",
    "    \n",
    "    if not all(size > 0 for size in chunk_size):\n",
    "        raise ValueError(\"All dimensions of chunk size must be positive\")\n",
    "\n",
    "    # Calculate stride based on the overlap percentage\n",
    "    stride = tuple(int(size * (1 - overlap_percentage)) for size in chunk_size)\n",
    "    \n",
    "    # Ensure that the stride is not zero in any dimension\n",
    "    stride = tuple(max(1, s) for s in stride)\n",
    "    \n",
    "    # Calculate the required padding for each dimension\n",
    "    padding = tuple((size - tensor.size(dim) % size) % size for dim, size in enumerate(chunk_size))\n",
    "    \n",
    "    # Convert padding to the format expected by torch.nn.functional.pad\n",
    "    padding = tuple(p // 2 for p in reversed(padding) for _ in range(2))\n",
    "    \n",
    "    # Pad the input tensor to a compatible size\n",
    "    padded_tensor = torch.nn.functional.pad(tensor, padding)\n",
    "    \n",
    "    # Calculate the number of chunks along each dimension\n",
    "    chunks = [padded_tensor.unfold(dim, size, stride[dim]) for dim, size in enumerate(chunk_size)]\n",
    "    \n",
    "    # Use the calculated stride to slide the window over the tensor\n",
    "    for i, _ in enumerate(chunk_size[1:], 1):\n",
    "        chunks = [chunk.contiguous().view(-1, *chunk.size()[i + 1:]) for chunk in chunks]\n",
    "        chunks = [chunk.unfold(0, chunk_size[i], stride[i]) for chunk in chunks]\n",
    "    \n",
    "    # Flatten the list of chunks\n",
    "    windowed_chunks = [chunk.reshape(-1, *chunk_size) for sublist in chunks for chunk in sublist]\n",
    "    \n",
    "    return windowed_chunks\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "# Define a tensor of any dimension, for example, a 3D tensor\n",
    "input_tensor = torch.arange(64).reshape(4, 4, 4).float()\n",
    "\n",
    "# Define the size of each chunk, for example, (2, 2, 2)\n",
    "chunk_sizes = (2, 2, 2)\n",
    "\n",
    "# Define the overlap percentage, for example, 0.5 for 50%\n",
    "overlap_percentage = 0.5\n",
    "\n",
    "# Chunk the tensor and apply sliding window with the specified overlap\n",
    "windowed_chunks = chunk_and_slide_tensor(input_tensor, chunk_sizes, overlap_percentage)\n",
    "\n",
    "# Print the windowed chunks for demonstration\n",
    "for i, chunk in enumerate(windowed_chunks):\n",
    "    print(f\"Chunk {i}:\\n{chunk}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import torch\n",
    "\n",
    "def chunk_and_slide_tensor(\n",
    "    tensor: torch.Tensor,\n",
    "    chunk_size: Tuple[int, ...],\n",
    "    overlap_percentage: float\n",
    ") -> List[torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Chunk a tensor into smaller tensors of a specified size and slide a window over \n",
    "    these chunks with a specified overlap percentage.\n",
    "    \n",
    "    Args:\n",
    "        tensor (torch.Tensor): The input tensor to chunk and slide.\n",
    "        chunk_size (Tuple[int, ...]): The size of each chunk tensor.\n",
    "        overlap_percentage (float): The percentage of overlap between windows (0 to 1).\n",
    "        \n",
    "    Returns:\n",
    "        List[torch.Tensor]: List of tensors after sliding window with overlap.\n",
    "    \"\"\"\n",
    "    if not 0 <= overlap_percentage < 1:\n",
    "        raise ValueError(\"Overlap percentage must be between 0 and 1.\")\n",
    "    \n",
    "    # Calculate the stride size based on the overlap percentage\n",
    "    stride_size = tuple(max(1, int(size * (1 - overlap_percentage))) for size in chunk_size)\n",
    "    \n",
    "    # Unfold the tensor into chunks\n",
    "    chunks = tensor.unfold(0, chunk_size[0], stride_size[0])\n",
    "    for dim in range(1, len(chunk_size)):\n",
    "        chunks = chunks.unfold(dim, chunk_size[dim], stride_size[dim])\n",
    "    \n",
    "    # Flatten the chunks into a list of tensors\n",
    "    chunks = chunks.reshape(-1, *chunk_size)\n",
    "    chunks_list = [chunk for chunk in chunks]\n",
    "    \n",
    "    return chunks_list\n",
    "\n",
    "\n",
    "# Example usage\n",
    "tensor = torch.arange(64).reshape(4, 4, 4)\n",
    "print(\"Original tensor:\")\n",
    "print(tensor)\n",
    "\n",
    "chunk_size = (2, 2, 2)\n",
    "overlap_percentage = 0.5\n",
    "\n",
    "result = chunk_and_slide_tensor(tensor, chunk_size, overlap_percentage)\n",
    "print(f\"\\nChunked and slided tensors (chunk size: {chunk_size}, overlap: {overlap_percentage}):\")\n",
    "for i, chunk in enumerate(result, 1):\n",
    "    print(f\"Chunk {i}:\")\n",
    "    print(chunk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "from typing import List, Tuple\n",
    "import torch\n",
    "\n",
    "def sliding_window(tensor: torch.Tensor, chunk_size: Tuple[int,...], overlap_percentage: float,) -> List[torch.Tensor]:\n",
    "    \"\"\"Chunk a tensor into smaller tensors of a specified size and slide a window over these chunks with a specified overlap percentage.\n",
    "    Args:\n",
    "        tensor (torch.Tensor): The input tensor to chunk and slide.\n",
    "        chunk_size (Tuple[int,...]): The size of each chunk tensor.\n",
    "        overlap_percentage (float): The percentage of overlap between windows (0 to 1).\n",
    "    Returns:\n",
    "        List[torch.Tensor]: List of tensors after sliding window with overlap.\n",
    "    \"\"\"\n",
    "    if overlap_percentage < 0 or overlap_percentage > 1:\n",
    "        raise ValueError(\"Overlap percentage must be between 0 and 1\")\n",
    "\n",
    "    chunks = torch.chunk(tensor, chunk_size, dim=0)\n",
    "    num_chunks = len(chunks)\n",
    "    overlap_size = int(overlap_percentage * chunk_size[0])\n",
    "    stride_size = chunk_size[0] - overlap_size\n",
    "\n",
    "    windows = []\n",
    "    for i in range(num_chunks - 1):\n",
    "        window = torch.cat((chunks[i], chunks[i + 1][:overlap_size]), dim=0)\n",
    "        windows.append(window)\n",
    "    windows.append(chunks[-1])\n",
    "\n",
    "    return windows\n",
    "\n",
    "tensor = torch.arange(64).reshape(4, 4, 4)\n",
    "print(\"Original tensor:\")\n",
    "print(tensor)\n",
    "\n",
    "chunk_size = (2, 2, 2)\n",
    "overlap_percentage = 0.5\n",
    "\n",
    "result = chunk_and_slide_tensor(tensor, chunk_size, overlap_percentage)\n",
    "print(f\"\\nChunked and slided tensors (chunk size: {chunk_size}, overlap: {overlap_percentage}):\")\n",
    "for i, chunk in enumerate(result, 1):\n",
    "    print(f\"Chunk {i}:\")\n",
    "    print(chunk.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Sliding Window\n",
    "2. Rotating Sliding Window\n",
    "3. Windowed Approach\n",
    "4. Patch-based Processing\n",
    "5. Temporal Segmentation\n",
    "6. Sequential Segmentation\n",
    "7. Frame-by-Frame Processing\n",
    "8. Time-windowed Segmentation\n",
    "9. Sequential Windowing\n",
    "10. Moving Window Analysis\n",
    "11. Sequential Sampling\n",
    "12. Temporal Windowing\n",
    "\n",
    "13. Hierarchical Windowing\n",
    "14. Multi-scale Windowed Processing\n",
    "15. Adaptive Windowing\n",
    "16. Dynamic Windowing\n",
    "17. Convolutional Windowing\n",
    "18. Recurrent Windowing\n",
    "19. Attention-based Windowing\n",
    "20. Contextual Windowing\n",
    "21. Multi-dimensional Sliding Windows\n",
    "22. Overlapping Windowing\n",
    "23. Non-uniform Windowing\n",
    "24. Variable-length Windowing\n",
    "25. Windowed Convolution\n",
    "26. Windowed Recurrent Neural Networks\n",
    "27. Spatial-Temporal Windowing\n",
    "28. Spatial Pyramid Windowing\n",
    "29. Wavelet-based Windowing\n",
    "30. Kernel-based Windowing\n",
    "\n",
    "\n",
    "31. Augmented Reality Sliding Windows\n",
    "32. Hierarchical Context-aware Windowing\n",
    "33. Attention-guided Adaptive Windowing\n",
    "34. Graph-based Windowed Processing\n",
    "35. Manifold-based Windowing\n",
    "36. Self-organizing Windowing Systems\n",
    "37. Dynamic Bayesian Windowing\n",
    "38. Meta-learning-based Windowing\n",
    "39. Multi-resolution Adaptive Windowing\n",
    "40. Topological Data Analysis for Windowing\n",
    "41. Deep Reinforcement Learning for Windowing Optimization\n",
    "42. Quantum Windowing\n",
    "43. Neuro-evolutionary Windowing Strategies\n",
    "44. Swarm Intelligence-guided Windowing\n",
    "45. Hybridized Windowing Techniques\n",
    "46. Bio-inspired Windowing Mechanisms\n",
    "47. Non-linear Dynamical Windowing\n",
    "48. Information Geometry-guided Windowing\n",
    "49. Compressed Sensing Windowing\n",
    "50. Domain-specific Windowing Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [ 8,  9, 10, 11]],\n",
      "\n",
      "        [[12, 13, 14, 15],\n",
      "         [16, 17, 18, 19],\n",
      "         [20, 21, 22, 23]]])\n",
      "\n",
      "Rotating sliding window (chunk size: (1, 2, 2), overlap: 0.5, frequency: 3):\n",
      "Window 1:\n",
      "torch.Size([3, 2, 2])\n",
      "Window 2:\n",
      "torch.Size([3, 2, 2])\n",
      "Window 3:\n",
      "torch.Size([3, 2, 2])\n",
      "Window 4:\n",
      "torch.Size([3, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Tuple\n",
    "import torch\n",
    "\n",
    "def rotating_sliding_window(\n",
    "    tensor: torch.Tensor,\n",
    "    chunk_size: Tuple[int, ...],\n",
    "    overlap_percentage: float,\n",
    "    frequency: int\n",
    ") -> List[torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Chunk a tensor into smaller tensors of a specified size and slide a rotating window\n",
    "    over these chunks with a specified overlap percentage and frequency.\n",
    "    \n",
    "    Args:\n",
    "        tensor (torch.Tensor): The input tensor to chunk and slide.\n",
    "        chunk_size (Tuple[int, ...]): The size of each chunk tensor.\n",
    "        overlap_percentage (float): The percentage of overlap between windows (0 to 1).\n",
    "        frequency (int): The frequency of rotation for the sliding window.\n",
    "        \n",
    "    Returns:\n",
    "        List[torch.Tensor]: List of tensors after applying the rotating sliding window.\n",
    "    \"\"\"\n",
    "    if not 0 <= overlap_percentage < 1:\n",
    "        raise ValueError(\"Overlap percentage must be between 0 and 1.\")\n",
    "    \n",
    "    if frequency <= 0:\n",
    "        raise ValueError(\"Frequency must be a positive integer.\")\n",
    "    \n",
    "    # Calculate the stride size based on the overlap percentage\n",
    "    stride_size = tuple(max(1, int(size * (1 - overlap_percentage))) for size in chunk_size)\n",
    "    \n",
    "    # Unfold the tensor into chunks\n",
    "    chunks = tensor.unfold(0, chunk_size[0], stride_size[0])\n",
    "    for dim in range(1, len(chunk_size)):\n",
    "        chunks = chunks.unfold(dim, chunk_size[dim], stride_size[dim])\n",
    "    \n",
    "    # Flatten the chunks into a list of tensors\n",
    "    chunks = chunks.reshape(-1, *chunk_size)\n",
    "    chunks_list = [chunk for chunk in chunks]\n",
    "    \n",
    "    # Apply the rotating sliding window based on the frequency\n",
    "    windows = []\n",
    "    for i in range(0, len(chunks_list), frequency):\n",
    "        window = torch.cat(chunks_list[i:i+frequency], dim=0)\n",
    "        windows.append(window)\n",
    "    \n",
    "    return windows\n",
    "\n",
    "\n",
    "# Example usage\n",
    "tensor = torch.arange(24).reshape(2, 3, 4)\n",
    "print(\"Original tensor:\")\n",
    "print(tensor)\n",
    "\n",
    "chunk_size = (1, 2, 2)\n",
    "overlap_percentage = 0.5\n",
    "frequency = 3\n",
    "\n",
    "result = rotating_sliding_window(tensor, chunk_size, overlap_percentage, frequency)\n",
    "print(f\"\\nRotating sliding window (chunk size: {chunk_size}, overlap: {overlap_percentage}, frequency: {frequency}):\")\n",
    "for i, window in enumerate(result, 1):\n",
    "    print(f\"Window {i}:\")\n",
    "    print(window.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import torch\n",
    "\n",
    "def windowed_chunking(\n",
    "    tensor: torch.Tensor,\n",
    "    chunk_size: Tuple[int, ...],\n",
    "    overlap_percentage: float\n",
    ") -> List[torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Chunk a tensor into smaller tensors of a specified size and slide a window over \n",
    "    these chunks with a specified overlap percentage.\n",
    "    \n",
    "    Args:\n",
    "        tensor (torch.Tensor): The input tensor to chunk and slide.\n",
    "        chunk_size (Tuple[int, ...]): The size of each chunk tensor.\n",
    "        overlap_percentage (float): The percentage of overlap between windows (0 to 1).\n",
    "        \n",
    "    Returns:\n",
    "        List[torch.Tensor]: List of tensors after sliding window with overlap.\n",
    "    \"\"\"\n",
    "    # Validate input arguments\n",
    "    if not isinstance(tensor, torch.Tensor):\n",
    "        raise TypeError(\"Input tensor must be a PyTorch tensor.\")\n",
    "    if not isinstance(chunk_size, tuple) or any(not isinstance(size, int) for size in chunk_size):\n",
    "        raise TypeError(\"Chunk size must be a tuple of integers.\")\n",
    "    if not isinstance(overlap_percentage, float) or overlap_percentage < 0 or overlap_percentage >= 1:\n",
    "        raise ValueError(\"Overlap percentage must be a float between 0 and 1 (exclusive).\")\n",
    "    \n",
    "    # Calculate the stride based on the overlap percentage\n",
    "    stride = tuple(int(size * (1 - overlap_percentage)) for size in chunk_size)\n",
    "    \n",
    "    # Chunk the tensor into smaller tensors\n",
    "    chunks = tensor.unfold(0, chunk_size[0], stride[0])\n",
    "    for dim in range(1, len(chunk_size)):\n",
    "        chunks = chunks.unfold(dim, chunk_size[dim], stride[dim])\n",
    "    \n",
    "    # Flatten the chunked tensor to get a list of smaller tensors\n",
    "    chunks = chunks.contiguous().view(-1, *chunk_size)\n",
    "    \n",
    "    return chunks.unbind(0)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "tensor = torch.arange(64).view(4, 4,4)\n",
    "print(\"Original tensor:\")\n",
    "print(tensor)\n",
    "\n",
    "chunk_size = (2, 3)\n",
    "overlap_percentage = 0.5\n",
    "\n",
    "result = windowed_chunking(tensor, chunk_size, overlap_percentage)\n",
    "print(\"\\nChunked tensors with overlap:\")\n",
    "for chunk in result:\n",
    "    print(chunk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Tuple\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def chunk_and_process_tensor(\n",
    "    tensor: torch.Tensor,\n",
    "    chunk_size: Union[int, Tuple[int, ...]],\n",
    "    patch_size: Union[int, Tuple[int, ...]]\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Chunk a tensor into user-specified chunk size and apply patch-based processing.\n",
    "\n",
    "    Args:\n",
    "        tensor (torch.Tensor): Input tensor of any dimensions.\n",
    "        chunk_size (Union[int, Tuple[int, ...]]): Size of the chunks.\n",
    "        patch_size (Union[int, Tuple[int, ...]]): Size of the patches.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Processed tensor after chunking and patch-based processing.\n",
    "    \"\"\"\n",
    "    # Convert chunk_size and patch_size to tuples if they are integers\n",
    "    if isinstance(chunk_size, int):\n",
    "        chunk_size = (chunk_size,) * tensor.ndim\n",
    "    if isinstance(patch_size, int):\n",
    "        patch_size = (patch_size,) * tensor.ndim\n",
    "\n",
    "    # Calculate the number of chunks along each dimension\n",
    "    num_chunks = [\n",
    "        (tensor.shape[i] + chunk_size[i] - 1) // chunk_size[i]\n",
    "        for i in range(tensor.ndim)\n",
    "    ]\n",
    "\n",
    "    # Create an output tensor to store the processed chunks\n",
    "    output_shape = [num_chunks[i] * patch_size[i] for i in range(tensor.ndim)]\n",
    "    output_tensor = torch.zeros(output_shape, dtype=tensor.dtype, device=tensor.device)\n",
    "\n",
    "    # Iterate over the chunks and apply patch-based processing\n",
    "    for chunk_indices in torch.cartesian_prod(*[torch.arange(nc) for nc in num_chunks]):\n",
    "        # Calculate the chunk slices\n",
    "        chunk_slices = [\n",
    "            slice(chunk_indices[i] * chunk_size[i], (chunk_indices[i] + 1) * chunk_size[i])\n",
    "            for i in range(tensor.ndim)\n",
    "        ]\n",
    "\n",
    "        # Extract the chunk from the input tensor\n",
    "        chunk = tensor[chunk_slices]\n",
    "\n",
    "        # Apply patch-based processing to the chunk\n",
    "        processed_chunk = process_patch(chunk, patch_size)\n",
    "\n",
    "        # Calculate the output slices for the processed chunk\n",
    "        output_slices = [\n",
    "            slice(chunk_indices[i] * patch_size[i], (chunk_indices[i] + 1) * patch_size[i])\n",
    "            for i in range(tensor.ndim)\n",
    "        ]\n",
    "\n",
    "        # Place the processed chunk into the output tensor\n",
    "        output_tensor[output_slices] = processed_chunk\n",
    "\n",
    "    return output_tensor\n",
    "\n",
    "\n",
    "def process_patch(patch: torch.Tensor, patch_size: Tuple[int, ...]) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Apply patch-based processing to a single patch.\n",
    "\n",
    "    Args:\n",
    "        patch (torch.Tensor): Input patch tensor.\n",
    "        patch_size (Tuple[int, ...]): Size of the patch.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Processed patch tensor.\n",
    "    \"\"\"\n",
    "    # Perform patch-based processing here\n",
    "    # This is just a placeholder example\n",
    "    processed_patch = F.avg_pool2d(patch, kernel_size=patch_size)\n",
    "\n",
    "    return processed_patch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_and_process_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment 1 shape: torch.Size([2, 6, 100])\n",
      "Segment 2 shape: torch.Size([2, 6, 100])\n",
      "Segment 3 shape: torch.Size([2, 6, 100])\n",
      "Segment 4 shape: torch.Size([2, 6, 100])\n",
      "Segment 5 shape: torch.Size([2, 6, 100])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from typing import Tuple\n",
    "\n",
    "def temporal_segmentation(tensor: torch.Tensor, chunks: int, dim: int) -> Tuple[torch.Tensor, ...]:\n",
    "    \"\"\"\n",
    "    Split a tensor into chunks along a specified dimension using temporal segmentation.\n",
    "\n",
    "    Parameters:\n",
    "    tensor (torch.Tensor): The input tensor to be split.\n",
    "    chunks (int): The number of chunks to split the tensor into.\n",
    "    dim (int): The dimension along which to split the tensor.\n",
    "\n",
    "    Returns:\n",
    "    Tuple[torch.Tensor, ...]: A tuple containing the resulting chunks as separate tensors.\n",
    "    \"\"\"\n",
    "    # Check if the dimension is valid\n",
    "    if dim >= tensor.dim():\n",
    "        raise ValueError(f\"Dimension {dim} is out of range for tensor with {tensor.dim()} dimensions.\")\n",
    "    \n",
    "    # Check if the number of chunks is valid\n",
    "    if chunks <= 0:\n",
    "        raise ValueError(\"Number of chunks must be a positive integer.\")\n",
    "    \n",
    "    # Calculate the size of each chunk\n",
    "    split_size = (tensor.size(dim) + chunks - 1) // chunks  # Use integer division with rounding up\n",
    "    \n",
    "    # Use torch.split to split the tensor into chunks\n",
    "    segments = torch.split(tensor, split_size, dim=dim)\n",
    "    \n",
    "    return segments\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a sample tensor with random data\n",
    "    sample_tensor = torch.randn(2, 30, 100)  # Example shape: (batch_size, sequence_length, features)\n",
    "    \n",
    "    # Specify the number of chunks and the dimension to split along\n",
    "    num_chunks = 5\n",
    "    dimension_to_split = 1\n",
    "    \n",
    "    # Call the temporal_segmentation function\n",
    "    output_tensors = temporal_segmentation(sample_tensor, num_chunks, dimension_to_split)\n",
    "    \n",
    "    # Print the shapes of the output tensors\n",
    "    for i, segment in enumerate(output_tensors):\n",
    "        print(f\"Segment {i+1} shape: {segment.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 4\n",
      "Chunk 1 shape: torch.Size([3, 3, 4])\n",
      "Chunk 2 shape: torch.Size([3, 3, 4])\n",
      "Chunk 3 shape: torch.Size([3, 3, 4])\n",
      "Chunk 4 shape: torch.Size([1, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from typing import List, Tuple\n",
    "\n",
    "def temporal_segmentation(tensor: torch.Tensor, chunk_size: int, dim: int = 0) -> List[torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Perform temporal segmentation on a tensor of any dimensions and split it into chunks along a specified dimension.\n",
    "\n",
    "    Args:\n",
    "        tensor (torch.Tensor): The input tensor to be segmented.\n",
    "        chunk_size (int): The size of each chunk along the specified dimension.\n",
    "        dim (int, optional): The dimension along which to split the tensor. Defaults to 0.\n",
    "\n",
    "    Returns:\n",
    "        List[torch.Tensor]: A list of tensors representing the segmented chunks.\n",
    "\n",
    "    Example:\n",
    "        >>> tensor = torch.randn(10, 3, 4)\n",
    "        >>> chunks = temporal_segmentation(tensor, chunk_size=3, dim=0)\n",
    "        >>> len(chunks)\n",
    "        4\n",
    "        >>> chunks[0].shape\n",
    "        torch.Size([3, 3, 4])\n",
    "    \"\"\"\n",
    "    # Get the size of the specified dimension\n",
    "    dim_size = tensor.size(dim)\n",
    "\n",
    "    # Calculate the number of chunks\n",
    "    num_chunks = (dim_size + chunk_size - 1) // chunk_size\n",
    "\n",
    "    # Split the tensor into chunks along the specified dimension\n",
    "    chunks = torch.chunk(tensor, num_chunks, dim=dim)\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a random tensor of shape (10, 3, 4)\n",
    "    tensor = torch.randn(10, 3, 4)\n",
    "\n",
    "    # Specify the chunk size and dimension for segmentation\n",
    "    chunk_size = 3\n",
    "    dim = 0\n",
    "\n",
    "    # Perform temporal segmentation\n",
    "    segmented_chunks = temporal_segmentation(tensor, chunk_size, dim)\n",
    "\n",
    "    # Print the number of chunks and their shapes\n",
    "    print(f\"Number of chunks: {len(segmented_chunks)}\")\n",
    "    for i, chunk in enumerate(segmented_chunks):\n",
    "        print(f\"Chunk {i+1} shape: {chunk.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 4\n",
      "Chunk 1 shape: torch.Size([5, 3, 4])\n",
      "Chunk 2 shape: torch.Size([5, 3, 4])\n",
      "Chunk 3 shape: torch.Size([5, 3, 4])\n",
      "Chunk 4 shape: torch.Size([5, 3, 4])\n",
      "\n",
      "Number of segmented chunks: 8\n",
      "Segmented Chunk 1 shape: torch.Size([2, 3, 4])\n",
      "Segmented Chunk 2 shape: torch.Size([2, 3, 4])\n",
      "Segmented Chunk 3 shape: torch.Size([2, 3, 4])\n",
      "Segmented Chunk 4 shape: torch.Size([2, 3, 4])\n",
      "Segmented Chunk 5 shape: torch.Size([2, 3, 4])\n",
      "Segmented Chunk 6 shape: torch.Size([2, 3, 4])\n",
      "Segmented Chunk 7 shape: torch.Size([2, 3, 4])\n",
      "Segmented Chunk 8 shape: torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from typing import List, Tuple\n",
    "\n",
    "def split_tensor(tensor: torch.Tensor, chunk_size: int, dim: int) -> List[torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Split a tensor into chunks along a specified dimension.\n",
    "\n",
    "    Args:\n",
    "        tensor (torch.Tensor): The input tensor to be split.\n",
    "        chunk_size (int): The size of each chunk along the specified dimension.\n",
    "        dim (int): The dimension along which to split the tensor.\n",
    "\n",
    "    Returns:\n",
    "        List[torch.Tensor]: A list of tensors representing the split chunks.\n",
    "    \"\"\"\n",
    "    return torch.split(tensor, chunk_size, dim=dim)\n",
    "\n",
    "def temporal_segmentation(chunks: List[torch.Tensor], segment_size: int) -> List[torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Perform temporal segmentation on a list of tensor chunks.\n",
    "\n",
    "    Args:\n",
    "        chunks (List[torch.Tensor]): A list of tensor chunks to be segmented.\n",
    "        segment_size (int): The size of each segment.\n",
    "\n",
    "    Returns:\n",
    "        List[torch.Tensor]: A list of tensors representing the segmented chunks.\n",
    "    \"\"\"\n",
    "    segmented_chunks = []\n",
    "    for chunk in chunks:\n",
    "        # Perform temporal segmentation on each chunk\n",
    "        num_segments = chunk.size(0) // segment_size\n",
    "        segments = torch.chunk(chunk[:num_segments * segment_size], num_segments, dim=0)\n",
    "        segmented_chunks.extend(segments)\n",
    "    return segmented_chunks\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a random tensor of shape (20, 3, 4)\n",
    "    tensor = torch.randn(20, 3, 4)\n",
    "\n",
    "    # Specify the chunk size and dimension for splitting\n",
    "    chunk_size = 5\n",
    "    split_dim = 0\n",
    "\n",
    "    # Split the tensor into chunks\n",
    "    chunks = split_tensor(tensor, chunk_size, split_dim)\n",
    "\n",
    "    # Specify the segment size for temporal segmentation\n",
    "    segment_size = 2\n",
    "\n",
    "    # Perform temporal segmentation on the chunks\n",
    "    segmented_chunks = temporal_segmentation(chunks, segment_size)\n",
    "\n",
    "    # Print the number of chunks and their shapes\n",
    "    print(f\"Number of chunks: {len(chunks)}\")\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"Chunk {i+1} shape: {chunk.shape}\")\n",
    "\n",
    "    print(f\"\\nNumber of segmented chunks: {len(segmented_chunks)}\")\n",
    "    for i, segment in enumerate(segmented_chunks):\n",
    "        print(f\"Segmented Chunk {i+1} shape: {segment.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import List, Tuple\n",
    "\n",
    "def split_tensor(tensor: torch.LongTensor, segment_size: Tuple[int, ...]) -> List[torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Splits a LongTensor into smaller tensors of the specified dimension.\n",
    "\n",
    "    Args:\n",
    "    tensor (torch.LongTensor): The input tensor to split.\n",
    "    segment_size (Tuple[int, ...]): The dimensions of the smaller tensors.\n",
    "\n",
    "    Returns:\n",
    "    List[torch.Tensor]: A list of smaller tensors.\n",
    "    \"\"\"\n",
    "    segments = []\n",
    "    for start in range(0, tensor.numel(), torch.prod(torch.tensor(segment_size))):\n",
    "        end = min(start + torch.prod(torch.tensor(segment_size)), tensor.numel())\n",
    "        if end - start < torch.prod(torch.tensor(segment_size)):\n",
    "            break  # Remaining elements less than segment size\n",
    "        segment = tensor.view(-1)[start:end].view(segment_size)\n",
    "        segments.append(segment)\n",
    "    return segments\n",
    "\n",
    "def temporal_segmentation(tensor_segments: List[torch.Tensor]) -> List[torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Applies temporal segmentation to a list of smaller tensors.\n",
    "\n",
    "    Args:\n",
    "    tensor_segments (List[torch.Tensor]): A list of smaller tensors to segment.\n",
    "\n",
    "    Returns:\n",
    "    List[torch.Tensor]: A list of temporally segmented tensors.\n",
    "    \"\"\"\n",
    "    # In a real-world scenario, this function would apply more complex segmentation logic.\n",
    "    # Here, we mimic the segmentation by simply returning the input list of tensors.\n",
    "    return tensor_segments\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a sample LongTensor of any dimension\n",
    "    long_tensor =torch.randn(10,10,10,10)\n",
    "\n",
    "    # Define the desired size for the smaller tensors (segments)\n",
    "    desired_segment_size = (10, 10, 10)\n",
    "\n",
    "    # Split the tensor into smaller tensors with the specified segment size\n",
    "    tensor_segments = split_tensor(long_tensor, desired_segment_size)\n",
    "\n",
    "    # Apply temporal segmentation to the list of tensors\n",
    "    temporally_segmented_tensors = temporal_segmentation(tensor_segments)\n",
    "\n",
    "    # Output the result\n",
    "    print(\"Segmented Tensors:\")\n",
    "    for i, segment in enumerate(temporally_segmented_tensors):\n",
    "        print(f\"Segment {i+1}:\\n{segment}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal Segments:\n",
      "Segment 1: [1, 2, 2, 3, 5, 6]\n",
      "Segment 2: [7, 12, 13]\n",
      "Segment 3: [2]\n",
      "Segment 4: [3]\n",
      "Segment 5: [1, 0, -1, -2, -3]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from typing import List\n",
    "\n",
    "def feature_extraction(input_tensor: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    (Optional) Extracts features from the input tensor for better segmentation.\n",
    "    This function is a placeholder and can be customized based on the specific application.\n",
    "    For now, we'll just return the input tensor as is.\n",
    "    \n",
    "    Args:\n",
    "        input_tensor (torch.Tensor): The input temporal sequence tensor.\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: The tensor with extracted features.\n",
    "    \"\"\"\n",
    "    # Placeholder for actual feature extraction logic\n",
    "    return input_tensor\n",
    "\n",
    "def identify_segment_boundaries(input_tensor: torch.Tensor, window_size: int, threshold: float) -> List[int]:\n",
    "    \"\"\"\n",
    "    Identify segment boundaries based on the change in mean value within a sliding window.\n",
    "    \n",
    "    Args:\n",
    "        input_tensor (torch.Tensor): The input temporal sequence tensor.\n",
    "        window_size (int): The size of the sliding window to evaluate the segmentation criteria.\n",
    "        threshold (float): The threshold for detecting a significant change in mean value.\n",
    "        \n",
    "    Returns:\n",
    "        List[int]: A list of indices representing segment boundaries.\n",
    "    \"\"\"\n",
    "    segment_boundaries = [0]  # Start with the beginning of the tensor\n",
    "    for i in range(window_size, len(input_tensor) - window_size):\n",
    "        prev_mean = input_tensor[i - window_size:i].float().mean()\n",
    "        next_mean = input_tensor[i:i + window_size].float().mean()\n",
    "        if abs(next_mean - prev_mean) > threshold:\n",
    "            segment_boundaries.append(i)\n",
    "    segment_boundaries.append(len(input_tensor))  # End with the last index of the tensor\n",
    "    return segment_boundaries\n",
    "\n",
    "def temporal_segmentation(input_tensor: torch.Tensor, window_size: int, threshold: float) -> List[torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Splits the input tensor into segments based on the temporal segmentation criteria.\n",
    "    \n",
    "    Args:\n",
    "        input_tensor (torch.Tensor): The input temporal sequence tensor.\n",
    "        window_size (int): The size of the sliding window to evaluate the segmentation criteria.\n",
    "        threshold (float): The threshold for detecting a significant change in mean value.\n",
    "        \n",
    "    Returns:\n",
    "        List[torch.Tensor]: A list of tensor segments.\n",
    "    \"\"\"\n",
    "    # Extract features from the input tensor (optional)\n",
    "    features = feature_extraction(input_tensor)\n",
    "    \n",
    "    # Identify segment boundaries\n",
    "    boundaries = identify_segment_boundaries(features, window_size, threshold)\n",
    "    \n",
    "    # Split the tensor into segments\n",
    "    segments = [input_tensor[boundaries[i]:boundaries[i+1]] for i in range(len(boundaries) - 1)]\n",
    "    return segments\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a sample LongTensor representing a temporal sequence\n",
    "    input_tensor = torch.LongTensor([1, 2, 2, 3, 5, 6, 7, 12, 13, 2, 3, 1, 0, -1, -2, -3])\n",
    "\n",
    "    # Define the window size and threshold for segmentation\n",
    "    window_size = 3\n",
    "    threshold = 5.0\n",
    "\n",
    "    # Perform temporal segmentation\n",
    "    segments = temporal_segmentation(input_tensor, window_size, threshold)\n",
    "\n",
    "    # Output the result\n",
    "    print(\"Temporal Segments:\")\n",
    "    for i, segment in enumerate(segments):\n",
    "        print(f\"Segment {i+1}: {segment.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import List, Tuple\n",
    "\n",
    "def split_tensor(tensor: torch.Tensor, segment_size: Tuple[int, ...]) -> List[torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Split a tensor into smaller tensors of a specified size.\n",
    "\n",
    "    Args:\n",
    "        tensor (torch.Tensor): The input tensor to be split.\n",
    "        segment_size (Tuple[int, ...]): The size of each segment.\n",
    "\n",
    "    Returns:\n",
    "        List[torch.Tensor]: A list of split tensors.\n",
    "    \"\"\"\n",
    "    split_tensors = []\n",
    "    for start_idx in range(0, tensor.size(0), segment_size[0]):\n",
    "        end_idx = min(start_idx + segment_size[0], tensor.size(0))\n",
    "        segment = tensor[start_idx:end_idx]\n",
    "        for dim in range(1, len(segment_size)):\n",
    "            segment = segment.unfold(dim, segment_size[dim], segment_size[dim])\n",
    "        split_tensors.extend(segment.unbind(0))\n",
    "    return split_tensors\n",
    "\n",
    "def sequential_segmentation(tensor_list: List[torch.Tensor], threshold: float) -> List[List[torch.Tensor]]:\n",
    "    \"\"\"\n",
    "    Apply sequential segmentation to a list of tensors.\n",
    "\n",
    "    Args:\n",
    "        tensor_list (List[torch.Tensor]): A list of input tensors.\n",
    "        threshold (float): The threshold value for segmentation.\n",
    "\n",
    "    Returns:\n",
    "        List[List[torch.Tensor]]: A list of segmented tensor sequences.\n",
    "    \"\"\"\n",
    "    segmented_sequences = []\n",
    "    current_sequence = []\n",
    "\n",
    "    for tensor in tensor_list:\n",
    "        # Check if the current tensor belongs to the current sequence\n",
    "        if current_sequence and torch.norm(tensor - current_sequence[-1]) <= threshold:\n",
    "            current_sequence.append(tensor)\n",
    "        else:\n",
    "            if current_sequence:\n",
    "                segmented_sequences.append(current_sequence)\n",
    "            current_sequence = [tensor]\n",
    "\n",
    "    if current_sequence:\n",
    "        segmented_sequences.append(current_sequence)\n",
    "\n",
    "    return segmented_sequences\n",
    "\n",
    "# Example usage\n",
    "long_tensor = torch.randn(100, 50, 60)\n",
    "segment_size = (10, 20, 30)\n",
    "threshold = 0.5\n",
    "\n",
    "split_tensors = split_tensor(long_tensor, segment_size)\n",
    "print(f\"Number of split tensors: {len(split_tensors)}\")\n",
    "print(f\"Size of each split tensor: {split_tensors[0].size()}\")\n",
    "\n",
    "segmented_sequences = sequential_segmentation(split_tensors, threshold)\n",
    "print(f\"Number of segmented sequences: {len(segmented_sequences)}\")\n",
    "print(f\"Lengths of segmented sequences: {[seq for seq in segmented_sequences]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequentially Segmented Tensors:\n",
      "Segment 1: [1, 2, 3, 4]\n",
      "Segment 2: [5, 6, 7, 8]\n",
      "Segment 3: [9, 10, 11, 12]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from typing import List, Tuple\n",
    "\n",
    "def split_tensor(tensor: torch.LongTensor, segment_size: Tuple[int, ...]) -> List[torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Splits a LongTensor into smaller tensors of the specified dimension.\n",
    "\n",
    "    Args:\n",
    "        tensor (torch.LongTensor): The input tensor to split.\n",
    "        segment_size (Tuple[int, ...]): The dimensions of the smaller tensors.\n",
    "\n",
    "    Returns:\n",
    "        List[torch.Tensor]: A list of smaller tensors.\n",
    "    \"\"\"\n",
    "    if tensor.numel() < torch.prod(torch.tensor(segment_size)):\n",
    "        raise ValueError(\"Segment size is bigger than total number of elements in the tensor.\")\n",
    "    \n",
    "    segments = []\n",
    "    tensor_flat = tensor.view(-1)\n",
    "    for start in range(0, tensor_flat.size(0), torch.prod(torch.tensor(segment_size))):\n",
    "        end = start + torch.prod(torch.tensor(segment_size))\n",
    "        if end > tensor_flat.size(0):\n",
    "            break  # Remaining elements less than segment size\n",
    "        segment = tensor_flat[start:end].view(segment_size)\n",
    "        segments.append(segment)\n",
    "    return segments\n",
    "\n",
    "def sequential_segmentation(tensor: torch.Tensor, threshold: int) -> List[torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Applies sequential segmentation to a tensor.\n",
    "\n",
    "    Args:\n",
    "        tensor (torch.Tensor): The input tensor to segment.\n",
    "        threshold (int): The threshold for identifying a change in the sequence.\n",
    "\n",
    "    Returns:\n",
    "        List[torch.Tensor]: A list of segmented tensors.\n",
    "    \"\"\"\n",
    "    tensor_flat = tensor.view(-1)\n",
    "    segments = []\n",
    "    current_segment = [tensor_flat[0].item()]\n",
    "\n",
    "    for i in range(1, len(tensor_flat)):\n",
    "        if abs(tensor_flat[i] - tensor_flat[i-1]) > threshold:\n",
    "            segments.append(torch.tensor(current_segment, dtype=tensor.dtype))\n",
    "            current_segment = [tensor_flat[i].item()]\n",
    "        else:\n",
    "            current_segment.append(tensor_flat[i].item())\n",
    "\n",
    "    segments.append(torch.tensor(current_segment, dtype=tensor.dtype))  # Add the last segment\n",
    "    return segments\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a sample LongTensor of any dimension\n",
    "    long_tensor = torch.tensor([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]], dtype=torch.long)\n",
    "\n",
    "    # Define the desired size for the smaller tensors (segments)\n",
    "    desired_segment_size = (2, 2)\n",
    "\n",
    "    # Split the tensor into smaller tensors with the specified segment size\n",
    "    tensor_segments = split_tensor(long_tensor, desired_segment_size)\n",
    "\n",
    "    # Define the threshold for sequential segmentation\n",
    "    threshold = 2\n",
    "\n",
    "    # Apply sequential segmentation to each split tensor\n",
    "    sequentially_segmented_tensors = []\n",
    "    for segment in tensor_segments:\n",
    "        sequentially_segmented_tensors.extend(sequential_segmentation(segment, threshold))\n",
    "\n",
    "    # Output the result\n",
    "    print(\"Sequentially Segmented Tensors:\")\n",
    "    for i, segment in enumerate(sequentially_segmented_tensors):\n",
    "        print(f\"Segment {i+1}: {segment.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of split tensors: 100\n",
      "Size of each split tensor: torch.Size([2, 2, 20, 30])\n",
      "Number of processed tensors: 100\n",
      "Size of each processed tensor: torch.Size([2, 2, 20, 30])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from typing import List, Tuple, Callable\n",
    "\n",
    "def split_tensor(tensor: torch.Tensor, segment_size: Tuple[int, ...]) -> List[torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Split a tensor into smaller tensors of a specified size.\n",
    "\n",
    "    Args:\n",
    "        tensor (torch.Tensor): The input tensor to be split.\n",
    "        segment_size (Tuple[int, ...]): The size of each segment.\n",
    "\n",
    "    Returns:\n",
    "        List[torch.Tensor]: A list of split tensors.\n",
    "    \"\"\"\n",
    "    split_tensors = []\n",
    "    for start_idx in range(0, tensor.size(0), segment_size[0]):\n",
    "        end_idx = min(start_idx + segment_size[0], tensor.size(0))\n",
    "        segment = tensor[start_idx:end_idx]\n",
    "        for dim in range(1, len(segment_size)):\n",
    "            segment = segment.unfold(dim, segment_size[dim], segment_size[dim])\n",
    "        split_tensors.extend(segment.unbind(0))\n",
    "    return split_tensors\n",
    "\n",
    "def frame_by_frame_processing(tensor_list: List[torch.Tensor], processing_func: Callable[[torch.Tensor], torch.Tensor]) -> List[torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Apply frame-by-frame processing to a list of tensors.\n",
    "\n",
    "    Args:\n",
    "        tensor_list (List[torch.Tensor]): A list of input tensors.\n",
    "        processing_func (Callable[[torch.Tensor], torch.Tensor]): The processing function to be applied to each frame.\n",
    "\n",
    "    Returns:\n",
    "        List[torch.Tensor]: A list of processed tensors.\n",
    "    \"\"\"\n",
    "    processed_tensors = []\n",
    "    for tensor in tensor_list:\n",
    "        processed_tensor = processing_func(tensor)\n",
    "        processed_tensors.append(processed_tensor)\n",
    "    return processed_tensors\n",
    "\n",
    "# Example processing function\n",
    "def example_processing_func(frame: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Example processing function that applies normalization to each frame.\n",
    "\n",
    "    Args:\n",
    "        frame (torch.Tensor): The input frame tensor.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The processed frame tensor.\n",
    "    \"\"\"\n",
    "    return (frame - frame.mean()) / frame.std()\n",
    "\n",
    "# Example usage\n",
    "long_tensor = torch.randn(100, 50, 60)\n",
    "segment_size = (10, 20, 30)\n",
    "\n",
    "split_tensors = split_tensor(long_tensor, segment_size)\n",
    "print(f\"Number of split tensors: {len(split_tensors)}\")\n",
    "print(f\"Size of each split tensor: {split_tensors[0].size()}\")\n",
    "\n",
    "processed_tensors = frame_by_frame_processing(split_tensors, example_processing_func)\n",
    "print(f\"Number of processed tensors: {len(processed_tensors)}\")\n",
    "print(f\"Size of each processed tensor: {processed_tensors[0].size()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Tensor Segments:\n",
      "Segment 1:\n",
      "tensor([[11, 12],\n",
      "        [13, 14]])\n",
      "Segment 2:\n",
      "tensor([[15, 16],\n",
      "        [17, 18]])\n",
      "Segment 3:\n",
      "tensor([[19, 20],\n",
      "        [21, 22]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from typing import List, Tuple, Callable\n",
    "\n",
    "def split_tensor(tensor: torch.LongTensor, segment_size: Tuple[int, ...]) -> List[torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Splits a LongTensor into smaller tensors of the specified dimension.\n",
    "    \n",
    "    Args:\n",
    "        tensor (torch.LongTensor): The input tensor to split.\n",
    "        segment_size (Tuple[int, ...]): The dimensions of the smaller tensors.\n",
    "        \n",
    "    Returns:\n",
    "        List[torch.Tensor]: A list of smaller tensors.\n",
    "    \"\"\"\n",
    "    if torch.prod(torch.tensor(tensor.shape)) < torch.prod(torch.tensor(segment_size)):\n",
    "        raise ValueError(\"Segment size is larger than the tensor size.\")\n",
    "    \n",
    "    # Calculate the number of segments that will be created\n",
    "    num_segments = tensor.numel() // torch.prod(torch.tensor(segment_size))\n",
    "    tensor_flat = tensor.view(-1)\n",
    "    segments = [\n",
    "        tensor_flat[i * torch.prod(torch.tensor(segment_size)): (i + 1) * torch.prod(torch.tensor(segment_size))]\n",
    "        .view(segment_size)\n",
    "        for i in range(num_segments)\n",
    "    ]\n",
    "    return segments\n",
    "\n",
    "def frame_by_frame_processing(segments: List[torch.Tensor], processing_function: Callable[[torch.Tensor], torch.Tensor]) -> List[torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Applies frame-by-frame processing to each tensor segment.\n",
    "    \n",
    "    Args:\n",
    "        segments (List[torch.Tensor]): A list of tensor segments to process.\n",
    "        processing_function (Callable[[torch.Tensor], torch.Tensor]): A function to apply to each frame.\n",
    "        \n",
    "    Returns:\n",
    "        List[torch.Tensor]: A list of processed tensor segments.\n",
    "    \"\"\"\n",
    "    processed_segments = []\n",
    "    for segment in segments:\n",
    "        processed_segment = torch.stack([processing_function(frame) for frame in segment.view(-1)])\n",
    "        processed_segments.append(processed_segment.view(segment.size()))\n",
    "    return processed_segments\n",
    "\n",
    "# Define a sample frame processing function\n",
    "def sample_processing_function(frame: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    A sample processing function that could represent any frame-level processing.\n",
    "    This example function just increments each value by 10.\n",
    "    \n",
    "    Args:\n",
    "        frame (torch.Tensor): The frame tensor to process.\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: The processed frame tensor.\n",
    "    \"\"\"\n",
    "    return frame + 10\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a sample LongTensor of any dimension\n",
    "    long_tensor = torch.tensor([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]], dtype=torch.long)\n",
    "\n",
    "    # Define the desired size for the smaller tensors (segments)\n",
    "    desired_segment_size = (2, 2)\n",
    "\n",
    "    # Split the tensor into smaller tensors with the specified segment size\n",
    "    tensor_segments = split_tensor(long_tensor, desired_segment_size)\n",
    "\n",
    "    # Apply frame-by-frame processing to each tensor segment\n",
    "    processed_segments = frame_by_frame_processing(tensor_segments, sample_processing_function)\n",
    "\n",
    "    # Output the result\n",
    "    print(\"Processed Tensor Segments:\")\n",
    "    for i, segment in enumerate(processed_segments):\n",
    "        print(f\"Segment {i+1}:\\n{segment}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of split tensors: 100\n",
      "Size of each split tensor: torch.Size([2, 2, 20, 30])\n",
      "Number of segmented windows: 48\n",
      "Number of tensors in each window: 5\n",
      "Size of each tensor in a window: torch.Size([2, 2, 20, 30])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from typing import List, Tuple\n",
    "\n",
    "def split_tensor(tensor: torch.Tensor, segment_size: Tuple[int, ...]) -> List[torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Split a tensor into smaller tensors of a specified size.\n",
    "\n",
    "    Args:\n",
    "        tensor (torch.Tensor): The input tensor to be split.\n",
    "        segment_size (Tuple[int, ...]): The size of each segment.\n",
    "\n",
    "    Returns:\n",
    "        List[torch.Tensor]: A list of split tensors.\n",
    "    \"\"\"\n",
    "    split_tensors = []\n",
    "    for start_idx in range(0, tensor.size(0), segment_size[0]):\n",
    "        end_idx = min(start_idx + segment_size[0], tensor.size(0))\n",
    "        segment = tensor[start_idx:end_idx]\n",
    "        for dim in range(1, len(segment_size)):\n",
    "            segment = segment.unfold(dim, segment_size[dim], segment_size[dim])\n",
    "        split_tensors.extend(segment.unbind(0))\n",
    "    return split_tensors\n",
    "\n",
    "def time_windowed_segmentation(tensor_list: List[torch.Tensor], window_size: int, stride: int) -> List[List[torch.Tensor]]:\n",
    "    \"\"\"\n",
    "    Apply time-windowed segmentation to a list of tensors.\n",
    "\n",
    "    Args:\n",
    "        tensor_list (List[torch.Tensor]): A list of input tensors.\n",
    "        window_size (int): The size of the time window.\n",
    "        stride (int): The stride or step size between consecutive windows.\n",
    "\n",
    "    Returns:\n",
    "        List[List[torch.Tensor]]: A list of segmented tensor windows.\n",
    "    \"\"\"\n",
    "    segmented_windows = []\n",
    "    for i in range(0, len(tensor_list) - window_size + 1, stride):\n",
    "        window = tensor_list[i:i+window_size]\n",
    "        segmented_windows.append(window)\n",
    "    return segmented_windows\n",
    "\n",
    "# Example usage\n",
    "long_tensor = torch.randn(100, 50, 60)\n",
    "segment_size = (10, 20, 30)\n",
    "window_size = 5\n",
    "stride = 2\n",
    "\n",
    "split_tensors = split_tensor(long_tensor, segment_size)\n",
    "print(f\"Number of split tensors: {len(split_tensors)}\")\n",
    "print(f\"Size of each split tensor: {split_tensors[0].size()}\")\n",
    "\n",
    "segmented_windows = time_windowed_segmentation(split_tensors, window_size, stride)\n",
    "print(f\"Number of segmented windows: {len(segmented_windows)}\")\n",
    "print(f\"Number of tensors in each window: {len(segmented_windows[0])}\")\n",
    "print(f\"Size of each tensor in a window: {segmented_windows[0][0].size()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time-windowed Segments:\n",
      "Window 1:\n",
      "tensor([[ 1,  2,  3,  4,  5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12, 13, 14, 15, 16],\n",
      "        [17, 18, 19, 20, 21, 22, 23, 24]])\n",
      "\n",
      "Window 2:\n",
      "tensor([[25, 26, 27, 28, 29, 30, 31, 32],\n",
      "        [33, 34, 35, 36, 37, 38, 39, 40],\n",
      "        [41, 42, 43, 44, 45, 46, 47, 48]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from typing import List, Tuple\n",
    "\n",
    "def split_tensor_into_windows(tensor: torch.LongTensor, window_size: int) -> List[torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Splits a LongTensor into smaller tensors based on a fixed window size.\n",
    "    \n",
    "    Args:\n",
    "        tensor (torch.LongTensor): The input tensor to split, assuming time is the first dimension.\n",
    "        window_size (int): The size of each time window.\n",
    "        \n",
    "    Returns:\n",
    "        List[torch.Tensor]: A list of smaller tensors, each representing a time window.\n",
    "    \"\"\"\n",
    "    if tensor.size(0) < window_size:\n",
    "        raise ValueError(\"Window size is larger than the tensor's time dimension.\")\n",
    "    \n",
    "    # Determine the number of windows that fit into the tensor's time dimension\n",
    "    num_windows = tensor.size(0) // window_size\n",
    "    windowed_segments = [\n",
    "        tensor[i * window_size:(i + 1) * window_size]\n",
    "        for i in range(num_windows)\n",
    "    ]\n",
    "    return windowed_segments\n",
    "\n",
    "def time_windowed_segmentation(tensor: torch.LongTensor, window_size: int) -> List[torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Applies time-windowed segmentation to a tensor.\n",
    "    \n",
    "    Args:\n",
    "        tensor (torch.LongTensor): The input tensor to segment.\n",
    "        window_size (int): The size of each time window.\n",
    "        \n",
    "    Returns:\n",
    "        List[torch.Tensor]: A list of tensor segments, each representing a time window.\n",
    "    \"\"\"\n",
    "    return split_tensor_into_windows(tensor, window_size)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a sample LongTensor with time dimension as the first dimension\n",
    "    long_tensor = torch.arange(1, 49, dtype=torch.long).view(6, 8)  # 6 time steps, 8 features\n",
    "\n",
    "    # Define the time window size\n",
    "    time_window_size = 3\n",
    "\n",
    "    # Perform time-windowed segmentation\n",
    "    windowed_segments = time_windowed_segmentation(long_tensor, time_window_size)\n",
    "\n",
    "    # Output the result\n",
    "    print(\"Time-windowed Segments:\")\n",
    "    for i, segment in enumerate(windowed_segments):\n",
    "        print(f\"Window {i+1}:\\n{segment}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of split tensors: 100\n",
      "Size of each split tensor: torch.Size([2, 2, 20, 30])\n",
      "Number of windowed sequences: 48\n",
      "Number of tensors in each window: 5\n",
      "Size of each tensor in a window: torch.Size([2, 2, 20, 30])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from typing import List, Tuple\n",
    "\n",
    "def split_tensor(tensor: torch.Tensor, segment_size: Tuple[int, ...]) -> List[torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Split a tensor into smaller tensors of a specified size.\n",
    "\n",
    "    Args:\n",
    "        tensor (torch.Tensor): The input tensor to be split.\n",
    "        segment_size (Tuple[int, ...]): The size of each segment.\n",
    "\n",
    "    Returns:\n",
    "        List[torch.Tensor]: A list of split tensors.\n",
    "    \"\"\"\n",
    "    split_tensors = []\n",
    "    for start_idx in range(0, tensor.size(0), segment_size[0]):\n",
    "        end_idx = min(start_idx + segment_size[0], tensor.size(0))\n",
    "        segment = tensor[start_idx:end_idx]\n",
    "        for dim in range(1, len(segment_size)):\n",
    "            segment = segment.unfold(dim, segment_size[dim], segment_size[dim])\n",
    "        split_tensors.extend(segment.unbind(0))\n",
    "    return split_tensors\n",
    "\n",
    "def sequential_windowing(tensor_list: List[torch.Tensor], window_size: int, stride: int) -> List[List[torch.Tensor]]:\n",
    "    \"\"\"\n",
    "    Apply sequential windowing to a list of tensors.\n",
    "\n",
    "    Args:\n",
    "        tensor_list (List[torch.Tensor]): A list of input tensors.\n",
    "        window_size (int): The size of the window.\n",
    "        stride (int): The stride or step size between consecutive windows.\n",
    "\n",
    "    Returns:\n",
    "        List[List[torch.Tensor]]: A list of windowed tensor sequences.\n",
    "    \"\"\"\n",
    "    windowed_sequences = []\n",
    "    for i in range(0, len(tensor_list), stride):\n",
    "        window = tensor_list[i:i+window_size]\n",
    "        if len(window) == window_size:\n",
    "            windowed_sequences.append(window)\n",
    "    return windowed_sequences\n",
    "\n",
    "# Example usage\n",
    "long_tensor = torch.randn(100, 50, 60)\n",
    "segment_size = (10, 20, 30)\n",
    "window_size = 5\n",
    "stride = 2\n",
    "\n",
    "split_tensors = split_tensor(long_tensor, segment_size)\n",
    "print(f\"Number of split tensors: {len(split_tensors)}\")\n",
    "print(f\"Size of each split tensor: {split_tensors[0].size()}\")\n",
    "\n",
    "windowed_sequences = sequential_windowing(split_tensors, window_size, stride)\n",
    "print(f\"Number of windowed sequences: {len(windowed_sequences)}\")\n",
    "print(f\"Number of tensors in each window: {len(windowed_sequences[0])}\")\n",
    "print(f\"Size of each tensor in a window: {windowed_sequences[0][0].size()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequentially Windowed Tensors:\n",
      "Window 1:\n",
      "tensor([[ 1,  2,  3,  4,  5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12, 13, 14, 15, 16],\n",
      "        [17, 18, 19, 20, 21, 22, 23, 24],\n",
      "        [25, 26, 27, 28, 29, 30, 31, 32]])\n",
      "\n",
      "Window 2:\n",
      "tensor([[17, 18, 19, 20, 21, 22, 23, 24],\n",
      "        [25, 26, 27, 28, 29, 30, 31, 32],\n",
      "        [33, 34, 35, 36, 37, 38, 39, 40],\n",
      "        [41, 42, 43, 44, 45, 46, 47, 48]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from typing import List, Tuple\n",
    "\n",
    "def sequential_windowing(tensor: torch.LongTensor, window_size: int, overlap_size: int) -> List[torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Applies sequential windowing to a LongTensor.\n",
    "    \n",
    "    Args:\n",
    "        tensor (torch.LongTensor): The input tensor to split. Assumes time is the first dimension.\n",
    "        window_size (int): The size of each window.\n",
    "        overlap_size (int): The number of elements to overlap between consecutive windows.\n",
    "        \n",
    "    Returns:\n",
    "        List[torch.Tensor]: A list of windowed tensors.\n",
    "    \"\"\"\n",
    "    if window_size <= overlap_size:\n",
    "        raise ValueError(\"Window size must be larger than overlap size.\")\n",
    "    if tensor.size(0) < window_size:\n",
    "        raise ValueError(\"Window size is larger than the tensor's time dimension.\")\n",
    "    \n",
    "    # Flatten the tensor if it has more than one dimension (excluding the time dimension)\n",
    "    if tensor.dim() > 1:\n",
    "        tensor = tensor.view(tensor.size(0), -1)\n",
    "    \n",
    "    windowed_segments = []\n",
    "    start_index = 0\n",
    "    while start_index + window_size <= tensor.size(0):\n",
    "        windowed_segments.append(tensor[start_index:start_index + window_size])\n",
    "        start_index += window_size - overlap_size\n",
    "        \n",
    "    return windowed_segments\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a sample LongTensor with time as the first dimension\n",
    "    long_tensor = torch.arange(1, 49, dtype=torch.long).view(6, 8)  # 6 time steps, 8 features\n",
    "\n",
    "    # Define the window size and overlap size for sequential windowing\n",
    "    window_size = 4\n",
    "    overlap_size = 2\n",
    "\n",
    "    # Apply sequential windowing to the tensor\n",
    "    windows = sequential_windowing(long_tensor, window_size, overlap_size)\n",
    "\n",
    "    # Output the result\n",
    "    print(\"Sequentially Windowed Tensors:\")\n",
    "    for i, window in enumerate(windows):\n",
    "        print(f\"Window {i+1}:\\n{window}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of split tensors: 100\n",
      "Size of each split tensor: torch.Size([2, 2, 20, 30])\n",
      "Number of analyzed tensors: 48\n",
      "Size of each analyzed tensor: torch.Size([2, 2, 20, 30])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from typing import List, Tuple\n",
    "\n",
    "def split_tensor(tensor: torch.Tensor, segment_size: Tuple[int, ...]) -> List[torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Split a tensor into smaller tensors of a specified size.\n",
    "\n",
    "    Args:\n",
    "        tensor (torch.Tensor): The input tensor to be split.\n",
    "        segment_size (Tuple[int, ...]): The size of each segment.\n",
    "\n",
    "    Returns:\n",
    "        List[torch.Tensor]: A list of split tensors.\n",
    "    \"\"\"\n",
    "    split_tensors = []\n",
    "    for start_idx in range(0, tensor.size(0), segment_size[0]):\n",
    "        end_idx = min(start_idx + segment_size[0], tensor.size(0))\n",
    "        segment = tensor[start_idx:end_idx]\n",
    "        for dim in range(1, len(segment_size)):\n",
    "            segment = segment.unfold(dim, segment_size[dim], segment_size[dim])\n",
    "        split_tensors.extend(segment.unbind(0))\n",
    "    return split_tensors\n",
    "\n",
    "def moving_window_analysis(tensor_list: List[torch.Tensor], window_size: int, stride: int) -> List[torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Apply moving window analysis to a list of tensors.\n",
    "\n",
    "    Args:\n",
    "        tensor_list (List[torch.Tensor]): A list of input tensors.\n",
    "        window_size (int): The size of the moving window.\n",
    "        stride (int): The stride or step size between consecutive windows.\n",
    "\n",
    "    Returns:\n",
    "        List[torch.Tensor]: A list of analyzed tensors for each window.\n",
    "    \"\"\"\n",
    "    analyzed_tensors = []\n",
    "    for i in range(0, len(tensor_list) - window_size + 1, stride):\n",
    "        window = tensor_list[i:i+window_size]\n",
    "        analyzed_tensor = torch.stack(window, dim=0)\n",
    "        \n",
    "        # Perform analysis on the window\n",
    "        # Replace this with your specific analysis logic\n",
    "        analyzed_tensor = analyzed_tensor.mean(dim=0)\n",
    "        \n",
    "        analyzed_tensors.append(analyzed_tensor)\n",
    "    return analyzed_tensors\n",
    "\n",
    "# Example usage\n",
    "long_tensor = torch.randn(100, 50, 60)\n",
    "segment_size = (10, 20, 30)\n",
    "window_size = 5\n",
    "stride = 2\n",
    "\n",
    "split_tensors = split_tensor(long_tensor, segment_size)\n",
    "print(f\"Number of split tensors: {len(split_tensors)}\")\n",
    "print(f\"Size of each split tensor: {split_tensors[0].size()}\")\n",
    "\n",
    "analyzed_tensors = moving_window_analysis(split_tensors, window_size, stride)\n",
    "print(f\"Number of analyzed tensors: {len(analyzed_tensors)}\")\n",
    "print(f\"Size of each analyzed tensor: {analyzed_tensors[0].size()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving Window Analysis Results:\n",
      "Window 1 result: 300\n",
      "Window 2 result: 492\n",
      "Window 3 result: 684\n",
      "Window 4 result: 876\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from typing import List, Tuple, Callable\n",
    "\n",
    "def moving_window_analysis(\n",
    "    tensor: torch.LongTensor,\n",
    "    window_size: int,\n",
    "    analysis_function: Callable[[torch.LongTensor], torch.Tensor]\n",
    ") -> List[torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Applies moving window analysis to a LongTensor using the provided analysis function.\n",
    "\n",
    "    Args:\n",
    "        tensor (torch.LongTensor): The input tensor to analyze. Assumes time is the first dimension.\n",
    "        window_size (int): The size of the moving window.\n",
    "        analysis_function (Callable[[torch.LongTensor], torch.Tensor]): The function to apply to each window.\n",
    "\n",
    "    Returns:\n",
    "        List[torch.Tensor]: A list of results from the analysis function applied to each window.\n",
    "    \"\"\"\n",
    "    if window_size <= 0:\n",
    "        raise ValueError(\"Window size must be a positive integer.\")\n",
    "    if tensor.size(0) < window_size:\n",
    "        raise ValueError(\"Window size is larger than the tensor's time dimension.\")\n",
    "\n",
    "    # Flatten the tensor if it has more than one dimension (excluding the time dimension)\n",
    "    if tensor.dim() > 1:\n",
    "        tensor = tensor.view(tensor.size(0), -1)\n",
    "\n",
    "    results = []\n",
    "    for start_index in range(tensor.size(0) - window_size + 1):\n",
    "        window = tensor[start_index:start_index + window_size]\n",
    "        result = analysis_function(window)\n",
    "        results.append(result)\n",
    "\n",
    "    return results\n",
    "\n",
    "# Define a sample analysis function\n",
    "def sample_analysis_function(window: torch.LongTensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    A sample analysis function that computes the sum of all elements in the window.\n",
    "\n",
    "    Args:\n",
    "        window (torch.LongTensor): A window of the input tensor.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The result of the analysis (sum in this case).\n",
    "    \"\"\"\n",
    "    return window.sum()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a sample LongTensor with time as the first dimension\n",
    "    long_tensor = torch.arange(1, 49, dtype=torch.long).view(6, 8)  # 6 time steps, 8 features\n",
    "\n",
    "    # Define the window size for moving window analysis\n",
    "    window_size = 3\n",
    "\n",
    "    # Apply moving window analysis to the tensor\n",
    "    analysis_results = moving_window_analysis(long_tensor, window_size, sample_analysis_function)\n",
    "\n",
    "    # Output the result\n",
    "    print(\"Moving Window Analysis Results:\")\n",
    "    for i, result in enumerate(analysis_results):\n",
    "        print(f\"Window {i+1} result: {result.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of split tensors: 100\n",
      "Size of each split tensor: torch.Size([2, 2, 20, 30])\n",
      "Number of sampled tensors: 34\n",
      "Size of each sampled tensor: torch.Size([2, 2, 20, 30])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from typing import List, Tuple\n",
    "\n",
    "def split_tensor(tensor: torch.Tensor, segment_size: Tuple[int, ...]) -> List[torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Split a tensor into smaller tensors of a specified size.\n",
    "\n",
    "    Args:\n",
    "        tensor (torch.Tensor): The input tensor to be split.\n",
    "        segment_size (Tuple[int, ...]): The size of each segment.\n",
    "\n",
    "    Returns:\n",
    "        List[torch.Tensor]: A list of split tensors.\n",
    "    \"\"\"\n",
    "    split_tensors = []\n",
    "    for start_idx in range(0, tensor.size(0), segment_size[0]):\n",
    "        end_idx = min(start_idx + segment_size[0], tensor.size(0))\n",
    "        segment = tensor[start_idx:end_idx]\n",
    "        for dim in range(1, len(segment_size)):\n",
    "            segment = segment.unfold(dim, segment_size[dim], segment_size[dim])\n",
    "        split_tensors.extend(segment.unbind(0))\n",
    "    return split_tensors\n",
    "\n",
    "def sequential_sampling(tensor_list: List[torch.Tensor], sampling_rate: int) -> List[torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Apply sequential sampling to a list of tensors.\n",
    "\n",
    "    Args:\n",
    "        tensor_list (List[torch.Tensor]): A list of input tensors.\n",
    "        sampling_rate (int): The sampling rate or interval between samples.\n",
    "\n",
    "    Returns:\n",
    "        List[torch.Tensor]: A list of sampled tensors.\n",
    "    \"\"\"\n",
    "    sampled_tensors = tensor_list[::sampling_rate]\n",
    "    return sampled_tensors\n",
    "\n",
    "# Example usage\n",
    "long_tensor = torch.randn(100, 50, 60)\n",
    "segment_size = (10, 20, 30)\n",
    "sampling_rate = 3\n",
    "\n",
    "split_tensors = split_tensor(long_tensor, segment_size)\n",
    "print(f\"Number of split tensors: {len(split_tensors)}\")\n",
    "print(f\"Size of each split tensor: {split_tensors[0].size()}\")\n",
    "\n",
    "sampled_tensors = sequential_sampling(split_tensors, sampling_rate)\n",
    "print(f\"Number of sampled tensors: {len(sampled_tensors)}\")\n",
    "print(f\"Size of each sampled tensor: {sampled_tensors[0].size()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequentially Sampled Tensor:\n",
      "tensor([[ 1,  2,  3,  4],\n",
      "        [ 9, 10, 11, 12],\n",
      "        [17, 18, 19, 20]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from typing import List, Tuple\n",
    "\n",
    "def sequential_sampling(tensor: torch.LongTensor, sample_rate: int) -> torch.LongTensor:\n",
    "    \"\"\"\n",
    "    Applies sequential sampling to a LongTensor by taking every nth element from the tensor\n",
    "    along the first dimension, which is typically the time or sequence dimension.\n",
    "\n",
    "    Args:\n",
    "        tensor (torch.LongTensor): The input tensor to sample from.\n",
    "        sample_rate (int): The rate at which to sample the tensor. Must be a positive integer.\n",
    "\n",
    "    Returns:\n",
    "        torch.LongTensor: The down-sampled tensor.\n",
    "    \"\"\"\n",
    "    if sample_rate <= 0:\n",
    "        raise ValueError(\"Sample rate must be a positive integer.\")\n",
    "    if tensor.dim() == 0 or tensor.size(0) < sample_rate:\n",
    "        raise ValueError(\"Sample rate is larger than the tensor's first dimension size or the tensor is empty.\")\n",
    "\n",
    "    # Take every nth element along the first dimension\n",
    "    sampled_tensor = tensor[::sample_rate]\n",
    "    return sampled_tensor\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a sample LongTensor of any dimension\n",
    "    long_tensor = torch.tensor([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12],\n",
    "                                [13, 14, 15, 16], [17, 18, 19, 20], [21, 22, 23, 24]], dtype=torch.long)\n",
    "\n",
    "    # Define the sample rate for sequential sampling\n",
    "    sample_rate = 2\n",
    "\n",
    "    # Apply sequential sampling to the tensor\n",
    "    sampled_tensor = sequential_sampling(long_tensor, sample_rate)\n",
    "\n",
    "    # Output the result\n",
    "    print(\"Sequentially Sampled Tensor:\")\n",
    "    print(sampled_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of split tensors: 100\n",
      "Size of each split tensor: torch.Size([2, 2, 20, 30])\n",
      "Number of windowed sequences: 48\n",
      "Number of tensors in each window: 5\n",
      "Size of each tensor in a window: torch.Size([2, 2, 20, 30])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from typing import List, Tuple\n",
    "\n",
    "def split_tensor(tensor: torch.Tensor, segment_size: Tuple[int, ...]) -> List[torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Split a tensor into smaller tensors of a specified size.\n",
    "\n",
    "    Args:\n",
    "        tensor (torch.Tensor): The input tensor to be split.\n",
    "        segment_size (Tuple[int, ...]): The size of each segment.\n",
    "\n",
    "    Returns:\n",
    "        List[torch.Tensor]: A list of split tensors.\n",
    "    \"\"\"\n",
    "    split_tensors = []\n",
    "    for start_idx in range(0, tensor.size(0), segment_size[0]):\n",
    "        end_idx = min(start_idx + segment_size[0], tensor.size(0))\n",
    "        segment = tensor[start_idx:end_idx]\n",
    "        for dim in range(1, len(segment_size)):\n",
    "            segment = segment.unfold(dim, segment_size[dim], segment_size[dim])\n",
    "        split_tensors.extend(segment.unbind(0))\n",
    "    return split_tensors\n",
    "\n",
    "def temporal_windowing(tensor_list: List[torch.Tensor], window_size: int, stride: int) -> List[List[torch.Tensor]]:\n",
    "    \"\"\"\n",
    "    Apply temporal windowing to a list of tensors.\n",
    "\n",
    "    Args:\n",
    "        tensor_list (List[torch.Tensor]): A list of input tensors.\n",
    "        window_size (int): The size of the temporal window.\n",
    "        stride (int): The stride or step size between consecutive windows.\n",
    "\n",
    "    Returns:\n",
    "        List[List[torch.Tensor]]: A list of windowed tensor sequences.\n",
    "    \"\"\"\n",
    "    windowed_sequences = []\n",
    "    for i in range(0, len(tensor_list) - window_size + 1, stride):\n",
    "        window = tensor_list[i:i+window_size]\n",
    "        windowed_sequences.append(window)\n",
    "    return windowed_sequences\n",
    "\n",
    "# Example usage\n",
    "long_tensor = torch.randn(100, 50, 60)\n",
    "segment_size = (10, 20, 30)\n",
    "window_size = 5\n",
    "stride = 2\n",
    "\n",
    "split_tensors = split_tensor(long_tensor, segment_size)\n",
    "print(f\"Number of split tensors: {len(split_tensors)}\")\n",
    "print(f\"Size of each split tensor: {split_tensors[0].size()}\")\n",
    "\n",
    "windowed_sequences = temporal_windowing(split_tensors, window_size, stride)\n",
    "print(f\"Number of windowed sequences: {len(windowed_sequences)}\")\n",
    "print(f\"Number of tensors in each window: {len(windowed_sequences[0])}\")\n",
    "print(f\"Size of each tensor in a window: {windowed_sequences[0][0].size()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windowed Tensor:\n",
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from typing import List, Callable\n",
    "from torch import Tensor\n",
    "\n",
    "def apply_window_function(tensor: Tensor, window_function: Callable[[int], Tensor]) -> Tensor:\n",
    "    \"\"\"\n",
    "    Apply a window function to a tensor along the first dimension.\n",
    "\n",
    "    Args:\n",
    "        tensor (Tensor): The input tensor, where the first dimension represents time.\n",
    "        window_function (Callable[[int], Tensor]): A function that returns a window tensor\n",
    "            given the window size.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: The windowed tensor.\n",
    "    \"\"\"\n",
    "    window_size = tensor.size(0)\n",
    "    window = window_function(window_size).to(tensor.dtype)\n",
    "    return tensor * window\n",
    "\n",
    "def generate_hamming_window(window_size: int) -> Tensor:\n",
    "    \"\"\"\n",
    "    Generate a Hamming window tensor for temporal windowing.\n",
    "\n",
    "    Args:\n",
    "        window_size (int): The size of the Hamming window.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: The Hamming window tensor.\n",
    "    \"\"\"\n",
    "    return torch.hamming_window(window_size)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a sample LongTensor of any dimension\n",
    "    long_tensor = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.long)\n",
    "\n",
    "    # Define the window function (Hamming window in this case)\n",
    "    window_function = generate_hamming_window\n",
    "\n",
    "    # Apply temporal windowing to the tensor\n",
    "    windowed_tensor = apply_window_function(long_tensor, window_function)\n",
    "\n",
    "    # Output the result\n",
    "    print(\"Windowed Tensor:\")\n",
    "    print(windowed_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
