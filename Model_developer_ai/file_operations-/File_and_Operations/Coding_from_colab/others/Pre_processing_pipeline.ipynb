{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "aa9103a6e74d47f2a5aea251fcbe37ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_68471ac2631842c096a78a3c16abfa3d",
              "IPY_MODEL_f8465bac73964b03a15d0e779d544c3a",
              "IPY_MODEL_2f66df262dca49b4b7a36ef10a91deae"
            ],
            "layout": "IPY_MODEL_64e232acc1104a91b2927b694c3a6f69"
          }
        },
        "68471ac2631842c096a78a3c16abfa3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3f98977605b47c38c1f31da3f34e08d",
            "placeholder": "​",
            "style": "IPY_MODEL_7dc40787b9c346f6849cf926e187b5d1",
            "value": "100%"
          }
        },
        "f8465bac73964b03a15d0e779d544c3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac10bfd3e6424c2fb91907f979b5fd28",
            "max": 528,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_89e2ec1573e4436e93d8beb8a948a313",
            "value": 528
          }
        },
        "2f66df262dca49b4b7a36ef10a91deae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1d98d6ae9d743649f089fb34b42a068",
            "placeholder": "​",
            "style": "IPY_MODEL_14e4098f745741ac8d84a9caa45e4dbd",
            "value": " 528/528 [00:00&lt;00:00, 6486.46it/s]"
          }
        },
        "64e232acc1104a91b2927b694c3a6f69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3f98977605b47c38c1f31da3f34e08d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dc40787b9c346f6849cf926e187b5d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac10bfd3e6424c2fb91907f979b5fd28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89e2ec1573e4436e93d8beb8a948a313": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a1d98d6ae9d743649f089fb34b42a068": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14e4098f745741ac8d84a9caa45e4dbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8d4c4bb3dcc4f91b71b50f033c99a8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d0a6ecc844fd4925a7a4faf9d49119e7",
              "IPY_MODEL_a5a9b1741029465dbd2a6306de207914",
              "IPY_MODEL_93d7850edce441e08462339178cc0510"
            ],
            "layout": "IPY_MODEL_11833ec18d594b7592cdea30c0bfdb34"
          }
        },
        "d0a6ecc844fd4925a7a4faf9d49119e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a72627711a84dc5933c1f436c361ae8",
            "placeholder": "​",
            "style": "IPY_MODEL_5d777860d8b049b9a50e0741b75513e9",
            "value": "Loading checkpoint shards:  25%"
          }
        },
        "a5a9b1741029465dbd2a6306de207914": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5d3e70bb86748b79733031bc3886a3f",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61f26bf686c5423c9d6fc8a46422d6f8",
            "value": 2
          }
        },
        "93d7850edce441e08462339178cc0510": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ef7732b5148471791618f3b94ba778b",
            "placeholder": "​",
            "style": "IPY_MODEL_6a7d3e02c6bb4aaab829ccab46a9552c",
            "value": " 2/8 [00:19&lt;00:57,  9.62s/it]"
          }
        },
        "11833ec18d594b7592cdea30c0bfdb34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a72627711a84dc5933c1f436c361ae8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d777860d8b049b9a50e0741b75513e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5d3e70bb86748b79733031bc3886a3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61f26bf686c5423c9d6fc8a46422d6f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ef7732b5148471791618f3b94ba778b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a7d3e02c6bb4aaab829ccab46a9552c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U langchain unstructured   arxiv datasets unstructured[all-docs] transformers\n",
        "!pip install -q -U torch transformers transformers accelerate bitsandbytes langchain sentence-transformers faiss-gpu openpyxl"
      ],
      "metadata": {
        "id": "AmjlzjvM4tP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5-jyzHHGSRY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import arxiv\n",
        "import csv\n",
        "import pandas as pd\n",
        "import warnings\n",
        "import torch\n",
        "\n",
        "from transformers import pipeline\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores.utils import DistanceStrategy\n",
        "from transformers import AutoTokenizer\n",
        "from langchain.docstore.document import Document as LangchainDocument\n",
        "from tqdm.notebook import tqdm\n",
        "from datasets import Dataset,load_dataset,DatasetDict\n",
        "from typing import Union,List, Dict, Optional,Tuple\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "\n",
        "def download_papers(query, max_results, save_dir):\n",
        "    \"\"\"\n",
        "    This function downloads papers from arXiv based on the provided query.\n",
        "\n",
        "    Parameters:\n",
        "    query (str): The search query for the papers.\n",
        "    max_results (int): The maximum number of results to return.\n",
        "    save_dir (str): The directory where the papers will be saved.\n",
        "    \"\"\"\n",
        "    # Construct the default API client\n",
        "    client = arxiv.Client()\n",
        "\n",
        "    # Create a search object\n",
        "    search = arxiv.Search(\n",
        "        query=query,\n",
        "        max_results=max_results,\n",
        "        sort_by=arxiv.SortCriterion.SubmittedDate\n",
        "    )\n",
        "\n",
        "    # Get the results as a list\n",
        "    results = list(client.results(search))\n",
        "\n",
        "    # Check if the folder exists\n",
        "    if not os.path.exists(save_dir):\n",
        "        # If not, create the folder\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    # Loop through the results\n",
        "    for result in results:\n",
        "        # Print the title of the paper\n",
        "        print(result.title)\n",
        "        # Download the paper as a PDF file and save it to the directory\n",
        "        result.download_pdf(save_dir)\n",
        "\n",
        "\n",
        "def write_to_csv(file_path: str, data: dict, write_header: bool) -> None:\n",
        "    \"\"\"\n",
        "    Function to append data into a CSV file.\n",
        "\n",
        "    Args:\n",
        "    file_path (str): The path to the CSV file.\n",
        "    data (dict): The data to be appended into the CSV file.\n",
        "    write_header (bool): Whether to write the header.\n",
        "    \"\"\"\n",
        "    mode = 'a' if os.path.exists(file_path) else 'w'\n",
        "    with open(file_path, mode, newline='', encoding='UTF-8', errors='ignore') as file:\n",
        "        writer = csv.DictWriter(file, fieldnames=[\"content\", \"documents\", \"metasource\"], quoting=csv.QUOTE_ALL, escapechar='\\\\')\n",
        "        if write_header and mode == 'w':\n",
        "            writer.writeheader()\n",
        "        try:\n",
        "            writer.writerow({k: data[k] for k in [\"content\", \"documents\", \"metasource\"]})\n",
        "        except UnicodeEncodeError:\n",
        "            print(f\"Warning: UnicodeEncodeError encountered for file {data['documents']}. Skipping this file.\")\n",
        "\n",
        "\n",
        "def read_pdfs_from_folder(folder_path: str, csv_file_path: str) -> None:\n",
        "    \"\"\"\n",
        "    Function to recursively read PDF files from a folder and its subfolders and extract their content.\n",
        "\n",
        "    Args:\n",
        "    folder_path (str): The path to the folder containing the PDF files.\n",
        "    csv_file_path (str): The path to the CSV file.\n",
        "    \"\"\"\n",
        "    for root, dirs, files in os.walk(folder_path):\n",
        "        for file_name in files:\n",
        "            if file_name.endswith(\".pdf\"):\n",
        "                full_file_path = os.path.join(root, file_name)\n",
        "                loader = PyPDFLoader(full_file_path)\n",
        "                pages = loader.load_and_split()\n",
        "                for page in pages:\n",
        "                    data = {\n",
        "                        \"content\": page.page_content,\n",
        "                        \"documents\": file_name,\n",
        "                        \"metasource\": page.metadata['source']\n",
        "                    }\n",
        "                    write_to_csv(csv_file_path, data, True)\n",
        "\n",
        "def load_files(folder_path: str, file_extension: str = None) -> List[str]:\n",
        "    \"\"\"\n",
        "    This function loads all files of a specific extension from a given folder.\n",
        "    If no extension is provided, it loads all files.\n",
        "\n",
        "    Parameters:\n",
        "    folder_path (str): The path to the folder.\n",
        "    file_extension (str): The file extension to look for.\n",
        "\n",
        "    Returns:\n",
        "    docs (List[str]): The list of loaded documents.\n",
        "    \"\"\"\n",
        "    glob_pattern = f\"**/*.{file_extension}\" if file_extension else \"**/[!.]*\"\n",
        "    # print(f\"============================* {file_extension if file_extension else 'all'} files *==============================\")\n",
        "    loader = DirectoryLoader(\n",
        "        folder_path,\n",
        "        glob=glob_pattern,\n",
        "        show_progress=True,\n",
        "        use_multithreading=True,\n",
        "        silent_errors=True\n",
        "    )\n",
        "    docs = loader.load()\n",
        "    return docs\n",
        "\n",
        "def advanced_data_loader(input: Union[str, Dict[str, str]], format: Optional[str] = None, split_ratios: Optional[Dict[str, float]] = None) -> Optional[DatasetDict]:\n",
        "    \"\"\"\n",
        "    Loads a dataset from a given input path or dictionary specifying file paths and splits it.\n",
        "\n",
        "    :param input: A string representing the dataset name or directory, or a dictionary containing file paths.\n",
        "    :param format: The format of the dataset if loading from a file (e.g., 'csv' or 'json').\n",
        "    :param split_ratios: A dictionary with keys 'train', 'test', and 'eval' containing split ratios.\n",
        "    :return: A loaded and split dataset or None in case of failure.\n",
        "    \"\"\"\n",
        "    if split_ratios is None:\n",
        "        split_ratios = {'train': 0.8, 'test': 0.1, 'eval': 0.1}\n",
        "\n",
        "    try:\n",
        "        # Load the dataset\n",
        "        if isinstance(input, dict) and format in ['csv', 'json']:\n",
        "            dataset = load_dataset(format, data_files=input)\n",
        "        elif isinstance(input, str) and format == 'text':\n",
        "            dataset = load_dataset(format, data_dir=input)\n",
        "        elif isinstance(input, str) and format is None:\n",
        "            dataset = load_dataset(input)\n",
        "        else:\n",
        "            warnings.warn(\"Invalid input or format. Please provide a valid dataset name, directory, or file paths.\")\n",
        "            return None\n",
        "    except FileNotFoundError as e:\n",
        "        warnings.warn(str(e))\n",
        "        return None\n",
        "\n",
        "    # Split the dataset\n",
        "    if dataset:\n",
        "        split_dataset = dataset['train'].train_test_split(test_size=split_ratios['test'] + split_ratios['eval'])\n",
        "        test_eval_dataset = split_dataset['test'].train_test_split(test_size=split_ratios['eval'] / (split_ratios['test'] + split_ratios['eval']))\n",
        "        dataset = DatasetDict({\n",
        "            'train': split_dataset['train'],\n",
        "            'test': test_eval_dataset['train'],\n",
        "            'eval': test_eval_dataset['test']\n",
        "        })\n",
        "\n",
        "    print(\"Splits: \", dataset.keys())\n",
        "    print(\"Columns: \", {split: dataset[split].column_names for split in dataset.keys()})\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def split_text_into_chunks(raw_knowledge_base: List[str],chunk_size:int=1000,chunk_overlap:int=100) -> List[str]:\n",
        "    \"\"\"\n",
        "    This function splits the text documents into chunks using the RecursiveCharacterTextSplitter.\n",
        "\n",
        "    Parameters:\n",
        "    raw_knowledge_base (List[str]): The list of documents to be split.\n",
        "\n",
        "    Returns:\n",
        "    docs_processed (List[str]): The list of processed documents.\n",
        "    \"\"\"\n",
        "    # Define the markdown separators\n",
        "    MARKDOWN_SEPARATORS = [\n",
        "        \"\\n#{1,6} \", \"```\\n\", \"\\n\\\\*\\\\*\\\\*+\\n\", \"\\n---+\\n\", \"\\n___+\\n\",\n",
        "        \"\\n\\n\", \"\\n\", \" \", \"\", \"\\n### \", \"\\n***\\n\", \"\\n---\\n\", \"\\n___\\n\", \"\\n\\n\\n\"\n",
        "    ]\n",
        "\n",
        "    # Initialize the text splitter\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=1000,  # Maximum number of characters in a chunk\n",
        "        chunk_overlap=100,  # Number of characters to overlap between chunks\n",
        "        add_start_index=True,  # If `True`, includes chunk's start index in metadata\n",
        "        strip_whitespace=True,  # If `True`, strips whitespace from the start and end of every document\n",
        "        separators=MARKDOWN_SEPARATORS,\n",
        "    )\n",
        "\n",
        "    # Process the documents\n",
        "    docs_processed = []\n",
        "    for doc in raw_knowledge_base:\n",
        "        docs_processed += text_splitter.split_documents([doc])\n",
        "\n",
        "    return docs_processed\n",
        "def save_to_csv(file_path: str, data: List[Dict[str, str]], mode: str = 'a') -> None:\n",
        "    \"\"\"\n",
        "    Save or append data to a CSV file.\n",
        "\n",
        "    :param file_path: Path to the CSV file to save or append data.\n",
        "    :param data: List of dictionaries containing the data to be saved.\n",
        "    :param mode: File opening mode ('a' for append, 'w' for write).\n",
        "    \"\"\"\n",
        "    with open(file_path, mode, newline='', encoding='utf-8') as csvfile:\n",
        "        fieldnames = data[0].keys() if data else []\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "\n",
        "        if mode == 'w':\n",
        "            writer.writeheader()\n",
        "\n",
        "        for row in data:\n",
        "            writer.writerow(row)\n",
        "\n",
        "def rename_columns(csv_file: str, new_columns: List[str]) -> None:\n",
        "    \"\"\"\n",
        "    Rename the columns of a CSV file.\n",
        "\n",
        "    :param csv_file: The path to the CSV file.\n",
        "    :param new_columns: The new column names.\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(csv_file)\n",
        "\n",
        "    if len(df.columns) != len(new_columns):\n",
        "        raise ValueError(\"The number of new column names must match the number of columns in the CSV file.\")\n",
        "\n",
        "    df.columns = new_columns\n",
        "    df.to_csv(csv_file, index=False)\n",
        "\n",
        "def load_docs_from_folder(folder_path: str, file_glob: str) -> List[Dict[str, str]]:\n",
        "    \"\"\"\n",
        "    Load documents from a folder with a specific file extension and return their content and metadata.\n",
        "\n",
        "    :param folder_path: The path to the folder containing the files.\n",
        "    :param file_glob: The file extension or pattern to filter files.\n",
        "    :return: A list of dictionaries with file content and metadata.\n",
        "    \"\"\"\n",
        "    directory_loader = DirectoryLoader(folder_path, glob=file_glob, show_progress=True,\n",
        "                                       use_multithreading=True, silent_errors=True)\n",
        "    return directory_loader.load()\n",
        "\n",
        "def Folder_csv_writer(folder_path: str, csv_output_path: str, file_extension: str = None, new_column_names: List[str] = None) -> None:\n",
        "    \"\"\"\n",
        "    Main function to load documents from a directory and save them into a CSV file.\n",
        "\n",
        "    :param folder_path: The path to the folder containing the files.\n",
        "    :param csv_output_path: The path to the output CSV file.\n",
        "    :param file_extension: The file extension to filter files. If None, use a pattern to match all files.\n",
        "    :param new_column_names: A list of new column names for the CSV file.\n",
        "    \"\"\"\n",
        "    file_glob = f\"**/*{file_extension}\" if file_extension else \"**/[!.]*\"\n",
        "    docs = load_docs_from_folder(folder_path, file_glob)\n",
        "\n",
        "\n",
        "    if not docs:\n",
        "        print(f\"No files found with extension {file_extension}.\")\n",
        "        return\n",
        "\n",
        "    data_to_save = [{'id': str(i),\n",
        "                     'content': doc.page_content,\n",
        "                     'source': doc.metadata['source']} for i, doc in enumerate(docs) if hasattr(doc, 'metadata')]\n",
        "\n",
        "    save_to_csv(csv_output_path, data_to_save, 'w')\n",
        "\n",
        "    if new_column_names is not None:\n",
        "        rename_columns(csv_output_path, new_column_names)\n",
        "def split_documents(\n",
        "    chunk_size: int,\n",
        "    knowledge_base: List[LangchainDocument],\n",
        "    tokenizer_name: Optional[str] ,\n",
        ") -> List[LangchainDocument]:\n",
        "    \"\"\"\n",
        "    Split documents into chunks of maximum size `chunk_size` tokens and return a list of documents.\n",
        "    \"\"\"\n",
        "   # Existing separators\n",
        "    MARKDOWN_SEPARATORS = [\n",
        "    \"\\n#{1,6} \", \"```\\n\", \"\\n\\\\*\\\\*\\\\*+\\n\", \"\\n---+\\n\", \"\\n___+\\n\",\n",
        "    \"\\n\\n\", \"\\n\", \" \", \"\", \"\\n### \", \"\\n***\\n\", \"\\n---\\n\", \"\\n___\\n\", \"\\n\\n\\n\"\n",
        "    ]\n",
        "\n",
        "    # Additional separators\n",
        "    additional_separators = [\"\\n====\\n\", \"\\n****\\n\", \"\\n----\\n\"]\n",
        "\n",
        "    # Append additional separators to the list\n",
        "    MARKDOWN_SEPARATORS.extend(additional_separators)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
        "    text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
        "        tokenizer,\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=int(chunk_size / 10),\n",
        "        add_start_index=True,\n",
        "        strip_whitespace=True,\n",
        "        separators=MARKDOWN_SEPARATORS,\n",
        "    )\n",
        "\n",
        "    docs_processed = []\n",
        "    for doc in knowledge_base:\n",
        "        docs_processed += text_splitter.split_documents([doc])\n",
        "\n",
        "    # Remove duplicates\n",
        "    unique_texts = {}\n",
        "    docs_processed_unique = []\n",
        "    for doc in docs_processed:\n",
        "        if doc.page_content not in unique_texts:\n",
        "            unique_texts[doc.page_content] = True\n",
        "            docs_processed_unique.append(doc)\n",
        "\n",
        "    return docs_processed_unique\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dnigIOOWDoqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Define the directory where the papers will be saved\n",
        "FOLDER_PATH = \"/content/sample_data/Hemanth_papers1\"\n",
        "query=\"LLMs large language models\"\n",
        "No_of_papers=100\n",
        "OUT_PUT_FILE='output3.csv'\n",
        "TEXT_CONTENT='content'\n",
        "LABEL_CONTENT='documents'\n",
        "NEW_COLUMN_NAMES=['ID',TEXT_CONTENT,LABEL_CONTENT]\n",
        "input1={'train':OUT_PUT_FILE, 'test':OUT_PUT_FILE}\n",
        "download_papers(query=query, max_results=No_of_papers, save_dir=FOLDER_PATH)\n",
        "Folder_csv_writer(folder_path=FOLDER_PATH, csv_output_path=OUT_PUT_FILE,file_extension=['.md','.pdf','.csv'], new_column_names=NEW_COLUMN_NAMES)\n",
        "dataset=advanced_data_loader(input=input1,format='csv')\n",
        "ds=dataset['train']\n",
        "RAW_KNOWLEDGE_BASE = [\n",
        "    LangchainDocument(page_content=doc[TEXT_CONTENT], metadata={\"source\": doc[LABEL_CONTENT]})\n",
        "    for doc in tqdm(ds)\n",
        "]\n",
        "# docs_processed = split_text_into_chunks(RAW_KNOWLEDGE_BASE)\n",
        "EMBEDDING_MODEL_NAME = \"thenlper/gte-small\"\n",
        "READER_MODEL_NAME = \"HuggingFaceH4/zephyr-7b-beta\"\n",
        "docs_processed = split_documents(\n",
        "    chunk_size=512,  # We choose a chunk size adapted to our model\n",
        "    knowledge_base=RAW_KNOWLEDGE_BASE,\n",
        "    tokenizer_name=EMBEDDING_MODEL_NAME,\n",
        ")\n",
        "embedding_model = HuggingFaceEmbeddings(\n",
        "    model_name=EMBEDDING_MODEL_NAME,\n",
        "    multi_process=True,\n",
        "    model_kwargs={\"device\": \"cpu\"},\n",
        "    encode_kwargs={\"normalize_embeddings\": True},  # set True for cosine similarity\n",
        ")\n",
        "KNOWLEDGE_VECTOR_DATABASE = FAISS.from_documents(\n",
        "    docs_processed, embedding_model, distance_strategy=DistanceStrategy.COSINE\n",
        ")\n",
        "USER_QUERY = \"what is recent advancement on llms\"\n",
        "query_vector = embedding_model.embed_query(USER_QUERY)\n",
        "retrieved_docs = KNOWLEDGE_VECTOR_DATABASE.similarity_search(query=USER_QUERY, k=5)\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        ")\n",
        "model = AutoModelForCausalLM.from_pretrained(READER_MODEL_NAME, quantization_config=bnb_config)\n",
        "tokenizer = AutoTokenizer.from_pretrained(READER_MODEL_NAME)\n",
        "\n",
        "READER_LLM = pipeline(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    task=\"text-generation\",\n",
        "    do_sample=True,\n",
        "    temperature=0.2,\n",
        "    repetition_penalty=1.1,\n",
        "    return_full_text=False,\n",
        "    max_new_tokens=500,\n",
        ")\n",
        "prompt_in_chat_format = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"\"\"Using the information contained in the context,\n",
        "give a comprehensive answer to the question.\n",
        "Respond only to the question asked, response should be concise and relevant to the question.\n",
        "Provide the number of the source document when relevant.\n",
        "If the answer cannot be deduced from the context, do not give an answer.\"\"\",\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"\"\"Context:\n",
        "{context}\n",
        "---\n",
        "Now here is the question you need to answer.\n",
        "\n",
        "Question: {question}\"\"\",\n",
        "    },\n",
        "]\n",
        "RAG_PROMPT_TEMPLATE = tokenizer.apply_chat_template(\n",
        "    prompt_in_chat_format, tokenize=False, add_generation_prompt=True\n",
        ")\n",
        "retrieved_docs_text = [\n",
        "    doc.page_content for doc in retrieved_docs\n",
        "]  # we only need the text of the documents\n",
        "context = \"\\nExtracted documents:\\n\"\n",
        "context += \"\".join([f\"Document {str(i)}:::\\n\" + doc for i, doc in enumerate(retrieved_docs_text)])\n",
        "\n",
        "final_prompt = RAG_PROMPT_TEMPLATE.format(\n",
        "    question=\"How to create a pipeline object?\", context=context\n",
        ")\n",
        "\n",
        "# Redact an answer\n",
        "answer = READER_LLM(final_prompt)[0][\"generated_text\"]\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xzYvHtFk4jRc",
        "outputId": "f71d3d0d-ec65-462c-aabc-0eb92410f64a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IM-3D: Iterative Multiview Diffusion and Reconstruction for High-Quality 3D Generation\n",
            "Chain Reaction of Ideas: Can Radioactive Decay Predict Technological Innovation?\n",
            "Mitigating Object Hallucination in Large Vision-Language Models via Classifier-Free Guidance\n",
            "COLD-Attack: Jailbreaking LLMs with Stealthiness and Controllability\n",
            "Graph Mamba: Towards Learning on Graphs with State Space Models\n",
            "Human Curriculum Effects Emerge with In-Context Learning in Neural Networks\n",
            "Model Assessment and Selection under Temporal Distribution Shift\n",
            "Rec-GPT4V: Multimodal Recommendation with Large Vision-Language Models\n",
            "Soliton gas of the integrable Boussinesq equation and its generalised hydrodynamics\n",
            "Target Score Matching\n",
            "Improving Generalization in Semantic Parsing by Increasing Natural Language Variation\n",
            "Crystallization of C*-algebras\n",
            "Complete Asymptotic Expansions for the Normalizing Constants of High-Dimensional Matrix Bingham and Matrix Langevin Distributions\n",
            "Learning Emergent Gaits with Decentralized Phase Oscillators: on the role of Observations, Rewards, and Feedback\n",
            "The Last JITAI? The Unreasonable Effectiveness of Large Language Models in Issuing Just-in-Time Adaptive Interventions: Fostering Physical Activity in a Prospective Cardiac Rehabilitation Setting\n",
            "PIN: Positional Insert Unlocks Object Localisation Abilities in VLMs\n",
            "NeuroBench: An Open-Source Benchmark Framework for the Standardization of Methodology in Brainwave-based Authentication Research\n",
            "Assessing the Privacy Risk of Cross-Platform Identity Linkage using Eye Movement Biometrics\n",
            "Learning Continuous 3D Words for Text-to-Image Generation\n",
            "SAGMAN: Stability Analysis of Graph Neural Networks on the Manifolds\n",
            "Dark matter as the trigger of flavor changing neutral current decays of the top quark\n",
            "Induced Saturation for Complete Bipartite Posets\n",
            "Sharing Spectrum and Services in the 7-24 GHz Upper Midband\n",
            "Generating Universal Adversarial Perturbations for Quantum Classifiers\n",
            "Tandem Transformers for Inference Efficient LLMs\n",
            "Clustering of primordial black holes from quantum diffusion during inflation\n",
            "Forecasting high-impact research topics via machine learning on evolving knowledge graphs\n",
            "SemRel2024: A Collection of Semantic Textual Relatedness Datasets for 14 Languages\n",
            "Finite density QCD equation of state: critical point and lattice-based $T'$-expansion\n",
            "BdSLW60: A Word-Level Bangla Sign Language Dataset\n",
            "Maxwell construction for a nonreciprocal Cahn-Hilliard model\n",
            "A local variational principle for fracture\n",
            "Knowledge Editing on Black-box Large Language Models\n",
            "Efficient arc-flow formulations for makespan minimisation on parallel machines with a common server\n",
            "Nonlinear Graphon mean-field systems\n",
            "Constraints on Variation of the Weak Scale from Big Bang Nucleosynthesis\n",
            "NeRF Analogies: Example-Based Visual Attribute Transfer for NeRFs\n",
            "Quasineutral multistability in an epidemiological-like model for defective-helper betacoronavirus infection in cell cultures\n",
            "An integral renewal equation approach to behavioural epidemic models with information index\n",
            "CaPS: Collaborative and Private Synthetic Data Generation from Distributed Sources\n",
            "Anomalous Casimir effect in an expanding ring\n",
            "Mixtures of Experts Unlock Parameter Scaling for Deep RL\n",
            "A robust second-order low-rank BUG integrator based on the midpoint rule\n",
            "Arbitrary Polynomial Separations in Trainable Quantum Machine Learning\n",
            "Measurement induced phase transitions in quantum raise and peel models\n",
            "Sampling Space-Saving Set Sketches\n",
            "Electron cooling in graphene thermal transistors\n",
            "Globally-Optimal Greedy Experiment Selection for Active Sequential Estimation\n",
            "Latent Inversion with Timestep-aware Sampling for Training-free Non-rigid Editing\n",
            "An X-ray and radio view of the 2022 reactivation of the magnetar SGRJ1935+2154\n",
            "Homomorphism Counts for Graph Neural Networks: All About That Basis\n",
            "Bayesian Multi-Task Transfer Learning for Soft Prompt Tuning\n",
            "Graph Feature Preprocessor: Real-time Extraction of Subgraph-based Features from Transaction Graphs\n",
            "Convolutional Neural Networks Towards Facial Skin Lesions Detection\n",
            "Tracking solar radio bursts using Bayesian multilateration\n",
            "Machine Learning based Pointing Models for Radio/Sub-millimeter Telescopes\n",
            "Couplings and Poisson approximation for stabilizing functionals of determinantal point processes\n",
            "Faster Repeated Evasion Attacks in Tree Ensembles\n",
            "Tail behavior and sample path properties of positive supOU processes\n",
            "Mixture of Link Predictors\n",
            "Improving Factual Error Correction for Abstractive Summarization via Data Distillation and Conditional-generation Cloze\n",
            "Tracking topological defect motion and incommensurate charge order melting in a perovskite manganite\n",
            "Training Coupled Phase Oscillators as a Neuromorphic Platform using Equilibrium Propagation\n",
            "FedLPS: Heterogeneous Federated Learning for Multiple Tasks with Local Parameter Sharing\n",
            "Test-Time Backdoor Attacks on Multimodal Large Language Models\n",
            "Heterogeneity, Uncertainty and Learning: Semiparametric Identification and Estimation\n",
            "Two Tales of Single-Phase Contrastive Hebbian Learning\n",
            "Online Foundation Model Selection in Robotics\n",
            "Glass Segmentation with Multi Scales and Primary Prediction Guiding\n",
            "Manifold functional multiple regression model with LRD error term\n",
            "Convergence Analysis of a Variable Projection Method for Regularized Separable Nonlinear Inverse Problems\n",
            "Agent Smith: A Single Image Can Jailbreak One Million Multimodal LLM Agents Exponentially Fast\n",
            "Gaussian-Sum Filter for Range-based 3D Relative Pose Estimation in the Presence of Ambiguities\n",
            "Artificial Intelligence for Literature Reviews: Opportunities and Challenges\n",
            "Denoising Diffusion Restoration Tackles Forward and Inverse Problems for the Laplace Operator\n",
            "Higher Layers Need More LoRA Experts\n",
            "Data efficiency and long term prediction capabilities for neural operator surrogate models of core and edge plasma codes\n",
            "Real-space analysis of Hatsugai-Kohmoto interaction\n",
            "Tensor network noise characterization for near-term quantum computers\n",
            "In-in correlators and scattering amplitudes on a causal set\n",
            "Incidence of the Brownian relaxation process on the magnetic properties of ferrofluids\n",
            "Confronting Reward Overoptimization for Diffusion Models: A Perspective of Inductive and Primacy Biases\n",
            "Competitive Revenue Extraction from Time-Discounted Transactions in the Semi-Myopic Regime\n",
            "Motion-Adaptive Inference for Flexible Learned B-Frame Compression\n",
            "Grounding LLMs For Robot Task Planning Using Closed-loop State Feedback\n",
            "Theoretical Analysis of Leave-one-out Cross Validation for Non-differentiable Penalties under High-dimensional Settings\n",
            "Continuous-Time Best-Response and Related Dynamics in Tullock Contests with Convex Costs\n",
            "Generative VS non-Generative Models in Engineering Shape Optimization\n",
            "Intelligent Diagnosis of Alzheimer's Disease Based on Machine Learning\n",
            "Non-double covered cubic graphs\n",
            "Self-Induced Superradiant Masing\n",
            "Multiplicity dependence of the freezeout parameters in high energy hadron-hadron collisions\n",
            "Toward Mass-Production of Transition Metal Dichalcogenide Solar Cells: Scalable Growth of Photovoltaic-Grade Multilayer WSe2 by Tungsten Selenization\n",
            "Grace Period is All You Need: Individual Fairness without Revenue Loss in Revenue Management\n",
            "Captions Are Worth a Thousand Words: Enhancing Product Retrieval with Pretrained Image-to-Text Models\n",
            "Galaxies decomposition with spiral arms -- II: A multiwavelength case study of M 51\n",
            "A Distributional Analogue to the Successor Representation\n",
            "Concept-1K: A Novel Benchmark for Instance Incremental Learning\n",
            "A new framework for calibrating COVID-19 SEIR models with spatial-/time-varying coefficients using genetic and sliding window algorithms\n",
            "Benchmarking multi-component signal processing methods in the time-frequency plane\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [15:25<00:00,  9.25s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "Error",
          "evalue": "need to escape, but no escapechar set",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-ad83d6291f7a>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0minput1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mOUT_PUT_FILE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mOUT_PUT_FILE\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdownload_papers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNo_of_papers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFOLDER_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mFolder_csv_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFOLDER_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsv_output_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOUT_PUT_FILE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile_extension\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'.md'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'.pdf'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_column_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNEW_COLUMN_NAMES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madvanced_data_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-51500a56987b>\u001b[0m in \u001b[0;36mFolder_csv_writer\u001b[0;34m(folder_path, csv_output_path, file_extension, new_column_names)\u001b[0m\n\u001b[1;32m    260\u001b[0m                      'source': doc.metadata['source']} for i, doc in enumerate(docs) if hasattr(doc, 'metadata')]\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m     \u001b[0msave_to_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_output_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_to_save\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnew_column_names\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-51500a56987b>\u001b[0m in \u001b[0;36msave_to_csv\u001b[0;34m(file_path, data, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrename_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_columns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/csv.py\u001b[0m in \u001b[0;36mwriterow\u001b[0;34m(self, rowdict)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrowdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dict_to_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrowdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwriterows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrowdicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mError\u001b[0m: need to escape, but no escapechar set"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sentence-transformers"
      ],
      "metadata": {
        "id": "7VRNWRk6BQjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUt_r-LSDJuO",
        "outputId": "96508a50-3474-455d-d88e-8095e3541f52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.27.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.0)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.3.101)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owyZoQCYEpWC",
        "outputId": "d0cdf862-a572-4f65-9b49-b32cef69c507"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.42.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->bitsandbytes) (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input1={'train':'/content/drive/MyDrive/Adversarial_chatbot_dataset _test.csv', 'test':'/content/drive/MyDrive/Adversarial_chatbot_dataset _test.csv', 'eval':'/content/drive/MyDrive/Adversarial_chatbot_dataset _test.csv'}\n",
        "dataset=advanced_data_loader(input=input1,format='csv')\n",
        "ds=dataset['train']\n",
        "RAW_KNOWLEDGE_BASE = [\n",
        "    LangchainDocument(page_content=doc['input'], metadata={\"source\": doc['output']})\n",
        "    for doc in tqdm(ds)\n",
        "]\n",
        "# docs_processed = split_text_into_chunks(RAW_KNOWLEDGE_BASE)\n",
        "EMBEDDING_MODEL_NAME = \"thenlper/gte-small\"\n",
        "READER_MODEL_NAME = \"HuggingFaceH4/zephyr-7b-beta\"\n",
        "docs_processed = split_documents(\n",
        "    chunk_size=512,  # We choose a chunk size adapted to our model\n",
        "    knowledge_base=RAW_KNOWLEDGE_BASE,\n",
        "    tokenizer_name=EMBEDDING_MODEL_NAME,\n",
        ")\n",
        "embedding_model = HuggingFaceEmbeddings(\n",
        "    model_name=EMBEDDING_MODEL_NAME,\n",
        "    multi_process=True,\n",
        "    model_kwargs={\"device\": \"cuda\"},\n",
        "    encode_kwargs={\"normalize_embeddings\": True},  # set True for cosine similarity\n",
        ")\n",
        "KNOWLEDGE_VECTOR_DATABASE = FAISS.from_documents(\n",
        "    docs_processed, embedding_model, distance_strategy=DistanceStrategy.COSINE\n",
        ")\n",
        "USER_QUERY = \"what is recent advancement on llms\"\n",
        "query_vector = embedding_model.embed_query(USER_QUERY)\n",
        "retrieved_docs = KNOWLEDGE_VECTOR_DATABASE.similarity_search(query=USER_QUERY, k=5)\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        ")\n",
        "model = AutoModelForCausalLM.from_pretrained(READER_MODEL_NAME)\n",
        "tokenizer = AutoTokenizer.from_pretrained(READER_MODEL_NAME)\n",
        "\n",
        "READER_LLM = pipeline(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    task=\"text-generation\",\n",
        "    do_sample=True,\n",
        "    temperature=0.2,\n",
        "    repetition_penalty=1.1,\n",
        "    return_full_text=False,\n",
        "    max_new_tokens=500,\n",
        ")\n",
        "prompt_in_chat_format = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"\"\"Using the information contained in the context,\n",
        "give a comprehensive answer to the question.\n",
        "Respond only to the question asked, response should be concise and relevant to the question.\n",
        "Provide the number of the source document when relevant.\n",
        "If the answer cannot be deduced from the context, do not give an answer.\"\"\",\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"\"\"Context:\n",
        "{context}\n",
        "---\n",
        "Now here is the question you need to answer.\n",
        "\n",
        "Question: {question}\"\"\",\n",
        "    },\n",
        "]\n",
        "RAG_PROMPT_TEMPLATE = tokenizer.apply_chat_template(\n",
        "    prompt_in_chat_format, tokenize=False, add_generation_prompt=True\n",
        ")\n",
        "retrieved_docs_text = [\n",
        "    doc.page_content for doc in retrieved_docs\n",
        "]  # we only need the text of the documents\n",
        "context = \"\\nExtracted documents:\\n\"\n",
        "context += \"\".join([f\"Document {str(i)}:::\\n\" + doc for i, doc in enumerate(retrieved_docs_text)])\n",
        "\n",
        "final_prompt = RAG_PROMPT_TEMPLATE.format(\n",
        "    question=\"How to create a pipeline object?\", context=context\n",
        ")\n",
        "\n",
        "# Redact an answer\n",
        "answer = READER_LLM(final_prompt)[0][\"generated_text\"]\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240,
          "referenced_widgets": [
            "aa9103a6e74d47f2a5aea251fcbe37ce",
            "68471ac2631842c096a78a3c16abfa3d",
            "f8465bac73964b03a15d0e779d544c3a",
            "2f66df262dca49b4b7a36ef10a91deae",
            "64e232acc1104a91b2927b694c3a6f69",
            "e3f98977605b47c38c1f31da3f34e08d",
            "7dc40787b9c346f6849cf926e187b5d1",
            "ac10bfd3e6424c2fb91907f979b5fd28",
            "89e2ec1573e4436e93d8beb8a948a313",
            "a1d98d6ae9d743649f089fb34b42a068",
            "14e4098f745741ac8d84a9caa45e4dbd",
            "b8d4c4bb3dcc4f91b71b50f033c99a8d",
            "d0a6ecc844fd4925a7a4faf9d49119e7",
            "a5a9b1741029465dbd2a6306de207914",
            "93d7850edce441e08462339178cc0510",
            "11833ec18d594b7592cdea30c0bfdb34",
            "5a72627711a84dc5933c1f436c361ae8",
            "5d777860d8b049b9a50e0741b75513e9",
            "a5d3e70bb86748b79733031bc3886a3f",
            "61f26bf686c5423c9d6fc8a46422d6f8",
            "6ef7732b5148471791618f3b94ba778b",
            "6a7d3e02c6bb4aaab829ccab46a9552c"
          ]
        },
        "id": "FNJJNm3b-Teb",
        "outputId": "c35f581a-9704-41c3-a0f0-8f05f47c5fd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Splits:  dict_keys(['train', 'test', 'eval'])\n",
            "Columns:  {'train': ['id', 'input', 'output'], 'test': ['id', 'input', 'output'], 'eval': ['id', 'input', 'output']}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/528 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa9103a6e74d47f2a5aea251fcbe37ce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8d4c4bb3dcc4f91b71b50f033c99a8d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.make_archive('/content/sample_data/Hemanth_papers1', 'zip', '/content/sample_data/Hemanth_papers1')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3ObatDiG9RKW",
        "outputId": "e5a9e798-647b-4cf1-e014-bcb903ee1162"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/sample_data/Hemanth_papers1.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/sample_data/Hemanth_papers1.zip')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "3mT5nrVc9I6L",
        "outputId": "608574c7-f95f-44bf-da2f-d5432aa98407"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_fa594a25-3aef-47b0-a175-63dab36b4db0\", \"Hemanth_papers1.zip\", 303134153)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_in_chat_format = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"\"\"Using the information contained in the context,\n",
        "give a comprehensive answer to the question.\n",
        "Respond only to the question asked, response should be concise and relevant to the question.\n",
        "Provide the number of the source document when relevant.\n",
        "If the answer cannot be deduced from the context, do not give an answer.\"\"\",\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"\"\"Context:\n",
        "{context}\n",
        "---\n",
        "Now here is the question you need to answer.\n",
        "\n",
        "Question: {question}\"\"\",\n",
        "    },\n",
        "]\n",
        "RAG_PROMPT_TEMPLATE = tokenizer.apply_chat_template(\n",
        "    prompt_in_chat_format, tokenize=False, add_generation_prompt=True\n",
        ")\n",
        "retrieved_docs_text = [\n",
        "    doc.page_content for doc in retrieved_docs\n",
        "]  # we only need the text of the documents\n",
        "context = \"\\nExtracted documents:\\n\"\n",
        "context += \"\".join([f\"Document {str(i)}:::\\n\" + doc for i, doc in enumerate(retrieved_docs_text)])\n",
        "\n",
        "final_prompt = RAG_PROMPT_TEMPLATE.format(\n",
        "    question=\"How to create a pipeline object?\", context=context\n",
        ")\n",
        "\n",
        "# Redact an answer\n",
        "answer = READER_LLM(final_prompt)[0][\"generated_text\"]\n",
        "print(answer)"
      ],
      "metadata": {
        "id": "aSgUdwHr5O4N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "85a36b09-a206-4760-ccac-cb0947867f37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tokenizer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-959a30c10514>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     },\n\u001b[1;32m     19\u001b[0m ]\n\u001b[0;32m---> 20\u001b[0;31m RAG_PROMPT_TEMPLATE = tokenizer.apply_chat_template(\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mprompt_in_chat_format\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_generation_prompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
          ]
        }
      ]
    }
  ]
}