{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CE-IDrMCD2bj"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "from datasets import load_dataset\n",
        "\n",
        "\n",
        "MODEL_NAME_OR_PATH=''\n",
        "USE_AUTH_TOKEN=True\n",
        "DATASET_NAME=''\n",
        "SYSTEM_PROMPT = \"\"\"  \"\"\"\n",
        "CONTENT_COLUMN=''\n",
        "DESCRIPTION_COLUMN=''\n",
        "ADD_COLUMN=''\n",
        "\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME_OR_PATH, use_auth_token=USE_AUTH_TOKEN)\n",
        "\n",
        "def preprocess(samples):\n",
        "    batch = []\n",
        "    for product, desc, ad_copy in zip(samples[CONTENT_COLUMN],samples[DESCRIPTION_COLUMN],samples[ADD_COLUMN]):\n",
        "        conversation = [\n",
        "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "            {\"role\": \"user\", \"content\": f\"\"\"Product: {product}\\nDescription: {desc}\\n\"\"\"},\n",
        "            {\"role\": \"assistant\", \"content\": f\"\"\"Ad: {ad_copy}\\n\"\"\"},\n",
        "        ]\n",
        "        batch.append(tokenizer.apply_chat_template(conversation, tokenize=False))\n",
        "    return {\"content\": batch}\n",
        "\n",
        "dataset = load_dataset(DATASET_NAME)\n",
        "\n",
        "dataset = dataset.map(\n",
        "    preprocess,\n",
        "    batched=True,\n",
        "    remove_columns=dataset[\"train\"].column_names\n",
        ")"
      ]
    }
  ]
}