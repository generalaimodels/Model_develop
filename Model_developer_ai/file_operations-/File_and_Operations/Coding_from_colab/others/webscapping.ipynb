{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from typing import List\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "def perform_search(query: str, num_results: int = 10, user_profile: str = \"\") -> List[str]:\n",
    "    \"\"\"\n",
    "    Performs a search using the given query and returns a list of URLs.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search query.\n",
    "        num_results (int, optional): The number of search results to return. Defaults to 10.\n",
    "        user_profile (str, optional): The user profile for personalized results. Defaults to \"\".\n",
    "\n",
    "    Returns:\n",
    "        List[str]: A list of URLs matching the search query.\n",
    "    \"\"\"\n",
    "    # Set up Firefox options\n",
    "    firefox_options = Options()\n",
    "    firefox_options.headless = True  # Run Firefox in headless mode\n",
    "\n",
    "    # Create a new instance of the Firefox driver\n",
    "    driver = webdriver.Firefox(options=firefox_options)\n",
    "\n",
    "    try:\n",
    "        # Construct the search URL with personalized results\n",
    "        search_url = f\"https://www.google.com/search?q={query}&num={num_results}&pws=0&gl=us&hl=en\"\n",
    "        if user_profile:\n",
    "            search_url += f\"&authuser={user_profile}\"\n",
    "\n",
    "        # Navigate to the search URL\n",
    "        driver.get(search_url)\n",
    "\n",
    "        # Wait for the search results to load (up to 10 seconds)\n",
    "        try:\n",
    "            search_results = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"div.yuRUbf\"))\n",
    "            )\n",
    "        except TimeoutException:\n",
    "            print(\"Timed out waiting for search results to load.\")\n",
    "            return []\n",
    "\n",
    "        # Extract the URLs from the search results\n",
    "        urls = [result.find_element(By.CSS_SELECTOR, \"a\").get_attribute(\"href\") for result in search_results]\n",
    "\n",
    "        # Perform additional search techniques\n",
    "        related_searches = driver.find_elements(By.CSS_SELECTOR, \"div.EIaa9b\")\n",
    "        for related_search in related_searches:\n",
    "            related_query = related_search.text\n",
    "            related_urls = perform_search(related_query, num_results=5)\n",
    "            urls.extend(related_urls)\n",
    "\n",
    "        return urls\n",
    "\n",
    "    finally:\n",
    "        # Close the browser\n",
    "        driver.quit()\n",
    "\n",
    "# Example usage\n",
    "search_query = \"telugu movies\"\n",
    "num_results = 50\n",
    "user_profile = \"user1\"\n",
    "\n",
    "search_results = perform_search(search_query, num_results, user_profile)\n",
    "\n",
    "print(f\"Search Results for '{search_query}':\")\n",
    "for url in search_results:\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from typing import List\n",
    "from urllib.parse import urlparse\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def extract_url_info(urls: List[str]) -> List[dict]:\n",
    "    \"\"\"\n",
    "    Extract information from a list of URLs and return the details as a list of dictionaries.\n",
    "\n",
    "    Args:\n",
    "        urls (List[str]): A list of URLs to extract information from.\n",
    "\n",
    "    Returns:\n",
    "        List[dict]: A list of dictionaries containing the extracted information for each URL.\n",
    "    \"\"\"\n",
    "    url_info_list = []\n",
    "\n",
    "    for url in urls:\n",
    "        url_info = {\n",
    "            'url': url,\n",
    "            'content_type': '',\n",
    "            'content_length': '',\n",
    "            'scheme': '',\n",
    "            'netloc': '',\n",
    "            'path': '',\n",
    "            'query': '',\n",
    "            'fragment': '',\n",
    "            'text_content': '',\n",
    "            'error': ''\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            # Send a GET request to the URL\n",
    "            response = requests.get(url)\n",
    "\n",
    "            # Check if the request was successful\n",
    "            if response.status_code == 200:\n",
    "                # Extract information from the response\n",
    "                url_info['content_type'] = response.headers.get('Content-Type')\n",
    "                url_info['content_length'] = response.headers.get('Content-Length')\n",
    "                parsed_url = urlparse(url)\n",
    "                url_info['scheme'] = parsed_url.scheme\n",
    "                url_info['netloc'] = parsed_url.netloc\n",
    "                url_info['path'] = parsed_url.path\n",
    "                url_info['query'] = parsed_url.query\n",
    "                url_info['fragment'] = parsed_url.fragment\n",
    "\n",
    "                # Extract basic text content from the URL\n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                url_info['text_content'] = soup.get_text(strip=True)[:500] + '...'  # Limit to 100 characters\n",
    "            else:\n",
    "                url_info['error'] = f\"Failed to retrieve information for URL: {url}\"\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            url_info['error'] = f\"Error occurred while processing URL: {url}. Error message: {str(e)}\"\n",
    "\n",
    "        url_info_list.append(url_info)\n",
    "\n",
    "    return url_info_list\n",
    "\n",
    "\n",
    "# Example usage\n",
    "url_list = [\n",
    "    'https://openai.com/',\n",
    "    'https://www.youtube.com/watch?v=XGJNo8TpuVA',\n",
    "    \"https://www.towermarketing.net/blog/google-best-search-engine/#:~:text=A%20large%20result%20of%20Google's,than%20any%20other%20search%20engine.\",\n",
    "    \"https://www.towermarketing.net/blog/google-best-search-engine/#:~:text=A%20large%20result%20of%20Google's,than%20any%20other%20search%20engine.\"\n",
    "]\n",
    "\n",
    "url_details = extract_url_info(url_list)\n",
    "\n",
    "# Print the extracted information in JSON format\n",
    "print(json.dumps(url_details, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import List\n",
    "from urllib.parse import urlparse\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def extract_url_info(urls: List[str]) -> List[dict]:\n",
    "    \"\"\"\n",
    "    Extract information from a list of URLs and return the details as a list of dictionaries.\n",
    "\n",
    "    Args:\n",
    "        urls (List[str]): A list of URLs to extract information from.\n",
    "\n",
    "    Returns:\n",
    "        List[dict]: A list of dictionaries containing the extracted information for each URL.\n",
    "    \"\"\"\n",
    "    url_info_list = []\n",
    "\n",
    "    # Set up Chrome options\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")  # Run Chrome in headless mode\n",
    "\n",
    "    driver = webdriver.Firefox()\n",
    "\n",
    "\n",
    "    for url in urls:\n",
    "        url_info = {\n",
    "            'url': url,\n",
    "            'content_type': '',\n",
    "            'content_length': '',\n",
    "            'scheme': '',\n",
    "            'netloc': '',\n",
    "            'path': '',\n",
    "            'query': '',\n",
    "            'fragment': '',\n",
    "            'text_content': '',\n",
    "            'error': ''\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            # Navigate to the URL\n",
    "            driver.get(url)\n",
    "\n",
    "            # Wait for the page to load completely\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.TAG_NAME, \"body\"))\n",
    "            )\n",
    "\n",
    "            # Extract information from the page\n",
    "            url_info['content_type'] = driver.execute_script(\"return document.contentType;\")\n",
    "            url_info['content_length'] = driver.execute_script(\"return document.body.innerHTML.length;\")\n",
    "            parsed_url = urlparse(url)\n",
    "            url_info['scheme'] = parsed_url.scheme\n",
    "            url_info['netloc'] = parsed_url.netloc\n",
    "            url_info['path'] = parsed_url.path\n",
    "            url_info['query'] = parsed_url.query\n",
    "            url_info['fragment'] = parsed_url.fragment\n",
    "\n",
    "            # Extract the complete text content from the URL\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            url_info['text_content'] = soup.get_text(strip=True)\n",
    "        except Exception as e:\n",
    "            url_info['error'] = f\"Error occurred while processing URL: {url}. Error message: {str(e)}\"\n",
    "\n",
    "        url_info_list.append(url_info)\n",
    "\n",
    "    # Quit the WebDriver\n",
    "    driver.quit()\n",
    "\n",
    "    return url_info_list\n",
    "\n",
    "# Example usage\n",
    "url_list = [\n",
    "    'https://openai.com/',\n",
    "    'https://www.youtube.com/watch?v=XGJNo8TpuVA',\n",
    "    \"https://www.towermarketing.net/blog/google-best-search-engine/#:~:text=A%20large%20result%20of%20Google's,than%20any%20other%20search%20engine.\",\n",
    "    \"https://en.wikipedia.org/wiki/Kareena_Kapoor_Khan_filmography\"\n",
    "]\n",
    "\n",
    "url_details = extract_url_info(url_list)\n",
    "\n",
    "# Print the extracted information in JSON format\n",
    "print(json.dumps(url_details, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import List, Dict\n",
    "\n",
    "def find_driver_paths(search_paths: List[str], driver_names: List[str]) -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Finds the paths of browser drivers on the user's operating system.\n",
    "\n",
    "    Args:\n",
    "        search_paths: A list of directories to search for browser drivers.\n",
    "        driver_names: A list of browser driver names to search for.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary with driver names as keys and lists of driver paths as values.\n",
    "    \"\"\"\n",
    "    driver_paths = {}\n",
    "\n",
    "    for path in search_paths:\n",
    "        for root, dirs, files in os.walk(path):\n",
    "            for file in files:\n",
    "                for driver in driver_names:\n",
    "                    if driver in file.lower():\n",
    "                        driver_path = os.path.join(root, file)\n",
    "                        if driver not in driver_paths:\n",
    "                            driver_paths[driver] = []\n",
    "                        driver_paths[driver].append(driver_path)\n",
    "\n",
    "    return driver_paths\n",
    "\n",
    "def save_to_json(data: Dict[str, List[str]], file_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Saves the driver information to a JSON file.\n",
    "\n",
    "    Args:\n",
    "        data: A dictionary containing the driver information.\n",
    "        file_path: The path to the JSON file.\n",
    "    \"\"\"\n",
    "    with open(file_path, \"w\") as file:\n",
    "        json.dump(data, file, indent=2)\n",
    "\n",
    "def main() -> None:\n",
    "    \"\"\"\n",
    "    Main function that finds the browser driver paths and saves the information to a JSON file.\n",
    "    \"\"\"\n",
    "    search_paths = [\n",
    "        \"/\",  # Linux and macOS root directory\n",
    "        \"C:\\\\\",  # Windows root directory\n",
    "        # Add more search paths if needed\n",
    "    ]\n",
    "\n",
    "    driver_names = [\n",
    "        \"chromedriver\",\n",
    "        \"geckodriver\",\n",
    "        # Add more driver names if needed\n",
    "    ]\n",
    "\n",
    "    driver_paths = find_driver_paths(search_paths, driver_names)\n",
    "    output_file = \"driver_info.json\"\n",
    "    save_to_json(driver_paths, output_file)\n",
    "\n",
    "    print(f\"Driver information saved to {output_file}:\")\n",
    "    print(json.dumps(driver_paths, indent=2))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from typing import List\n",
    "from urllib.parse import urlparse\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "\n",
    "def extract_url_info(urls: List[str], proxy: str = None) -> List[dict]:\n",
    "    \"\"\"\n",
    "    Extract information from a list of URLs and return the details as a list of dictionaries.\n",
    "\n",
    "    Args:\n",
    "        urls (List[str]): A list of URLs to extract information from.\n",
    "        proxy (str): Proxy server URL to use for requests (optional).\n",
    "\n",
    "    Returns:\n",
    "        List[dict]: A list of dictionaries containing the extracted information for each URL.\n",
    "    \"\"\"\n",
    "    url_info_list = []\n",
    "\n",
    "    # Set up Chrome options\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")  # Run Chrome in headless mode\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    chrome_options.add_argument(\"--ignore-certificate-errors\")\n",
    "    chrome_options.add_argument(\"--allow-running-insecure-content\")\n",
    "    chrome_options.add_argument(\"--disable-web-security\")\n",
    "    chrome_options.add_argument(\"--disable-site-isolation-trials\")\n",
    "\n",
    "    if proxy:\n",
    "        chrome_options.add_argument(f\"--proxy-server={proxy}\")\n",
    "\n",
    "    # Set up Chrome WebDriver\n",
    "    service = Service(\"/Users/heman/.cache/selenium/firefox/win64/122.0.1/firefox.exe\")  # Replace with the path to your chromedriver executable\n",
    "    driver = webdriver.Firefox(service=service, options=chrome_options)\n",
    "\n",
    "    for url in urls:\n",
    "        url_info = {\n",
    "            'url': url,\n",
    "            'content_type': '',\n",
    "            'content_length': '',\n",
    "            'scheme': '',\n",
    "            'netloc': '',\n",
    "            'path': '',\n",
    "            'query': '',\n",
    "            'fragment': '',\n",
    "            'text_content': '',\n",
    "            'error': ''\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            # Navigate to the URL\n",
    "            driver.get(url)\n",
    "\n",
    "            # Wait for the page to load completely\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.TAG_NAME, \"body\"))\n",
    "            )\n",
    "\n",
    "            # Extract information from the page\n",
    "            url_info['content_type'] = driver.execute_script(\"return document.contentType;\")\n",
    "            url_info['content_length'] = driver.execute_script(\"return document.body.innerHTML.length;\")\n",
    "            parsed_url = urlparse(url)\n",
    "            url_info['scheme'] = parsed_url.scheme\n",
    "            url_info['netloc'] = parsed_url.netloc\n",
    "            url_info['path'] = parsed_url.path\n",
    "            url_info['query'] = parsed_url.query\n",
    "            url_info['fragment'] = parsed_url.fragment\n",
    "\n",
    "            # Extract the complete text content from the URL\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            url_info['text_content'] = soup.get_text(strip=True)\n",
    "        except Exception as e:\n",
    "            url_info['error'] = f\"Error occurred while processing URL: {url}. Error message: {str(e)}\"\n",
    "\n",
    "        url_info_list.append(url_info)\n",
    "\n",
    "    # Quit the WebDriver\n",
    "    driver.quit()\n",
    "\n",
    "    return url_info_list\n",
    "\n",
    "\n",
    "# Example usage\n",
    "url_list = [\n",
    "    'https://www.selenium.dev/',\n",
    "    'https://www.youtube.com/watch?v=XGJNo8TpuVA',\n",
    "\n",
    "]\n",
    "\n",
    "# Specify a proxy server URL if needed (replace with your own proxy)\n",
    "proxy_url = \"http://proxy.example.com:8080\"\n",
    "\n",
    "url_details = extract_url_info(url_list,proxy=False)\n",
    "\n",
    "# Print the extracted information in JSON format\n",
    "print(json.dumps(url_details, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from typing import List\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "def download_files(url_list: List[str]) -> None:\n",
    "    for url in url_list:\n",
    "        download_file(url)\n",
    "\n",
    "def download_file(url: str) -> None:\n",
    "    response = requests.get(url)\n",
    "    file_name = os.path.basename(urlparse(url).path)\n",
    "    file_extension = os.path.splitext(file_name)[1]\n",
    "\n",
    "    if file_extension in ['.jpg', '.jpeg', '.png', '.gif', '.bmp']:\n",
    "        folder = 'images'\n",
    "    elif file_extension in ['.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv', '.webm', '.m4v', '.mpeg', '.mpg', '.3gp', '.rm', '.rmvb', '.ts', '.asf', '.vob', '.ogv']:\n",
    "        folder = 'videos'\n",
    "    elif file_extension in ['.txt', '.doc', '.docx', '.rtf', '.pdf', '.html', '.htm', '.xml', '.json', '.csv', '.tsv', '.log', '.cfg', '.conf', '.ini', '.yaml', '.yml', '.md', '.markdown', '.tex']:\n",
    "        folder = 'text'\n",
    "    else:\n",
    "        print(f'Unsupported file type: {file_extension}')\n",
    "        return\n",
    "\n",
    "    subfolder = os.path.join(folder, file_extension.lstrip('.'))\n",
    "    os.makedirs(subfolder, exist_ok=True)\n",
    "    with open(os.path.join(subfolder, file_name), 'wb') as file:\n",
    "        file.write(response.content)\n",
    "\n",
    "# Example usage:\n",
    "# download_files(['http://example.com/image.jpg', 'http://example.com/video.mp4', 'http://example.com/document.pdf'])\n",
    "\n",
    "\n",
    "# Example usage\n",
    "file_urls = [\n",
    "    'https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/blob/main/01.png',\n",
    "    'https://cdn-uploads.huggingface.co/production/uploads/1670928184033-62441d1d9fdefb55a0b7d12c.gif',\n",
    "    # 'https://example.com/video1.mp4',\n",
    "    # 'https://example.com/video2.avi',\n",
    "    # 'https://example.com/otherfile.pdf'\n",
    "]\n",
    "download_files(file_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from typing import List\n",
    "\n",
    "def download_files(url_list: List[str], download_path: str) -> None:\n",
    "    file_types = {\n",
    "        'image': ['.jpg', '.jpeg', '.png', '.gif', '.bmp'],\n",
    "        'video': ['.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv', '.webm', '.m4v', '.mpeg', '.mpg', '.3gp', '.rm', '.rmvb', '.ts', '.asf', '.vob', '.ogv'],\n",
    "        'text': ['.txt', '.doc', '.docx', '.rtf', '.pdf', '.html', '.htm', '.xml', '.json', '.csv', '.tsv', '.log', '.cfg', '.conf', '.ini', '.yaml', '.yml', '.md', '.markdown', '.tex']\n",
    "    }\n",
    "\n",
    "    for url in url_list:\n",
    "        file_name = url.split('/')[-1]\n",
    "        file_extension = os.path.splitext(file_name)[-1]\n",
    "\n",
    "        for file_type, extensions in file_types.items():\n",
    "            if file_extension in extensions:\n",
    "                folder_path = os.path.join(download_path, file_type, file_extension.replace('.', ''))\n",
    "                os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "                response = requests.get(url)\n",
    "                with open(os.path.join(folder_path, file_name), 'wb') as file:\n",
    "                    file.write(response.content)\n",
    "                break\n",
    "\n",
    "\n",
    "# Example usage\n",
    "file_urls = [\n",
    "    'https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/blob/main/01.png',\n",
    "    'https://cdn-uploads.huggingface.co/production/uploads/1670928184033-62441d1d9fdefb55a0b7d12c.gif',\n",
    "    # 'https://example.com/video1.mp4',\n",
    "    # 'https://example.com/video2.avi',\n",
    "    # 'https://example.com/otherfile.pdf'\n",
    "]\n",
    "download_files(file_urls,download_path=r\"C:/Users/heman/Desktop/Deep learning/file_operations-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from typing import List\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "def download_file(url: str, folder: str) -> None:\n",
    "    \"\"\"\n",
    "    Download a file from the given URL and save it in the specified folder.\n",
    "    \n",
    "    Args:\n",
    "        url (str): The URL of the file to download.\n",
    "        folder (str): The folder to save the downloaded file.\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        file_name = os.path.basename(urlparse(url).path)\n",
    "        file_path = os.path.join(folder, file_name)\n",
    "        with open(file_path, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"Downloaded: {file_name}\")\n",
    "    else:\n",
    "        print(f\"Failed to download: {url}\")\n",
    "\n",
    "def create_folder(folder: str) -> None:\n",
    "    \"\"\"\n",
    "    Create a folder if it doesn't exist.\n",
    "    \n",
    "    Args:\n",
    "        folder (str): The folder to create.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "def download_files(urls: List[str]) -> None:\n",
    "    \"\"\"\n",
    "    Download files from the given list of URLs into corresponding folders.\n",
    "    \n",
    "    Args:\n",
    "        urls (List[str]): The list of URLs to download files from.\n",
    "    \"\"\"\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.bmp']\n",
    "    video_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv', '.webm', '.m4v', '.mpeg', '.mpg', '.3gp', '.rm', '.rmvb', '.ts', '.asf', '.vob', '.ogv']\n",
    "    text_extensions = ['.txt', '.doc', '.docx', '.rtf', '.pdf', '.html', '.htm', '.xml', '.json', '.csv', '.tsv', '.log', '.cfg', '.conf', '.ini', '.yaml', '.yml', '.md', '.markdown', '.tex']\n",
    "    \n",
    "    for url in urls:\n",
    "        file_extension = os.path.splitext(urlparse(url).path)[1].lower()\n",
    "        \n",
    "        if file_extension in image_extensions:\n",
    "            folder = os.path.join('images', file_extension[1:])\n",
    "            create_folder(folder)\n",
    "            download_file(url, folder)\n",
    "        elif file_extension in video_extensions:\n",
    "            folder = os.path.join('videos', file_extension[1:])\n",
    "            create_folder(folder)\n",
    "            download_file(url, folder)\n",
    "        elif file_extension in text_extensions:\n",
    "            folder = os.path.join('texts', file_extension[1:])\n",
    "            create_folder(folder)\n",
    "            download_file(url, folder)\n",
    "        else:\n",
    "            print(f\"Unsupported file extension: {file_extension}\")\n",
    "\n",
    "# Example usage\n",
    "urls = [\n",
    "    'https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/blob/main/01.png',\n",
    "    'https://cdn-uploads.huggingface.co/production/uploads/1670928184033-62441d1d9fdefb55a0b7d12c.gif',\n",
    "    # 'https://example.com/video1.mp4',\n",
    "    # 'https://example.com/video2.avi',\n",
    "    # 'https://example.com/otherfile.pdf'\n",
    "]\n",
    "\n",
    "download_files(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from typing import List\n",
    "from pathlib import Path\n",
    "\n",
    "def download_files(file_urls: List[str], save_dir: str = 'downloads'):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    for url in file_urls:\n",
    "        response = requests.get(url, stream=True)\n",
    "        if response.status_code == 200:\n",
    "            file_extension = Path(url).suffix.lower()\n",
    "            save_path = os.path.join(save_dir, f'file{file_extension}')\n",
    "\n",
    "            if file_extension == '.png':\n",
    "                file_folder = 'images'\n",
    "            elif file_extension in ['.mp4', '.avi', '.wmv', '.mov']:\n",
    "                file_folder = 'videos'\n",
    "            else:\n",
    "                file_folder = 'other'\n",
    "\n",
    "            save_path = os.path.join(save_dir, file_folder, save_path)\n",
    "\n",
    "            if not os.path.exists(os.path.dirname(save_path)):\n",
    "                os.makedirs(os.path.dirname(save_path))\n",
    "\n",
    "            with open(save_path, 'wb') as f:\n",
    "                for chunk in response.iter_content(1024):\n",
    "                    f.write(chunk)\n",
    "            print(f'Successfully downloaded: {url} to {save_path}')\n",
    "        else:\n",
    "            print(f'Failed to download: {url}')\n",
    "\n",
    "# Example usage\n",
    "file_urls = [\n",
    "    'https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/blob/main/01.png',\n",
    "    'https://cdn-uploads.huggingface.co/production/uploads/1670928184033-62441d1d9fdefb55a0b7d12c.gif',\n",
    "    # 'https://example.com/video1.mp4',\n",
    "    # 'https://example.com/video2.avi',\n",
    "    # 'https://example.com/otherfile.pdf'\n",
    "]\n",
    "\n",
    "download_files(file_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from typing import List\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "def download_file(url: str, folder: str) -> None:\n",
    "    \"\"\"\n",
    "    Download a file from the given URL or local path and save it in the specified folder.\n",
    "    \n",
    "    Args:\n",
    "        url (str): The URL or local path of the file to download.\n",
    "        folder (str): The folder to save the downloaded file.\n",
    "    \"\"\"\n",
    "    if url.startswith(('http://', 'https://')):\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            file_name = os.path.basename(urlparse(url).path)\n",
    "            file_path = os.path.join(folder, file_name)\n",
    "            with open(file_path, 'wb') as file:\n",
    "                file.write(response.content)\n",
    "            print(f\"Downloaded: {file_name}\")\n",
    "        else:\n",
    "            print(f\"Failed to download: {url}\")\n",
    "    else:\n",
    "        file_name = os.path.basename(url)\n",
    "        file_path = os.path.join(folder, file_name)\n",
    "        with open(url, 'rb') as src_file, open(file_path, 'wb') as dst_file:\n",
    "            dst_file.write(src_file.read())\n",
    "        print(f\"Copied: {file_name}\")\n",
    "\n",
    "def create_folder(folder: str) -> None:\n",
    "    \"\"\"\n",
    "    Create a folder if it doesn't exist.\n",
    "    \n",
    "    Args:\n",
    "        folder (str): The folder to create.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "def download_files(urls: List[str]) -> None:\n",
    "    \"\"\"\n",
    "    Download files from the given list of URLs or local paths into corresponding folders.\n",
    "    \n",
    "    Args:\n",
    "        urls (List[str]): The list of URLs or local paths to download files from.\n",
    "    \"\"\"\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.bmp']\n",
    "    video_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv', '.webm', '.m4v', '.mpeg', '.mpg', '.3gp', '.rm', '.rmvb', '.ts', '.asf', '.vob', '.ogv']\n",
    "    text_extensions = ['.txt', '.doc', '.docx', '.rtf', '.pdf', '.html', '.htm', '.xml', '.json', '.csv', '.tsv', '.log', '.cfg', '.conf', '.ini', '.yaml', '.yml', '.md', '.markdown', '.tex']\n",
    "    archive_extensions = ['.zip', '.tar', '.gz', '.bz2', '.xz', '.7z', '.rar', '.tgz', '.tbz2', '.txz', '.t7z', '.zipx', '.iso', '.z', '.arj']\n",
    "    \n",
    "    for url in urls:\n",
    "        file_extension = os.path.splitext(url)[1].lower()\n",
    "        \n",
    "        if file_extension in image_extensions:\n",
    "            folder = os.path.join('images', file_extension[1:])\n",
    "            create_folder(folder)\n",
    "            download_file(url, folder)\n",
    "        elif file_extension in video_extensions:\n",
    "            folder = os.path.join('videos', file_extension[1:])\n",
    "            create_folder(folder)\n",
    "            download_file(url, folder)\n",
    "        elif file_extension in text_extensions:\n",
    "            folder = os.path.join('texts', file_extension[1:])\n",
    "            create_folder(folder)\n",
    "            download_file(url, folder)\n",
    "        elif file_extension in archive_extensions:\n",
    "            folder = os.path.join('archives', file_extension[1:])\n",
    "            create_folder(folder)\n",
    "            download_file(url, folder)\n",
    "        else:\n",
    "            print(f\"Unsupported file extension: {file_extension}\")\n",
    "# Example usage\n",
    "file_urls = [\n",
    "    'https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/blob/main/01.png',\n",
    "    'https://cdn-uploads.huggingface.co/production/uploads/1670928184033-62441d1d9fdefb55a0b7d12c.gif',\n",
    "    'C:/Users/heman/Desktop/Deep learning/downloads/test-other.tar.gz',\n",
    "     'C:/Users/heman/Desktop/Deep learning/datasets/dvc.yaml',\n",
    "    # 'https://example.com/otherfile.pdf'\n",
    "]\n",
    "\n",
    "download_files(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import shutil\n",
    "from typing import List\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "def download_file(url: str, folder: str) -> None:\n",
    "    \"\"\"\n",
    "    Download a file from the given URL or local path and save it in the specified folder.\n",
    "    \n",
    "    Args:\n",
    "        url (str): The URL or local path of the file to download.\n",
    "        folder (str): The folder to save the downloaded file.\n",
    "    \"\"\"\n",
    "    if url.startswith(('http://', 'https://')):\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            file_name = os.path.basename(urlparse(url).path)\n",
    "            file_path = os.path.join(folder, file_name)\n",
    "            with open(file_path, 'wb') as file:\n",
    "                file.write(response.content)\n",
    "            print(f\"Downloaded: {file_name}\")\n",
    "        else:\n",
    "            print(f\"Failed to download: {url}\")\n",
    "    else:\n",
    "        file_name = os.path.basename(url)\n",
    "        file_path = os.path.join(folder, file_name)\n",
    "        with open(url, 'rb') as src_file, open(file_path, 'wb') as dst_file:\n",
    "            dst_file.write(src_file.read())\n",
    "        print(f\"Copied: {file_name}\")\n",
    "\n",
    "def create_folder(folder: str) -> None:\n",
    "    \"\"\"\n",
    "    Create a folder if it doesn't exist.\n",
    "    \n",
    "    Args:\n",
    "        folder (str): The folder to create.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "def extract_archive(file_path: str, folder: str) -> None:\n",
    "    \"\"\"\n",
    "    Extract the contents of an archive file to the specified folder.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): The path to the archive file.\n",
    "        folder (str): The folder to extract the contents to.\n",
    "    \"\"\"\n",
    "    shutil.unpack_archive(file_path, folder)\n",
    "    print(f\"Extracted: {os.path.basename(file_path)}\")\n",
    "\n",
    "def download_files(urls: List[str]) -> None:\n",
    "    \"\"\"\n",
    "    Download files from the given list of URLs or local paths into corresponding folders.\n",
    "    \n",
    "    Args:\n",
    "        urls (List[str]): The list of URLs or local paths to download files from.\n",
    "    \"\"\"\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.bmp']\n",
    "    video_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv', '.webm', '.m4v', '.mpeg', '.mpg', '.3gp', '.rm', '.rmvb', '.ts', '.asf', '.vob', '.ogv']\n",
    "    text_extensions = ['.txt', '.doc', '.docx', '.rtf', '.pdf', '.html', '.htm', '.xml', '.json', '.csv', '.tsv', '.log', '.cfg', '.conf', '.ini', '.yaml', '.yml', '.md', '.markdown', '.tex']\n",
    "    archive_extensions = ['.zip', '.tar', '.gz', '.bz2', '.xz', '.7z', '.rar', '.tgz', '.tbz2', '.txz', '.t7z', '.zipx', '.iso', '.z', '.arj']\n",
    "    \n",
    "    for url in urls:\n",
    "        file_extension = os.path.splitext(url)[1].lower()\n",
    "        \n",
    "        if file_extension in image_extensions:\n",
    "            folder = os.path.join('images', file_extension[1:])\n",
    "            create_folder(folder)\n",
    "            download_file(url, folder)\n",
    "        elif file_extension in video_extensions:\n",
    "            folder = os.path.join('videos', file_extension[1:])\n",
    "            create_folder(folder)\n",
    "            download_file(url, folder)\n",
    "        elif file_extension in text_extensions:\n",
    "            folder = os.path.join('texts', file_extension[1:])\n",
    "            create_folder(folder)\n",
    "            download_file(url, folder)\n",
    "        elif file_extension in archive_extensions:\n",
    "            folder = os.path.join('archives', file_extension[1:])\n",
    "            create_folder(folder)\n",
    "            download_file(url, folder)\n",
    "            \n",
    "            # Extract the contents of the archive file\n",
    "            file_name = os.path.basename(urlparse(url).path)\n",
    "            file_path = os.path.join(folder, file_name)\n",
    "            extract_folder = os.path.join(folder, os.path.splitext(file_name)[0])\n",
    "            create_folder(extract_folder)\n",
    "            extract_archive(file_path, extract_folder)\n",
    "        else:\n",
    "            print(f\"Unsupported file extension: {file_extension}\")\n",
    "\n",
    "# Example usage\n",
    "file_urls = [\n",
    "    'https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/blob/main/01.png',\n",
    "    'https://cdn-uploads.huggingface.co/production/uploads/1670928184033-62441d1d9fdefb55a0b7d12c.gif',\n",
    "    'C:/Users/heman/Desktop/Deep learning/downloads/test-other.tar.gz',\n",
    "    'C:/Users/heman/Desktop/Deep learning/datasets/dvc.yaml',\n",
    "    # 'https://example.com/otherfile.pdf'\n",
    "]\n",
    "\n",
    "download_files(file_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C:/Users/heman/.cache/selenium/chromedriver/win32/113.0.5672.63/chromedriver.exe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "from typing import List, Dict\n",
    "\n",
    "def find_driver_paths(search_paths: List[str], driver_names: List[str]) -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Finds the paths of browser drivers on the user's operating system.\n",
    "\n",
    "    Args:\n",
    "        search_paths: A list of directories to search for browser drivers.\n",
    "        driver_names: A list of browser driver names to search for.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary with driver names as keys and lists of driver paths as values.\n",
    "    \"\"\"\n",
    "    driver_paths = {}\n",
    "\n",
    "    for path in search_paths:\n",
    "        for root, dirs, files in os.walk(path):\n",
    "            for file in files:\n",
    "                for driver in driver_names:\n",
    "                    if driver in file.lower():\n",
    "                        driver_path = os.path.join(root, file)\n",
    "                        driver_path = os.path.normpath(driver_path)\n",
    "                        driver_path = driver_path.replace(\"\\\\\", \"/\")\n",
    "                        if driver not in driver_paths:\n",
    "                            driver_paths[driver] = []\n",
    "                        driver_paths[driver].append(driver_path)\n",
    "\n",
    "    return driver_paths\n",
    "\n",
    "def save_to_json(data: Dict[str, List[str]], file_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Saves the driver information to a JSON file.\n",
    "\n",
    "    Args:\n",
    "        data: A dictionary containing the driver information.\n",
    "        file_path: The path to the JSON file.\n",
    "    \"\"\"\n",
    "    with open(file_path, \"w\") as file:\n",
    "        json.dump(data, file, indent=2)\n",
    "\n",
    "def main() -> None:\n",
    "    \"\"\"\n",
    "    Main function that finds the browser driver paths and saves the information to a JSON file.\n",
    "    \"\"\"\n",
    "    search_paths = [\n",
    "        \"/\",  # Linux and macOS root directory\n",
    "        \"/usr/local/bin\",  # Common location for user-installed binaries on Linux and macOS\n",
    "        \"/usr/bin\",  # Common location for system-wide binaries on Linux\n",
    "        \"/bin\",  # Common location for essential binaries on Linux\n",
    "        \"/opt\",  # Common location for optional software packages on Linux\n",
    "        \"/usr/local/share\",  # Common location for shared data on Linux and macOS\n",
    "        \"/usr/share\",  # Common location for system-wide shared data on Linux\n",
    "        \"/var/lib\",  # Common location for variable data on Linux\n",
    "        \"/home\",  # Common location for user home directories on Linux\n",
    "        \"/Users\",  # Common location for user home directories on macOS\n",
    "        \"C:\\\\\",  # Windows root directory\n",
    "        \"C:\\\\Program Files\",  # Common location for installed programs on Windows\n",
    "        \"C:\\\\Program Files (x86)\",  # Common location for 32-bit programs on 64-bit Windows\n",
    "        \"C:\\\\Windows\",  # Windows system directory\n",
    "        \"C:\\\\Windows\\\\System32\",  # Common location for system binaries on Windows\n",
    "        \"C:\\\\Users\",  # Common location for user directories on Windows\n",
    "        \"C:\\\\ProgramData\",  # Common location for application data on Windows\n",
    "        \"C:\\\\AppData\",  # Common location for application data on Windows\n",
    "        \"C:\\\\Drivers\",  # Common location for driver files on Windows\n",
    "        \"C:\\\\Tools\",  # Common location for tools and utilities on Windows\n",
    "        \"C:\\\\Selenium\",  # Common location for Selenium-related files on Windows\n",
    "        \"C:\\\\WebDrivers\",  # Common location for web driver files on Windows\n",
    "    ]\n",
    "\n",
    "    driver_names = [\n",
    "        \"chromedriver\",\n",
    "        \"geckodriver\",\n",
    "        \"edgedriver\",\n",
    "        \"iedriver\",\n",
    "        \"operadriver\",\n",
    "        \"phantomjs\",\n",
    "        \"safaridriver\",\n",
    "        \"webdriver\",\n",
    "        \"selenium\",\n",
    "        \"driver\",\n",
    "        \"chrome\",\n",
    "        \"firefox\",\n",
    "        \"edge\",\n",
    "        \"ie\",\n",
    "        \"opera\",\n",
    "        \"safari\",\n",
    "        \"gecko\",\n",
    "        \"phantom\",\n",
    "    ]\n",
    "\n",
    "    driver_paths = find_driver_paths(search_paths, driver_names)\n",
    "    output_file = \"driver_info.json\"\n",
    "    save_to_json(driver_paths, output_file)\n",
    "\n",
    "    print(f\"Driver information saved to {output_file}:\")\n",
    "    print(json.dumps(driver_paths, indent=2))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import List, Dict, Optional\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.firefox.service import Service as FirefoxService\n",
    "from selenium.webdriver.edge.service import Service as EdgeService\n",
    "from selenium.webdriver.ie.service import Service as IEService\n",
    "# from selenium.webdriver.opera.webdriver import Service as OperaService\n",
    "from selenium.webdriver.safari.webdriver import Service as SafariService\n",
    "\n",
    "def find_driver_paths(search_paths: List[str], driver_names: List[str]) -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Finds the paths of browser drivers on the user's operating system.\n",
    "\n",
    "    Args:\n",
    "        search_paths: A list of directories to search for browser drivers.\n",
    "        driver_names: A list of browser driver names to search for.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary with driver names as keys and lists of driver paths as values.\n",
    "    \"\"\"\n",
    "    driver_paths: Dict[str, List[str]] = {}\n",
    "\n",
    "    for path in search_paths:\n",
    "        for root, dirs, files in os.walk(path):\n",
    "            for file in files:\n",
    "                for driver in driver_names:\n",
    "                    if driver in file.lower():\n",
    "                        driver_path = os.path.join(root, file)\n",
    "                        if driver not in driver_paths:\n",
    "                            driver_paths[driver] = []\n",
    "                        driver_paths[driver].append(driver_path)\n",
    "\n",
    "    return driver_paths\n",
    "\n",
    "def download_driver(driver_name: str, download_url: str, output_dir: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Downloads a browser driver from the specified URL.\n",
    "\n",
    "    Args:\n",
    "        driver_name: The name of the browser driver.\n",
    "        download_url: The URL to download the driver from.\n",
    "        output_dir: The directory to save the downloaded driver.\n",
    "\n",
    "    Returns:\n",
    "        The path to the downloaded driver file, or None if the download fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(download_url)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        driver_path = os.path.join(output_dir, f\"{driver_name}.zip\")\n",
    "        with open(driver_path, \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "\n",
    "        return driver_path\n",
    "    except requests.exceptions.RequestException:\n",
    "        return None\n",
    "\n",
    "def save_to_json(data: Dict[str, List[str]], file_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Saves the driver information to a JSON file.\n",
    "\n",
    "    Args:\n",
    "        data: A dictionary containing the driver information.\n",
    "        file_path: The path to the JSON file.\n",
    "    \"\"\"\n",
    "    with open(file_path, \"w\") as file:\n",
    "        json.dump(data, file, indent=2)\n",
    "\n",
    "def get_user_input(prompt: str, default: Optional[str] = None) -> str:\n",
    "    \"\"\"\n",
    "    Prompts the user for input and returns the entered value.\n",
    "\n",
    "    Args:\n",
    "        prompt: The prompt message to display to the user.\n",
    "        default: The default value to use if the user doesn't provide input.\n",
    "\n",
    "    Returns:\n",
    "        The user's input or the default value if no input is provided.\n",
    "    \"\"\"\n",
    "    user_input = input(prompt)\n",
    "    return user_input.strip() or default\n",
    "\n",
    "def perform_web_scraping(query: str, location: str, limit: int) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Performs web scraping based on the user's query.\n",
    "\n",
    "    Args:\n",
    "        query: The search query.\n",
    "        location: The search location.\n",
    "        limit: The maximum number of results to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        A list of dictionaries containing the scraped data.\n",
    "    \"\"\"\n",
    "    search_url = f\"https://www.google.com/search?q={query}&location={location}&num={limit}\"\n",
    "    response = requests.get(search_url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    search_results = []\n",
    "    for result in soup.select(\".g\"):\n",
    "        title = result.select_one(\".r a\").text\n",
    "        url = result.select_one(\".r a\")[\"href\"]\n",
    "        description = result.select_one(\".st\").text\n",
    "\n",
    "        search_results.append({\n",
    "            \"title\": title,\n",
    "            \"url\": url,\n",
    "            \"description\": description\n",
    "        })\n",
    "\n",
    "    return search_results\n",
    "\n",
    "def main() -> None:\n",
    "    \"\"\"\n",
    "    Main function that finds the browser driver paths, performs web scraping, and saves the information to a JSON file.\n",
    "    \"\"\"\n",
    "    search_paths = [\n",
    "        \"/\",  # Linux and macOS root directory\n",
    "        \"/usr/local/bin\",  # Common location for user-installed binaries on Linux and macOS\n",
    "        \"/usr/bin\",  # Common location for system-wide binaries on Linux\n",
    "        \"/bin\",  # Common location for essential binaries on Linux\n",
    "        \"/opt\",  # Common location for optional software packages on Linux\n",
    "        \"/usr/local/share\",  # Common location for shared data on Linux and macOS\n",
    "        \"/usr/share\",  # Common location for system-wide shared data on Linux\n",
    "        \"/var/lib\",  # Common location for variable data on Linux\n",
    "        \"/home\",  # Common location for user home directories on Linux\n",
    "        \"/Users\",  # Common location for user home directories on macOS\n",
    "        \"C:\\\\\",  # Windows root directory\n",
    "        \"C:\\\\Program Files\",  # Common location for installed programs on Windows\n",
    "        \"C:\\\\Program Files (x86)\",  # Common location for 32-bit programs on 64-bit Windows\n",
    "        \"C:\\\\Windows\",  # Windows system directory\n",
    "        \"C:\\\\Windows\\\\System32\",  # Common location for system binaries on Windows\n",
    "        \"C:\\\\Users\",  # Common location for user directories on Windows\n",
    "        \"C:\\\\ProgramData\",  # Common location for application data on Windows\n",
    "        \"C:\\\\AppData\",  # Common location for application data on Windows\n",
    "        \"C:\\\\Drivers\",  # Common location for driver files on Windows\n",
    "        \"C:\\\\Tools\",  # Common location for tools and utilities on Windows\n",
    "        \"C:\\\\Selenium\",  # Common location for Selenium-related files on Windows\n",
    "        \"C:\\\\WebDrivers\",  # Common location for web driver files on Windows\n",
    "    ]\n",
    "\n",
    "    driver_names = [\n",
    "        \"chromedriver\",\n",
    "        \"geckodriver\",\n",
    "        \"edgedriver\",\n",
    "        \"iedriver\",\n",
    "        \"operadriver\",\n",
    "        \"phantomjs\",\n",
    "        \"safaridriver\",\n",
    "        \"webdriver\",\n",
    "        \"selenium\",\n",
    "        \"driver\",\n",
    "        \"chrome\",\n",
    "        \"firefox\",\n",
    "        \"edge\",\n",
    "        \"ie\",\n",
    "        \"opera\",\n",
    "        \"safari\",\n",
    "        \"gecko\",\n",
    "        \"phantom\",\n",
    "    ]\n",
    "\n",
    "    driver_paths = find_driver_paths(search_paths, driver_names)\n",
    "\n",
    "    # Download missing drivers\n",
    "    for driver_name in driver_names:\n",
    "        if driver_name not in driver_paths:\n",
    "            download_url = f\"https://example.com/drivers/{driver_name}.zip\"\n",
    "            downloaded_path = download_driver(driver_name, download_url, \"drivers\")\n",
    "            if downloaded_path:\n",
    "                driver_paths[driver_name] = [downloaded_path]\n",
    "\n",
    "    # Get user input for query, location, and limit\n",
    "    query = get_user_input(\"Enter your query: \")\n",
    "    location = get_user_input(\"Enter your location: \")\n",
    "    limit = int(get_user_input(\"Enter the limit (default: 5): \", default=\"5\"))\n",
    "\n",
    "    # Perform web scraping based on the user's query\n",
    "    scraped_data = perform_web_scraping(query, location, limit)\n",
    "\n",
    "    # Filter out garbage from driver paths\n",
    "    filtered_driver_paths: Dict[str, List[str]] = {}\n",
    "    for driver, paths in driver_paths.items():\n",
    "        filtered_paths = [path for path in paths if not any(garbage in path for garbage in [\"tmp\", \"temp\", \"cache\", \"old\", \"backup\"])]\n",
    "        if filtered_paths:\n",
    "            filtered_driver_paths[driver] = filtered_paths\n",
    "\n",
    "    # Prepare the output data\n",
    "    output_data = {\n",
    "        \"query\": query,\n",
    "        \"location\": location,\n",
    "        \"limit\": limit,\n",
    "        \"driver_paths\": filtered_driver_paths,\n",
    "        \"scraped_data\": scraped_data\n",
    "    }\n",
    "\n",
    "    # Save the output data to a JSON file\n",
    "    output_file = \"search_results.json\"\n",
    "    save_to_json(output_data, output_file)\n",
    "\n",
    "    print(f\"Search results saved to {output_file}:\")\n",
    "    print(json.dumps(output_data, indent=2))\n",
    "\n",
    "    # Perform web scraping using different browsers\n",
    "    for driver_name, driver_paths in filtered_driver_paths.items():\n",
    "        if driver_paths:\n",
    "            driver_path = driver_paths[0]  # Use the first available driver path\n",
    "\n",
    "            if \"chrome\" in driver_name.lower():\n",
    "                service = ChromeService(executable_path=driver_path)\n",
    "                driver = webdriver.Chrome(service=service)\n",
    "            elif \"firefox\" in driver_name.lower():\n",
    "                service = FirefoxService(executable_path=driver_path)\n",
    "                driver = webdriver.Firefox(service=service)\n",
    "            elif \"edge\" in driver_name.lower():\n",
    "                service = EdgeService(executable_path=driver_path)\n",
    "                driver = webdriver.Edge(service=service)\n",
    "            elif \"ie\" in driver_name.lower():\n",
    "                service = IEService(executable_path=driver_path)\n",
    "                driver = webdriver.Ie(service=service)\n",
    "            # elif \"opera\" in driver_name.lower():\n",
    "            #     service = OperaService(executable_path=driver_path)\n",
    "            #     driver = webdriver.Opera(service=service)\n",
    "            elif \"safari\" in driver_name.lower():\n",
    "                service = SafariService(executable_path=driver_path)\n",
    "                driver = webdriver.Safari(service=service)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                driver.get(f\"https://www.google.com/search?q={query}&location={location}&num={limit}\")\n",
    "                browser_scraped_data = []\n",
    "\n",
    "                search_results = driver.find_elements_by_css_selector(\".g\")\n",
    "                for result in search_results:\n",
    "                    title = result.find_element_by_css_selector(\".r a\").text\n",
    "                    url = result.find_element_by_css_selector(\".r a\").get_attribute(\"href\")\n",
    "                    description = result.find_element_by_css_selector(\".st\").text\n",
    "\n",
    "                    browser_scraped_data.append({\n",
    "                        \"title\": title,\n",
    "                        \"url\": url,\n",
    "                        \"description\": description\n",
    "                    })\n",
    "\n",
    "                browser_output_file = f\"{driver_name}_results.json\"\n",
    "                save_to_json(browser_scraped_data, browser_output_file)\n",
    "                print(f\"Search results from {driver_name} saved to {browser_output_file}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error occurred while scraping with {driver_name}: {str(e)}\")\n",
    "\n",
    "            finally:\n",
    "                driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import Dict, List\n",
    "import platform\n",
    "\n",
    "# Define browser executable names for different platforms\n",
    "BROWSER_EXECUTABLES = {\n",
    "    'Windows': ['chrome.exe', 'firefox.exe', 'iexplore.exe', 'MicrosoftEdge.exe', 'opera.exe'],\n",
    "    'Linux': ['chrome', 'firefox', 'opera'],\n",
    "    'Darwin': ['Google Chrome', 'Firefox', 'Safari', 'Opera']\n",
    "}\n",
    "\n",
    "\n",
    "def find_browsers(browser_executables: List[str], search_paths: List[str]) -> Dict[str, str]:\n",
    "    browsers_found = {}\n",
    "    for exec_name in browser_executables:\n",
    "        for search_path in search_paths:\n",
    "            for root, dirs, files in os.walk(search_path):\n",
    "                if exec_name in files:\n",
    "                    browsers_found[exec_name] = os.path.join(root, exec_name)\n",
    "    return browsers_found\n",
    "\n",
    "\n",
    "def get_os_type() -> str:\n",
    "    os_type = platform.system()\n",
    "    if os_type not in BROWSER_EXECUTABLES:\n",
    "        raise ValueError(f\"Unsupported operating system: {os_type}\")\n",
    "    return os_type\n",
    "\n",
    "\n",
    "def main():\n",
    "    os_type = get_os_type()\n",
    "    browser_exec_names = BROWSER_EXECUTABLES[os_type]\n",
    "\n",
    "    # Define the search paths based on OS\n",
    "    search_paths = {\n",
    "        'Windows': ['C:\\\\Program Files', 'C:\\\\Program Files (x86)', 'C:\\\\Users'],\n",
    "        'Linux': ['/usr/bin', '/opt'],\n",
    "        'Darwin': ['/Applications', '/Users']\n",
    "    }[os_type]\n",
    "\n",
    "    browsers = find_browsers(browser_exec_names, search_paths)\n",
    "\n",
    "    # Save to JSON\n",
    "    with open('browsers_paths.json', 'w') as json_file:\n",
    "        json.dump(browsers, json_file, indent=4)\n",
    "\n",
    "    print(f\"Browsers found: {len(browsers)}\")\n",
    "    for name, path in browsers.items():\n",
    "        print(f\"{name}: {path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "browser = webdriver.Firefox(keep_alive=True)\n",
    "browser.get('http://selenium.dev/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "browser = webdriver.Firefox()\n",
    "\n",
    "browser.get('http://www.yahoo.com')\n",
    "assert 'Yahoo' in browser.title\n",
    "\n",
    "elem = browser.find_element(By.NAME, 'p')  # Find the search box\n",
    "elem.send_keys('seleniumhq' + Keys.RETURN)\n",
    "\n",
    "browser.quit()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "# Initialize the Firefox webdriver\n",
    "browser = webdriver.Firefox()\n",
    "\n",
    "# Open Yahoo search engine\n",
    "browser.get('http://www.yahoo.com')\n",
    "assert 'Yahoo' in browser.title\n",
    "\n",
    "# Find the search box and enter the query\n",
    "search_box = browser.find_element(By.NAME, 'p')\n",
    "search_box.send_keys('seleniumhq' + Keys.RETURN)\n",
    "\n",
    "# Wait for the search results to load\n",
    "browser.implicitly_wait(10)  # Adjust the wait time as needed\n",
    "\n",
    "# Find all search result links\n",
    "search_results = browser.find_elements(By.XPATH, \"//a[@href]\")\n",
    "\n",
    "# Extract and print the URLs\n",
    "for result in search_results:\n",
    "    url = result.get_attribute(\"href\")\n",
    "    if url:\n",
    "        print(url)\n",
    "\n",
    "# Quit the browser\n",
    "browser.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "def tell_jokes(query):\n",
    "    # Initialize the Firefox webdriver\n",
    "    browser = webdriver.Firefox()\n",
    "\n",
    "    # Open a search engine (Yahoo in this case)\n",
    "    browser.get('http://www.yahoo.com')\n",
    "    assert 'Yahoo' in browser.title\n",
    "\n",
    "    # Find the search box and enter the user's query\n",
    "    search_box = browser.find_element(By.NAME, 'p')\n",
    "    search_box.send_keys(query + ' jokes' + Keys.RETURN)\n",
    "\n",
    "    # Wait for the search results to load\n",
    "    browser.implicitly_wait(10)  # Adjust the wait time as needed\n",
    "\n",
    "    # Find all search result links\n",
    "    search_results = browser.find_elements(By.XPATH, \"//a[@href]\")\n",
    "\n",
    "    # Extract and print the URLs\n",
    "    for result in search_results:\n",
    "        url = result.get_attribute(\"href\")\n",
    "        if url:\n",
    "            print(url)\n",
    "\n",
    "    # Quit the browser\n",
    "    browser.quit()\n",
    "\n",
    "# Ask the user for a joke category or keyword\n",
    "user_input = 'women'\n",
    "\n",
    "# Tell jokes based on the user's input\n",
    "tell_jokes(user_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def count_driver_paths(browser_name):\n",
    "    # Define the driver executable names for different browsers\n",
    "    driver_executables = {\n",
    "        'chrome': 'chromedriver',\n",
    "        'firefox': 'geckodriver',\n",
    "        'edge': 'msedgedriver',\n",
    "        # Add more browser-driver mappings as needed\n",
    "    }\n",
    "\n",
    "    # Get the PATH environment variable and split it into individual directories\n",
    "    path_list = os.environ['PATH'].split(os.pathsep)\n",
    "\n",
    "    # Initialize a counter for the number of driver paths found\n",
    "    count = 0\n",
    "\n",
    "    # Iterate through each directory in the PATH\n",
    "    for directory in path_list:\n",
    "        # Check if the driver executable exists for the specified browser\n",
    "        driver_executable = driver_executables.get(browser_name)\n",
    "        if driver_executable and os.path.exists(os.path.join(directory, driver_executable)):\n",
    "            count += 1\n",
    "\n",
    "    return count\n",
    "\n",
    "# Example usage:\n",
    "browser_name = 'chrome'  # Change this to 'firefox', 'edge', etc., as needed\n",
    "driver_count = count_driver_paths(browser_name)\n",
    "print(f\"Number of {browser_name} driver paths found: {driver_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "browser = webdriver.Firefox()\n",
    "\n",
    "browser.get('http://www.yahoo.com')\n",
    "assert 'Yahoo' in browser.title\n",
    "\n",
    "elem = browser.find_element(By.NAME, 'p')  # Find the search box\n",
    "elem.send_keys('seleniumhq' + Keys.RETURN)\n",
    "\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from typing import List, Dict\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "\n",
    "def search_locations(query: str, driver_path: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Searches for locations using the provided query and returns the response as a list of dictionaries.\n",
    "\n",
    "    :param query: The search query for locations.\n",
    "    :param driver_path: The path to the Firefox WebDriver executable.\n",
    "    :return: A list of dictionaries containing the search results.\n",
    "    \"\"\"\n",
    "    # Set up Firefox WebDriver options\n",
    "    options = Options()\n",
    "    options.headless = True  # Run Firefox in headless mode\n",
    "\n",
    "    # Set up Firefox WebDriver service\n",
    "    service = Service(executable_path=driver_path)\n",
    "\n",
    "    # Create a new instance of the Firefox driver\n",
    "    browser = webdriver.Firefox(service=service, options=options)\n",
    "\n",
    "    try:\n",
    "        # Navigate to Yahoo\n",
    "        browser.get('https://www.yahoo.com')\n",
    "        assert 'Yahoo' in browser.title\n",
    "\n",
    "        # Find the search box and enter the query\n",
    "        search_box = WebDriverWait(browser, 10).until(\n",
    "            EC.presence_of_element_located((By.NAME, 'p'))\n",
    "        )\n",
    "        search_box.send_keys(query + Keys.RETURN)\n",
    "\n",
    "        # Wait for the search results to load\n",
    "        time.sleep(5)\n",
    "\n",
    "        # Extract the search results\n",
    "        search_results = browser.find_elements(By.CSS_SELECTOR, 'div.result')\n",
    "\n",
    "        # Process the search results\n",
    "        results = []\n",
    "        for result in search_results:\n",
    "            title = result.find_element(By.CSS_SELECTOR, 'h3').text\n",
    "            url = result.find_element(By.CSS_SELECTOR, 'a').get_attribute('href')\n",
    "            results.append({'title': title, 'url': url})\n",
    "\n",
    "        return results\n",
    "\n",
    "    finally:\n",
    "        # Quit the browser\n",
    "        browser.quit()\n",
    "\n",
    "\n",
    "def save_to_json(data: List[Dict[str, str]], filename: str) -> None:\n",
    "    \"\"\"\n",
    "    Saves the provided data to a JSON file.\n",
    "\n",
    "    :param data: The data to be saved as JSON.\n",
    "    :param filename: The name of the JSON file.\n",
    "    \"\"\"\n",
    "    with open(filename, 'w') as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == '__main__':\n",
    "    query = 'restaurants in New York'\n",
    "    driver_path = '/path/to/geckodriver'  # Replace with the actual path to geckodriver\n",
    "\n",
    "    search_results = search_locations(query, driver_path)\n",
    "    save_to_json(search_results, 'search_results.json')\n",
    "\n",
    "    # Print the search results\n",
    "    for result in search_results:\n",
    "        print(f\"Title: {result['title']}\")\n",
    "        print(f\"URL: {result['url']}\")\n",
    "        print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q webdriver_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selenium 3\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "\n",
    "driver = webdriver.Firefox(executable_path=GeckoDriverManager().install())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "from typing import List, Dict\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "\n",
    "def search_locations(query: str, driver_path: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Searches for locations using the provided query and returns the response as a list of dictionaries.\n",
    "\n",
    "    :param query: The search query for locations.\n",
    "    :param driver_path: The path to the Firefox WebDriver executable.\n",
    "    :return: A list of dictionaries containing the search results.\n",
    "    \"\"\"\n",
    "    # Set up Firefox WebDriver options\n",
    "    options = Options()\n",
    "    options.headless = True  # Run Firefox in headless mode\n",
    "\n",
    "    # Set up Firefox WebDriver service\n",
    "    service = Service(executable_path=driver_path)\n",
    "\n",
    "    # Create a new instance of the Firefox driver\n",
    "    browser = webdriver.Firefox(service=service, options=options)\n",
    "\n",
    "    try:\n",
    "        # Navigate to Yahoo\n",
    "        browser.get('https://www.yahoo.com')\n",
    "        assert 'Yahoo' in browser.title\n",
    "\n",
    "        # Find the search box and enter the query\n",
    "        search_box = WebDriverWait(browser, 10).until(\n",
    "            EC.presence_of_element_located((By.NAME, 'p'))\n",
    "        )\n",
    "        search_box.send_keys(query + Keys.RETURN)\n",
    "\n",
    "        # Wait for the search results to load\n",
    "        WebDriverWait(browser, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, 'div#web'))\n",
    "        )\n",
    "\n",
    "        # Extract the search results\n",
    "        search_results = browser.find_elements(By.CSS_SELECTOR, 'div#web > ol > li')\n",
    "\n",
    "        # Process the search results\n",
    "        results = []\n",
    "        for result in search_results:\n",
    "            title = result.find_element(By.CSS_SELECTOR, 'h3').text\n",
    "            url = result.find_element(By.CSS_SELECTOR, 'a').get_attribute('href')\n",
    "            results.append({'title': title, 'url': url})\n",
    "\n",
    "        return results\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return []\n",
    "    finally:\n",
    "        # Quit the browser\n",
    "        browser.quit()\n",
    "\n",
    "\n",
    "def save_to_json(data: List[Dict[str, str]], filename: str) -> None:\n",
    "    \"\"\"\n",
    "    Saves the provided data to a JSON file.\n",
    "\n",
    "    :param data: The data to be saved as JSON.\n",
    "    :param filename: The name of the JSON file.\n",
    "    \"\"\"\n",
    "    with open(filename, 'w') as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == '__main__':\n",
    "    query = ' '.join(sys.argv[1:]) if len(sys.argv) > 1 else 'restaurants in New York'\n",
    "    driver_path = os.getenv('GECKO_DRIVER_PATH', '/path/to/geckodriver')  # Get the path from an environment variable\n",
    "\n",
    "    search_results = search_locations(query, driver_path)\n",
    "    save_to_json(search_results, 'search_results.json')\n",
    "\n",
    "    # Print the search results\n",
    "    for result in search_results:\n",
    "        print(f\"Title: {result['title']}\")\n",
    "        print(f\"URL: {result['url']}\")\n",
    "        print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "from selenium import webdriver\n",
    "\n",
    "class GoogleTestCase(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        self.browser = webdriver.Firefox()\n",
    "        self.addCleanup(self.browser.quit)\n",
    "\n",
    "    def test_page_title(self):\n",
    "        self.browser.get('http://www.google.com')\n",
    "        self.assertIn('Google', self.browser.title)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "from typing import List\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.firefox.firefox_binary import FirefoxBinary\n",
    "from selenium.common.exceptions import WebDriverException\n",
    "\n",
    "\n",
    "def search_locations(query: str, driver_path: str, firefox_binary_path: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Performs a search for locations based on the query provided using Selenium.\n",
    "\n",
    "    :param query: The search query for locations.\n",
    "    :param driver_path: The file path to the geckodriver executable.\n",
    "    :param firefox_binary_path: The file path to the Firefox binary.\n",
    "    :return: A list of location details.\n",
    "    \"\"\"\n",
    "    # Set up Firefox options\n",
    "    firefox_options = Options()\n",
    "    firefox_options.add_argument(\"--headless\")  # Run in headless mode\n",
    "    firefox_options.binary = FirefoxBinary(firefox_binary_path)\n",
    "\n",
    "    # Set up Firefox service\n",
    "    firefox_service = Service(executable_path=driver_path)\n",
    "\n",
    "    # Create a new Firefox driver instance\n",
    "    driver = webdriver.Firefox(service=firefox_service, options=firefox_options)\n",
    "\n",
    "    try:\n",
    "        # Navigate to the Google search page\n",
    "        driver.get(\"https://www.google.com/search\")\n",
    "\n",
    "        # Find the search input field and enter the query\n",
    "        search_input = driver.find_element(By.NAME, \"q\")\n",
    "        search_input.send_keys(query)\n",
    "        search_input.submit()\n",
    "\n",
    "        # Wait for the search results to load\n",
    "        time.sleep(5)\n",
    "\n",
    "        # Find all the location elements\n",
    "        location_elements = driver.find_elements(By.CLASS_NAME, \"rllt__details\")\n",
    "\n",
    "        # Extract the location details\n",
    "        locations = [element.text for element in location_elements]\n",
    "\n",
    "        return locations\n",
    "    except WebDriverException as e:\n",
    "        print(f\"An error occurred while searching for locations: {e}\")\n",
    "        return []\n",
    "    finally:\n",
    "        # Close the browser\n",
    "        driver.quit()\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Define the search query and paths\n",
    "    query ='jokes'\n",
    "    download_path = \"C:/Users/heman/Desktop/Deep learning/file_operations-/\" \n",
    "    firefox_binary_path ='C:/Users/heman/Desktop/Deep learning/file_operations-/geckodriver.exe'\n",
    "\n",
    "    # Check if geckodriver is already downloaded\n",
    "    driver_path = os.path.join(download_path, \"geckodriver.exe\")\n",
    "    if not os.path.exists(driver_path):\n",
    "        print(\"geckodriver is not found. Please download it manually and place it in the specified download path.\")\n",
    "        exit(1)\n",
    "\n",
    "    # Perform the search and retrieve the locations\n",
    "    results = search_locations(query, driver_path, firefox_binary_path)\n",
    "\n",
    "    # Save the results to a JSON file\n",
    "    with open(\"location_results.json\", \"w\") as file:\n",
    "        json.dump(results, file, indent=2)\n",
    "\n",
    "    # Print the location details\n",
    "    print(\"Location Details:\")\n",
    "    for location in results:\n",
    "        print(location)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "from typing import List\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.common.exceptions import WebDriverException\n",
    "# selenium 3\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "\n",
    "driver = webdriver.Firefox(executable_path=GeckoDriverManager().install())\n",
    "\n",
    "def search_locations(query: str, driver_path: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Performs a search for locations based on the query provided using Selenium.\n",
    "\n",
    "    :param query: The search query for locations.\n",
    "    :param driver_path: The file path to the geckodriver executable.\n",
    "    :return: A list of location details.\n",
    "    \"\"\"\n",
    "    # Set up Firefox options\n",
    "    firefox_options = Options()\n",
    "    firefox_options.add_argument(\"--headless\")  # Run in headless mode\n",
    "\n",
    "    # # Set up Firefox service\n",
    "    # firefox_service = Service(executable_path=driver_path)\n",
    "\n",
    "    # Create a new Firefox driver instance\n",
    "    driver = webdriver.Firefox(executable_path=GeckoDriverManager().install())\n",
    "\n",
    "    try:\n",
    "        # Navigate to the Google search page\n",
    "        driver.get(\"https://www.google.com/search\")\n",
    "\n",
    "        # Find the search input field and enter the query\n",
    "        search_input = driver.find_element(By.NAME, \"q\")\n",
    "        search_input.send_keys(query)\n",
    "        search_input.submit()\n",
    "\n",
    "        # Wait for the search results to load\n",
    "        time.sleep(5)\n",
    "\n",
    "        # Find all the location elements\n",
    "        location_elements = driver.find_elements(By.CLASS_NAME, \"rllt__details\")\n",
    "\n",
    "        # Extract the location details\n",
    "        locations = [element.text for element in location_elements]\n",
    "\n",
    "        return locations\n",
    "    except WebDriverException as e:\n",
    "        print(f\"An error occurred while searching for locations: {e}\")\n",
    "        return []\n",
    "    finally:\n",
    "        # Close the browser\n",
    "        driver.quit()\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Define the search query and paths\n",
    "    query = 'jokes'\n",
    "    # download_path = \"C:/Users/heman/Desktop/Deep learning/file_operations-/\"\n",
    "\n",
    "    # # Check if geckodriver is already downloaded\n",
    "    # driver_path = os.path.join(download_path, \"geckodriver.exe\")\n",
    "    # if not os.path.exists(driver_path):\n",
    "    #     print(\"geckodriver is not found. Please download it manually and place it in the specified download path.\")\n",
    "    #     exit(1)\n",
    "\n",
    "    # Perform the search and retrieve the locations\n",
    "    results = search_locations(query, driver_path)\n",
    "\n",
    "    # Save the results to a JSON file\n",
    "    with open(\"location_results.json\", \"w\") as file:\n",
    "        json.dump(results, file, indent=2)\n",
    "\n",
    "    # Print the location details\n",
    "    print(\"Location Details:\")\n",
    "    for location in results:\n",
    "        print(location)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import os\n",
    "import stat\n",
    "import time\n",
    "from typing import List\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.firefox.firefox_profile import FirefoxProfile\n",
    "import requests\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "\n",
    "\n",
    "\n",
    "def search_locations(query: str, driver_path: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Perform an advanced search for locations using Selenium.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search query for locations.\n",
    "        driver_path (str): The path to the Firefox driver executable.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: A list of location details.\n",
    "    \"\"\"\n",
    "    # Set up Firefox options\n",
    "    firefox_options = Options()\n",
    "    firefox_options.add_argument(\"--headless\")  # Run in headless mode\n",
    "\n",
    "    # Set up Firefox profile\n",
    "    firefox_profile = FirefoxProfile()\n",
    "\n",
    "    # Set up Firefox service\n",
    "    firefox_service = Service(executable_path=driver_path)\n",
    "\n",
    "    # Create a new Firefox driver instance\n",
    "    driver = webdriver.Firefox(service=firefox_service, options=firefox_options, firefox_profile=firefox_profile)\n",
    "\n",
    "    try:\n",
    "        # Navigate to the search page\n",
    "        driver.get(\"https://www.google.com/search\")\n",
    "\n",
    "        # Find the search input field and enter the query\n",
    "        search_input = driver.find_element(By.NAME, \"q\")\n",
    "        search_input.send_keys(query)\n",
    "        search_input.submit()\n",
    "\n",
    "        # Wait for the search results to load\n",
    "        time.sleep(30)\n",
    "\n",
    "        # Find all the location elements\n",
    "        location_elements = driver.find_elements(By.CLASS_NAME, \"rllt__details\")\n",
    "\n",
    "        # Extract the location details\n",
    "        locations = []\n",
    "        for element in location_elements:\n",
    "            location_details = element.text\n",
    "            locations.append(location_details)\n",
    "\n",
    "        return locations\n",
    "\n",
    "    finally:\n",
    "        # Close the browser\n",
    "        driver.quit()\n",
    "\n",
    "# Example usage\n",
    "query = \"Restaurants in New York\"\n",
    "download_path = \"C:/Users/heman/Desktop/Deep learning/file_operations-/\"  # Replace with the desired download path\n",
    "\n",
    "# Download geckodriver if it doesn't exist\n",
    "driver_path = os.path.join(download_path, \"geckodriver.exe\")\n",
    "if not os.path.exists(driver_path):\n",
    "    driver_path = download_geckodriver(download_path)\n",
    "    if driver_path is None:\n",
    "        print(\"Failed to download geckodriver. Exiting.\")\n",
    "        exit(1)\n",
    "else:\n",
    "    print(\"geckodriver is already downloaded.\")\n",
    "\n",
    "results = search_locations(query, driver_path)\n",
    "\n",
    "# Save the results to a JSON file\n",
    "with open(\"location_results.json\", \"w\") as file:\n",
    "    json.dump(results, file, indent=2)\n",
    "\n",
    "# Print the location details\n",
    "print(\"Location Details:\")\n",
    "for location in results:\n",
    "    print(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import stat\n",
    "import time\n",
    "from typing import List\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "import requests\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "\n",
    "def download_geckodriver(download_path: str):\n",
    "    # ... (download_geckodriver function code remains the same)\n",
    "\n",
    "def search_locations(query: str, driver_path: str, firefox_binary_path: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Perform an advanced search for locations using Selenium.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search query for locations.\n",
    "        driver_path (str): The path to the Firefox driver executable.\n",
    "        firefox_binary_path (str): The path to the Firefox binary executable.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: A list of location details.\n",
    "    \"\"\"\n",
    "    # Set up Firefox options\n",
    "    firefox_options = Options()\n",
    "    firefox_options.binary_location = firefox_binary_path\n",
    "    firefox_options.add_argument(\"--headless\")  # Run in headless mode\n",
    "\n",
    "    # Set up Firefox service\n",
    "    firefox_service = Service(executable_path=driver_path)\n",
    "\n",
    "    # Create a new Firefox driver instance\n",
    "    driver = webdriver.Firefox(service=firefox_service, options=firefox_options)\n",
    "\n",
    "    try:\n",
    "        # Navigate to the search page\n",
    "        driver.get(\"https://www.google.com/search\")\n",
    "\n",
    "        # Find the search input field and enter the query\n",
    "        search_input = driver.find_element(By.NAME, \"q\")\n",
    "        search_input.send_keys(query)\n",
    "        search_input.submit()\n",
    "\n",
    "        # Wait for the search results to load\n",
    "        time.sleep(5)\n",
    "\n",
    "        # Find all the location elements\n",
    "        location_elements = driver.find_elements(By.CLASS_NAME, \"rllt__details\")\n",
    "\n",
    "        # Extract the location details\n",
    "        locations = []\n",
    "        for element in location_elements:\n",
    "            location_details = element.text\n",
    "            locations.append(location_details)\n",
    "\n",
    "        return locations\n",
    "\n",
    "    finally:\n",
    "        # Close the browser\n",
    "        driver.quit()\n",
    "\n",
    "# Example usage\n",
    "query = \"Restaurants in New York\"\n",
    "download_path = \"C:/Users/heman/Desktop/Deep learning/file_operations-/\"  # Replace with the desired download path\n",
    "firefox_binary_path = \"C:/Program Files/Mozilla Firefox/firefox.exe\"  # Replace with the path to your Firefox binary\n",
    "\n",
    "# Download geckodriver if it doesn't exist\n",
    "driver_path = os.path.join(download_path, \"geckodriver.exe\")\n",
    "if not os.path.exists(driver_path):\n",
    "    driver_path = download_geckodriver(download_path)\n",
    "    if driver_path is None:\n",
    "        print(\"Failed to download geckodriver. Exiting.\")\n",
    "        exit(1)\n",
    "else:\n",
    "    print(\"geckodriver is already downloaded.\")\n",
    "\n",
    "results = search_locations(query, driver_path, firefox_binary_path)\n",
    "\n",
    "# Save the results to a JSON file\n",
    "with open(\"location_results.json\", \"w\") as file:\n",
    "    json.dump(results, file, indent=2)\n",
    "\n",
    "# Print the location details\n",
    "print(\"Location Details:\")\n",
    "for location in results:\n",
    "    print(location)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
